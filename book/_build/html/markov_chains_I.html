

<!DOCTYPE html>


<html lang="en" data-content_root="" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>33. Markov Chains: Basic Concepts &#8212; My Jupyter Book</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="_static/styles/sphinx-book-theme.css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/code.css" />
    <link rel="stylesheet" type="text/css" href="_static/image_dark_mode.css" />
    <link rel="stylesheet" type="text/css" href="_static/exercise.css" />
    <link rel="stylesheet" type="text/css" href="_static/proof.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-design.5ea377869091fd0449014c60fc090103.min.css" />
    <link rel="stylesheet" type="text/css" href="_static/fix_admonition_style.css" />
    <link rel="stylesheet" type="text/css" href="_static/fix_dropdown_style.css" />
    <link rel="stylesheet" type="text/css" href="_static/fix_code_header_style.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/sphinx_highlight.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script src="_static/scripts/sphinx-book-theme.js"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js"></script>
    <script async="async" src="https://www.googletagmanager.com/gtag/js?id=G-KZLV7PM9LL"></script>
    <script>
                window.dataLayer = window.dataLayer || [];
                function gtag(){ dataLayer.push(arguments); }
                gtag('js', new Date());
                gtag('config', 'G-KZLV7PM9LL');
            </script>
    <script defer="defer" src="_static/refresh.js"></script>
    <script>const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script defer="defer" src="_static/sphinx-thebe-lite.js"></script>
    <script>window.MathJax = {"chtml": {"mtextInheritFont": true}, "options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'markov_chains_I';</script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <link rel="canonical" href="https://quantecon.org/markov_chains_I.html" />
    <link rel="shortcut icon" href="_static/favicon.ico"/>
    <link rel="author" title="About these documents" href="about.html" />
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="34. Markov Chains: Irreducibility and Ergodicity" href="markov_chains_II.html" />
    <link rel="prev" title="32. AR(1) Processes" href="ar1_processes.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
    <meta name="docbuild:last-update" content="February 1, 2025"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search..."
         aria-label="Search..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="_static/qe-logo.png" class="logo__image only-light" alt=""/>
    <script>document.write(`<img src="_static/qe-logo.png" class="logo__image only-dark" alt=""/>`);</script>
  
  
    <p class="title logo__title">QuantEcon Intro Lectures</p>
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Introduction</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="about.html">1. About These Lectures</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Economic Data</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="long_run_growth.html">2. Long-Run Growth</a></li>
<li class="toctree-l1"><a class="reference internal" href="business_cycle.html">3. Business Cycles</a></li>
<li class="toctree-l1"><a class="reference internal" href="inflation_history.html">4. Price Level Histories</a></li>
<li class="toctree-l1"><a class="reference internal" href="french_rev.html">5. Inflation During French Revolution</a></li>
<li class="toctree-l1"><a class="reference internal" href="inequality.html">6. Income and Wealth Inequality</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Foundations</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="intro_supply_demand.html">7. Introduction to Supply and Demand</a></li>
<li class="toctree-l1"><a class="reference internal" href="linear_equations.html">8. Linear Equations and Matrix Algebra</a></li>
<li class="toctree-l1"><a class="reference internal" href="complex_and_trig.html">9. Complex Numbers and Trigonometry</a></li>
<li class="toctree-l1"><a class="reference internal" href="geom_series.html">10. Geometric Series for Elementary Economics</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Linear Dynamics: Finite Horizons</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="pv.html">11. Present Values</a></li>
<li class="toctree-l1"><a class="reference internal" href="cons_smooth.html">12. Consumption Smoothing</a></li>
<li class="toctree-l1"><a class="reference internal" href="equalizing_difference.html">13. Equalizing Difference Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="cagan_ree.html">14. A Monetarist Theory of Price Levels</a></li>
<li class="toctree-l1"><a class="reference internal" href="cagan_adaptive.html">15. Monetarist Theory of Price Levels with Adaptive Expectations</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Linear Dynamics: Infinite Horizons</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="eigen_I.html">16. Eigenvalues and Eigenvectors</a></li>
<li class="toctree-l1"><a class="reference internal" href="greek_square.html">17. Computing Square Roots</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Probability and Distributions</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="prob_dist.html">18. Distributions and Probabilities</a></li>
<li class="toctree-l1"><a class="reference internal" href="lln_clt.html">19. LLN and CLT</a></li>
<li class="toctree-l1"><a class="reference internal" href="monte_carlo.html">20. Monte Carlo and Option Pricing</a></li>
<li class="toctree-l1"><a class="reference internal" href="heavy_tails.html">21. Heavy-Tailed Distributions</a></li>
<li class="toctree-l1"><a class="reference internal" href="schelling.html">22. Racial Segregation</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Nonlinear Dynamics</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="scalar_dynam.html">23. Dynamics in One Dimension</a></li>
<li class="toctree-l1"><a class="reference internal" href="solow.html">24. The Solow-Swan Growth Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="cobweb.html">25. The Cobweb Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="olg.html">26. The Overlapping Generations Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="commod_price.html">27. Commodity Prices</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Monetary-Fiscal Policy Interactions</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="money_inflation.html">28. Money Financed Government Deficits and Price Levels</a></li>
<li class="toctree-l1"><a class="reference internal" href="unpleasant.html">29. Some Unpleasant Monetarist Arithmetic</a></li>
<li class="toctree-l1"><a class="reference internal" href="money_inflation_nonlinear.html">30. Inflation Rate Laffer Curves</a></li>
<li class="toctree-l1"><a class="reference internal" href="laffer_adaptive.html">31. Laffer Curves  with Adaptive Expectations</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Stochastic Dynamics</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="ar1_processes.html">32. AR(1) Processes</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">33. Markov Chains: Basic Concepts</a></li>
<li class="toctree-l1"><a class="reference internal" href="markov_chains_II.html">34. Markov Chains: Irreducibility and Ergodicity</a></li>
<li class="toctree-l1"><a class="reference internal" href="time_series_with_matrices.html">35. Univariate Time Series with Matrix Algebra</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Optimization</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="lp_intro.html">36. Linear Programming</a></li>
<li class="toctree-l1"><a class="reference internal" href="short_path.html">37. Shortest Paths</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Modeling in Higher Dimensions</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="eigen_II.html">38. The Perron-Frobenius Theorem</a></li>
<li class="toctree-l1"><a class="reference internal" href="input_output.html">39. Input-Output Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="lake_model.html">40. A Lake Model of Employment</a></li>
<li class="toctree-l1"><a class="reference internal" href="networks.html">41. Networks</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Markets and Competitive Equilibrium</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="supply_demand_multiple_goods.html">42. Supply and Demand with Many Goods</a></li>
<li class="toctree-l1"><a class="reference internal" href="supply_demand_heterogeneity.html">43. Market Equilibrium with Heterogeneity</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Estimation</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="simple_linear_regression.html">44. Simple Linear Regression Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="mle.html">45. Maximum Likelihood Estimation</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Other</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="troubleshooting.html">46. Troubleshooting</a></li>
<li class="toctree-l1"><a class="reference internal" href="zreferences.html">47. References</a></li>
<li class="toctree-l1"><a class="reference internal" href="status.html">48. Execution Statistics</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-launch-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Launch interactive content">
    <i class="fas fa-rocket"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li>
<button onclick="initThebeSBT()"
  class="btn btn-sm btn-launch-thebe dropdown-item"
  title="Launch Thebe"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-play"></i>
  </span>
<span class="btn__text-container">Live Code</span>
</button>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/markov_chains_I.ipynb" target="_blank"
   class="btn btn-sm btn-download-notebook-button dropdown-item"
   title="Download notebook file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-code"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li><a href="_sources/markov_chains_I.md" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.md</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Markov Chains: Basic Concepts</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#overview">33.1. Overview</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#definitions-and-examples">33.2. Definitions and examples</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#stochastic-matrices">33.2.1. Stochastic matrices</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#markov-chains">33.2.2. Markov chains</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#example-1">33.2.2.1. Example 1</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#example-2">33.2.2.2. Example 2</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#example-3">33.2.2.3. Example 3</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#defining-markov-chains">33.2.3. Defining Markov chains</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#simulation">33.3. Simulation</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#writing-our-own-simulation-code">33.3.1. Writing our own simulation code</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#using-quantecon-s-routines">33.3.2. Using QuantEcon’s routines</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#adding-state-values-and-initial-conditions">33.3.2.1. Adding state values and initial conditions</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#distributions-over-time">33.4. Distributions over time</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#multiple-step-transition-probabilities">33.4.1. Multiple step transition probabilities</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#example-probability-of-recession">33.4.2. Example: probability of recession</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#example-2-cross-sectional-distributions">33.4.3. Example 2: cross-sectional distributions</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#stationary-distributions">33.5. Stationary distributions</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#example">33.5.1. Example</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#calculating-stationary-distributions">33.5.2. Calculating stationary distributions</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#asymptotic-stationarity">33.5.3. Asymptotic stationarity</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#example-hamilton-s-chain">33.5.3.1. Example: Hamilton’s chain</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#example-failure-of-convergence">33.5.3.2. Example: failure of convergence</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#computing-expectations">33.6. Computing expectations</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#expectations-of-geometric-sums">33.6.1. Expectations of geometric sums</a></li>
</ul>
</li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="markov-chains-basic-concepts">
<h1><span class="section-number">33. </span>Markov Chains: Basic Concepts<a class="headerlink" href="#markov-chains-basic-concepts" title="Permalink to this heading">#</a></h1>
<p id="index-0">In addition to what’s in Anaconda, this lecture will need the following libraries:</p>
<div class="cell tag_hide-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="n">pip</span> <span class="n">install</span> <span class="n">quantecon</span>
</pre></div>
</div>
</div>
</div>
<section id="overview">
<h2><span class="section-number">33.1. </span>Overview<a class="headerlink" href="#overview" title="Permalink to this heading">#</a></h2>
<p>Markov chains provide  a way to model situations in which  the past casts shadows on the future.</p>
<p>By this we mean that observing measurements about a present situation can help us forecast future situations.</p>
<p>This can be possible when there are statistical dependencies among measurements of something taken at different points of time.</p>
<p>For example,</p>
<ul class="simple">
<li><p>inflation next year might co-vary  with inflation this year</p></li>
<li><p>unemployment next month might co-vary with unemployment this month</p></li>
</ul>
<p>Markov chains are a workhorse for economics and finance.</p>
<p>The theory of Markov chains is beautiful and provides many insights into
probability and dynamics.</p>
<p>In this  lecture, we will</p>
<ul class="simple">
<li><p>review some of the key ideas from the theory of Markov chains and</p></li>
<li><p>show how Markov chains appear in some economic applications.</p></li>
</ul>
<p>Let’s start with some standard imports:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">quantecon</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">qe</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">networkx</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">nx</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">matplotlib</span><span class="w"> </span><span class="kn">import</span> <span class="n">cm</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">mpl</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">mpl_toolkits.mplot3d</span><span class="w"> </span><span class="kn">import</span> <span class="n">Axes3D</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">matplotlib.animation</span><span class="w"> </span><span class="kn">import</span> <span class="n">FuncAnimation</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">IPython.display</span><span class="w"> </span><span class="kn">import</span> <span class="n">HTML</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">matplotlib.patches</span><span class="w"> </span><span class="kn">import</span> <span class="n">Polygon</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">mpl_toolkits.mplot3d.art3d</span><span class="w"> </span><span class="kn">import</span> <span class="n">Poly3DCollection</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="definitions-and-examples">
<h2><span class="section-number">33.2. </span>Definitions and examples<a class="headerlink" href="#definitions-and-examples" title="Permalink to this heading">#</a></h2>
<p>In this section we provide some definitions and  elementary examples.</p>
<section id="stochastic-matrices">
<span id="finite-dp-stoch-mat"></span><h3><span class="section-number">33.2.1. </span>Stochastic matrices<a class="headerlink" href="#stochastic-matrices" title="Permalink to this heading">#</a></h3>
<p>Recall that a <strong>probability mass function</strong> over <span class="math notranslate nohighlight">\(n\)</span> possible outcomes is a
nonnegative <span class="math notranslate nohighlight">\(n\)</span>-vector <span class="math notranslate nohighlight">\(p\)</span> that sums to one.</p>
<p>For example, <span class="math notranslate nohighlight">\(p = (0.2, 0.2, 0.6)\)</span> is a probability mass function over <span class="math notranslate nohighlight">\(3\)</span> outcomes.</p>
<p>A <strong>stochastic matrix</strong> (or <strong>Markov matrix</strong>)  is an <span class="math notranslate nohighlight">\(n \times n\)</span> square matrix <span class="math notranslate nohighlight">\(P\)</span>
such that each row of <span class="math notranslate nohighlight">\(P\)</span> is a probability mass function over <span class="math notranslate nohighlight">\(n\)</span> outcomes.</p>
<p>In other words,</p>
<ol class="arabic simple">
<li><p>each element of <span class="math notranslate nohighlight">\(P\)</span> is nonnegative, and</p></li>
<li><p>each row of <span class="math notranslate nohighlight">\(P\)</span> sums to one</p></li>
</ol>
<p>If <span class="math notranslate nohighlight">\(P\)</span> is a stochastic matrix, then so is the <span class="math notranslate nohighlight">\(k\)</span>-th power <span class="math notranslate nohighlight">\(P^k\)</span> for all <span class="math notranslate nohighlight">\(k \in \mathbb N\)</span>.</p>
<p>You are asked to check this in <a class="reference internal" href="#mc1_ex_3"><span class="std std-ref">an exercise</span></a> below.</p>
</section>
<section id="markov-chains">
<h3><span class="section-number">33.2.2. </span>Markov chains<a class="headerlink" href="#markov-chains" title="Permalink to this heading">#</a></h3>
<p>Now we can introduce Markov chains.</p>
<p>Before defining a Markov chain rigorously, we’ll  give some examples.</p>
<section id="example-1">
<span id="mc-eg2"></span><h4><span class="section-number">33.2.2.1. </span>Example 1<a class="headerlink" href="#example-1" title="Permalink to this heading">#</a></h4>
<p>From  US unemployment data, Hamilton <span id="id1">[]</span> estimated the following dynamics.</p>
<img alt="_images/Hamilton.png" class="align-center" id="mc-hamilton" src="_images/Hamilton.png" />
<p>Here there are three <strong>states</strong></p>
<ul class="simple">
<li><p>“ng” represents normal growth</p></li>
<li><p>“mr” represents mild recession</p></li>
<li><p>“sr” represents severe recession</p></li>
</ul>
<p>The arrows represent transition probabilities over one month.</p>
<p>For example, the arrow from mild recession to normal growth has 0.145 next to it.</p>
<p>This tells us that, according to past data, there is a 14.5% probability of transitioning from mild recession to normal growth in one month.</p>
<p>The arrow from normal growth back to normal growth tells us that there is a
97% probability of transitioning from normal growth to normal growth (staying
in the same state).</p>
<p>Note that these are conditional probabilities — the probability of
transitioning from one state to another (or staying at the same one) conditional on the
current state.</p>
<p>To make the problem easier to work with numerically, let’s convert states to
numbers.</p>
<p>In particular, we agree that</p>
<ul class="simple">
<li><p>state 0 represents normal growth</p></li>
<li><p>state 1 represents mild recession</p></li>
<li><p>state 2 represents severe recession</p></li>
</ul>
<p>Let <span class="math notranslate nohighlight">\(X_t\)</span> record the value of the state at time <span class="math notranslate nohighlight">\(t\)</span>.</p>
<p>Now we can write the statement “there is a 14.5% probability of transitioning from mild recession to normal growth in one month” as</p>
<div class="math notranslate nohighlight">
\[
    \mathbb P\{X_{t+1} = 0 \,|\, X_t = 1\} = 0.145
\]</div>
<p>We can collect all of these conditional probabilities into a matrix, as follows</p>
<div class="math notranslate nohighlight">
\[\begin{split}
P =
\begin{bmatrix}
0.971 &amp; 0.029 &amp; 0 \\
0.145 &amp; 0.778 &amp; 0.077 \\
0 &amp; 0.508 &amp; 0.492
\end{bmatrix}
\end{split}\]</div>
<p>Notice that <span class="math notranslate nohighlight">\(P\)</span> is a stochastic matrix.</p>
<p>Now we have the following relationship</p>
<div class="math notranslate nohighlight">
\[
    P(i,j)
    = \mathbb P\{X_{t+1} = j \,|\, X_t = i\}
\]</div>
<p>This holds for any <span class="math notranslate nohighlight">\(i,j\)</span> between 0 and 2.</p>
<p>In particular, <span class="math notranslate nohighlight">\(P(i,j)\)</span> is the
probability of transitioning from state <span class="math notranslate nohighlight">\(i\)</span> to state <span class="math notranslate nohighlight">\(j\)</span> in one month.</p>
</section>
<section id="example-2">
<span id="mc-eg1"></span><h4><span class="section-number">33.2.2.2. </span>Example 2<a class="headerlink" href="#example-2" title="Permalink to this heading">#</a></h4>
<p>Consider a worker who, at any given time <span class="math notranslate nohighlight">\(t\)</span>, is either unemployed (state 0)
or employed (state 1).</p>
<p>Suppose that, over a one-month period,</p>
<ol class="arabic simple">
<li><p>the unemployed worker finds a job with probability <span class="math notranslate nohighlight">\(\alpha \in (0, 1)\)</span>.</p></li>
<li><p>the employed worker loses her job and becomes unemployed with probability <span class="math notranslate nohighlight">\(\beta \in (0, 1)\)</span>.</p></li>
</ol>
<p>Given the above information, we can write out the transition probabilities in matrix form as</p>
<div class="math notranslate nohighlight" id="equation-p-unempemp">
<span class="eqno">(33.1)<a class="headerlink" href="#equation-p-unempemp" title="Permalink to this equation">#</a></span>\[\begin{split}P =
\begin{bmatrix}
    1 - \alpha &amp; \alpha \\
    \beta &amp; 1 - \beta
\end{bmatrix}\end{split}\]</div>
<p>For example,</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
    P(0,1)
        &amp; =
        \text{ probability of transitioning from state $0$ to state $1$ in one month}
        \\
        &amp; =
        \text{ probability finding a job next month}
        \\
        &amp; = \alpha
\end{aligned}
\end{split}\]</div>
<p>Suppose we can estimate the values <span class="math notranslate nohighlight">\(\alpha\)</span> and <span class="math notranslate nohighlight">\(\beta\)</span>.</p>
<p>Then we can address a range of questions, such as</p>
<ul class="simple">
<li><p>What is the average duration of unemployment?</p></li>
<li><p>Over the long-run, what fraction of the time does a worker find herself unemployed?</p></li>
<li><p>Conditional on employment, what is the probability of becoming unemployed at least once over the next 12 months?</p></li>
</ul>
<p>We’ll cover some of these applications below.</p>
</section>
<section id="example-3">
<span id="mc-eg3"></span><h4><span class="section-number">33.2.2.3. </span>Example 3<a class="headerlink" href="#example-3" title="Permalink to this heading">#</a></h4>
<p>Imam and Temple <span id="id2">[]</span> categorize political institutions into
three types: democracy <span class="math notranslate nohighlight">\(\text{(D)}\)</span>, autocracy <span class="math notranslate nohighlight">\(\text{(A)}\)</span>, and an intermediate
state called anocracy <span class="math notranslate nohighlight">\(\text{(N)}\)</span>.</p>
<p>Each institution can have two potential development regimes: collapse <span class="math notranslate nohighlight">\(\text{(C)}\)</span> and growth <span class="math notranslate nohighlight">\(\text{(G)}\)</span>. This results in six possible states: <span class="math notranslate nohighlight">\(\text{DG, DC, NG, NC, AG}\)</span> and <span class="math notranslate nohighlight">\(\text{AC}\)</span>.</p>
<p>Imam and Temple <span id="id3">[]</span> estimate the following transition
probabilities:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
P :=
\begin{bmatrix}
0.86 &amp; 0.11 &amp; 0.03 &amp; 0.00 &amp; 0.00 &amp; 0.00 \\
0.52 &amp; 0.33 &amp; 0.13 &amp; 0.02 &amp; 0.00 &amp; 0.00 \\
0.12 &amp; 0.03 &amp; 0.70 &amp; 0.11 &amp; 0.03 &amp; 0.01 \\
0.13 &amp; 0.02 &amp; 0.35 &amp; 0.36 &amp; 0.10 &amp; 0.04 \\
0.00 &amp; 0.00 &amp; 0.09 &amp; 0.11 &amp; 0.55 &amp; 0.25 \\
0.00 &amp; 0.00 &amp; 0.09 &amp; 0.15 &amp; 0.26 &amp; 0.50
\end{bmatrix}
\end{split}\]</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">nodes</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;DG&#39;</span><span class="p">,</span> <span class="s1">&#39;DC&#39;</span><span class="p">,</span> <span class="s1">&#39;NG&#39;</span><span class="p">,</span> <span class="s1">&#39;NC&#39;</span><span class="p">,</span> <span class="s1">&#39;AG&#39;</span><span class="p">,</span> <span class="s1">&#39;AC&#39;</span><span class="p">]</span>
<span class="n">P</span> <span class="o">=</span> <span class="p">[[</span><span class="mf">0.86</span><span class="p">,</span> <span class="mf">0.11</span><span class="p">,</span> <span class="mf">0.03</span><span class="p">,</span> <span class="mf">0.00</span><span class="p">,</span> <span class="mf">0.00</span><span class="p">,</span> <span class="mf">0.00</span><span class="p">],</span>
     <span class="p">[</span><span class="mf">0.52</span><span class="p">,</span> <span class="mf">0.33</span><span class="p">,</span> <span class="mf">0.13</span><span class="p">,</span> <span class="mf">0.02</span><span class="p">,</span> <span class="mf">0.00</span><span class="p">,</span> <span class="mf">0.00</span><span class="p">],</span>
     <span class="p">[</span><span class="mf">0.12</span><span class="p">,</span> <span class="mf">0.03</span><span class="p">,</span> <span class="mf">0.70</span><span class="p">,</span> <span class="mf">0.11</span><span class="p">,</span> <span class="mf">0.03</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">],</span>
     <span class="p">[</span><span class="mf">0.13</span><span class="p">,</span> <span class="mf">0.02</span><span class="p">,</span> <span class="mf">0.35</span><span class="p">,</span> <span class="mf">0.36</span><span class="p">,</span> <span class="mf">0.10</span><span class="p">,</span> <span class="mf">0.04</span><span class="p">],</span>
     <span class="p">[</span><span class="mf">0.00</span><span class="p">,</span> <span class="mf">0.00</span><span class="p">,</span> <span class="mf">0.09</span><span class="p">,</span> <span class="mf">0.11</span><span class="p">,</span> <span class="mf">0.55</span><span class="p">,</span> <span class="mf">0.25</span><span class="p">],</span>
     <span class="p">[</span><span class="mf">0.00</span><span class="p">,</span> <span class="mf">0.00</span><span class="p">,</span> <span class="mf">0.09</span><span class="p">,</span> <span class="mf">0.15</span><span class="p">,</span> <span class="mf">0.26</span><span class="p">,</span> <span class="mf">0.50</span><span class="p">]]</span>
</pre></div>
</div>
</div>
</div>
<p>Here is a visualization, with darker colors indicating higher probability.</p>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">G</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">MultiDiGraph</span><span class="p">()</span>

<span class="k">for</span> <span class="n">start_idx</span><span class="p">,</span> <span class="n">node_start</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">nodes</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">end_idx</span><span class="p">,</span> <span class="n">node_end</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">nodes</span><span class="p">):</span>
        <span class="n">value</span> <span class="o">=</span> <span class="n">P</span><span class="p">[</span><span class="n">start_idx</span><span class="p">][</span><span class="n">end_idx</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">value</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">G</span><span class="o">.</span><span class="n">add_edge</span><span class="p">(</span><span class="n">node_start</span><span class="p">,</span><span class="n">node_end</span><span class="p">,</span> <span class="n">weight</span><span class="o">=</span><span class="n">value</span><span class="p">)</span>

<span class="n">pos</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">spring_layout</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">nx</span><span class="o">.</span><span class="n">draw_networkx_nodes</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> <span class="n">pos</span><span class="p">,</span> <span class="n">node_size</span><span class="o">=</span><span class="mi">600</span><span class="p">,</span> <span class="n">edgecolors</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">,</span> <span class="n">node_color</span><span class="o">=</span><span class="s1">&#39;white&#39;</span><span class="p">)</span>
<span class="n">nx</span><span class="o">.</span><span class="n">draw_networkx_labels</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> <span class="n">pos</span><span class="p">)</span>

<span class="n">arc_rad</span> <span class="o">=</span> <span class="mf">0.2</span>

<span class="n">edges</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">draw_networkx_edges</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> <span class="n">pos</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span> <span class="n">connectionstyle</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;arc3, rad = </span><span class="si">{</span><span class="n">arc_rad</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">edge_cmap</span><span class="o">=</span><span class="n">cm</span><span class="o">.</span><span class="n">Blues</span><span class="p">,</span> <span class="n">width</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
    <span class="n">edge_color</span><span class="o">=</span><span class="p">[</span><span class="n">G</span><span class="p">[</span><span class="n">nodes</span><span class="p">[</span><span class="mi">0</span><span class="p">]][</span><span class="n">nodes</span><span class="p">[</span><span class="mi">1</span><span class="p">]][</span><span class="mi">0</span><span class="p">][</span><span class="s1">&#39;weight&#39;</span><span class="p">]</span> <span class="k">for</span> <span class="n">nodes</span> <span class="ow">in</span> <span class="n">G</span><span class="o">.</span><span class="n">edges</span><span class="p">])</span>

<span class="n">pc</span> <span class="o">=</span> <span class="n">mpl</span><span class="o">.</span><span class="n">collections</span><span class="o">.</span><span class="n">PatchCollection</span><span class="p">(</span><span class="n">edges</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cm</span><span class="o">.</span><span class="n">Blues</span><span class="p">)</span>

<span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_axis_off</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">colorbar</span><span class="p">(</span><span class="n">pc</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</details>
</div>
<p>Looking at the data, we see that democracies tend to have longer-lasting growth
regimes compared to autocracies (as indicated by the lower probability of
transitioning from growth to growth in autocracies).</p>
<p>We can also find a higher probability from collapse to growth in democratic regimes.</p>
</section>
</section>
<section id="defining-markov-chains">
<h3><span class="section-number">33.2.3. </span>Defining Markov chains<a class="headerlink" href="#defining-markov-chains" title="Permalink to this heading">#</a></h3>
<p>So far we’ve given examples of Markov chains but we haven’t defined them.</p>
<p>Let’s do that now.</p>
<p>To begin, let <span class="math notranslate nohighlight">\(S\)</span> be a finite set <span class="math notranslate nohighlight">\(\{x_1, \ldots, x_n\}\)</span> with <span class="math notranslate nohighlight">\(n\)</span> elements.</p>
<p>The set <span class="math notranslate nohighlight">\(S\)</span> is called the <strong>state space</strong> and <span class="math notranslate nohighlight">\(x_1, \ldots, x_n\)</span> are the <strong>state values</strong>.</p>
<p>A <strong>distribution</strong> <span class="math notranslate nohighlight">\(\psi\)</span> on <span class="math notranslate nohighlight">\(S\)</span> is a probability mass function of length <span class="math notranslate nohighlight">\(n\)</span>, where <span class="math notranslate nohighlight">\(\psi(i)\)</span> is the amount of probability allocated to state <span class="math notranslate nohighlight">\(x_i\)</span>.</p>
<p>A <strong>Markov chain</strong> <span class="math notranslate nohighlight">\(\{X_t\}\)</span> on <span class="math notranslate nohighlight">\(S\)</span> is a sequence of random variables taking values in <span class="math notranslate nohighlight">\(S\)</span>
that have the <strong>Markov property</strong>.</p>
<p>This means that, for any date <span class="math notranslate nohighlight">\(t\)</span> and any state <span class="math notranslate nohighlight">\(y \in S\)</span>,</p>
<div class="math notranslate nohighlight" id="equation-fin-markov-mp">
<span class="eqno">(33.2)<a class="headerlink" href="#equation-fin-markov-mp" title="Permalink to this equation">#</a></span>\[\mathbb P \{ X_{t+1} = y  \,|\, X_t \}
= \mathbb P \{ X_{t+1}  = y \,|\, X_t, X_{t-1}, \ldots \}\]</div>
<p>This means that once we know the current state <span class="math notranslate nohighlight">\(X_t\)</span>,  adding knowledge of earlier states <span class="math notranslate nohighlight">\(X_{t-1}, X_{t-2}\)</span> provides no additional information about probabilities of <em>future</em> states.</p>
<p>Thus, the dynamics of a Markov chain are fully determined by the set of <strong>conditional probabilities</strong></p>
<div class="math notranslate nohighlight" id="equation-mpp">
<span class="eqno">(33.3)<a class="headerlink" href="#equation-mpp" title="Permalink to this equation">#</a></span>\[P(x, y) := \mathbb P \{ X_{t+1} = y \,|\, X_t = x \}
\qquad (x, y \in S)\]</div>
<p>By construction,</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(P(x, y)\)</span> is the probability of going from <span class="math notranslate nohighlight">\(x\)</span> to <span class="math notranslate nohighlight">\(y\)</span> in one unit of time (one step)</p></li>
<li><p><span class="math notranslate nohighlight">\(P(x, \cdot)\)</span> is the conditional distribution of <span class="math notranslate nohighlight">\(X_{t+1}\)</span> given <span class="math notranslate nohighlight">\(X_t = x\)</span></p></li>
</ul>
<p>We can view <span class="math notranslate nohighlight">\(P\)</span> as a stochastic matrix where</p>
<div class="math notranslate nohighlight">
\[
    P_{ij} = P(x_i, x_j)
    \qquad 1 \leq i, j \leq n
\]</div>
<p>Going the other way, if we take a stochastic matrix <span class="math notranslate nohighlight">\(P\)</span>, we can generate a Markov
chain <span class="math notranslate nohighlight">\(\{X_t\}\)</span> as follows:</p>
<ul class="simple">
<li><p>draw <span class="math notranslate nohighlight">\(X_0\)</span> from a distribution <span class="math notranslate nohighlight">\(\psi_0\)</span> on <span class="math notranslate nohighlight">\(S\)</span></p></li>
<li><p>for each <span class="math notranslate nohighlight">\(t = 0, 1, \ldots\)</span>, draw <span class="math notranslate nohighlight">\(X_{t+1}\)</span> from <span class="math notranslate nohighlight">\(P(X_t,\cdot)\)</span></p></li>
</ul>
<p>By construction, the resulting process satisfies <a class="reference internal" href="#equation-mpp">(33.3)</a>.</p>
</section>
</section>
<section id="simulation">
<h2><span class="section-number">33.3. </span>Simulation<a class="headerlink" href="#simulation" title="Permalink to this heading">#</a></h2>
<p id="index-1">A good way to study Markov chains is to simulate them.</p>
<p>Let’s start by doing this ourselves and then look at libraries that can help
us.</p>
<p>In these exercises, we’ll take the state space to be <span class="math notranslate nohighlight">\(S = 0,\ldots, n-1\)</span>.</p>
<p>(We start at <span class="math notranslate nohighlight">\(0\)</span> because Python arrays are indexed from <span class="math notranslate nohighlight">\(0\)</span>.)</p>
<section id="writing-our-own-simulation-code">
<h3><span class="section-number">33.3.1. </span>Writing our own simulation code<a class="headerlink" href="#writing-our-own-simulation-code" title="Permalink to this heading">#</a></h3>
<p>To simulate a Markov chain, we need</p>
<ol class="arabic simple">
<li><p>a stochastic matrix <span class="math notranslate nohighlight">\(P\)</span> and</p></li>
<li><p>a probability mass function <span class="math notranslate nohighlight">\(\psi_0\)</span> of length <span class="math notranslate nohighlight">\(n\)</span> from which to draw an initial realization of <span class="math notranslate nohighlight">\(X_0\)</span>.</p></li>
</ol>
<p>The Markov chain is then constructed as follows:</p>
<ol class="arabic simple">
<li><p>At time <span class="math notranslate nohighlight">\(t=0\)</span>, draw a realization of <span class="math notranslate nohighlight">\(X_0\)</span> from the distribution <span class="math notranslate nohighlight">\(\psi_0\)</span>.</p></li>
<li><p>At each subsequent time <span class="math notranslate nohighlight">\(t\)</span>, draw a realization of the new state <span class="math notranslate nohighlight">\(X_{t+1}\)</span> from <span class="math notranslate nohighlight">\(P(X_t, \cdot)\)</span>.</p></li>
</ol>
<p>(That is, draw from row <span class="math notranslate nohighlight">\(X_t\)</span> of <span class="math notranslate nohighlight">\(P\)</span>.)</p>
<p>To implement this simulation procedure, we need a method for generating draws
from a discrete distribution.</p>
<p>For this task, we’ll use <code class="docutils literal notranslate"><span class="pre">random.draw</span></code> from <a class="reference external" href="http://quantecon.org/quantecon-py">QuantEcon.py</a>.</p>
<p>To use <code class="docutils literal notranslate"><span class="pre">random.draw</span></code>, we first need to convert the probability mass function
to a cumulative distribution</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">ψ_0</span> <span class="o">=</span> <span class="p">(</span><span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">)</span>           <span class="c1"># probabilities over {0, 1}</span>
<span class="n">cdf</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="n">ψ_0</span><span class="p">)</span>       <span class="c1"># convert into cumulative distribution</span>
<span class="n">qe</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">draw</span><span class="p">(</span><span class="n">cdf</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>   <span class="c1"># generate 5 independent draws from ψ</span>
</pre></div>
</div>
</div>
</div>
<p>We’ll write our code as a function that accepts the following three arguments</p>
<ul class="simple">
<li><p>A stochastic matrix <code class="docutils literal notranslate"><span class="pre">P</span></code>.</p></li>
<li><p>An initial distribution <code class="docutils literal notranslate"><span class="pre">ψ_0</span></code>.</p></li>
<li><p>A positive integer <code class="docutils literal notranslate"><span class="pre">ts_length</span></code> representing the length of the time series the function should return.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">mc_sample_path</span><span class="p">(</span><span class="n">P</span><span class="p">,</span> <span class="n">ψ_0</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">ts_length</span><span class="o">=</span><span class="mi">1_000</span><span class="p">):</span>

    <span class="c1"># set up</span>
    <span class="n">P</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">P</span><span class="p">)</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">ts_length</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">)</span>

    <span class="c1"># Convert each row of P into a cdf</span>
    <span class="n">P_dist</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="n">P</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># Convert rows into cdfs</span>

    <span class="c1"># draw initial state, defaulting to 0</span>
    <span class="k">if</span> <span class="n">ψ_0</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">X_0</span> <span class="o">=</span> <span class="n">qe</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">draw</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="n">ψ_0</span><span class="p">))</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">X_0</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="c1"># simulate</span>
    <span class="n">X</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">X_0</span>
    <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">ts_length</span> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>
        <span class="n">X</span><span class="p">[</span><span class="n">t</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">qe</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">draw</span><span class="p">(</span><span class="n">P_dist</span><span class="p">[</span><span class="n">X</span><span class="p">[</span><span class="n">t</span><span class="p">],</span> <span class="p">:])</span>

    <span class="k">return</span> <span class="n">X</span>
</pre></div>
</div>
</div>
</div>
<p>Let’s see how it works using the small matrix</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">P</span> <span class="o">=</span> <span class="p">[[</span><span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">],</span>
     <span class="p">[</span><span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">]]</span>
</pre></div>
</div>
</div>
</div>
<p>Here’s a short time series.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">mc_sample_path</span><span class="p">(</span><span class="n">P</span><span class="p">,</span> <span class="n">ψ_0</span><span class="o">=</span><span class="p">(</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">),</span> <span class="n">ts_length</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>It can be shown that for a long series drawn from <code class="docutils literal notranslate"><span class="pre">P</span></code>, the fraction of the
sample that takes value 0 will be about 0.25.</p>
<p>(We will explain why <a class="reference internal" href="markov_chains_II.html#ergodicity"><span class="std std-ref">later</span></a>.)</p>
<p>Moreover, this is true regardless of the initial distribution from which
<span class="math notranslate nohighlight">\(X_0\)</span> is drawn.</p>
<p>The following code illustrates this</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">X</span> <span class="o">=</span> <span class="n">mc_sample_path</span><span class="p">(</span><span class="n">P</span><span class="p">,</span> <span class="n">ψ_0</span><span class="o">=</span><span class="p">(</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">),</span> <span class="n">ts_length</span><span class="o">=</span><span class="mi">1_000_000</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">X</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>You can try changing the initial distribution to confirm that the output is
always close to 0.25 (for the <code class="docutils literal notranslate"><span class="pre">P</span></code> matrix above).</p>
</section>
<section id="using-quantecon-s-routines">
<h3><span class="section-number">33.3.2. </span>Using QuantEcon’s routines<a class="headerlink" href="#using-quantecon-s-routines" title="Permalink to this heading">#</a></h3>
<p><a class="reference external" href="http://quantecon.org/quantecon-py">QuantEcon.py</a> has routines for handling Markov chains, including simulation.</p>
<p>Here’s an illustration using the same <span class="math notranslate nohighlight">\(P\)</span> as the preceding example</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">mc</span> <span class="o">=</span> <span class="n">qe</span><span class="o">.</span><span class="n">MarkovChain</span><span class="p">(</span><span class="n">P</span><span class="p">)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">mc</span><span class="o">.</span><span class="n">simulate</span><span class="p">(</span><span class="n">ts_length</span><span class="o">=</span><span class="mi">1_000_000</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">X</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">simulate</span></code> routine is faster (because it is <a class="reference external" href="https://python-programming.quantecon.org/numba.html#numba-link">JIT compiled</a>).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="n">time</span> <span class="n">mc_sample_path</span><span class="p">(</span><span class="n">P</span><span class="p">,</span> <span class="n">ts_length</span><span class="o">=</span><span class="mi">1_000_000</span><span class="p">)</span> <span class="c1"># Our homemade code version</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="n">time</span> <span class="n">mc</span><span class="o">.</span><span class="n">simulate</span><span class="p">(</span><span class="n">ts_length</span><span class="o">=</span><span class="mi">1_000_000</span><span class="p">)</span> <span class="c1"># qe code version</span>
</pre></div>
</div>
</div>
</div>
<section id="adding-state-values-and-initial-conditions">
<h4><span class="section-number">33.3.2.1. </span>Adding state values and initial conditions<a class="headerlink" href="#adding-state-values-and-initial-conditions" title="Permalink to this heading">#</a></h4>
<p>If we wish to, we can provide a specification of state values to <code class="docutils literal notranslate"><span class="pre">MarkovChain</span></code>.</p>
<p>These state values can be integers, floats, or even strings.</p>
<p>The following code illustrates</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">mc</span> <span class="o">=</span> <span class="n">qe</span><span class="o">.</span><span class="n">MarkovChain</span><span class="p">(</span><span class="n">P</span><span class="p">,</span> <span class="n">state_values</span><span class="o">=</span><span class="p">(</span><span class="s1">&#39;unemployed&#39;</span><span class="p">,</span> <span class="s1">&#39;employed&#39;</span><span class="p">))</span>
<span class="n">mc</span><span class="o">.</span><span class="n">simulate</span><span class="p">(</span><span class="n">ts_length</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">init</span><span class="o">=</span><span class="s1">&#39;employed&#39;</span><span class="p">)</span>  <span class="c1"># Start at employed initial state</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">mc</span><span class="o">.</span><span class="n">simulate</span><span class="p">(</span><span class="n">ts_length</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">init</span><span class="o">=</span><span class="s1">&#39;unemployed&#39;</span><span class="p">)</span>  <span class="c1"># Start at unemployed initial state</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">mc</span><span class="o">.</span><span class="n">simulate</span><span class="p">(</span><span class="n">ts_length</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>  <span class="c1"># Start at randomly chosen initial state</span>
</pre></div>
</div>
</div>
</div>
<p>If we want to see indices rather than state values as outputs as  we can use</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">mc</span><span class="o">.</span><span class="n">simulate_indices</span><span class="p">(</span><span class="n">ts_length</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
</section>
<section id="distributions-over-time">
<span id="mc-md"></span><h2><span class="section-number">33.4. </span>Distributions over time<a class="headerlink" href="#distributions-over-time" title="Permalink to this heading">#</a></h2>
<p>We learned that</p>
<ol class="arabic simple">
<li><p><span class="math notranslate nohighlight">\(\{X_t\}\)</span> is a Markov chain with stochastic matrix <span class="math notranslate nohighlight">\(P\)</span></p></li>
<li><p>the distribution of <span class="math notranslate nohighlight">\(X_t\)</span> is known to be <span class="math notranslate nohighlight">\(\psi_t\)</span></p></li>
</ol>
<p>What then is the distribution of <span class="math notranslate nohighlight">\(X_{t+1}\)</span>, or, more generally, of <span class="math notranslate nohighlight">\(X_{t+m}\)</span>?</p>
<p>To answer this, we let <span class="math notranslate nohighlight">\(\psi_t\)</span> be the distribution of <span class="math notranslate nohighlight">\(X_t\)</span> for <span class="math notranslate nohighlight">\(t = 0, 1, 2, \ldots\)</span>.</p>
<p>Our first aim is to find <span class="math notranslate nohighlight">\(\psi_{t + 1}\)</span> given <span class="math notranslate nohighlight">\(\psi_t\)</span> and <span class="math notranslate nohighlight">\(P\)</span>.</p>
<p>To begin, pick any <span class="math notranslate nohighlight">\(y \in S\)</span>.</p>
<p>To get the probability of being at <span class="math notranslate nohighlight">\(y\)</span> tomorrow (at <span class="math notranslate nohighlight">\(t+1\)</span>), we account for
all ways this can happen and sum their probabilities.</p>
<p>This leads to</p>
<div class="math notranslate nohighlight">
\[
\mathbb P \{X_{t+1} = y \}
   = \sum_{x \in S} \mathbb P \{ X_{t+1} = y \, | \, X_t = x \}
               \cdot \mathbb P \{ X_t = x \}
\]</div>
<p>(We are using the <a class="reference external" href="https://en.wikipedia.org/wiki/Law_of_total_probability">law of total probability</a>.)</p>
<p>Rewriting this statement in terms of  marginal and conditional probabilities gives</p>
<div class="math notranslate nohighlight">
\[
    \psi_{t+1}(y) = \sum_{x \in S} P(x,y) \psi_t(x)
\]</div>
<p>There are <span class="math notranslate nohighlight">\(n\)</span> such equations, one for each <span class="math notranslate nohighlight">\(y \in S\)</span>.</p>
<p>If we think of <span class="math notranslate nohighlight">\(\psi_{t+1}\)</span> and <span class="math notranslate nohighlight">\(\psi_t\)</span> as row vectors, these <span class="math notranslate nohighlight">\(n\)</span> equations are summarized by the matrix expression</p>
<div class="math notranslate nohighlight" id="equation-fin-mc-fr">
<span class="eqno">(33.4)<a class="headerlink" href="#equation-fin-mc-fr" title="Permalink to this equation">#</a></span>\[\psi_{t+1} = \psi_t P\]</div>
<p>Thus, we postmultiply by <span class="math notranslate nohighlight">\(P\)</span> to move a distribution forward one unit of time.</p>
<p>By postmultiplying <span class="math notranslate nohighlight">\(m\)</span> times, we move a distribution forward <span class="math notranslate nohighlight">\(m\)</span> steps into the future.</p>
<p>Hence, iterating on <a class="reference internal" href="#equation-fin-mc-fr">(33.4)</a>, the expression <span class="math notranslate nohighlight">\(\psi_{t+m} = \psi_t P^m\)</span> is also valid — here <span class="math notranslate nohighlight">\(P^m\)</span> is the <span class="math notranslate nohighlight">\(m\)</span>-th power of <span class="math notranslate nohighlight">\(P\)</span>.</p>
<p>As a special case, we see that if <span class="math notranslate nohighlight">\(\psi_0\)</span> is the initial distribution from
which <span class="math notranslate nohighlight">\(X_0\)</span> is drawn, then <span class="math notranslate nohighlight">\(\psi_0 P^m\)</span> is the distribution of
<span class="math notranslate nohighlight">\(X_m\)</span>.</p>
<p>This is very important, so let’s repeat it</p>
<div class="math notranslate nohighlight" id="equation-mdfmc">
<span class="eqno">(33.5)<a class="headerlink" href="#equation-mdfmc" title="Permalink to this equation">#</a></span>\[X_0 \sim \psi_0 \quad \implies \quad X_m \sim \psi_0 P^m\]</div>
<p>The general rule is that postmultiplying a distribution by <span class="math notranslate nohighlight">\(P^m\)</span> shifts it forward <span class="math notranslate nohighlight">\(m\)</span> units of time.</p>
<p>Hence the following is also valid.</p>
<div class="math notranslate nohighlight" id="equation-mdfmc2">
<span class="eqno">(33.6)<a class="headerlink" href="#equation-mdfmc2" title="Permalink to this equation">#</a></span>\[X_t \sim \psi_t \quad \implies \quad X_{t+m} \sim \psi_t P^m\]</div>
<section id="multiple-step-transition-probabilities">
<span id="finite-mc-mstp"></span><h3><span class="section-number">33.4.1. </span>Multiple step transition probabilities<a class="headerlink" href="#multiple-step-transition-probabilities" title="Permalink to this heading">#</a></h3>
<p>We know that the probability of transitioning from <span class="math notranslate nohighlight">\(x\)</span> to <span class="math notranslate nohighlight">\(y\)</span> in
one step is <span class="math notranslate nohighlight">\(P(x,y)\)</span>.</p>
<p>It turns out that the probability of transitioning from <span class="math notranslate nohighlight">\(x\)</span> to <span class="math notranslate nohighlight">\(y\)</span> in
<span class="math notranslate nohighlight">\(m\)</span> steps is <span class="math notranslate nohighlight">\(P^m(x,y)\)</span>, the <span class="math notranslate nohighlight">\((x,y)\)</span>-th element of the
<span class="math notranslate nohighlight">\(m\)</span>-th power of <span class="math notranslate nohighlight">\(P\)</span>.</p>
<p>To see why, consider again <a class="reference internal" href="#equation-mdfmc2">(33.6)</a>, but now with a <span class="math notranslate nohighlight">\(\psi_t\)</span> that puts all probability on state <span class="math notranslate nohighlight">\(x\)</span>.</p>
<p>Then <span class="math notranslate nohighlight">\(\psi_t\)</span> is a vector with <span class="math notranslate nohighlight">\(1\)</span> in position <span class="math notranslate nohighlight">\(x\)</span> and zero elsewhere.</p>
<p>Inserting this into <a class="reference internal" href="#equation-mdfmc2">(33.6)</a>, we see that, conditional on <span class="math notranslate nohighlight">\(X_t = x\)</span>, the distribution of <span class="math notranslate nohighlight">\(X_{t+m}\)</span> is the <span class="math notranslate nohighlight">\(x\)</span>-th row of <span class="math notranslate nohighlight">\(P^m\)</span>.</p>
<p>In particular</p>
<div class="math notranslate nohighlight">
\[
\mathbb P \{X_{t+m} = y \,|\, X_t = x \} = P^m(x, y) = (x, y) \text{-th element of } P^m
\]</div>
</section>
<section id="example-probability-of-recession">
<h3><span class="section-number">33.4.2. </span>Example: probability of recession<a class="headerlink" href="#example-probability-of-recession" title="Permalink to this heading">#</a></h3>
<p id="index-2">Recall the stochastic matrix <span class="math notranslate nohighlight">\(P\)</span> for recession and growth <a class="reference internal" href="#mc-eg2"><span class="std std-ref">considered above</span></a>.</p>
<p>Suppose that the current state is unknown — perhaps statistics are available only at the <em>end</em> of the current month.</p>
<p>We guess that the probability that the economy is in state <span class="math notranslate nohighlight">\(x\)</span> is <span class="math notranslate nohighlight">\(\psi_t(x)\)</span> at time t.</p>
<p>The probability of being in recession (either mild or severe) in 6 months time is given by</p>
<div class="math notranslate nohighlight">
\[
(\psi_t P^6)(1) + (\psi_t P^6)(2)
\]</div>
</section>
<section id="example-2-cross-sectional-distributions">
<span id="mc-eg1-1"></span><h3><span class="section-number">33.4.3. </span>Example 2: cross-sectional distributions<a class="headerlink" href="#example-2-cross-sectional-distributions" title="Permalink to this heading">#</a></h3>
<p>The distributions we have been studying can be viewed either</p>
<ol class="arabic simple">
<li><p>as probabilities or</p></li>
<li><p>as cross-sectional frequencies that the law of large numbers leads us to anticipate for large samples.</p></li>
</ol>
<p>To illustrate, recall our model of employment/unemployment dynamics for a given worker <a class="reference internal" href="#mc-eg1"><span class="std std-ref">discussed above</span></a>.</p>
<p>Consider a large population of workers, each of whose lifetime experience is
described by the specified dynamics, with each worker’s outcomes being
realizations of processes that are statistically independent of all other
workers’ processes.</p>
<p>Let <span class="math notranslate nohighlight">\(\psi_t\)</span> be the current <em>cross-sectional</em> distribution over <span class="math notranslate nohighlight">\(\{ 0, 1 \}\)</span>.</p>
<p>The cross-sectional distribution records fractions of workers employed and unemployed at a given moment <span class="math notranslate nohighlight">\(t\)</span>.</p>
<ul class="simple">
<li><p>For example, <span class="math notranslate nohighlight">\(\psi_t(0)\)</span> is the unemployment rate at time <span class="math notranslate nohighlight">\(t\)</span>.</p></li>
</ul>
<p>What will the cross-sectional distribution be in 10 periods hence?</p>
<p>The answer is <span class="math notranslate nohighlight">\(\psi_t P^{10}\)</span>, where <span class="math notranslate nohighlight">\(P\)</span> is the stochastic matrix in
<a class="reference internal" href="#equation-p-unempemp">(33.1)</a>.</p>
<p>This is because each worker’s state evolves according to <span class="math notranslate nohighlight">\(P\)</span>, so
<span class="math notranslate nohighlight">\(\psi_t P^{10}\)</span> is a <a class="reference external" href="https://en.wikipedia.org/wiki/Marginal_distribution">marginal distribution</a>  for a single randomly selected
worker.</p>
<p>But when the sample is large, outcomes and probabilities are roughly equal (by an application of the law
of large numbers).</p>
<p>So for a very large (tending to infinite) population,
<span class="math notranslate nohighlight">\(\psi_t P^{10}\)</span> also represents  fractions of workers in
each state.</p>
<p>This is exactly the cross-sectional distribution.</p>
</section>
</section>
<section id="stationary-distributions">
<span id="stationary"></span><h2><span class="section-number">33.5. </span>Stationary distributions<a class="headerlink" href="#stationary-distributions" title="Permalink to this heading">#</a></h2>
<p>As seen in <a class="reference internal" href="#equation-fin-mc-fr">(33.4)</a>, we can shift a distribution forward one
unit of time via postmultiplication by <span class="math notranslate nohighlight">\(P\)</span>.</p>
<p>Some distributions are invariant under this updating process — for example,</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">P</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">],</span>
              <span class="p">[</span><span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">]])</span>
<span class="n">ψ</span> <span class="o">=</span> <span class="p">(</span><span class="mf">0.25</span><span class="p">,</span> <span class="mf">0.75</span><span class="p">)</span>
<span class="n">ψ</span> <span class="o">@</span> <span class="n">P</span>
</pre></div>
</div>
</div>
</div>
<p>Notice that <code class="docutils literal notranslate"><span class="pre">ψ</span> <span class="pre">&#64;</span> <span class="pre">P</span></code> is the same as <code class="docutils literal notranslate"><span class="pre">ψ</span></code>.</p>
<p>Such distributions are called <strong>stationary</strong> or <strong>invariant</strong>.</p>
<p id="mc-stat-dd">Formally, a distribution <span class="math notranslate nohighlight">\(\psi^*\)</span> on <span class="math notranslate nohighlight">\(S\)</span> is called <strong>stationary</strong> for <span class="math notranslate nohighlight">\(P\)</span> if <span class="math notranslate nohighlight">\(\psi^* P = \psi^* \)</span>.</p>
<p>Notice that, postmultiplying by <span class="math notranslate nohighlight">\(P\)</span>, we have <span class="math notranslate nohighlight">\(\psi^* P^2 = \psi^* P = \psi^*\)</span>.</p>
<p>Continuing in the same way leads to <span class="math notranslate nohighlight">\(\psi^* = \psi^* P^t\)</span> for all <span class="math notranslate nohighlight">\(t \ge 0\)</span>.</p>
<p>This tells us an important fact: If the distribution of <span class="math notranslate nohighlight">\(\psi_0\)</span> is a stationary distribution, then <span class="math notranslate nohighlight">\(\psi_t\)</span> will have this same distribution for all <span class="math notranslate nohighlight">\(t \ge 0\)</span>.</p>
<p>The following theorem is proved in Chapter 4 of <span id="id4">[]</span> and numerous other sources.</p>
<div class="proof theorem admonition" id="unique_stat">
<p class="admonition-title"><span class="caption-number">Theorem 33.1 </span></p>
<section class="theorem-content" id="proof-content">
<p>Every stochastic matrix <span class="math notranslate nohighlight">\(P\)</span> has at least one stationary distribution.</p>
</section>
</div><p>Note that there can be many stationary distributions corresponding to a given
stochastic matrix <span class="math notranslate nohighlight">\(P\)</span>.</p>
<ul class="simple">
<li><p>For example, if <span class="math notranslate nohighlight">\(P\)</span> is the identity matrix, then all distributions on <span class="math notranslate nohighlight">\(S\)</span> are stationary.</p></li>
</ul>
<p>To get uniqueness, we need the Markov chain to “mix around,” so that the state
doesn’t get stuck in some part of the state space.</p>
<p>This gives some intuition for the following theorem.</p>
<div class="proof theorem admonition" id="mc_po_conv_thm">
<p class="admonition-title"><span class="caption-number">Theorem 33.2 </span></p>
<section class="theorem-content" id="proof-content">
<p>If <span class="math notranslate nohighlight">\(P\)</span> is everywhere positive, then <span class="math notranslate nohighlight">\(P\)</span> has exactly one stationary
distribution.</p>
</section>
</div><p>We will come back to this when we introduce irreducibility in the <a class="reference internal" href="markov_chains_II.html"><span class="doc">next lecture</span></a> on Markov chains.</p>
<section id="example">
<h3><span class="section-number">33.5.1. </span>Example<a class="headerlink" href="#example" title="Permalink to this heading">#</a></h3>
<p>Recall our model of the employment/unemployment dynamics of a particular worker <a class="reference internal" href="#mc-eg1"><span class="std std-ref">discussed above</span></a>.</p>
<p>If <span class="math notranslate nohighlight">\(\alpha \in (0,1)\)</span> and <span class="math notranslate nohighlight">\(\beta \in (0,1)\)</span>, then the transition matrix is everywhere positive.</p>
<p>Let <span class="math notranslate nohighlight">\(\psi^* = (p, 1-p)\)</span> be the stationary distribution, so that <span class="math notranslate nohighlight">\(p\)</span>
corresponds to unemployment (state 0).</p>
<p>Using <span class="math notranslate nohighlight">\(\psi^* = \psi^* P\)</span> and a bit of algebra yields</p>
<div class="math notranslate nohighlight">
\[
    p = \frac{\beta}{\alpha + \beta}
\]</div>
<p>This is, in some sense, a steady state probability of unemployment.</p>
<p>Not surprisingly it tends to zero as <span class="math notranslate nohighlight">\(\beta \to 0\)</span>, and to one as <span class="math notranslate nohighlight">\(\alpha \to 0\)</span>.</p>
</section>
<section id="calculating-stationary-distributions">
<h3><span class="section-number">33.5.2. </span>Calculating stationary distributions<a class="headerlink" href="#calculating-stationary-distributions" title="Permalink to this heading">#</a></h3>
<p>A stable algorithm for computing stationary distributions is implemented in <a class="reference external" href="http://quantecon.org/quantecon-py">QuantEcon.py</a>.</p>
<p>Here’s an example</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">P</span> <span class="o">=</span> <span class="p">[[</span><span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">],</span>
     <span class="p">[</span><span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">]]</span>

<span class="n">mc</span> <span class="o">=</span> <span class="n">qe</span><span class="o">.</span><span class="n">MarkovChain</span><span class="p">(</span><span class="n">P</span><span class="p">)</span>
<span class="n">mc</span><span class="o">.</span><span class="n">stationary_distributions</span>  <span class="c1"># Show all stationary distributions</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="asymptotic-stationarity">
<h3><span class="section-number">33.5.3. </span>Asymptotic stationarity<a class="headerlink" href="#asymptotic-stationarity" title="Permalink to this heading">#</a></h3>
<p>Consider an everywhere positive stochastic matrix with unique stationary distribution <span class="math notranslate nohighlight">\(\psi^*\)</span>.</p>
<p>Sometimes the distribution <span class="math notranslate nohighlight">\(\psi_t = \psi_0 P^t\)</span> of <span class="math notranslate nohighlight">\(X_t\)</span> converges to <span class="math notranslate nohighlight">\(\psi^*\)</span> regardless of <span class="math notranslate nohighlight">\(\psi_0\)</span>.</p>
<p>For example, we have the following result</p>
<div class="proof theorem admonition" id="mc_gs_thm">
<span id="strict-stationary"></span><p class="admonition-title"><span class="caption-number">Theorem 33.3 </span></p>
<section class="theorem-content" id="proof-content">
<p>If there exists an integer <span class="math notranslate nohighlight">\(m\)</span> such that all entries of <span class="math notranslate nohighlight">\(P^m\)</span> are
strictly positive, then</p>
<div class="math notranslate nohighlight">
\[
    \psi_0 P^t \to \psi^*
    \quad \text{ as } t \to \infty
\]</div>
<p>where <span class="math notranslate nohighlight">\(\psi^*\)</span> is the unique stationary distribution.</p>
</section>
</div><p>This situation is often referred to as <strong>asymptotic stationarity</strong> or <strong>global stability</strong>.</p>
<p>A proof of the theorem can be found in Chapter 4 of <span id="id5">[]</span>, as well as many other sources.</p>
<section id="example-hamilton-s-chain">
<span id="hamilton"></span><h4><span class="section-number">33.5.3.1. </span>Example: Hamilton’s chain<a class="headerlink" href="#example-hamilton-s-chain" title="Permalink to this heading">#</a></h4>
<p>Hamilton’s chain satisfies the conditions of the theorem because <span class="math notranslate nohighlight">\(P^2\)</span> is everywhere positive:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">P</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mf">0.971</span><span class="p">,</span> <span class="mf">0.029</span><span class="p">,</span> <span class="mf">0.000</span><span class="p">],</span>
              <span class="p">[</span><span class="mf">0.145</span><span class="p">,</span> <span class="mf">0.778</span><span class="p">,</span> <span class="mf">0.077</span><span class="p">],</span>
              <span class="p">[</span><span class="mf">0.000</span><span class="p">,</span> <span class="mf">0.508</span><span class="p">,</span> <span class="mf">0.492</span><span class="p">]])</span>
<span class="n">P</span> <span class="o">@</span> <span class="n">P</span>
</pre></div>
</div>
</div>
</div>
<p>Let’s pick an initial distribution <span class="math notranslate nohighlight">\(\psi_1, \psi_2, \psi_3\)</span> and trace out the sequence of distributions <span class="math notranslate nohighlight">\(\psi_i P^t\)</span> for <span class="math notranslate nohighlight">\(t = 0, 1, 2, \ldots\)</span>, for <span class="math notranslate nohighlight">\(i=1, 2, 3\)</span>.</p>
<p>First, we write a function to iterate the sequence of distributions for <code class="docutils literal notranslate"><span class="pre">ts_length</span></code> period</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">iterate_ψ</span><span class="p">(</span><span class="n">ψ_0</span><span class="p">,</span> <span class="n">P</span><span class="p">,</span> <span class="n">ts_length</span><span class="p">):</span>
    <span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">P</span><span class="p">)</span>
    <span class="n">ψ_t</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="n">ts_length</span><span class="p">,</span> <span class="n">n</span><span class="p">))</span>
    <span class="n">ψ_t</span><span class="p">[</span><span class="mi">0</span> <span class="p">]</span><span class="o">=</span> <span class="n">ψ_0</span>
    <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">ts_length</span><span class="p">):</span>
        <span class="n">ψ_t</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="o">=</span> <span class="n">ψ_t</span><span class="p">[</span><span class="n">t</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">@</span> <span class="n">P</span>
    <span class="k">return</span> <span class="n">ψ_t</span>
</pre></div>
</div>
</div>
</div>
<p>Now we plot the sequence</p>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">ψ_1</span> <span class="o">=</span> <span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">)</span>
<span class="n">ψ_2</span> <span class="o">=</span> <span class="p">(</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">)</span>
<span class="n">ψ_3</span> <span class="o">=</span> <span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">)</span>                   <span class="c1"># Three initial conditions</span>
<span class="n">colors</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;blue&#39;</span><span class="p">,</span><span class="s1">&#39;red&#39;</span><span class="p">,</span> <span class="s1">&#39;green&#39;</span><span class="p">]</span>   <span class="c1"># Different colors for each initial point</span>

<span class="c1"># Define the vertices of the unit simplex</span>
<span class="n">v</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]])</span>

<span class="c1"># Define the faces of the unit simplex</span>
<span class="n">faces</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">[</span><span class="n">v</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">v</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">v</span><span class="p">[</span><span class="mi">2</span><span class="p">]],</span>
    <span class="p">[</span><span class="n">v</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">v</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">v</span><span class="p">[</span><span class="mi">3</span><span class="p">]],</span>
    <span class="p">[</span><span class="n">v</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">v</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">v</span><span class="p">[</span><span class="mi">3</span><span class="p">]],</span>
    <span class="p">[</span><span class="n">v</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">v</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">v</span><span class="p">[</span><span class="mi">3</span><span class="p">]]</span>
<span class="p">]</span>

<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="n">projection</span><span class="o">=</span><span class="s1">&#39;3d&#39;</span><span class="p">)</span>

<span class="k">def</span><span class="w"> </span><span class="nf">update</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>    
    <span class="n">ax</span><span class="o">.</span><span class="n">clear</span><span class="p">()</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_zlim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">view_init</span><span class="p">(</span><span class="mi">45</span><span class="p">,</span> <span class="mi">45</span><span class="p">)</span>
    
    <span class="n">simplex</span> <span class="o">=</span> <span class="n">Poly3DCollection</span><span class="p">(</span><span class="n">faces</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.03</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">add_collection3d</span><span class="p">(</span><span class="n">simplex</span><span class="p">)</span>
    
    <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">ψ_0</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">([</span><span class="n">ψ_1</span><span class="p">,</span> <span class="n">ψ_2</span><span class="p">,</span> <span class="n">ψ_3</span><span class="p">]):</span>
        <span class="n">ψ_t</span> <span class="o">=</span> <span class="n">iterate_ψ</span><span class="p">(</span><span class="n">ψ_0</span><span class="p">,</span> <span class="n">P</span><span class="p">,</span> <span class="n">n</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
        
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">point</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">ψ_t</span><span class="p">):</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">point</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">point</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">point</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="n">colors</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span> <span class="n">s</span><span class="o">=</span><span class="mi">60</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">ψ_t</span><span class="p">))</span>
            
    <span class="n">mc</span> <span class="o">=</span> <span class="n">qe</span><span class="o">.</span><span class="n">MarkovChain</span><span class="p">(</span><span class="n">P</span><span class="p">)</span>
    <span class="n">ψ_star</span> <span class="o">=</span> <span class="n">mc</span><span class="o">.</span><span class="n">stationary_distributions</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">ψ_star</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">ψ_star</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">ψ_star</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;yellow&#39;</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">60</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">fig</span><span class="p">,</span>

<span class="n">anim</span> <span class="o">=</span> <span class="n">FuncAnimation</span><span class="p">(</span><span class="n">fig</span><span class="p">,</span> <span class="n">update</span><span class="p">,</span> <span class="n">frames</span><span class="o">=</span><span class="nb">range</span><span class="p">(</span><span class="mi">20</span><span class="p">),</span> <span class="n">blit</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">repeat</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
<span class="n">HTML</span><span class="p">(</span><span class="n">anim</span><span class="o">.</span><span class="n">to_jshtml</span><span class="p">())</span>
</pre></div>
</div>
</div>
</details>
</div>
<p>Here</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(P\)</span> is the stochastic matrix for recession and growth <a class="reference internal" href="#mc-eg2"><span class="std std-ref">considered above</span></a>.</p></li>
<li><p>The red, blue and green dots are initial marginal probability distributions  <span class="math notranslate nohighlight">\(\psi_1, \psi_2, \psi_3\)</span>, each of which is represented as a vector in <span class="math notranslate nohighlight">\(\mathbb R^3\)</span>.</p></li>
<li><p>The transparent dots are the marginal distributions <span class="math notranslate nohighlight">\(\psi_i P^t\)</span> for <span class="math notranslate nohighlight">\(t = 1, 2, \ldots\)</span>, for <span class="math notranslate nohighlight">\(i=1,2,3.\)</span>.</p></li>
<li><p>The yellow dot is <span class="math notranslate nohighlight">\(\psi^*\)</span>.</p></li>
</ul>
<p>You might like to try experimenting with different initial conditions.</p>
</section>
<section id="example-failure-of-convergence">
<h4><span class="section-number">33.5.3.2. </span>Example: failure of convergence<a class="headerlink" href="#example-failure-of-convergence" title="Permalink to this heading">#</a></h4>
<p>Consider the periodic chain with stochastic matrix</p>
<div class="math notranslate nohighlight">
\[\begin{split}
P = 
\begin{bmatrix}
    0 &amp; 1 \\
    1 &amp; 0 \\
\end{bmatrix}
\end{split}\]</div>
<p>This matrix does not satisfy the conditions of
<span class="xref std std-ref">strict_stationary</span> because, as you can readily check,</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(P^m = P\)</span> when <span class="math notranslate nohighlight">\(m\)</span> is odd and</p></li>
<li><p><span class="math notranslate nohighlight">\(P^m = I\)</span>, the identity matrix, when <span class="math notranslate nohighlight">\(m\)</span> is even.</p></li>
</ul>
<p>Hence there is no <span class="math notranslate nohighlight">\(m\)</span> such that all elements of <span class="math notranslate nohighlight">\(P^m\)</span> are strictly positive.</p>
<p>Moreover, we can see that global stability does not hold.</p>
<p>For instance, if we start at <span class="math notranslate nohighlight">\(\psi_0 = (1,0)\)</span>, then <span class="math notranslate nohighlight">\(\psi_m = \psi_0 P^m\)</span> is <span class="math notranslate nohighlight">\((1, 0)\)</span> when <span class="math notranslate nohighlight">\(m\)</span> is even and <span class="math notranslate nohighlight">\((0,1)\)</span> when <span class="math notranslate nohighlight">\(m\)</span> is odd.</p>
<p>We can see similar phenomena in higher dimensions.</p>
<p>The next figure illustrates this for a periodic Markov chain with three states.</p>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">ψ_1</span> <span class="o">=</span> <span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">)</span>
<span class="n">ψ_2</span> <span class="o">=</span> <span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">)</span>
<span class="n">ψ_3</span> <span class="o">=</span> <span class="p">(</span><span class="mf">0.25</span><span class="p">,</span> <span class="mf">0.25</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">)</span>
<span class="n">ψ_4</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="o">/</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="o">/</span><span class="mi">3</span><span class="p">)</span>

<span class="n">P</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">],</span>
              <span class="p">[</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">],</span>
              <span class="p">[</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">]])</span>

<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="n">projection</span><span class="o">=</span><span class="s1">&#39;3d&#39;</span><span class="p">)</span>
<span class="n">colors</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;red&#39;</span><span class="p">,</span><span class="s1">&#39;yellow&#39;</span><span class="p">,</span> <span class="s1">&#39;green&#39;</span><span class="p">,</span> <span class="s1">&#39;blue&#39;</span><span class="p">]</span>  <span class="c1"># Different colors for each initial point</span>

<span class="c1"># Define the vertices of the unit simplex</span>
<span class="n">v</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]])</span>

<span class="c1"># Define the faces of the unit simplex</span>
<span class="n">faces</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">[</span><span class="n">v</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">v</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">v</span><span class="p">[</span><span class="mi">2</span><span class="p">]],</span>
    <span class="p">[</span><span class="n">v</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">v</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">v</span><span class="p">[</span><span class="mi">3</span><span class="p">]],</span>
    <span class="p">[</span><span class="n">v</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">v</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">v</span><span class="p">[</span><span class="mi">3</span><span class="p">]],</span>
    <span class="p">[</span><span class="n">v</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">v</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">v</span><span class="p">[</span><span class="mi">3</span><span class="p">]]</span>
<span class="p">]</span>

<span class="k">def</span><span class="w"> </span><span class="nf">update</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">clear</span><span class="p">()</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_zlim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">view_init</span><span class="p">(</span><span class="mi">45</span><span class="p">,</span> <span class="mi">45</span><span class="p">)</span>
    
    <span class="c1"># Plot the 3D unit simplex as planes</span>
    <span class="n">simplex</span> <span class="o">=</span> <span class="n">Poly3DCollection</span><span class="p">(</span><span class="n">faces</span><span class="p">,</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.05</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">add_collection3d</span><span class="p">(</span><span class="n">simplex</span><span class="p">)</span>
    
    <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">ψ_0</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">([</span><span class="n">ψ_1</span><span class="p">,</span> <span class="n">ψ_2</span><span class="p">,</span> <span class="n">ψ_3</span><span class="p">,</span> <span class="n">ψ_4</span><span class="p">]):</span>
        <span class="n">ψ_t</span> <span class="o">=</span> <span class="n">iterate_ψ</span><span class="p">(</span><span class="n">ψ_0</span><span class="p">,</span> <span class="n">P</span><span class="p">,</span> <span class="n">n</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
        
        <span class="n">point</span> <span class="o">=</span> <span class="n">ψ_t</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">point</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">point</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">point</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="n">colors</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span> <span class="n">s</span><span class="o">=</span><span class="mi">60</span><span class="p">)</span>
        <span class="n">points</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">ψ_t</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">points</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">points</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">points</span><span class="p">[:,</span> <span class="mi">2</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="n">colors</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span><span class="n">linewidth</span><span class="o">=</span><span class="mf">0.75</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">fig</span><span class="p">,</span>

<span class="n">anim</span> <span class="o">=</span> <span class="n">FuncAnimation</span><span class="p">(</span><span class="n">fig</span><span class="p">,</span> <span class="n">update</span><span class="p">,</span> <span class="n">frames</span><span class="o">=</span><span class="nb">range</span><span class="p">(</span><span class="mi">20</span><span class="p">),</span> <span class="n">blit</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">repeat</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
<span class="n">HTML</span><span class="p">(</span><span class="n">anim</span><span class="o">.</span><span class="n">to_jshtml</span><span class="p">())</span>
</pre></div>
</div>
</div>
</details>
</div>
<p>This animation demonstrates the behavior of an irreducible and periodic stochastic matrix.</p>
<p>The red, yellow, and green dots represent different initial probability distributions.</p>
<p>The blue dot represents the unique stationary distribution.</p>
<p>Unlike Hamilton’s Markov chain, these initial distributions do not converge to the unique stationary distribution.</p>
<p>Instead, they cycle periodically around the probability simplex, illustrating that asymptotic stability fails.</p>
</section>
</section>
</section>
<section id="computing-expectations">
<span id="finite-mc-expec"></span><h2><span class="section-number">33.6. </span>Computing expectations<a class="headerlink" href="#computing-expectations" title="Permalink to this heading">#</a></h2>
<p id="index-3">We sometimes want to  compute mathematical  expectations of functions of <span class="math notranslate nohighlight">\(X_t\)</span> of the form</p>
<div class="math notranslate nohighlight" id="equation-mc-une">
<span class="eqno">(33.7)<a class="headerlink" href="#equation-mc-une" title="Permalink to this equation">#</a></span>\[\mathbb E [ h(X_t) ]\]</div>
<p>and conditional expectations such as</p>
<div class="math notranslate nohighlight" id="equation-mc-cce">
<span class="eqno">(33.8)<a class="headerlink" href="#equation-mc-cce" title="Permalink to this equation">#</a></span>\[\mathbb E [ h(X_{t + k})  \mid X_t = x]\]</div>
<p>where</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\{X_t\}\)</span> is a Markov chain generated by <span class="math notranslate nohighlight">\(n \times n\)</span> stochastic matrix <span class="math notranslate nohighlight">\(P\)</span>.</p></li>
<li><p><span class="math notranslate nohighlight">\(h\)</span> is a given function, which, in terms of matrix
algebra, we’ll think of as the column vector</p></li>
</ul>
<div class="math notranslate nohighlight">
\[\begin{split}
h =
\begin{bmatrix}
    h(x_1) \\
    \vdots \\
    h(x_n)
\end{bmatrix}.
\end{split}\]</div>
<p>Computing the unconditional expectation <a class="reference internal" href="#equation-mc-une">(33.7)</a> is easy.</p>
<p>We just sum over the marginal  distribution  of <span class="math notranslate nohighlight">\(X_t\)</span> to get</p>
<div class="math notranslate nohighlight">
\[
\mathbb E [ h(X_t) ]
= \sum_{x \in S} (\psi P^t)(x) h(x)
\]</div>
<p>Here <span class="math notranslate nohighlight">\(\psi\)</span> is the distribution of <span class="math notranslate nohighlight">\(X_0\)</span>.</p>
<p>Since <span class="math notranslate nohighlight">\(\psi\)</span> and hence <span class="math notranslate nohighlight">\(\psi P^t\)</span> are row vectors, we can also
write this as</p>
<div class="math notranslate nohighlight">
\[
\mathbb E [ h(X_t) ]
=  \psi P^t h
\]</div>
<p>For the conditional expectation <a class="reference internal" href="#equation-mc-cce">(33.8)</a>, we need to sum over
the conditional distribution of <span class="math notranslate nohighlight">\(X_{t + k}\)</span> given <span class="math notranslate nohighlight">\(X_t = x\)</span>.</p>
<p>We already know that this is <span class="math notranslate nohighlight">\(P^k(x, \cdot)\)</span>, so</p>
<div class="math notranslate nohighlight" id="equation-mc-cce2">
<span class="eqno">(33.9)<a class="headerlink" href="#equation-mc-cce2" title="Permalink to this equation">#</a></span>\[\mathbb E [ h(X_{t + k})  \mid X_t = x]
= (P^k h)(x)\]</div>
<section id="expectations-of-geometric-sums">
<h3><span class="section-number">33.6.1. </span>Expectations of geometric sums<a class="headerlink" href="#expectations-of-geometric-sums" title="Permalink to this heading">#</a></h3>
<p>Sometimes we want to compute the mathematical expectation of a geometric sum, such as
<span class="math notranslate nohighlight">\(\sum_t \beta^t h(X_t)\)</span>.</p>
<p>In view of the preceding discussion, this is</p>
<div class="math notranslate nohighlight">
\[
\mathbb{E}
    \left[
        \sum_{j=0}^\infty \beta^j h(X_{t+j}) \mid X_t
        = x
    \right]
    = x + \beta (Ph)(x) + \beta^2 (P^2 h)(x) + \cdots
\]</div>
<p>By the <a class="reference internal" href="eigen_I.html#la-neumann"><span class="std std-ref">Neumann series lemma</span></a>, this sum can be calculated using</p>
<div class="math notranslate nohighlight">
\[
    I + \beta P + \beta^2 P^2 + \cdots = (I - \beta P)^{-1}
\]</div>
<p>The vector <span class="math notranslate nohighlight">\(P^k h\)</span> stores the conditional expectation <span class="math notranslate nohighlight">\(\mathbb E [ h(X_{t + k})  \mid X_t = x]\)</span> over all <span class="math notranslate nohighlight">\(x\)</span>.</p>
<div class="exercise admonition" id="mc1_ex_1">

<p class="admonition-title"><span class="caption-number">Exercise 33.1 </span></p>
<section id="exercise-content">
<p>Imam and Temple <span id="id6">[]</span> used a three-state transition matrix to describe the transition of three states of a regime: growth, stagnation, and collapse</p>
<div class="math notranslate nohighlight">
\[\begin{split}
P :=
\begin{bmatrix}
    0.68 &amp; 0.12 &amp; 0.20 \\
    0.50 &amp; 0.24 &amp; 0.26 \\
    0.36 &amp; 0.18 &amp; 0.46
\end{bmatrix}
\end{split}\]</div>
<p>where rows, from top to down, correspond to growth, stagnation, and collapse.</p>
<p>In this exercise,</p>
<ol class="arabic simple">
<li><p>visualize the transition matrix and show this process is asymptotically stationary</p></li>
<li><p>calculate the stationary distribution using simulations</p></li>
<li><p>visualize the dynamics of  <span class="math notranslate nohighlight">\((\psi_0 P^t)(i)\)</span> where <span class="math notranslate nohighlight">\(t \in 0, ..., 25\)</span> and compare the convergent path with the previous transition matrix</p></li>
</ol>
<p>Compare your solution to the paper.</p>
</section>
</div>
<div class="solution dropdown admonition" id="markov_chains_I-solution-4">

<p class="admonition-title">Solution to<a class="reference internal" href="#mc1_ex_1"> Exercise 33.1</a></p>
<section id="solution-content">
<p>Solution 1:</p>
<img alt="_images/Temple.png" class="align-center" id="mc-temple" src="_images/Temple.png" />
<p>Since the matrix is everywhere positive, there is a unique stationary distribution <span class="math notranslate nohighlight">\(\psi^*\)</span> such that <span class="math notranslate nohighlight">\(\psi_t\to \psi^*\)</span> as <span class="math notranslate nohighlight">\(t\to \infty\)</span>.</p>
<p>Solution 2:</p>
<p>One simple way to calculate the stationary distribution is to take the power of the transition matrix as we have shown before</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">P</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mf">0.68</span><span class="p">,</span> <span class="mf">0.12</span><span class="p">,</span> <span class="mf">0.20</span><span class="p">],</span>
              <span class="p">[</span><span class="mf">0.50</span><span class="p">,</span> <span class="mf">0.24</span><span class="p">,</span> <span class="mf">0.26</span><span class="p">],</span>
              <span class="p">[</span><span class="mf">0.36</span><span class="p">,</span> <span class="mf">0.18</span><span class="p">,</span> <span class="mf">0.46</span><span class="p">]])</span>
<span class="n">P_power</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">matrix_power</span><span class="p">(</span><span class="n">P</span><span class="p">,</span> <span class="mi">20</span><span class="p">)</span>
<span class="n">P_power</span>
</pre></div>
</div>
</div>
</div>
<p>Note that rows of the transition matrix converge to the stationary distribution.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">ψ_star_p</span> <span class="o">=</span> <span class="n">P_power</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">ψ_star_p</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">mc</span> <span class="o">=</span> <span class="n">qe</span><span class="o">.</span><span class="n">MarkovChain</span><span class="p">(</span><span class="n">P</span><span class="p">)</span>
<span class="n">ψ_star</span> <span class="o">=</span> <span class="n">mc</span><span class="o">.</span><span class="n">stationary_distributions</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">ψ_star</span>
</pre></div>
</div>
</div>
</div>
</section>
</div>
<div class="exercise admonition" id="mc1_ex_2">

<p class="admonition-title"><span class="caption-number">Exercise 33.2 </span></p>
<section id="exercise-content">
<p>We discussed the six-state transition matrix estimated by Imam &amp; Temple <span id="id7">[]</span> <a class="reference internal" href="#mc-eg3"><span class="std std-ref">before</span></a>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">nodes</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;DG&#39;</span><span class="p">,</span> <span class="s1">&#39;DC&#39;</span><span class="p">,</span> <span class="s1">&#39;NG&#39;</span><span class="p">,</span> <span class="s1">&#39;NC&#39;</span><span class="p">,</span> <span class="s1">&#39;AG&#39;</span><span class="p">,</span> <span class="s1">&#39;AC&#39;</span><span class="p">]</span>
<span class="n">P</span> <span class="o">=</span> <span class="p">[[</span><span class="mf">0.86</span><span class="p">,</span> <span class="mf">0.11</span><span class="p">,</span> <span class="mf">0.03</span><span class="p">,</span> <span class="mf">0.00</span><span class="p">,</span> <span class="mf">0.00</span><span class="p">,</span> <span class="mf">0.00</span><span class="p">],</span>
     <span class="p">[</span><span class="mf">0.52</span><span class="p">,</span> <span class="mf">0.33</span><span class="p">,</span> <span class="mf">0.13</span><span class="p">,</span> <span class="mf">0.02</span><span class="p">,</span> <span class="mf">0.00</span><span class="p">,</span> <span class="mf">0.00</span><span class="p">],</span>
     <span class="p">[</span><span class="mf">0.12</span><span class="p">,</span> <span class="mf">0.03</span><span class="p">,</span> <span class="mf">0.70</span><span class="p">,</span> <span class="mf">0.11</span><span class="p">,</span> <span class="mf">0.03</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">],</span>
     <span class="p">[</span><span class="mf">0.13</span><span class="p">,</span> <span class="mf">0.02</span><span class="p">,</span> <span class="mf">0.35</span><span class="p">,</span> <span class="mf">0.36</span><span class="p">,</span> <span class="mf">0.10</span><span class="p">,</span> <span class="mf">0.04</span><span class="p">],</span>
     <span class="p">[</span><span class="mf">0.00</span><span class="p">,</span> <span class="mf">0.00</span><span class="p">,</span> <span class="mf">0.09</span><span class="p">,</span> <span class="mf">0.11</span><span class="p">,</span> <span class="mf">0.55</span><span class="p">,</span> <span class="mf">0.25</span><span class="p">],</span>
     <span class="p">[</span><span class="mf">0.00</span><span class="p">,</span> <span class="mf">0.00</span><span class="p">,</span> <span class="mf">0.09</span><span class="p">,</span> <span class="mf">0.15</span><span class="p">,</span> <span class="mf">0.26</span><span class="p">,</span> <span class="mf">0.50</span><span class="p">]]</span>
</pre></div>
</div>
<p>In this exercise,</p>
<ol class="arabic simple">
<li><p>show this process is asymptotically stationary without simulation</p></li>
<li><p>simulate and visualize the dynamics starting with a uniform distribution across states (each state will have a probability of 1/6)</p></li>
<li><p>change the initial distribution to P(DG) = 1, while all other states have a probability of 0</p></li>
</ol>
</section>
</div>
<div class="solution dropdown admonition" id="markov_chains_I-solution-6">

<p class="admonition-title">Solution to<a class="reference internal" href="#mc1_ex_2"> Exercise 33.2</a></p>
<section id="solution-content">
<p>Solution 1:</p>
<p>Although <span class="math notranslate nohighlight">\(P\)</span> is not every positive, <span class="math notranslate nohighlight">\(P^m\)</span> when <span class="math notranslate nohighlight">\(m=3\)</span> is everywhere positive.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">P</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mf">0.86</span><span class="p">,</span> <span class="mf">0.11</span><span class="p">,</span> <span class="mf">0.03</span><span class="p">,</span> <span class="mf">0.00</span><span class="p">,</span> <span class="mf">0.00</span><span class="p">,</span> <span class="mf">0.00</span><span class="p">],</span>
              <span class="p">[</span><span class="mf">0.52</span><span class="p">,</span> <span class="mf">0.33</span><span class="p">,</span> <span class="mf">0.13</span><span class="p">,</span> <span class="mf">0.02</span><span class="p">,</span> <span class="mf">0.00</span><span class="p">,</span> <span class="mf">0.00</span><span class="p">],</span>
              <span class="p">[</span><span class="mf">0.12</span><span class="p">,</span> <span class="mf">0.03</span><span class="p">,</span> <span class="mf">0.70</span><span class="p">,</span> <span class="mf">0.11</span><span class="p">,</span> <span class="mf">0.03</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">],</span>
              <span class="p">[</span><span class="mf">0.13</span><span class="p">,</span> <span class="mf">0.02</span><span class="p">,</span> <span class="mf">0.35</span><span class="p">,</span> <span class="mf">0.36</span><span class="p">,</span> <span class="mf">0.10</span><span class="p">,</span> <span class="mf">0.04</span><span class="p">],</span>
              <span class="p">[</span><span class="mf">0.00</span><span class="p">,</span> <span class="mf">0.00</span><span class="p">,</span> <span class="mf">0.09</span><span class="p">,</span> <span class="mf">0.11</span><span class="p">,</span> <span class="mf">0.55</span><span class="p">,</span> <span class="mf">0.25</span><span class="p">],</span>
              <span class="p">[</span><span class="mf">0.00</span><span class="p">,</span> <span class="mf">0.00</span><span class="p">,</span> <span class="mf">0.09</span><span class="p">,</span> <span class="mf">0.15</span><span class="p">,</span> <span class="mf">0.26</span><span class="p">,</span> <span class="mf">0.50</span><span class="p">]])</span>

<span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">matrix_power</span><span class="p">(</span><span class="n">P</span><span class="p">,</span><span class="mi">3</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>So it satisfies the requirement.</p>
<p>Solution 2:</p>
<p>We find the distribution <span class="math notranslate nohighlight">\(\psi\)</span> converges to the stationary distribution quickly regardless of the initial distributions</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">ts_length</span> <span class="o">=</span> <span class="mi">30</span>
<span class="n">num_distributions</span> <span class="o">=</span> <span class="mi">20</span>
<span class="n">nodes</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;DG&#39;</span><span class="p">,</span> <span class="s1">&#39;DC&#39;</span><span class="p">,</span> <span class="s1">&#39;NG&#39;</span><span class="p">,</span> <span class="s1">&#39;NC&#39;</span><span class="p">,</span> <span class="s1">&#39;AG&#39;</span><span class="p">,</span> <span class="s1">&#39;AC&#39;</span><span class="p">]</span>

<span class="c1"># Get parameters of transition matrix</span>
<span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">P</span><span class="p">)</span>
<span class="n">mc</span> <span class="o">=</span> <span class="n">qe</span><span class="o">.</span><span class="n">MarkovChain</span><span class="p">(</span><span class="n">P</span><span class="p">)</span>
<span class="n">ψ_star</span> <span class="o">=</span> <span class="n">mc</span><span class="o">.</span><span class="n">stationary_distributions</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">ψ_0</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="o">/</span><span class="mi">6</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">6</span><span class="p">)],</span>
                <span class="p">[</span><span class="mi">0</span> <span class="k">if</span> <span class="n">i</span> <span class="o">!=</span> <span class="mi">0</span> <span class="k">else</span> <span class="mi">1</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">6</span><span class="p">)]])</span>
<span class="c1">## Draw the plot</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">ncols</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">wspace</span><span class="o">=</span><span class="mf">0.35</span><span class="p">)</span>
<span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">):</span>
    <span class="n">ψ_t</span> <span class="o">=</span> <span class="n">iterate_ψ</span><span class="p">(</span><span class="n">ψ_0</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span> <span class="n">P</span><span class="p">,</span> <span class="n">ts_length</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
        <span class="n">axes</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">ψ_t</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]</span> <span class="o">-</span> <span class="n">ψ_star</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">fr</span><span class="s1">&#39;$\psi_t(</span><span class="si">{</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s1">)$&#39;</span><span class="p">)</span>
        <span class="n">axes</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">([</span><span class="o">-</span><span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">])</span>
        <span class="n">axes</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;t&#39;</span><span class="p">)</span>
        <span class="n">axes</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="sa">fr</span><span class="s1">&#39;$\psi_t$&#39;</span><span class="p">)</span>
        <span class="n">axes</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
        <span class="n">axes</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;dashed&#39;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="s1">&#39;black&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</section>
</div>
<div class="exercise admonition" id="mc1_ex_3">

<p class="admonition-title"><span class="caption-number">Exercise 33.3 </span></p>
<section id="exercise-content">
<p>Prove the following: If <span class="math notranslate nohighlight">\(P\)</span> is a stochastic matrix, then so is the <span class="math notranslate nohighlight">\(k\)</span>-th
power <span class="math notranslate nohighlight">\(P^k\)</span> for all <span class="math notranslate nohighlight">\(k \in \mathbb N\)</span>.</p>
</section>
</div>
<div class="solution dropdown admonition" id="markov_chains_I-solution-8">

<p class="admonition-title">Solution to<a class="reference internal" href="#mc1_ex_3"> Exercise 33.3</a></p>
<section id="solution-content">
<p>Suppose that <span class="math notranslate nohighlight">\(P\)</span> is stochastic and, moreover, that <span class="math notranslate nohighlight">\(P^k\)</span> is
stochastic for some integer <span class="math notranslate nohighlight">\(k\)</span>.</p>
<p>We will prove that <span class="math notranslate nohighlight">\(P^{k+1} = P P^k\)</span> is also stochastic.</p>
<p>(We are doing proof by induction — we assume the claim is true at <span class="math notranslate nohighlight">\(k\)</span> and
now prove it is true at <span class="math notranslate nohighlight">\(k+1\)</span>.)</p>
<p>To see this, observe that, since <span class="math notranslate nohighlight">\(P^k\)</span> is stochastic and the product of
nonnegative matrices is nonnegative, <span class="math notranslate nohighlight">\(P^{k+1} = P P^k\)</span> is nonnegative.</p>
<p>Also, if <span class="math notranslate nohighlight">\(\mathbf 1\)</span> is a column vector of ones, then, since <span class="math notranslate nohighlight">\(P^k\)</span> is stochastic we
have <span class="math notranslate nohighlight">\(P^k \mathbf 1 = \mathbf 1\)</span> (rows sum to one).</p>
<p>Therefore <span class="math notranslate nohighlight">\(P^{k+1} \mathbf 1 = P P^k \mathbf 1 = P \mathbf 1 = \mathbf 1\)</span></p>
<p>The proof is done.</p>
</section>
</div>
</section>
</section>
</section>

        <script type="text/x-thebe-config">
        {
            "rootPath": "./",
            "requestKernel": true,
            "useJupyterLite": true,
            "useBinder": false,
            "kernelOptions": {
                "path": "/"
            },
            "codeMirrorConfig": {
                "theme": "default",
                "mode": "python"
            },
            "mountRestartButton": false,
            "mountRestartallButton": false
        }
        </script>
        <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="ar1_processes.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title"><span class="section-number">32. </span>AR(1) Processes</p>
      </div>
    </a>
    <a class="right-next"
       href="markov_chains_II.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">34. </span>Markov Chains: Irreducibility and Ergodicity</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#overview">33.1. Overview</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#definitions-and-examples">33.2. Definitions and examples</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#stochastic-matrices">33.2.1. Stochastic matrices</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#markov-chains">33.2.2. Markov chains</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#example-1">33.2.2.1. Example 1</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#example-2">33.2.2.2. Example 2</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#example-3">33.2.2.3. Example 3</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#defining-markov-chains">33.2.3. Defining Markov chains</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#simulation">33.3. Simulation</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#writing-our-own-simulation-code">33.3.1. Writing our own simulation code</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#using-quantecon-s-routines">33.3.2. Using QuantEcon’s routines</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#adding-state-values-and-initial-conditions">33.3.2.1. Adding state values and initial conditions</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#distributions-over-time">33.4. Distributions over time</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#multiple-step-transition-probabilities">33.4.1. Multiple step transition probabilities</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#example-probability-of-recession">33.4.2. Example: probability of recession</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#example-2-cross-sectional-distributions">33.4.3. Example 2: cross-sectional distributions</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#stationary-distributions">33.5. Stationary distributions</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#example">33.5.1. Example</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#calculating-stationary-distributions">33.5.2. Calculating stationary distributions</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#asymptotic-stationarity">33.5.3. Asymptotic stationarity</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#example-hamilton-s-chain">33.5.3.1. Example: Hamilton’s chain</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#example-failure-of-convergence">33.5.3.2. Example: failure of convergence</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#computing-expectations">33.6. Computing expectations</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#expectations-of-geometric-sums">33.6.1. Expectations of geometric sums</a></li>
</ul>
</li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By QuantEcon team
</p>

  </div>
  
  <div class="footer-item">
    

  </div>
  
  <div class="footer-item">
    <p class="last-updated">
  Last updated on February 1, 2025.
  <br/>
</p>
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>
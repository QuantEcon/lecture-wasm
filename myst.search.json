{"version":"1","records":[{"hierarchy":{"lvl1":"AR(1) Processes"},"type":"lvl1","url":"/ar1-processes","position":0},{"hierarchy":{"lvl1":"AR(1) Processes"},"content":"","type":"content","url":"/ar1-processes","position":1},{"hierarchy":{"lvl1":"AR(1) Processes","lvl2":"Overview"},"type":"lvl2","url":"/ar1-processes#overview","position":2},{"hierarchy":{"lvl1":"AR(1) Processes","lvl2":"Overview"},"content":"In this lecture we are going to study a very simple class of stochastic\nmodels called AR(1) processes.\n\nThese simple models are used again and again in economic research to represent the dynamics of series such as\n\nlabor income\n\ndividends\n\nproductivity, etc.\n\nWe are going to study AR(1) processes partly because they are useful and\npartly because they help us understand important concepts.\n\nLet’s start with some imports:\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nplt.rcParams[\"figure.figsize\"] = (11, 5)  #set default figure size\n\n","type":"content","url":"/ar1-processes#overview","position":3},{"hierarchy":{"lvl1":"AR(1) Processes","lvl2":"The AR(1) model"},"type":"lvl2","url":"/ar1-processes#the-ar-1-model","position":4},{"hierarchy":{"lvl1":"AR(1) Processes","lvl2":"The AR(1) model"},"content":"The AR(1) model (autoregressive model of order 1) takes the formX_{t+1} = a X_t + b + c W_{t+1}\n\nwhere a, b, c are scalar-valued parameters\n\n(Equation \n\n(1) is sometimes called a stochastic difference equation.)\n\nFor example, X_t might be\n\nthe log of labor income for a given household, or\n\nthe log of money demand in a given economy.\n\nIn either case, \n\n(1) shows that the current value evolves as a linear function\nof the previous value and an IID shock W_{t+1}.\n\n(We use t+1 for the subscript of W_{t+1} because this random variable is not\nobserved at time t.)\n\nThe specification \n\n(1) generates a time series \\{ X_t\\} as soon as we\nspecify an initial condition X_0.\n\nTo make things even simpler, we will assume that\n\nthe process \\{ W_t \\} is \n\nIID and standard normal,\n\nthe initial condition X_0 is drawn from the normal distribution N(\\mu_0, v_0) and\n\nthe initial condition X_0 is independent of \\{ W_t \\}.","type":"content","url":"/ar1-processes#the-ar-1-model","position":5},{"hierarchy":{"lvl1":"AR(1) Processes","lvl3":"Moving average representation","lvl2":"The AR(1) model"},"type":"lvl3","url":"/ar1-processes#moving-average-representation","position":6},{"hierarchy":{"lvl1":"AR(1) Processes","lvl3":"Moving average representation","lvl2":"The AR(1) model"},"content":"Iterating backwards from time t, we obtainX_t = a X_{t-1} + b +  c W_t\n        = a^2 X_{t-2} + a b + a c W_{t-1} + b + c W_t\n        = a^3 X_{t-3} + a^2 b + a^2 c W_{t-2} + b + c W_t\n        = \\cdots\n\nIf we work all the way back to time zero, we getX_t = a^t X_0 + b \\sum_{j=0}^{t-1} a^j +\n        c \\sum_{j=0}^{t-1} a^j  W_{t-j}\n\nEquation \n\n(3) shows that X_t is a well defined random variable, the value of which depends on\n\nthe parameters,\n\nthe initial condition X_0 and\n\nthe shocks W_1, \\ldots W_t from time t=1 to the present.\n\nThroughout, the symbol \\psi_t will be used to refer to the\ndensity of this random variable X_t.","type":"content","url":"/ar1-processes#moving-average-representation","position":7},{"hierarchy":{"lvl1":"AR(1) Processes","lvl3":"Distribution dynamics","lvl2":"The AR(1) model"},"type":"lvl3","url":"/ar1-processes#distribution-dynamics","position":8},{"hierarchy":{"lvl1":"AR(1) Processes","lvl3":"Distribution dynamics","lvl2":"The AR(1) model"},"content":"One of the nice things about this model is that it’s so easy to trace out the sequence of distributions \\{ \\psi_t \\} corresponding to the time\nseries \\{ X_t\\}.\n\nTo see this, we first note that X_t is normally distributed for each t.\n\nThis is immediate from \n\n(3), since linear combinations of independent\nnormal random variables are normal.\n\nGiven that X_t is normally distributed, we will know the full distribution\n\\psi_t if we can pin down its first two \n\nmoments.\n\nLet \\mu_t and v_t denote the mean and variance of X_t respectively.\n\nWe can pin down these values from \n\n(3) or we can use the following\nrecursive expressions:\\mu_{t+1} = a \\mu_t + b\n\\quad \\text{and} \\quad\nv_{t+1} = a^2 v_t + c^2\n\nThese expressions are obtained from \n\n(1) by taking, respectively, the expectation and variance of both sides of the equality.\n\nIn calculating the second expression, we are using the fact that X_t\nand W_{t+1} are independent.\n\n(This follows from our assumptions and \n\n(3).)\n\nGiven the dynamics in \n\n(3) and initial conditions \\mu_0,\nv_0, we obtain \\mu_t, v_t and hence\\psi_t = N(\\mu_t, v_t)\n\nThe following code uses these facts to track the sequence of marginal distributions \\{ \\psi_t \\}.\n\nThe parameters are\n\na, b, c = 0.9, 0.1, 0.5\n\nmu, v = -3.0, 0.6  # initial conditions mu_0, v_0\n\nHere’s the sequence of distributions:\n\nfrom scipy.stats import norm\n\nsim_length = 10\ngrid = np.linspace(-5, 7, 120)\n\nfig, ax = plt.subplots()\n\nfor t in range(sim_length):\n    mu = a * mu + b\n    v = a**2 * v + c**2\n    ax.plot(grid, norm.pdf(grid, loc=mu, scale=np.sqrt(v)),\n            label=fr\"$\\psi_{t}$\",\n            alpha=0.7)\n\nax.legend(bbox_to_anchor=[1.05,1],loc=2,borderaxespad=1)\n\nplt.show()\n\n","type":"content","url":"/ar1-processes#distribution-dynamics","position":9},{"hierarchy":{"lvl1":"AR(1) Processes","lvl2":"Stationarity and asymptotic stability"},"type":"lvl2","url":"/ar1-processes#stationarity-and-asymptotic-stability","position":10},{"hierarchy":{"lvl1":"AR(1) Processes","lvl2":"Stationarity and asymptotic stability"},"content":"When we use models to study the real world, it is generally preferable that our\nmodels have clear, sharp predictions.\n\nFor dynamic problems, sharp predictions are related to stability.\n\nFor example, if a dynamic model predicts that inflation always converges to some\nkind of steady state, then the model gives a sharp prediction.\n\n(The prediction might be wrong, but even this is helpful, because we can judge the quality of the model.)\n\nNotice that, in the figure above, the sequence \\{ \\psi_t \\} seems to be converging to a limiting distribution, suggesting some kind of stability.\n\nThis is even clearer if we project forward further into the future:\n\ndef plot_density_seq(ax, mu_0=-3.0, v_0=0.6, sim_length=40):\n    mu, v = mu_0, v_0\n    for t in range(sim_length):\n        mu = a * mu + b\n        v = a**2 * v + c**2\n        ax.plot(grid,\n                norm.pdf(grid, loc=mu, scale=np.sqrt(v)),\n                alpha=0.5)\n\nfig, ax = plt.subplots()\nplot_density_seq(ax)\nplt.show()\n\nMoreover, the limit does not depend on the initial condition.\n\nFor example, this alternative density sequence also converges to the same limit.\n\nfig, ax = plt.subplots()\nplot_density_seq(ax, mu_0=4.0)\nplt.show()\n\nIn fact it’s easy to show that such convergence will occur, regardless of the initial condition, whenever |a| < 1.\n\nTo see this, we just have to look at the dynamics of the first two moments, as\ngiven in \n\n(4).\n\nWhen |a| < 1, these sequences converge to the respective limits\\mu^* := \\frac{b}{1-a}\n\\quad \\text{and} \\quad\nv^* = \\frac{c^2}{1 - a^2}\n\n(See our \n\nlecture on one dimensional dynamics for background on deterministic convergence.)\n\nHence\\psi_t \\to \\psi^* = N(\\mu^*, v^*)\n\\quad \\text{as }\nt \\to \\infty\n\nWe can confirm this is valid for the sequence above using the following code.\n\nfig, ax = plt.subplots()\nplot_density_seq(ax, mu_0=4.0)\n\nmu_star = b / (1 - a)\nstd_star = np.sqrt(c**2 / (1 - a**2))  # square root of v_star\npsi_star = norm.pdf(grid, loc=mu_star, scale=std_star)\nax.plot(grid, psi_star, 'k-', lw=2, label=r\"$\\psi^*$\")\nax.legend()\n\nplt.show()\n\nAs claimed, the sequence \\{ \\psi_t \\} converges to \\psi^*.\n\nWe see that, at least for these parameters, the AR(1) model has strong stability\nproperties.","type":"content","url":"/ar1-processes#stationarity-and-asymptotic-stability","position":11},{"hierarchy":{"lvl1":"AR(1) Processes","lvl3":"Stationary distributions","lvl2":"Stationarity and asymptotic stability"},"type":"lvl3","url":"/ar1-processes#stationary-distributions","position":12},{"hierarchy":{"lvl1":"AR(1) Processes","lvl3":"Stationary distributions","lvl2":"Stationarity and asymptotic stability"},"content":"Let’s try to better understand the limiting distribution \\psi^*.\n\nA stationary distribution is a distribution that is a “fixed point” of the update rule for the AR(1) process.\n\nIn other words, if \\psi_t is stationary, then \\psi_{t+j} = \\psi_t for all j in \\mathbb N.\n\nA different way to put this, specialized to the current setting, is as follows: a density \\psi on \\mathbb R is stationary for the AR(1) process ifX_t \\sim \\psi\n\\quad \\implies \\quad\na X_t + b + c W_{t+1} \\sim \\psi\n\nThe distribution \\psi^* in \n\n(7) has this property ---\nchecking this is an exercise.\n\n(Of course, we are assuming that |a| < 1 so that \\psi^* is\nwell defined.)\n\nIn fact, it can be shown that no other distribution on \\mathbb R has this property.\n\nThus, when |a| < 1, the AR(1) model has exactly one stationary density and that density is given by \\psi^*.","type":"content","url":"/ar1-processes#stationary-distributions","position":13},{"hierarchy":{"lvl1":"AR(1) Processes","lvl2":"Ergodicity"},"type":"lvl2","url":"/ar1-processes#ergodicity","position":14},{"hierarchy":{"lvl1":"AR(1) Processes","lvl2":"Ergodicity"},"content":"The concept of ergodicity is used in different ways by different authors.\n\nOne way to understand it in the present setting is that a version of the law\nof large numbers is valid for \\{X_t\\}, even though it is not IID.\n\nIn particular, averages over time series converge to expectations under the\nstationary distribution.\n\nIndeed, it can be proved that, whenever |a| < 1, we have\\frac{1}{m} \\sum_{t = 1}^m h(X_t)  \\to\n\\int h(x) \\psi^*(x) dx\n    \\quad \\text{as } m \\to \\infty\n\nwhenever the integral on the right hand side is finite and well defined.\n\nNotes:\n\nIn \n\n(9), convergence holds with probability one.\n\nThe textbook by \n\nMeyn & Tweedie (2009) is a classic reference on ergodicity.\n\nIf we consider the identity function h(x) = x, we get\\frac{1}{m} \\sum_{t = 1}^m X_t  \\to\n\\int x \\psi^*(x) dx\n    \\quad \\text{as } m \\to \\infty\n\nIn other words, the time series sample mean converges to the mean of the stationary distribution.\n\nErgodicity is important for a range of reasons.\n\nFor example, \n\n(9) can be used to test theory.\n\nIn this equation, we can use observed data to evaluate the left hand side of \n\n(9).\n\nAnd we can use a theoretical AR(1) model to calculate the right hand side.\n\nIf \\frac{1}{m} \\sum_{t = 1}^m X_t is not close to \\psi^(x), even for many\nobservations, then our theory seems to be incorrect and we will need to revise\nit.","type":"content","url":"/ar1-processes#ergodicity","position":15},{"hierarchy":{"lvl1":"AR(1) Processes","lvl2":"Exercises"},"type":"lvl2","url":"/ar1-processes#exercises","position":16},{"hierarchy":{"lvl1":"AR(1) Processes","lvl2":"Exercises"},"content":"Let k be a natural number.\n\nThe k-th central moment of a  random variable is defined asM_k := \\mathbb E [ (X - \\mathbb E X )^k ]\n\nWhen that random variable is N(\\mu, \\sigma^2), it is known thatM_k =\n\\begin{cases}\n    0 & \\text{ if } k \\text{ is odd} \\\\\n    \\sigma^k (k-1)!! & \\text{ if } k \\text{ is even}\n\\end{cases}\n\nHere n!! is the \n\ndouble factorial.\n\nAccording to \n\n(9), we should have, for any k \\in \\mathbb N,\\frac{1}{m} \\sum_{t = 1}^m\n    (X_t - \\mu^* )^k\n    \\approx M_k\n\nwhen m is large.\n\nConfirm this by simulation at a range of k using the default parameters from the lecture.\n\nSolution to \n\nExercise 1\n\nHere is one solution:\n\nfrom scipy.special import factorial2\n\ndef sample_moments_ar1(k, m=100_000, mu_0=0.0, sigma_0=1.0, seed=1234):\n    np.random.seed(seed)\n    sample_sum = 0.0\n    x = mu_0 + sigma_0 * np.random.randn()\n    for t in range(m):\n        sample_sum += (x - mu_star)**k\n        x = a * x + b + c * np.random.randn()\n    return sample_sum / m\n\ndef true_moments_ar1(k):\n    if k % 2 == 0:\n        return std_star**k * factorial2(k - 1)\n    else:\n        return 0\n\nk_vals = np.arange(6) + 1\nsample_moments = np.empty_like(k_vals)\ntrue_moments = np.empty_like(k_vals)\n\nfor k_idx, k in enumerate(k_vals):\n    sample_moments[k_idx] = sample_moments_ar1(k)\n    true_moments[k_idx] = true_moments_ar1(k)\n\nfig, ax = plt.subplots()\nax.plot(k_vals, true_moments, label=\"true moments\")\nax.plot(k_vals, sample_moments, label=\"sample moments\")\nax.legend()\n\nplt.show()\n\n\n\nWrite your own version of a one dimensional \n\nkernel density\nestimator,\nwhich estimates a density from a sample.\n\nWrite it as a class that takes the data X and bandwidth\nh when initialized and provides a method f such thatf(x) = \\frac{1}{hn} \\sum_{i=1}^n\nK \\left( \\frac{x-X_i}{h} \\right)\n\nFor K use the Gaussian kernel (K is the standard normal\ndensity).\n\nWrite the class so that the bandwidth defaults to Silverman’s rule (see\nthe “rule of thumb” discussion on \n\nthis\npage). Test\nthe class you have written by going through the steps\n\nsimulate data X_1, \\ldots, X_n from distribution \\phi\n\nplot the kernel density estimate over a suitable range\n\nplot the density of \\phi on the same figure\n\nfor distributions \\phi of the following types\n\nbeta\ndistribution\nwith \\alpha = \\beta = 2\n\nbeta\ndistribution\nwith \\alpha = 2 and \\beta = 5\n\nbeta\ndistribution\nwith \\alpha = \\beta = 0.5\n\nUse n=500.\n\nMake a comment on your results. (Do you think this is a good estimator\nof these distributions?)\n\nSolution to \n\nExercise 2\n\nHere is one solution:\n\nK = norm.pdf\n\nclass KDE:\n\n    def __init__(self, x_data, h=None):\n\n        if h is None:\n            c = x_data.std()\n            n = len(x_data)\n            h = 1.06 * c * n**(-1/5)\n        self.h = h\n        self.x_data = x_data\n\n    def f(self, x):\n        if np.isscalar(x):\n            return K((x - self.x_data) / self.h).mean() * (1/self.h)\n        else:\n            y = np.empty_like(x)\n            for i, x_val in enumerate(x):\n                y[i] = K((x_val - self.x_data) / self.h).mean() * (1/self.h)\n            return y\n\ndef plot_kde(ϕ, x_min=-0.2, x_max=1.2):\n    x_data = ϕ.rvs(n)\n    kde = KDE(x_data)\n\n    x_grid = np.linspace(-0.2, 1.2, 100)\n    fig, ax = plt.subplots()\n    ax.plot(x_grid, kde.f(x_grid), label=\"estimate\")\n    ax.plot(x_grid, ϕ.pdf(x_grid), label=\"true density\")\n    ax.legend()\n    plt.show()\n\nfrom scipy.stats import beta\n\nn = 500\nparameter_pairs= (2, 2), (2, 5), (0.5, 0.5)\nfor α, β in parameter_pairs:\n    plot_kde(beta(α, β))\n\nWe see that the kernel density estimator is effective when the underlying\ndistribution is smooth but less so otherwise.\n\nIn the lecture we discussed the following fact: for the AR(1) processX_{t+1} = a X_t + b + c W_{t+1}\n\nwith \\{ W_t \\} iid and standard normal,\\psi_t = N(\\mu, s^2) \\implies \\psi_{t+1}\n= N(a \\mu + b, a^2 s^2 + c^2)\n\nConfirm this, at least approximately, by simulation. Let\n\na = 0.9\n\nb = 0.0\n\nc = 0.1\n\n\\mu = -3\n\ns = 0.2\n\nFirst, plot \\psi_t and \\psi_{t+1} using the true\ndistributions described above.\n\nSecond, plot \\psi_{t+1} on the same figure (in a different\ncolor) as follows:\n\nGenerate n draws of X_t from the N(\\mu, s^2)\ndistribution\n\nUpdate them all using the rule\nX_{t+1} = a X_t + b + c W_{t+1}\n\nUse the resulting sample of X_{t+1} values to produce a\ndensity estimate via kernel density estimation.\n\nTry this for n=2000 and confirm that the\nsimulation based estimate of \\psi_{t+1} does converge to the\ntheoretical distribution.\n\nSolution to \n\nExercise 3\n\nHere is our solution\n\na = 0.9\nb = 0.0\nc = 0.1\nμ = -3\ns = 0.2\n\nμ_next = a * μ + b\ns_next = np.sqrt(a**2 * s**2 + c**2)\n\nψ = lambda x: K((x - μ) / s)\nψ_next = lambda x: K((x - μ_next) / s_next)\n\nψ = norm(μ, s)\nψ_next = norm(μ_next, s_next)\n\nn = 2000\nx_draws = ψ.rvs(n)\nx_draws_next = a * x_draws + b + c * np.random.randn(n)\nkde = KDE(x_draws_next)\n\nx_grid = np.linspace(μ - 1, μ + 1, 100)\nfig, ax = plt.subplots()\n\nax.plot(x_grid, ψ.pdf(x_grid), label=\"$\\psi_t$\")\nax.plot(x_grid, ψ_next.pdf(x_grid), label=\"$\\psi_{t+1}$\")\nax.plot(x_grid, kde.f(x_grid), label=\"estimate of $\\psi_{t+1}$\")\n\nax.legend()\nplt.show()\n\nThe simulated distribution approximately coincides with the theoretical\ndistribution, as predicted.","type":"content","url":"/ar1-processes#exercises","position":17},{"hierarchy":{"lvl1":"Monetarist Theory of Price Levels with Adaptive Expectations"},"type":"lvl1","url":"/cagan-adaptive","position":0},{"hierarchy":{"lvl1":"Monetarist Theory of Price Levels with Adaptive Expectations"},"content":"","type":"content","url":"/cagan-adaptive","position":1},{"hierarchy":{"lvl1":"Monetarist Theory of Price Levels with Adaptive Expectations","lvl2":"Overview"},"type":"lvl2","url":"/cagan-adaptive#overview","position":2},{"hierarchy":{"lvl1":"Monetarist Theory of Price Levels with Adaptive Expectations","lvl2":"Overview"},"content":"This lecture is a sequel or prequel to \n\nA Monetarist Theory of Price Levels.\n\nWe’ll use linear algebra to do some experiments with  an alternative “monetarist” or  “fiscal” theory of  price levels.\n\nLike the model in \n\nA Monetarist Theory of Price Levels, the model asserts that when a government persistently spends more than it collects in taxes and prints money to finance the shortfall, it puts upward pressure on the price level and generates persistent inflation.\n\nInstead of the “perfect foresight” or “rational expectations” version of the model in \n\nA Monetarist Theory of Price Levels, our model in the present lecture is an “adaptive expectations”  version of a model that  \n\nCagan (1956) used to study the monetary dynamics of hyperinflations.\n\nIt combines these components:\n\na demand function for real money balances that asserts that the logarithm of the quantity of real balances demanded depends inversely on the public’s expected rate of inflation\n\nan adaptive expectations model that describes how the public’s anticipated rate of inflation responds to past values of actual inflation\n\nan equilibrium condition that equates the demand for money to the supply\n\nan exogenous sequence of rates of growth of the money supply\n\nOur model stays quite close to Cagan’s original specification.\n\nAs in \n\nPresent Values and \n\nConsumption Smoothing, the only linear algebra operations that we’ll be  using are matrix multiplication and matrix inversion.\n\nTo facilitate using  linear matrix algebra as our principal mathematical tool, we’ll use a finite horizon version of\nthe model.","type":"content","url":"/cagan-adaptive#overview","position":3},{"hierarchy":{"lvl1":"Monetarist Theory of Price Levels with Adaptive Expectations","lvl2":"Structure of the model"},"type":"lvl2","url":"/cagan-adaptive#structure-of-the-model","position":4},{"hierarchy":{"lvl1":"Monetarist Theory of Price Levels with Adaptive Expectations","lvl2":"Structure of the model"},"content":"Let\n\n m_t  be the log of the supply of  nominal money balances;\n\n\\mu_t = m_{t+1} - m_t  be the net rate of growth of  nominal balances;\n\np_t  be the log of the price level;\n\n\\pi_t = p_{t+1} - p_t  be the net rate of inflation  between t and  t+1;\n\n\\pi_t^*  be the public’s expected rate of inflation between  t and t+1;\n\nT the horizon -- i.e., the last period for which the model will determine p_t\n\n\\pi_0^* public’s initial expected rate of inflation between time 0 and time 1.\n\nThe demand for real balances \\exp\\left(m_t^d-p_t\\right) is governed by the following  version of the Cagan demand functionm_t^d - p_t = -\\alpha \\pi_t^* \\: , \\: \\alpha > 0 ; \\quad t = 0, 1, \\ldots, T .\n\nThis equation  asserts that the demand for real balances\nis inversely related to the public’s expected rate of inflation with sensitivity \\alpha.\n\nEquating the logarithm m_t^d of the demand for money  to the logarithm  m_t of the supply of money in equation \n\n(1) and solving for the logarithm p_t\nof the price level givesp_t = m_t + \\alpha \\pi_t^*\n\nTaking the difference between equation \n\n(2) at time t+1 and at time\nt gives\\pi_t = \\mu_t + \\alpha \\pi_{t+1}^* - \\alpha \\pi_t^*\n\nWe assume that the expected rate of inflation \\pi_t^* is governed\nby the following adaptive expectations scheme proposed by \n\nFriedman (1956) and \n\nCagan (1956), where \\lambda\\in [0,1] denotes the weight on expected inflation.\\pi_{t+1}^* = \\lambda \\pi_t^* + (1 -\\lambda) \\pi_t\n\nAs exogenous inputs into the model, we take initial conditions m_0, \\pi_0^*\nand a money growth sequence \\mu = \\{\\mu_t\\}_{t=0}^T.\n\nAs endogenous outputs of our model we want to find sequences \\pi = \\{\\pi_t\\}_{t=0}^T, p = \\{p_t\\}_{t=0}^T as functions of the exogenous inputs.\n\nWe’ll do some mental experiments by studying how the model outputs vary as we vary\nthe model inputs.","type":"content","url":"/cagan-adaptive#structure-of-the-model","position":5},{"hierarchy":{"lvl1":"Monetarist Theory of Price Levels with Adaptive Expectations","lvl2":"Representing key equations with linear algebra"},"type":"lvl2","url":"/cagan-adaptive#representing-key-equations-with-linear-algebra","position":6},{"hierarchy":{"lvl1":"Monetarist Theory of Price Levels with Adaptive Expectations","lvl2":"Representing key equations with linear algebra"},"content":"We begin by writing the equation \n\n(4)  adaptive expectations model for \\pi_t^* for t=0, \\ldots, T as\\begin{bmatrix} 1 & 0 & 0 & \\cdots & 0 & 0 \\cr\n-\\lambda & 1 & 0 & \\cdots & 0 & 0 \\cr\n0 & - \\lambda  & 1  & \\cdots & 0 & 0 \\cr\n\\vdots & \\vdots & \\vdots & \\cdots & \\vdots & \\vdots \\cr\n0 & 0 & 0 & \\cdots & -\\lambda & 1\n\\end{bmatrix}\n\\begin{bmatrix} \\pi_0^* \\cr\n  \\pi_1^* \\cr\n  \\pi_2^* \\cr\n  \\vdots \\cr\n  \\pi_{T+1}^* \n  \\end{bmatrix} =\n  (1-\\lambda) \\begin{bmatrix} \n  0 & 0 & 0 & \\cdots & 0  \\cr\n  1 & 0 & 0 & \\cdots & 0   \\cr\n   0 & 1 & 0 & \\cdots & 0  \\cr\n    \\vdots &\\vdots & \\vdots & \\cdots & \\vdots  \\cr\n     0 & 0 & 0 & \\cdots & 1  \\end{bmatrix}\n     \\begin{bmatrix}\\pi_0 \\cr \\pi_1 \\cr \\pi_2 \\cr \\vdots \\cr \\pi_T\n  \\end{bmatrix} +\n  \\begin{bmatrix} \\pi_0^* \\cr 0 \\cr 0 \\cr \\vdots \\cr 0 \\end{bmatrix}\n\nWrite this equation asA \\pi^* = (1-\\lambda) B \\pi + \\pi_0^*\n\nwhere the (T+2) \\times (T+2) matrix A, the (T+2)\\times (T+1) matrix B, and the vectors \\pi^* , \\pi_0, \\pi_0^*\nare defined implicitly by aligning these two equations.\n\nNext we write the key equation \n\n(3) in matrix notation as\\begin{bmatrix}\n\\pi_0 \\cr \\pi_1 \\cr \\pi_1 \\cr \\vdots \\cr \\pi_T \\end{bmatrix}\n= \\begin{bmatrix}\n\\mu_0 \\cr \\mu_1 \\cr \\mu_2 \\cr  \\vdots \\cr \\mu_T \\end{bmatrix}\n+ \\begin{bmatrix} - \\alpha &  \\alpha & 0 & \\cdots & 0 & 0 \\cr\n0 & -\\alpha & \\alpha & \\cdots & 0 & 0 \\cr\n0 & 0 & -\\alpha & \\cdots & 0 & 0 \\cr\n\\vdots & \\vdots & \\vdots & \\cdots & \\alpha & 0 \\cr\n0 & 0 & 0 & \\cdots & -\\alpha  & \\alpha \n\\end{bmatrix}\n\\begin{bmatrix} \\pi_0^* \\cr\n  \\pi_1^* \\cr\n  \\pi_2^* \\cr\n  \\vdots \\cr\n  \\pi_{T+1}^* \n  \\end{bmatrix}\n\nRepresent the previous equation system in terms of vectors and matrices as\\pi = \\mu + C \\pi^*\n\nwhere the (T+1) \\times (T+2) matrix C is defined implicitly to align this equation with the preceding\nequation system.","type":"content","url":"/cagan-adaptive#representing-key-equations-with-linear-algebra","position":7},{"hierarchy":{"lvl1":"Monetarist Theory of Price Levels with Adaptive Expectations","lvl2":"Harvesting insights from our matrix formulation"},"type":"lvl2","url":"/cagan-adaptive#harvesting-insights-from-our-matrix-formulation","position":8},{"hierarchy":{"lvl1":"Monetarist Theory of Price Levels with Adaptive Expectations","lvl2":"Harvesting insights from our matrix formulation"},"content":"We now have all of the ingredients we need to solve for \\pi as\na function of \\mu, \\pi_0, \\pi_0^*.\n\nCombine equations \n\n(6)and \n\n(8)  to get\\begin{aligned}\nA \\pi^* & = (1-\\lambda) B \\pi + \\pi_0^* \\cr\n & = (1-\\lambda) B \\left[ \\mu + C \\pi^* \\right] + \\pi_0^*\n\\end{aligned}\n\nwhich implies that\\left[ A - (1-\\lambda) B C \\right] \\pi^* = (1-\\lambda) B \\mu+ \\pi_0^*\n\nMultiplying both sides of the above equation by the inverse of the matrix on the left side gives\\pi^* = \\left[ A - (1-\\lambda) B C \\right]^{-1} \\left[ (1-\\lambda) B \\mu+ \\pi_0^* \\right]\n\nHaving solved equation \n\n(11) for \\pi^*, we can use  equation \n\n(8)  to solve for \\pi:\\pi = \\mu + C \\pi^*\n\nWe have thus solved for two of the key endogenous time series determined by our model, namely, the sequence \\pi^*\nof expected inflation rates and the sequence \\pi of actual inflation rates.\n\nKnowing these, we can then quickly calculate the associated sequence p  of the logarithm of the  price level\nfrom equation \n\n(2).\n\nLet’s fill in the details for this step.\n\nSince we now know \\mu  it is easy to compute m.\n\nThus, notice that we can represent the equationsm_{t+1} = m_t + \\mu_t , \\quad t = 0, 1, \\ldots, T\n\nas the matrix equation\\begin{bmatrix}\n1 & 0 & 0 & \\cdots & 0 & 0 \\cr\n-1 & 1 & 0 & \\cdots & 0 & 0 \\cr\n0  & -1 & 1 & \\cdots & 0 & 0 \\cr\n\\vdots  & \\vdots & \\vdots & \\vdots & 0 & 0 \\cr\n0  & 0 & 0 & \\cdots & 1 & 0 \\cr\n0  & 0 & 0 & \\cdots & -1 & 1 \n\\end{bmatrix}\n\\begin{bmatrix}  \nm_1 \\cr m_2 \\cr m_3 \\cr \\vdots \\cr m_T \\cr m_{T+1}\n\\end{bmatrix}\n= \\begin{bmatrix}  \n\\mu_0 \\cr \\mu_1 \\cr \\mu_2 \\cr \\vdots \\cr \\mu_{T-1} \\cr \\mu_T\n\\end{bmatrix}\n+ \\begin{bmatrix}  \nm_0 \\cr 0 \\cr 0 \\cr \\vdots \\cr 0 \\cr 0\n\\end{bmatrix}\n\nMultiplying both sides of equation \n\n(14)  with the inverse of the matrix on the left will givem_t = m_0 + \\sum_{s=0}^{t-1} \\mu_s, \\quad t =1, \\ldots, T+1\n\nEquation \n\n(15) shows that the log of the money supply at t equals the log m_0 of the initial money supply\nplus accumulation of rates of money growth between times 0 and t.\n\nWe can then compute p_t for each t from equation \n\n(2).\n\nWe can write a compact formula for p  asp = m + \\alpha \\hat \\pi^*\n\nwhere\\hat \\pi^* = \\begin{bmatrix} \\pi_0^* \\cr\n  \\pi_1^* \\cr\n  \\pi_2^* \\cr\n  \\vdots \\cr\n  \\pi_{T}^* \n  \\end{bmatrix},\n\nwhich is just \\pi^* with the last element dropped.","type":"content","url":"/cagan-adaptive#harvesting-insights-from-our-matrix-formulation","position":9},{"hierarchy":{"lvl1":"Monetarist Theory of Price Levels with Adaptive Expectations","lvl2":"Forecast errors and model computation"},"type":"lvl2","url":"/cagan-adaptive#forecast-errors-and-model-computation","position":10},{"hierarchy":{"lvl1":"Monetarist Theory of Price Levels with Adaptive Expectations","lvl2":"Forecast errors and model computation"},"content":"Our computations will verify that\\hat \\pi^* \\neq  \\pi,\n\nso that in general\\pi_t^* \\neq \\pi_t, \\quad t = 0, 1, \\ldots , T\n\nThis outcome is typical in models in which adaptive expectations hypothesis like equation \n\n(4) appear as a\ncomponent.\n\nIn \n\nA Monetarist Theory of Price Levels, we studied a version of the model that replaces hypothesis \n\n(4) with\na “perfect foresight” or “rational expectations” hypothesis.\n\nBut now, let’s dive in and do some computations with the adaptive expectations version of the model.\n\nAs usual, we’ll start by importing some Python modules.\n\nimport numpy as np\nfrom collections import namedtuple\nimport matplotlib.pyplot as plt\n\nCagan_Adaptive = namedtuple(\"Cagan_Adaptive\", \n                        [\"α\", \"m0\", \"Eπ0\", \"T\", \"λ\"])\n\ndef create_cagan_adaptive_model(α = 5, m0 = 1, Eπ0 = 0.5, T=80, λ = 0.9):\n    return Cagan_Adaptive(α, m0, Eπ0, T, λ)\n\nmd = create_cagan_adaptive_model()\n\nWe solve the model and plot variables of interests using the following functions.\n\ndef solve_cagan_adaptive(model, μ_seq):\n    \" Solve the Cagan model in finite time. \"\n    α, m0, Eπ0, T, λ = model\n    \n    A = np.eye(T+2, T+2) - λ*np.eye(T+2, T+2, k=-1)\n    B = np.eye(T+2, T+1, k=-1)\n    C = -α*np.eye(T+1, T+2) + α*np.eye(T+1, T+2, k=1)\n    Eπ0_seq = np.append(Eπ0, np.zeros(T+1))\n\n    # Eπ_seq is of length T+2\n    Eπ_seq = np.linalg.solve(A - (1-λ)*B @ C, (1-λ) * B @ μ_seq + Eπ0_seq)\n\n    # π_seq is of length T+1\n    π_seq = μ_seq + C @ Eπ_seq\n\n    D = np.eye(T+1, T+1) - np.eye(T+1, T+1, k=-1) # D is the coefficient matrix in Equation (14.8)\n    m0_seq = np.append(m0, np.zeros(T))\n\n    # m_seq is of length T+2\n    m_seq = np.linalg.solve(D, μ_seq + m0_seq)\n    m_seq = np.append(m0, m_seq)\n\n    # p_seq is of length T+2\n    p_seq = m_seq + α * Eπ_seq\n\n    return π_seq, Eπ_seq, m_seq, p_seq\n\n\n\ndef solve_and_plot(model, μ_seq):\n    \n    π_seq, Eπ_seq, m_seq, p_seq = solve_cagan_adaptive(model, μ_seq)\n    \n    T_seq = range(model.T+2)\n    \n    fig, ax = plt.subplots(5, 1, figsize=[5, 12], dpi=200)\n    ax[0].plot(T_seq[:-1], μ_seq)\n    ax[1].plot(T_seq[:-1], π_seq, label=r'$\\pi_t$')\n    ax[1].plot(T_seq, Eπ_seq, label=r'$\\pi^{*}_{t}$')\n    ax[2].plot(T_seq, m_seq - p_seq)\n    ax[3].plot(T_seq, m_seq)\n    ax[4].plot(T_seq, p_seq)\n    \n    y_labs = [r'$\\mu$', r'$\\pi$', r'$m - p$', r'$m$', r'$p$']\n    subplot_title = [r'Money supply growth', r'Inflation', r'Real balances', r'Money supply', r'Price level']\n\n    for i in range(5):\n        ax[i].set_xlabel(r'$t$')\n        ax[i].set_ylabel(y_labs[i])\n        ax[i].set_title(subplot_title[i])\n\n    ax[1].legend()\n    plt.tight_layout()\n    plt.show()\n    \n    return π_seq, Eπ_seq, m_seq, p_seq\n\n","type":"content","url":"/cagan-adaptive#forecast-errors-and-model-computation","position":11},{"hierarchy":{"lvl1":"Monetarist Theory of Price Levels with Adaptive Expectations","lvl2":"Technical condition for stability"},"type":"lvl2","url":"/cagan-adaptive#technical-condition-for-stability","position":12},{"hierarchy":{"lvl1":"Monetarist Theory of Price Levels with Adaptive Expectations","lvl2":"Technical condition for stability"},"content":"In constructing our examples, we shall assume that (\\lambda, \\alpha) satisfy\\Bigl| \\frac{\\lambda-\\alpha(1-\\lambda)}{1-\\alpha(1-\\lambda)} \\Bigr| < 1\n\nThe  source of this condition is the following string of deductions:\\begin{aligned}\n\\pi_{t}&=\\mu_{t}+\\alpha\\pi_{t+1}^{*}-\\alpha\\pi_{t}^{*}\\\\\\pi_{t+1}^{*}&=\\lambda\\pi_{t}^{*}+(1-\\lambda)\\pi_{t}\\\\\\pi_{t}&=\\frac{\\mu_{t}}{1-\\alpha(1-\\lambda)}-\\frac{\\alpha(1-\\lambda)}{1-\\alpha(1-\\lambda)}\\pi_{t}^{*}\\\\\\implies\\pi_{t}^{*}&=\\frac{1}{\\alpha(1-\\lambda)}\\mu_{t}-\\frac{1-\\alpha(1-\\lambda)}{\\alpha(1-\\lambda)}\\pi_{t}\\\\\\pi_{t+1}&=\\frac{\\mu_{t+1}}{1-\\alpha(1-\\lambda)}-\\frac{\\alpha(1-\\lambda)}{1-\\alpha(1-\\lambda)}\\left(\\lambda\\pi_{t}^{*}+(1-\\lambda)\\pi_{t}\\right)\\\\&=\\frac{\\mu_{t+1}}{1-\\alpha(1-\\lambda)}-\\frac{\\lambda}{1-\\alpha(1-\\lambda)}\\mu_{t}+\\frac{\\lambda-\\alpha(1-\\lambda)}{1-\\alpha(1-\\lambda)}\\pi_{t}\n\\end{aligned}\n\nBy assuring that the coefficient on \\pi_t is less than one in absolute value, condition \n\n(20) assures stability of the dynamics of \\{\\pi_t\\} described by the last line of our string of deductions.\n\nThe reader is free to study outcomes in examples that violate condition \n\n(20).\n\nprint(np.abs((md.λ - md.α*(1-md.λ))/(1 - md.α*(1-md.λ))))\n\n","type":"content","url":"/cagan-adaptive#technical-condition-for-stability","position":13},{"hierarchy":{"lvl1":"Monetarist Theory of Price Levels with Adaptive Expectations","lvl2":"Experiments"},"type":"lvl2","url":"/cagan-adaptive#experiments","position":14},{"hierarchy":{"lvl1":"Monetarist Theory of Price Levels with Adaptive Expectations","lvl2":"Experiments"},"content":"Now we’ll turn to some experiments.","type":"content","url":"/cagan-adaptive#experiments","position":15},{"hierarchy":{"lvl1":"Monetarist Theory of Price Levels with Adaptive Expectations","lvl3":"Experiment 1","lvl2":"Experiments"},"type":"lvl3","url":"/cagan-adaptive#experiment-1","position":16},{"hierarchy":{"lvl1":"Monetarist Theory of Price Levels with Adaptive Expectations","lvl3":"Experiment 1","lvl2":"Experiments"},"content":"We’ll study a situation in which the rate of growth of the money supply is \\mu_0\nfrom t=0 to t= T_1 and then permanently falls to \\mu^* at t=T_1.\n\nThus, let T_1 \\in (0, T).\n\nSo where \\mu_0 > \\mu^*, we assume that\\mu_{t} = \\begin{cases}\n    \\mu_0  , & t = 0, \\ldots, T_1 -1 \\\\\n     \\mu^* , & t \\geq T_1\n     \\end{cases}\n\nNotice that  we studied exactly this experiment  in a rational expectations version of the model in \n\nA Monetarist Theory of Price Levels.\n\nSo by comparing outcomes across the two lectures, we can learn about consequences of assuming adaptive expectations, as we do here, instead of  rational expectations as we assumed in that other lecture.\n\n# Parameters for the experiment 1\nT1 = 60\nμ0 = 0.5\nμ_star = 0\n\nμ_seq_1 = np.append(μ0*np.ones(T1), μ_star*np.ones(md.T+1-T1))\n\n# solve and plot\nπ_seq_1, Eπ_seq_1, m_seq_1, p_seq_1 = solve_and_plot(md, μ_seq_1)\n\nWe invite the reader to compare outcomes with those under rational expectations studied in \n\nA Monetarist Theory of Price Levels.\n\nPlease note how the actual inflation rate \\pi_t “overshoots” its ultimate steady-state value at the time of the sudden reduction in the rate of growth of the money supply at time T_1.\n\nWe invite you to explain to  yourself the source of this overshooting and why it does not occur in  the rational expectations version of the model.","type":"content","url":"/cagan-adaptive#experiment-1","position":17},{"hierarchy":{"lvl1":"Monetarist Theory of Price Levels with Adaptive Expectations","lvl3":"Experiment 2","lvl2":"Experiments"},"type":"lvl3","url":"/cagan-adaptive#experiment-2","position":18},{"hierarchy":{"lvl1":"Monetarist Theory of Price Levels with Adaptive Expectations","lvl3":"Experiment 2","lvl2":"Experiments"},"content":"Now we’ll do a different experiment, namely, a gradual stabilization in which the rate of growth of the money supply smoothly\ndecline from a high value to a persistently low value.\n\nWhile price level inflation eventually falls, it falls more slowly than the driving  force that ultimately causes it to fall, namely, the falling rate of growth of the money supply.\n\nThe sluggish fall in inflation is explained by how anticipated  inflation \\pi_t^* persistently exceeds actual inflation \\pi_t during the transition from a high inflation to a low inflation situation.\n\n# parameters\nϕ = 0.9\nμ_seq_2 = np.array([ϕ**t * μ0 + (1-ϕ**t)*μ_star for t in range(md.T)])\nμ_seq_2 = np.append(μ_seq_2, μ_star)\n\n\n# solve and plot\nπ_seq_2, Eπ_seq_2, m_seq_2, p_seq_2 = solve_and_plot(md, μ_seq_2)","type":"content","url":"/cagan-adaptive#experiment-2","position":19},{"hierarchy":{"lvl1":"A Monetarist Theory of Price Levels"},"type":"lvl1","url":"/cagan-ree","position":0},{"hierarchy":{"lvl1":"A Monetarist Theory of Price Levels"},"content":"","type":"content","url":"/cagan-ree","position":1},{"hierarchy":{"lvl1":"A Monetarist Theory of Price Levels","lvl2":"Overview"},"type":"lvl2","url":"/cagan-ree#overview","position":2},{"hierarchy":{"lvl1":"A Monetarist Theory of Price Levels","lvl2":"Overview"},"content":"We’ll use linear algebra first to explain and then do some experiments with a “monetarist theory of price levels”.\n\nEconomists call it a “monetary” or “monetarist” theory of price levels because effects on price levels occur via a central bank’s decisions to print money supply.\n\na goverment’s fiscal policies determine whether its expenditures exceed its tax collections\n\nif its expenditures exceed its tax collections, the government can instruct the central bank to cover the difference by printing money\n\nthat leads to effects on the price level as price level path adjusts to equate the supply of money to the demand for money\n\nSuch a theory of price levels was described by Thomas Sargent and Neil Wallace in chapter 5 of\n\n\nSargent (2013), which reprints a 1981 Federal Reserve Bank of Minneapolis article entitled “Unpleasant Monetarist Arithmetic”.\n\nSometimes this theory is also called a “fiscal theory of price levels” to emphasize the importance of fiscal deficits in shaping changes in the money supply.\n\nThe theory has been extended, criticized, and applied by John Cochrane \n\nCochrane (2023).\n\nIn another lecture \n\nprice level histories, we described some European hyperinflations that occurred in the wake of World War I.\n\nElemental forces at work in the fiscal theory of the price level help to understand those episodes.\n\nAccording to this theory, when the government persistently spends more than it collects in taxes and prints money to finance the shortfall (the “shortfall” is called the “government deficit”), it puts upward pressure on the price level and generates\npersistent inflation.\n\nThe “monetarist” or “fiscal theory of price levels” asserts that\n\nto start a persistent inflation the government begins persistently to run a money-financed government deficit\n\nto stop a persistent inflation the government stops persistently running a money-financed government deficit\n\nThe model in this lecture is a “rational expectations” (or “perfect foresight”) version of a model that Philip Cagan \n\nCagan (1956) used to study the monetary dynamics of hyperinflations.\n\nWhile Cagan didn’t use that “rational expectations” version of the model, Thomas Sargent \n\nSargent (1982) did when he studied the Ends of Four Big Inflations in Europe after World War I.\n\nthis lecture \n\nfiscal theory of the price level with adaptive expectations describes a version of the model that does not impose “rational expectations” but instead uses\nwhat Cagan and his teacher Milton Friedman called “adaptive expectations”\n\na reader of both lectures will notice that the algebra is less complicated in the present rational expectations version of the model\n\nthe difference in algebra complications can be traced to the following source: the adaptive expectations version of the model has more endogenous variables and more free parameters\n\nSome of our quantitative experiments with the rational expectations version of the model are designed to illustrate how the fiscal theory explains the abrupt end of those big inflations.\n\nIn those experiments, we’ll encounter an instance of a “velocity dividend” that has sometimes accompanied successful inflation stabilization programs.\n\nTo facilitate using linear matrix algebra as our main mathematical tool, we’ll use a finite horizon version of the model.\n\nAs in the \n\npresent values and \n\nconsumption smoothing lectures, our mathematical tools are matrix multiplication and matrix inversion.","type":"content","url":"/cagan-ree#overview","position":3},{"hierarchy":{"lvl1":"A Monetarist Theory of Price Levels","lvl2":"Structure of the model"},"type":"lvl2","url":"/cagan-ree#structure-of-the-model","position":4},{"hierarchy":{"lvl1":"A Monetarist Theory of Price Levels","lvl2":"Structure of the model"},"content":"The model consists of\n\na function that expresses the demand for real balances of government printed money as an inverse function of the public’s expected rate of inflation\n\nan exogenous sequence of rates of growth of the money supply. The money supply grows because the government prints it to pay for goods and services\n\nan equilibrium condition that equates the demand for money to the supply\n\na “perfect foresight” assumption that the public’s expected rate of inflation equals the actual rate of inflation.\n\nTo represent the model formally, let\n\n m_t  be the log of the supply of nominal money balances;\n\n\\mu_t = m_{t+1} - m_t  be the net rate of growth of nominal balances;\n\np_t  be the log of the price level;\n\n\\pi_t = p_{t+1} - p_t  be the net rate of inflation between t and  t+1;\n\n\\pi_t^* be the public’s expected rate of inflation between t and t+1;\n\nT the horizon -- i.e., the last period for which the model will determine p_t\n\n\\pi_{T+1}^* the terminal rate of inflation between times T and T+1.\n\nThe demand for real balances \\exp\\left(m_t^d - p_t\\right) is governed by the following version of the Cagan demand functionm_t^d - p_t = -\\alpha \\pi_t^* \\: , \\: \\alpha > 0 ; \\quad t = 0, 1, \\ldots, T .\n\nThis equation asserts that the demand for real balances\nis inversely related to the public’s expected rate of inflation with sensitivity \\alpha.\n\nPeople somehow acquire perfect foresight by their having solved a forecasting\nproblem.\n\nThis lets us set\\pi_t^* = \\pi_t , % \\forall t\n\nwhile equating demand for money to supply lets us set m_t^d = m_t for all t \\geq 0.\n\nThe preceding equations then implym_t - p_t = -\\alpha(p_{t+1} - p_t)\n\nTo fill in details about what it means for private agents\nto have perfect foresight, we subtract equation \n\n(3) at time  t  from the same equation at  t+1 to get\\mu_t - \\pi_t = -\\alpha \\pi_{t+1} + \\alpha \\pi_t ,\n\nwhich we rewrite as a forward-looking first-order linear difference\nequation in \\pi_s with \\mu_s as a “forcing variable”:\\pi_t = \\frac{\\alpha}{1+\\alpha} \\pi_{t+1} + \\frac{1}{1+\\alpha} \\mu_t , \\quad t= 0, 1, \\ldots , T\n\nwhere  0< \\frac{\\alpha}{1+\\alpha} <1 .\n\nSetting \\delta =\\frac{\\alpha}{1+\\alpha}, let’s us represent the preceding equation as\\pi_t = \\delta \\pi_{t+1} + (1-\\delta) \\mu_t , \\quad t =0, 1, \\ldots, T\n\nWrite this system of T+1 equations as the single matrix equation\\begin{bmatrix} 1 & -\\delta & 0 & 0 & \\cdots & 0 & 0 \\cr\n                0 & 1 & -\\delta & 0 & \\cdots & 0 & 0 \\cr\n                0 & 0 & 1 & -\\delta & \\cdots & 0 & 0 \\cr\n                \\vdots & \\vdots & \\vdots & \\vdots & \\vdots & -\\delta & 0 \\cr\n                0 & 0 & 0 & 0 & \\cdots & 1 & -\\delta \\cr\n                0 & 0 & 0 & 0 & \\cdots & 0 & 1 \\end{bmatrix}\n\\begin{bmatrix} \\pi_0 \\cr \\pi_1 \\cr \\pi_2 \\cr \\vdots \\cr \\pi_{T-1} \\cr \\pi_T \n\\end{bmatrix} \n= (1 - \\delta) \\begin{bmatrix} \n\\mu_0 \\cr \\mu_1 \\cr \\mu_2 \\cr \\vdots \\cr \\mu_{T-1} \\cr \\mu_T\n\\end{bmatrix}\n+ \\begin{bmatrix} \n0 \\cr 0 \\cr 0 \\cr \\vdots \\cr 0 \\cr \\delta \\pi_{T+1}^*\n\\end{bmatrix}\n\nBy multiplying both sides of equation \n\n(7) by the inverse of the matrix on the left side, we can calculate\\pi \\equiv \\begin{bmatrix} \\pi_0 \\cr \\pi_1 \\cr \\pi_2 \\cr \\vdots \\cr \\pi_{T-1} \\cr \\pi_T \n\\end{bmatrix}\n\nIt turns out that\\pi_t = (1-\\delta) \\sum_{s=t}^T \\delta^{s-t} \\mu_s + \\delta^{T+1-t} \\pi_{T+1}^*\n\nWe can represent the equationsm_{t+1} = m_t + \\mu_t , \\quad t = 0, 1, \\ldots, T\n\nas the matrix equation\\begin{bmatrix}\n1 & 0 & 0 & \\cdots & 0 & 0 \\cr\n-1 & 1 & 0 & \\cdots & 0 & 0 \\cr\n0 & -1 & 1 & \\cdots & 0 & 0 \\cr\n\\vdots & \\vdots & \\vdots & \\vdots & 0 & 0 \\cr\n0 & 0 & 0 & \\cdots & 1 & 0 \\cr\n0 & 0 & 0 & \\cdots & -1 & 1 \n\\end{bmatrix}\n\\begin{bmatrix} \nm_1 \\cr m_2 \\cr m_3 \\cr \\vdots \\cr m_T \\cr m_{T+1}\n\\end{bmatrix}\n= \\begin{bmatrix} \n\\mu_0 \\cr \\mu_1 \\cr \\mu_2 \\cr \\vdots \\cr \\mu_{T-1} \\cr \\mu_T\n\\end{bmatrix}\n+ \\begin{bmatrix} \nm_0 \\cr 0 \\cr 0 \\cr \\vdots \\cr 0 \\cr 0\n\\end{bmatrix}\n\nMultiplying both sides of equation \n\n(11) with the inverse of the matrix on the left will givem_t = m_0 + \\sum_{s=0}^{t-1} \\mu_s, \\quad t =1, \\ldots, T+1\n\nEquation \n\n(12) shows that the log of the money supply at t equals the log of the initial money supply m_0\nplus accumulation of rates of money growth between times 0 and T.","type":"content","url":"/cagan-ree#structure-of-the-model","position":5},{"hierarchy":{"lvl1":"A Monetarist Theory of Price Levels","lvl2":"Continuation values"},"type":"lvl2","url":"/cagan-ree#continuation-values","position":6},{"hierarchy":{"lvl1":"A Monetarist Theory of Price Levels","lvl2":"Continuation values"},"content":"To determine the continuation inflation rate \\pi_{T+1}^* we shall proceed by applying the following infinite-horizon\nversion of equation \n\n(9) at time t = T+1:\\pi_t = (1-\\delta) \\sum_{s=t}^\\infty \\delta^{s-t} \\mu_s ,\n\nand by also assuming the following continuation path for \\mu_t beyond T:\\mu_{t+1} = \\gamma^* \\mu_t, \\quad t \\geq T .\n\nPlugging the preceding equation into equation \n\n(13) at t = T+1 and rearranging we can deduce that\\pi_{T+1}^* = \\frac{1 - \\delta}{1 - \\delta \\gamma^*} \\gamma^* \\mu_T\n\nwhere we require that \\vert \\gamma^* \\delta \\vert < 1.\n\nLet’s implement and solve this model.\n\nAs usual, we’ll start by importing some Python modules.\n\nimport numpy as np\nfrom collections import namedtuple\nimport matplotlib.pyplot as plt\n\nFirst, we store parameters in a namedtuple:\n\n# Create the rational expectation version of Cagan model in finite time\nCaganREE = namedtuple(\"CaganREE\", \n                        [\"m0\",    # initial money supply\n                         \"μ_seq\", # sequence of rate of growth\n                         \"α\",     # sensitivity parameter\n                         \"δ\",     # α/(1 + α)\n                         \"π_end\"  # terminal expected inflation\n                        ])\n\ndef create_cagan_model(m0=1, α=5, μ_seq=None):\n    δ = α/(1 + α)\n    π_end = μ_seq[-1]    # compute terminal expected inflation\n    return CaganREE(m0, μ_seq, α, δ, π_end)\n\nNow we can solve the model to compute \\pi_t, m_t and p_t for t =1, \\ldots, T+1 using the matrix equation above\n\ndef solve(model, T):\n    m0, π_end, μ_seq, α, δ = (model.m0, model.π_end, \n                              model.μ_seq, model.α, model.δ)\n    \n    # Create matrix representation above\n    A1 = np.eye(T+1, T+1) - δ * np.eye(T+1, T+1, k=1)\n    A2 = np.eye(T+1, T+1) - np.eye(T+1, T+1, k=-1)\n\n    b1 = (1-δ) * μ_seq + np.concatenate([np.zeros(T), [δ * π_end]])\n    b2 = μ_seq + np.concatenate([[m0], np.zeros(T)])\n\n    π_seq = np.linalg.solve(A1, b1)\n    m_seq = np.linalg.solve(A2, b2)\n\n    π_seq = np.append(π_seq, π_end)\n    m_seq = np.append(m0, m_seq)\n\n    p_seq = m_seq + α * π_seq\n\n    return π_seq, m_seq, p_seq\n\n","type":"content","url":"/cagan-ree#continuation-values","position":7},{"hierarchy":{"lvl1":"A Monetarist Theory of Price Levels","lvl3":"Some quantitative experiments","lvl2":"Continuation values"},"type":"lvl3","url":"/cagan-ree#some-quantitative-experiments","position":8},{"hierarchy":{"lvl1":"A Monetarist Theory of Price Levels","lvl3":"Some quantitative experiments","lvl2":"Continuation values"},"content":"In the experiments below, we’ll use formula \n\n(15) as our terminal condition for expected inflation.\n\nIn devising these experiments, we’ll make assumptions about \\{\\mu_t\\} that are consistent with formula\n\n\n(15).\n\nWe  describe several such experiments.\n\nIn all of them,\\mu_t = \\mu^* , \\quad t \\geq T_1\n\nso that, in terms of our notation and formula for \\pi_{T+1}^* above, \\gamma^* = 1.","type":"content","url":"/cagan-ree#some-quantitative-experiments","position":9},{"hierarchy":{"lvl1":"A Monetarist Theory of Price Levels","lvl4":"Experiment 1: Foreseen sudden stabilization","lvl3":"Some quantitative experiments","lvl2":"Continuation values"},"type":"lvl4","url":"/cagan-ree#experiment-1-foreseen-sudden-stabilization","position":10},{"hierarchy":{"lvl1":"A Monetarist Theory of Price Levels","lvl4":"Experiment 1: Foreseen sudden stabilization","lvl3":"Some quantitative experiments","lvl2":"Continuation values"},"content":"In this experiment, we’ll study how, when \\alpha >0, a foreseen inflation stabilization has effects on inflation that proceed it.\n\nWe’ll study a situation in which the rate of growth of the money supply is \\mu_0\nfrom t=0 to t= T_1 and then permanently falls to \\mu^* at t=T_1.\n\nThus, let T_1 \\in (0, T).\n\nSo where \\mu_0 > \\mu^*, we assume that\\mu_{t+1} = \\begin{cases}\n    \\mu_0  , & t = 0, \\ldots, T_1 -1 \\\\\n     \\mu^* , & t \\geq T_1\n     \\end{cases}\n\nWe’ll start by executing a version of our “experiment 1” in which the government implements a foreseen sudden permanent reduction in the rate of money creation at time T_1.\n\nLet’s experiment with the following parameters\n\nT1 = 60\nμ0 = 0.5\nμ_star = 0\nT = 80\n\nμ_seq_1 = np.append(μ0*np.ones(T1+1), μ_star*np.ones(T-T1))\n\ncm = create_cagan_model(μ_seq=μ_seq_1)\n\n# solve the model\nπ_seq_1, m_seq_1, p_seq_1 = solve(cm, T)\n\nNow we use the following function to plot the result\n\ndef plot_sequences(sequences, labels):\n    fig, axs = plt.subplots(len(sequences), 1, figsize=(5, 12), dpi=200)\n    for ax, seq, label in zip(axs, sequences, labels):\n        ax.plot(range(len(seq)), seq, label=label)\n        ax.set_ylabel(label)\n        ax.set_xlabel('$t$')\n        ax.legend()\n    plt.tight_layout()\n    plt.show()\n\nsequences = (μ_seq_1, π_seq_1, m_seq_1 - p_seq_1, m_seq_1, p_seq_1)\nplot_sequences(sequences, (r'$\\mu$', r'$\\pi$', r'$m - p$', r'$m$', r'$p$'))\n\nThe plot of the money growth rate \\mu_t in the top level panel portrays\na sudden reduction from .5 to 0 at time T_1 = 60.\n\nThis brings about a gradual reduction of the inflation rate \\pi_t that precedes the\nmoney supply growth rate reduction at time T_1.\n\nNotice how the inflation rate declines smoothly (i.e., continuously) to 0 at T_1 --\nunlike the money growth rate, it does not suddenly “jump” downward at T_1.\n\nThis is because the reduction in \\mu at T_1 has been foreseen from the start.\n\nWhile the log money supply portrayed in the bottom panel has a kink at T_1, the log price level does not -- it is “smooth” -- once again a consequence of the fact that the\nreduction in \\mu has been foreseen.\n\nTo set the stage for our next experiment, we want to study the determinants of the price level a little more.","type":"content","url":"/cagan-ree#experiment-1-foreseen-sudden-stabilization","position":11},{"hierarchy":{"lvl1":"A Monetarist Theory of Price Levels","lvl3":"The log price level","lvl2":"Continuation values"},"type":"lvl3","url":"/cagan-ree#the-log-price-level","position":12},{"hierarchy":{"lvl1":"A Monetarist Theory of Price Levels","lvl3":"The log price level","lvl2":"Continuation values"},"content":"We can use equations \n\n(1) and \n\n(2)\nto discover that the log of the price level satisfiesp_t = m_t + \\alpha \\pi_t\n\nor, by using equation \n\n(9),p_t = m_t + \\alpha \\left[ (1-\\delta) \\sum_{s=t}^T \\delta^{s-t} \\mu_s + \\delta^{T+1-t} \\pi_{T+1}^* \\right]\n\nIn our next experiment, we’ll study a “surprise” permanent change in the money growth that beforehand\nwas completely unanticipated.\n\nAt time T_1 when the “surprise” money growth rate change occurs, to satisfy\nequation \n\n(18), the log of real balances jumps\nupward as \\pi_t jumps downward.\n\nBut in order for m_t - p_t to jump, which variable jumps, m_{T_1} or p_{T_1}?\n\nWe’ll study that interesting question next.","type":"content","url":"/cagan-ree#the-log-price-level","position":13},{"hierarchy":{"lvl1":"A Monetarist Theory of Price Levels","lvl3":"What jumps?","lvl2":"Continuation values"},"type":"lvl3","url":"/cagan-ree#what-jumps","position":14},{"hierarchy":{"lvl1":"A Monetarist Theory of Price Levels","lvl3":"What jumps?","lvl2":"Continuation values"},"content":"What jumps at T_1?\n\nIs it p_{T_1} or m_{T_1}?\n\nIf we insist that the money supply m_{T_1} is locked at its value m_{T_1}^1 inherited from the past, then formula \n\n(18) implies that the price level jumps downward at time T_1, to coincide with the downward jump in\n\\pi_{T_1}\n\nAn alternative assumption about the money supply level is that as part of the “inflation stabilization”,\nthe government resets m_{T_1} according tom_{T_1}^2 - m_{T_1}^1 = \\alpha (\\pi_{T_1}^1 - \\pi_{T_1}^2),\n\nwhich describes how the government could reset the money supply at T_1 in response to the jump in expected inflation associated with monetary stabilization.\n\nDoing this would let the price level be continuous at T_1.\n\nBy letting money jump according to equation \n\n(20) the monetary authority prevents the price level from falling at the moment that the unanticipated stabilization arrives.\n\nIn various research papers about stabilizations of high inflations, the jump in the money supply described by equation \n\n(20) has been called\n“the velocity dividend” that a government reaps from implementing a regime change that sustains a permanently lower inflation rate.","type":"content","url":"/cagan-ree#what-jumps","position":15},{"hierarchy":{"lvl1":"A Monetarist Theory of Price Levels","lvl4":"Technical details about whether p or m jumps at T_1","lvl3":"What jumps?","lvl2":"Continuation values"},"type":"lvl4","url":"/cagan-ree#technical-details-about-whether-p-or-m-jumps-at-t-1","position":16},{"hierarchy":{"lvl1":"A Monetarist Theory of Price Levels","lvl4":"Technical details about whether p or m jumps at T_1","lvl3":"What jumps?","lvl2":"Continuation values"},"content":"We have noted that with a constant expected forward sequence \\mu_s = \\bar \\mu for s\\geq t, \\pi_{t} =\\bar{\\mu}.\n\nA consequence is that at T_1, either m or p must “jump” at T_1.\n\nWe’ll study both cases.","type":"content","url":"/cagan-ree#technical-details-about-whether-p-or-m-jumps-at-t-1","position":17},{"hierarchy":{"lvl1":"A Monetarist Theory of Price Levels","lvl4":"m_{T_{1}} does not jump.","lvl3":"What jumps?","lvl2":"Continuation values"},"type":"lvl4","url":"/cagan-ree#m-t-1-does-not-jump","position":18},{"hierarchy":{"lvl1":"A Monetarist Theory of Price Levels","lvl4":"m_{T_{1}} does not jump.","lvl3":"What jumps?","lvl2":"Continuation values"},"content":"\\begin{aligned}\nm_{T_{1}}&=m_{T_{1}-1}+\\mu_{0}\\\\\\pi_{T_{1}}&=\\mu^{*}\\\\p_{T_{1}}&=m_{T_{1}}+\\alpha\\pi_{T_{1}}\n\\end{aligned}\n\nSimply glue the sequences t\\leq T_1 and t > T_1.","type":"content","url":"/cagan-ree#m-t-1-does-not-jump","position":19},{"hierarchy":{"lvl1":"A Monetarist Theory of Price Levels","lvl4":"m_{T_{1}} jumps.","lvl3":"What jumps?","lvl2":"Continuation values"},"type":"lvl4","url":"/cagan-ree#m-t-1-jumps","position":20},{"hierarchy":{"lvl1":"A Monetarist Theory of Price Levels","lvl4":"m_{T_{1}} jumps.","lvl3":"What jumps?","lvl2":"Continuation values"},"content":"We reset m_{T_{1}} so that p_{T_{1}}=\\left(m_{T_{1}-1}+\\mu_{0}\\right)+\\alpha\\mu_{0}, with \\pi_{T_{1}}=\\mu^{*}.\n\nThen,m_{T_{1}}=p_{T_{1}}-\\alpha\\pi_{T_{1}}=\\left(m_{T_{1}-1}+\\mu_{0}\\right)+\\alpha\\left(\\mu_{0}-\\mu^{*}\\right)\n\nWe then compute for the remaining T-T_{1} periods with \\mu_{s}=\\mu^{*},\\forall s\\geq T_{1} and the initial condition m_{T_{1}} from above.\n\nWe are now technically equipped to discuss our next experiment.","type":"content","url":"/cagan-ree#m-t-1-jumps","position":21},{"hierarchy":{"lvl1":"A Monetarist Theory of Price Levels","lvl4":"Experiment 2: an unforeseen sudden stabilization","lvl3":"What jumps?","lvl2":"Continuation values"},"type":"lvl4","url":"/cagan-ree#experiment-2-an-unforeseen-sudden-stabilization","position":22},{"hierarchy":{"lvl1":"A Monetarist Theory of Price Levels","lvl4":"Experiment 2: an unforeseen sudden stabilization","lvl3":"What jumps?","lvl2":"Continuation values"},"content":"This experiment deviates a little bit from a pure version of our “perfect foresight”\nassumption by assuming that a sudden permanent reduction in \\mu_t like that\nanalyzed in experiment 1 is completely unanticipated.\n\nSuch a completely unanticipated shock is popularly known as an “MIT shock”.\n\nThe mental experiment involves switching at time T_1 from an initial “continuation path” for \\{\\mu_t, \\pi_t\\}  to another path that involves a permanently lower inflation rate.\n\nInitial Path: \\mu_t = \\mu_0 for all t \\geq 0. So this path is for \\{\\mu_t\\}_{t=0}^\\infty; the associated\npath for \\pi_t has \\pi_t = \\mu_0.\n\nRevised Continuation Path Where  \\mu_0 > \\mu^*, we construct a continuation path \\{\\mu_s\\}_{s=T_1}^\\infty\nby setting \\mu_s = \\mu^* for all s \\geq T_1. The perfect foresight continuation path for\n\\pi is \\pi_s = \\mu^*\n\nTo capture a \"completely unanticipated permanent shock to the \\{\\mu_t\\} process at time T_1, we simply glue the \\mu_t, \\pi_t\nthat emerges under path 2 for t \\geq T_1 to the \\mu_t, \\pi_t path that had emerged under path 1 for  t=0, \\ldots,\nT_1 -1.\n\nWe can do the MIT shock calculations mostly by hand.\n\nThus, for path 1, \\pi_t = \\mu_0  for all t \\in [0, T_1-1], while for path 2,\n\\mu_s = \\mu^* for all s \\geq T_1.\n\nWe now move on to experiment 2, our “MIT shock”, completely unforeseen\nsudden stabilization.\n\nWe set this up so that the \\{\\mu_t\\} sequences that describe the sudden stabilization\nare identical to those for experiment 1, the foreseen sudden stabilization.\n\nThe following code does the calculations and plots outcomes.\n\n# path 1\nμ_seq_2_path1 = μ0 * np.ones(T+1)\n\ncm1 = create_cagan_model(μ_seq=μ_seq_2_path1)\nπ_seq_2_path1, m_seq_2_path1, p_seq_2_path1 = solve(cm1, T)\n\n# continuation path\nμ_seq_2_cont = μ_star * np.ones(T-T1)\n\ncm2 = create_cagan_model(m0=m_seq_2_path1[T1+1], \n                         μ_seq=μ_seq_2_cont)\nπ_seq_2_cont, m_seq_2_cont1, p_seq_2_cont1 = solve(cm2, T-1-T1)\n\n\n# regime 1 - simply glue π_seq, μ_seq\nμ_seq_2 = np.concatenate((μ_seq_2_path1[:T1+1],\n                          μ_seq_2_cont))\nπ_seq_2 = np.concatenate((π_seq_2_path1[:T1+1], \n                          π_seq_2_cont))\nm_seq_2_regime1 = np.concatenate((m_seq_2_path1[:T1+1], \n                                  m_seq_2_cont1))\np_seq_2_regime1 = np.concatenate((p_seq_2_path1[:T1+1], \n                                  p_seq_2_cont1))\n\n# regime 2 - reset m_T1\nm_T1 = (m_seq_2_path1[T1] + μ0) + cm2.α*(μ0 - μ_star)\n\ncm3 = create_cagan_model(m0=m_T1, μ_seq=μ_seq_2_cont)\nπ_seq_2_cont2, m_seq_2_cont2, p_seq_2_cont2 = solve(cm3, T-1-T1)\n\nm_seq_2_regime2 = np.concatenate((m_seq_2_path1[:T1+1], \n                                  m_seq_2_cont2))\np_seq_2_regime2 = np.concatenate((p_seq_2_path1[:T1+1],\n                                  p_seq_2_cont2))\n\nT_seq = range(T+2)\n\n# plot both regimes\nfig, ax = plt.subplots(5, 1, figsize=(5, 12), dpi=200)\n\n# Configuration for each subplot\nplot_configs = [\n    {'data': [(T_seq[:-1], μ_seq_2)], 'ylabel': r'$\\mu$'},\n    {'data': [(T_seq, π_seq_2)], 'ylabel': r'$\\pi$'},\n    {'data': [(T_seq, m_seq_2_regime1 - p_seq_2_regime1)], \n     'ylabel': r'$m - p$'},\n    {'data': [(T_seq, m_seq_2_regime1, 'Smooth $m_{T_1}$'), \n              (T_seq, m_seq_2_regime2, 'Jumpy $m_{T_1}$')], \n     'ylabel': r'$m$'},\n    {'data': [(T_seq, p_seq_2_regime1, 'Smooth $p_{T_1}$'), \n              (T_seq, p_seq_2_regime2, 'Jumpy $p_{T_1}$')], \n     'ylabel': r'$p$'}\n]\n\ndef experiment_plot(plot_configs, ax):\n    # Loop through each subplot configuration\n    for axi, config in zip(ax, plot_configs):\n        for data in config['data']:\n            if len(data) == 3:  # Plot with label for legend\n                axi.plot(data[0], data[1], label=data[2])\n                axi.legend()\n            else:  # Plot without label\n                axi.plot(data[0], data[1])\n        axi.set_ylabel(config['ylabel'])\n        axi.set_xlabel(r'$t$')\n    plt.tight_layout()\n    plt.show()\n    \nexperiment_plot(plot_configs, ax)\n\nWe invite you to compare these graphs with corresponding ones for the foreseen stabilization analyzed in experiment 1 above.\n\nNote how the inflation graph in the second panel is now identical to the\nmoney growth graph in the top panel, and how now the log of real balances portrayed in the third panel jumps upward at time T_1.\n\nThe bottom two panels plot m and p under two possible ways that m_{T_1} might adjust\nas required by the upward jump in m - p at T_1.\n\nthe orange line lets m_{T_1} jump upward in order to make sure that the log price level p_{T_1} does not fall.\n\nthe blue line lets p_{T_1} fall while stopping the money supply from jumping.\n\nHere is a way to interpret what the government is doing when the orange line policy is in place.\n\nThe government prints money to finance expenditure with the “velocity dividend” that it reaps from the increased demand for real balances brought about by the permanent decrease in the rate of growth of the money supply.\n\nThe next code generates a multi-panel graph that includes outcomes of both experiments 1 and 2.\n\nThat allows us to assess how important it is to understand whether the sudden permanent drop in \\mu_t at t=T_1 is fully unanticipated, as in experiment 1, or completely\nunanticipated, as in experiment 2.\n\n# compare foreseen vs unforeseen shock\nfig, ax = plt.subplots(5, figsize=(5, 12), dpi=200)\n\nplot_configs = [\n    {'data': [(T_seq[:-1], μ_seq_2)], 'ylabel': r'$\\mu$'},\n    {'data': [(T_seq, π_seq_2, 'Unforeseen'), \n              (T_seq, π_seq_1, 'Foreseen')], 'ylabel': r'$p$'},\n    {'data': [(T_seq, m_seq_2_regime1 - p_seq_2_regime1, 'Unforeseen'), \n              (T_seq, m_seq_1 - p_seq_1, 'Foreseen')], 'ylabel': r'$m - p$'},\n    {'data': [(T_seq, m_seq_2_regime1, 'Unforeseen (Smooth $m_{T_1}$)'), \n              (T_seq, m_seq_2_regime2, 'Unforeseen ($m_{T_1}$ jumps)'),\n              (T_seq, m_seq_1, 'Foreseen')], 'ylabel': r'$m$'},   \n    {'data': [(T_seq, p_seq_2_regime1, 'Unforeseen (Smooth $m_{T_1}$)'), \n          (T_seq, p_seq_2_regime2, 'Unforeseen ($m_{T_1}$ jumps)'),\n          (T_seq, p_seq_1, 'Foreseen')], 'ylabel': r'$p$'}   \n]\n\nexperiment_plot(plot_configs, ax)\n\nIt is instructive to compare the preceding graphs with graphs of log price levels and inflation rates for data from four big inflations described in\n\n\nthis lecture.\n\nIn particular, in the above graphs, notice how a gradual fall in inflation precedes the “sudden stop” when it has been anticipated long beforehand, but how\ninflation instead falls abruptly when the permanent drop in money supply growth is unanticipated.\n\nIt seems to the author team at quantecon that the drops in inflation near the ends of the four hyperinflations described in \n\nthis lecture\nmore closely resemble outcomes from the experiment 2 “unforeseen stabilization”.\n\n(It is fair to say that the preceding informal pattern recognition exercise should be supplemented with a more formal structural statistical analysis.)","type":"content","url":"/cagan-ree#experiment-2-an-unforeseen-sudden-stabilization","position":23},{"hierarchy":{"lvl1":"A Monetarist Theory of Price Levels","lvl4":"Experiment 3","lvl3":"What jumps?","lvl2":"Continuation values"},"type":"lvl4","url":"/cagan-ree#experiment-3","position":24},{"hierarchy":{"lvl1":"A Monetarist Theory of Price Levels","lvl4":"Experiment 3","lvl3":"What jumps?","lvl2":"Continuation values"},"content":"Foreseen gradual stabilization\n\nInstead of a foreseen sudden stabilization of the type studied with experiment 1,\nit is also interesting to study the consequences of a foreseen gradual stabilization.\n\nThus, suppose that \\phi \\in (0,1), that \\mu_0 > \\mu^*, and that for t = 0, \\ldots, T-1\\mu_t = \\phi^t \\mu_0 + (1 - \\phi^t) \\mu^* .\n\nNext we perform an experiment in which there is a perfectly foreseen gradual decrease in the rate of growth of the money supply.\n\nThe following code does the calculations and plots the results.\n\n# parameters\nϕ = 0.9\nμ_seq_stab = np.array([ϕ**t * μ0 + (1-ϕ**t)*μ_star for t in range(T)])\nμ_seq_stab = np.append(μ_seq_stab, μ_star)\n\ncm4 = create_cagan_model(μ_seq=μ_seq_stab)\n\nπ_seq_4, m_seq_4, p_seq_4 = solve(cm4, T)\n\nsequences = (μ_seq_stab, π_seq_4, \n             m_seq_4 - p_seq_4, m_seq_4, p_seq_4)\nplot_sequences(sequences, (r'$\\mu$', r'$\\pi$', \n                           r'$m - p$', r'$m$', r'$p$'))\n\n","type":"content","url":"/cagan-ree#experiment-3","position":25},{"hierarchy":{"lvl1":"A Monetarist Theory of Price Levels","lvl2":"Sequel"},"type":"lvl2","url":"/cagan-ree#sequel","position":26},{"hierarchy":{"lvl1":"A Monetarist Theory of Price Levels","lvl2":"Sequel"},"content":"Another lecture \n\nmonetarist theory of price levels with adaptive expectations describes an “adaptive expectations” version of Cagan’s model.\n\nThe dynamics become more complicated and so does the algebra.\n\nNowadays, the “rational expectations” version of the model is more popular among central bankers and economists advising them.","type":"content","url":"/cagan-ree#sequel","position":27},{"hierarchy":{"lvl1":"The Cobweb Model"},"type":"lvl1","url":"/cobweb","position":0},{"hierarchy":{"lvl1":"The Cobweb Model"},"content":"The cobweb model is a model of prices and quantities in a given market, and how they evolve over time.","type":"content","url":"/cobweb","position":1},{"hierarchy":{"lvl1":"The Cobweb Model","lvl2":"Overview"},"type":"lvl2","url":"/cobweb#overview","position":2},{"hierarchy":{"lvl1":"The Cobweb Model","lvl2":"Overview"},"content":"The cobweb model dates back to the 1930s and, while simple, it remains significant\nbecause it shows the fundamental importance of expectations.\n\nTo give some idea of how the model operates, and why expectations matter, imagine the following scenario.\n\nThere is a market for soybeans, say, where prices and traded quantities\ndepend on the choices of buyers and sellers.\n\nThe buyers are represented by a demand curve --- they buy more at low prices\nand less at high prices.\n\nThe sellers have a supply curve --- they wish to sell more at high prices and\nless at low prices.\n\nHowever, the sellers (who are farmers) need time to grow their crops.\n\nSuppose now that the price is currently high.\n\nSeeing this high price, and perhaps expecting that the high price will remain\nfor some time, the farmers plant many fields with soybeans.\n\nNext period the resulting high supply floods the market, causing the price to drop.\n\nSeeing this low price, the farmers now shift out of soybeans, restricting\nsupply and causing the price to climb again.\n\nYou can imagine how these dynamics could cause cycles in prices and quantities\nthat persist over time.\n\nThe cobweb model puts these ideas into equations so we can try to quantify\nthem, and to study conditions under which cycles persist (or disappear).\n\nIn this lecture, we investigate and simulate the basic model under different\nassumptions regarding the way that producers form expectations.\n\nOur discussion and simulations draw on \n\nhigh quality lectures by \n\nCars Hommes.\n\nWe will use the following imports.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n","type":"content","url":"/cobweb#overview","position":3},{"hierarchy":{"lvl1":"The Cobweb Model","lvl2":"History"},"type":"lvl2","url":"/cobweb#history","position":4},{"hierarchy":{"lvl1":"The Cobweb Model","lvl2":"History"},"content":"Early papers on the cobweb cycle include \n\nWaugh (1964) and \n\nHarlow (1960).\n\nThe paper \n\nHarlow (1960) uses the cobweb theorem to explain the prices of hog in the US over 1920--1950.\n\nThe next plot replicates part of Figure 2 from that paper, which plots the price of hogs at yearly frequency.\n\nNotice the cyclical price dynamics, which match the kind of cyclical soybean price dynamics discussed above.\n\nhog_prices = [55, 57, 80, 70, 60, 65, 72, 65, 51, 49, 45, 80, 85,\n              78, 80, 68, 52, 65, 83, 78, 60, 62, 80, 87, 81, 70,\n              69, 65, 62, 85, 87, 65, 63, 75, 80, 62]\nyears = np.arange(1924, 1960)\nfig, ax = plt.subplots()\nax.plot(years, hog_prices, '-o', ms=4, label='hog price')\nax.set_xlabel('year')\nax.set_ylabel('dollars')\nax.legend()\nax.grid()\nplt.show()\n\n","type":"content","url":"/cobweb#history","position":5},{"hierarchy":{"lvl1":"The Cobweb Model","lvl2":"The model"},"type":"lvl2","url":"/cobweb#the-model","position":6},{"hierarchy":{"lvl1":"The Cobweb Model","lvl2":"The model"},"content":"Let’s return to our discussion of a hypothetical soybean market, where price is determined by supply and demand.\n\nWe suppose that demand for soybeans is given byD(p_t) = a - b p_t\n\nwhere a, b are nonnegative constants and p_t is the spot (i.e, current market) price at time t.\n\n(D(p_t) is the quantity demanded in some fixed unit, such as thousands of tons.)\n\nBecause the crop of soybeans for time t is planted at t-1, supply of soybeans at time t depends on expected prices at time t, which we denote p^e_t.\n\nWe suppose that supply is nonlinear in expected prices, and takes the formS(p^e_t) = \\tanh(\\lambda(p^e_t - c)) + d\n\nwhere \\lambda is a positive constant, c, d are nonnegative constants and \\tanh is a type of \n\nhyperbolic function.\n\nLet’s make a plot of supply and demand for particular choices of the parameter values.\n\nFirst we store the parameters in a class and define the functions above as methods.\n\nclass Market:\n\n    def __init__(self,\n                 a=8,      # demand parameter\n                 b=1,      # demand parameter\n                 c=6,      # supply parameter\n                 d=1,      # supply parameter\n                 λ=2.0):   # supply parameter\n        self.a, self.b, self.c, self.d = a, b, c, d\n        self.λ = λ\n\n    def demand(self, p):\n        a, b = self.a, self.b\n        return a - b * p\n\n    def supply(self, p):\n        c, d, λ = self.c, self.d, self.λ\n        return np.tanh(λ * (p - c)) + d\n\nNow let’s plot.\n\np_grid = np.linspace(5, 8, 200)\nm = Market()\nfig, ax = plt.subplots()\n\nax.plot(p_grid, m.demand(p_grid), label=\"$D$\")\nax.plot(p_grid, m.supply(p_grid), label=\"$S$\")\nax.set_xlabel(\"price\")\nax.set_ylabel(\"quantity\")\nax.legend()\n\nplt.show()\n\nMarket equilibrium requires that supply equals demand, ora - b p_t = S(p^e_t)\n\nRewriting in terms of p_t givesp_t = - \\frac{1}{b} [S(p^e_t) - a]\n\nFinally, to complete the model, we need to describe how price expectations are formed.\n\nWe will assume that expected prices at time t depend on past prices.\n\nIn particular, we suppose that    p^e_t = f(p_{t-1}, p_{t-2})\n\nwhere f is some function.\n\nThus, we are assuming that producers expect the time-t price to be some function of lagged prices, up to 2 lags.\n\n(We could of course add additional lags and readers are encouraged to experiment with such cases.)\n\nCombining the last two equations gives the dynamics for prices:    p_t = - \\frac{1}{b} [ S(f(p_{t-1}, p_{t-2})) - a]\n\nThe price dynamics depend on the parameter values and also on the function f that determines how producers form expectations.","type":"content","url":"/cobweb#the-model","position":7},{"hierarchy":{"lvl1":"The Cobweb Model","lvl2":"Naive expectations"},"type":"lvl2","url":"/cobweb#naive-expectations","position":8},{"hierarchy":{"lvl1":"The Cobweb Model","lvl2":"Naive expectations"},"content":"To go further in our analysis we need to specify the function f; that is, how expectations are formed.\n\nLet’s start with naive expectations, which refers to the case where producers expect the next period spot price to be whatever the price is in the current period.\n\nIn other words,p_t^e = p_{t-1}\n\nUsing \n\n(6), we then havep_t = - \\frac{1}{b} [ S(p_{t-1}) - a]\n\nWe can write this asp_t = g(p_{t-1})\n\nwhere g is the function defined by    g(p) = - \\frac{1}{b} [ S(p) - a]\n\nHere we represent the function g\n\ndef g(model, current_price):\n    \"\"\"\n    Function to find the next price given the current price\n    and Market model\n    \"\"\"\n    a, b = model.a, model.b\n    next_price = - (model.supply(current_price) - a) / b\n    return next_price\n\nLet’s try to understand how prices will evolve using a 45-degree diagram, which is a tool for studying one-dimensional dynamics.\n\nThe function plot45 defined below helps us draw the 45-degree diagram.\n\ndef plot45(model, pmin, pmax, p0, num_arrows=5):\n    \"\"\"\n    Function to plot a 45 degree plot\n\n    Parameters\n    ==========\n\n    model: Market model\n\n    pmin: Lower price limit\n\n    pmax: Upper price limit\n\n    p0: Initial value of price (needed to simulate prices)\n\n    num_arrows: Number of simulations to plot\n    \"\"\"\n    pgrid = np.linspace(pmin, pmax, 200)\n\n    fig, ax = plt.subplots()\n    ax.set_xlim(pmin, pmax)\n    ax.set_ylim(pmin, pmax)\n\n    hw = (pmax - pmin) * 0.01\n    hl = 2 * hw\n    arrow_args = dict(fc=\"k\", ec=\"k\", head_width=hw,\n            length_includes_head=True, lw=1,\n            alpha=0.6, head_length=hl)\n\n    ax.plot(pgrid, g(model, pgrid), 'b-',\n            lw=2, alpha=0.6, label='g')\n    ax.plot(pgrid, pgrid, lw=1, alpha=0.7, label=r'$45\\degree$')\n\n    x = p0\n    xticks = [pmin]\n    xtick_labels = [pmin]\n\n    for i in range(num_arrows):\n        if i == 0:\n            ax.arrow(x, 0.0, 0.0, g(model, x),\n                     **arrow_args)\n        else:\n            ax.arrow(x, x, 0.0, g(model, x) - x,\n                     **arrow_args)\n            ax.plot((x, x), (0, x), ls='dotted')\n\n        ax.arrow(x, g(model, x),\n                 g(model, x) - x, 0, **arrow_args)\n        xticks.append(x)\n        xtick_labels.append(r'$p_{}$'.format(str(i)))\n\n        x = g(model, x)\n        xticks.append(x)\n        xtick_labels.append(r'$p_{}$'.format(str(i+1)))\n        ax.plot((x, x), (0, x), '->', alpha=0.5, color='orange')\n\n    xticks.append(pmax)\n    xtick_labels.append(pmax)\n    ax.set_ylabel(r'$p_{t+1}$')\n    ax.set_xlabel(r'$p_t$')\n    ax.set_xticks(xticks)\n    ax.set_yticks(xticks)\n    ax.set_xticklabels(xtick_labels)\n    ax.set_yticklabels(xtick_labels)\n\n    bbox = (0., 1.04, 1., .104)\n    legend_args = {'bbox_to_anchor': bbox, 'loc': 'upper right'}\n\n    ax.legend(ncol=2, frameon=False, **legend_args, fontsize=14)\n    plt.show()\n\nNow we can set up a market and plot the 45-degree diagram.\n\nm = Market()\n\nplot45(m, 0, 9, 2, num_arrows=3)\n\nThe plot shows the function g defined in \n\n(10) and the 45-degree line.\n\nThink of  p_t  as a value on the horizontal axis.\n\nSince p_{t+1} = g(p_t), we use the graph of g to see p_{t+1} on the vertical axis.\n\nClearly,\n\nIf  g  lies above the 45-degree line at p_t, then we have  p_{t+1} > p_t .\n\nIf  g  lies below the 45-degree line at p_t, then we have  p_{t+1} < p_t .\n\nIf  g  hits the 45-degree line at p_t, then we have  p_{t+1} = p_t , so  p_t  is a steady state.\n\nConsider the sequence of prices starting at p_0, as shown in the figure.\n\nWe find p_1 on the vertical axis and then shift it to the horizontal axis using the 45-degree line (where values on the two axes are equal).\n\nThen from p_1 we obtain p_2 and continue.\n\nWe can see the start of a cycle.\n\nTo confirm this, let’s plot a time series.\n\ndef ts_plot_price(model,             # Market model\n                  p0,                # Initial price\n                  y_a=3, y_b= 12,    # Controls y-axis\n                  ts_length=10):     # Length of time series\n    \"\"\"\n    Function to simulate and plot the time series of price.\n\n    \"\"\"\n    fig, ax = plt.subplots()\n    ax.set_xlabel(r'$t$', fontsize=12)\n    ax.set_ylabel(r'$p_t$', fontsize=12)\n    p = np.empty(ts_length)\n    p[0] = p0\n    for t in range(1, ts_length):\n        p[t] = g(model, p[t-1])\n    ax.plot(np.arange(ts_length),\n            p,\n            'bo-',\n            alpha=0.6,\n            lw=2,\n            label=r'$p_t$')\n    ax.legend(loc='best', fontsize=10)\n    ax.set_ylim(y_a, y_b)\n    ax.set_xticks(np.arange(ts_length))\n    plt.show()\n\nts_plot_price(m, 4, ts_length=15)\n\nWe see that a cycle has formed and the cycle is persistent.\n\n(You can confirm this by plotting over a longer time horizon.)\n\nThe cycle is “stable”, in the sense that prices converge to it from most starting conditions.\n\nFor example,\n\nts_plot_price(m, 10, ts_length=15)\n\n","type":"content","url":"/cobweb#naive-expectations","position":9},{"hierarchy":{"lvl1":"The Cobweb Model","lvl2":"Adaptive expectations"},"type":"lvl2","url":"/cobweb#adaptive-expectations","position":10},{"hierarchy":{"lvl1":"The Cobweb Model","lvl2":"Adaptive expectations"},"content":"Naive expectations are quite simple and also important in driving the cycle that we found.\n\nWhat if expectations are formed in a different way?\n\nNext we consider adaptive expectations.\n\nThis refers to the case where producers form expectations for\nthe next period price as a weighted average of their last guess and the\ncurrent spot price.\n\nThat is,p_t^e = \\alpha p_{t-1} + (1-\\alpha) p^e_{t-1}\n\\qquad (0 \\leq \\alpha \\leq 1)\n\nAnother way to write this isp_t^e = p^e_{t-1} + \\alpha (p_{t-1} - p_{t-1}^e)\n\nThis equation helps to show that expectations shift\n\nup when prices last period were above expectations\n\ndown when prices last period were below expectations\n\nUsing \n\n(11), we obtain the dynamicsp_t = - \\frac{1}{b} [ S(\\alpha p_{t-1} + (1-\\alpha) p^e_{t-1}) - a]\n\nLet’s try to simulate the price and observe the dynamics using different values of \\alpha.\n\ndef find_next_price_adaptive(model, curr_price_exp):\n    \"\"\"\n    Function to find the next price given the current price expectation\n    and Market model\n    \"\"\"\n    return - (model.supply(curr_price_exp) - model.a) / model.b\n\nThe function below plots price dynamics under adaptive expectations for different values of \\alpha.\n\ndef ts_price_plot_adaptive(model, p0, ts_length=10, α=[1.0, 0.9, 0.75]):\n    fig, axs = plt.subplots(1, len(α), figsize=(12, 5))\n    for i_plot, a in enumerate(α):\n        pe_last = p0\n        p_values = np.empty(ts_length)\n        p_values[0] = p0\n        for i in range(1, ts_length):\n            p_values[i] = find_next_price_adaptive(model, pe_last)\n            pe_last = a*p_values[i] + (1 - a)*pe_last\n\n        axs[i_plot].plot(np.arange(ts_length), p_values)\n        axs[i_plot].set_title(r'$\\alpha={}$'.format(a))\n        axs[i_plot].set_xlabel('t')\n        axs[i_plot].set_ylabel('price')\n    plt.show()\n\nLet’s call the function with prices starting at p_0 = 5.\n\nts_price_plot_adaptive(m, 5, ts_length=30)\n\nNote that if \\alpha=1, then adaptive expectations are just naive expectation.\n\nDecreasing the value of \\alpha shifts more weight to the previous\nexpectations, which stabilizes expected prices.\n\nThis increased stability can be seen in the figures.","type":"content","url":"/cobweb#adaptive-expectations","position":11},{"hierarchy":{"lvl1":"The Cobweb Model","lvl2":"Exercises"},"type":"lvl2","url":"/cobweb#exercises","position":12},{"hierarchy":{"lvl1":"The Cobweb Model","lvl2":"Exercises"},"content":"Using the default Market class and naive expectations, plot a time series simulation of supply (rather than the price).\n\nShow, in particular, that supply also cycles.\n\nSolution to \n\nExercise 1\n\ndef ts_plot_supply(model, p0, ts_length=10):\n    \"\"\"\n    Function to simulate and plot the supply function\n    given the initial price.\n    \"\"\"\n    pe_last = p0\n    s_values = np.empty(ts_length)\n    for i in range(ts_length):\n        # store quantity\n        s_values[i] = model.supply(pe_last)\n        # update price\n        pe_last = - (s_values[i] - model.a) / model.b\n\n\n    fig, ax = plt.subplots()\n    ax.plot(np.arange(ts_length),\n            s_values,\n            'bo-',\n            alpha=0.6,\n            lw=2,\n            label=r'supply')\n\n    ax.legend(loc='best', fontsize=10)\n    ax.set_xticks(np.arange(ts_length))\n    ax.set_xlabel(\"time\")\n    ax.set_ylabel(\"quantity\")\n    plt.show()\n\nm = Market()\nts_plot_supply(m, 5, 15)\n\n\n\nBackward looking average expectations\n\nBackward looking average expectations refers to the case where producers form\nexpectations for the next period price as a linear combination of their last\nguess and the second last guess.\n\nThat is,p_t^e = \\alpha p_{t-1} + (1-\\alpha) p_{t-2}\n\nSimulate and plot the price dynamics for \\alpha \\in \\{0.1, 0.3, 0.5, 0.8\\} where p_0=1 and p_1=2.5.\n\nSolution to \n\nExercise 2\n\ndef find_next_price_blae(model, curr_price_exp):\n    \"\"\"\n    Function to find the next price given the current price expectation\n    and Market model\n    \"\"\"\n    return - (model.supply(curr_price_exp) - model.a) / model.b\n\ndef ts_plot_price_blae(model, p0, p1, alphas, ts_length=15):\n    \"\"\"\n    Function to simulate and plot the time series of price\n    using backward looking average expectations.\n    \"\"\"\n    fig, axes = plt.subplots(len(alphas), 1, figsize=(8, 16))\n\n    for ax, a in zip(axes.flatten(), alphas):\n        p = np.empty(ts_length)\n        p[0] = p0\n        p[1] = p1\n        for t in range(2, ts_length):\n            pe = a*p[t-1] + (1 - a)*p[t-2]\n            p[t] = -(model.supply(pe) - model.a) / model.b\n        ax.plot(np.arange(ts_length),\n                p,\n                'o-',\n                alpha=0.6,\n                label=r'$\\alpha={}$'.format(a))\n        ax.legend(loc='best', fontsize=10)\n        ax.set_xlabel(r'$t$', fontsize=12)\n        ax.set_ylabel(r'$p_t$', fontsize=12)\n    plt.show()\n\nm = Market()\nts_plot_price_blae(m, \n                   p0=5, \n                   p1=6, \n                   alphas=[0.1, 0.3, 0.5, 0.8], \n                   ts_length=20)\n\n","type":"content","url":"/cobweb#exercises","position":13},{"hierarchy":{"lvl1":"Complex Numbers and Trigonometry"},"type":"lvl1","url":"/complex-and-trig","position":0},{"hierarchy":{"lvl1":"Complex Numbers and Trigonometry"},"content":"","type":"content","url":"/complex-and-trig","position":1},{"hierarchy":{"lvl1":"Complex Numbers and Trigonometry","lvl2":"Overview"},"type":"lvl2","url":"/complex-and-trig#overview","position":2},{"hierarchy":{"lvl1":"Complex Numbers and Trigonometry","lvl2":"Overview"},"content":"This lecture introduces some elementary mathematics and trigonometry.\n\nUseful and interesting in its own right, these concepts reap substantial rewards when studying dynamics generated\nby linear difference equations or linear differential equations.\n\nFor example, these tools are keys to understanding outcomes attained by Paul\nSamuelson (1939) \n\nSamuelson (1939) in his classic paper on interactions\nbetween the investment accelerator and the Keynesian consumption function, our\ntopic in the lecture \n\nSamuelson Multiplier Accelerator.\n\nIn addition to providing foundations for Samuelson’s work and extensions of\nit, this lecture can be read as a stand-alone quick reminder of key results\nfrom elementary high school trigonometry.\n\nSo let’s dive in.","type":"content","url":"/complex-and-trig#overview","position":3},{"hierarchy":{"lvl1":"Complex Numbers and Trigonometry","lvl3":"Complex Numbers","lvl2":"Overview"},"type":"lvl3","url":"/complex-and-trig#complex-numbers","position":4},{"hierarchy":{"lvl1":"Complex Numbers and Trigonometry","lvl3":"Complex Numbers","lvl2":"Overview"},"content":"A complex number has a real part x and a purely imaginary part y.\n\nThe Euclidean, polar, and trigonometric forms of a complex number z are:z = x + iy = re^{i\\theta} = r(\\cos{\\theta} + i \\sin{\\theta})\n\nThe second equality above is known as Euler’s formula\n\nEuler contributed many other formulas too!\n\nThe complex conjugate \\bar z of z is defined as\\bar z = x - iy = r e^{-i \\theta} = r (\\cos{\\theta} - i \\sin{\\theta} )\n\nThe value x is the real part of z and y is the\nimaginary part of z.\n\nThe symbol | z | = \\sqrt{\\bar{z}\\cdot z} = r represents the modulus of z.\n\nThe value r is the Euclidean distance of vector (x,y) from the\norigin:r = |z| = \\sqrt{x^2 + y^2}\n\nThe value \\theta is the angle of (x,y) with respect to the real axis.\n\nEvidently, the tangent of \\theta is \\left(\\frac{y}{x}\\right).\n\nTherefore,\\theta = \\tan^{-1} \\Big( \\frac{y}{x} \\Big)\n\nThree elementary trigonometric functions are\\cos{\\theta} = \\frac{x}{r} = \\frac{e^{i\\theta} + e^{-i\\theta}}{2} , \\quad\n\\sin{\\theta} = \\frac{y}{r} = \\frac{e^{i\\theta} - e^{-i\\theta}}{2i} , \\quad\n\\tan{\\theta} = \\frac{y}{x}\n\nWe’ll need the following imports:\n\nimport matplotlib.pyplot as plt\nplt.rcParams[\"figure.figsize\"] = (11, 5)  #set default figure size\nimport numpy as np\nfrom sympy import (Symbol, symbols, Eq, nsolve, sqrt, cos, sin, simplify,\n                  init_printing, integrate)\n\n","type":"content","url":"/complex-and-trig#complex-numbers","position":5},{"hierarchy":{"lvl1":"Complex Numbers and Trigonometry","lvl3":"An Example","lvl2":"Overview"},"type":"lvl3","url":"/complex-and-trig#an-example","position":6},{"hierarchy":{"lvl1":"Complex Numbers and Trigonometry","lvl3":"An Example","lvl2":"Overview"},"content":"Consider the complex number z = 1 + \\sqrt{3} i.\n\nFor z = 1 + \\sqrt{3} i, x = 1, y = \\sqrt{3}.\n\nIt follows that r = 2 and\n\\theta = \\tan^{-1}(\\sqrt{3}) = \\frac{\\pi}{3} = 60^o.\n\nLet’s use Python to plot the trigonometric form of the complex number\nz = 1 + \\sqrt{3} i.\n\n# Abbreviate useful values and functions\nπ = np.pi\n\n\n# Set parameters\nr = 2\nθ = π/3\nx = r * np.cos(θ)\nx_range = np.linspace(0, x, 1000)\nθ_range = np.linspace(0, θ, 1000)\n\n# Plot\nfig = plt.figure(figsize=(8, 8))\nax = plt.subplot(111, projection='polar')\n\nax.plot((0, θ), (0, r), marker='o', color='b')          # Plot r\nax.plot(np.zeros(x_range.shape), x_range, color='b')       # Plot x\nax.plot(θ_range, x / np.cos(θ_range), color='b')        # Plot y\nax.plot(θ_range, np.full(θ_range.shape, 0.1), color='r')  # Plot θ\n\nax.margins(0) # Let the plot starts at origin\n\nax.set_title(\"Trigonometry of complex numbers\", va='bottom',\n    fontsize='x-large')\n\nax.set_rmax(2)\nax.set_rticks((0.5, 1, 1.5, 2))  # Less radial ticks\nax.set_rlabel_position(-88.5)    # Get radial labels away from plotted line\n\nax.text(θ, r+0.01 , r'$z = x + iy = 1 + \\sqrt{3}\\, i$')   # Label z\nax.text(θ+0.2, 1 , '$r = 2$')                             # Label r\nax.text(0-0.2, 0.5, '$x = 1$')                            # Label x\nax.text(0.5, 1.2, r'$y = \\sqrt{3}$')                      # Label y\nax.text(0.25, 0.15, r'$\\theta = 60^o$')                   # Label θ\n\nax.grid(True)\nplt.show()\n\n","type":"content","url":"/complex-and-trig#an-example","position":7},{"hierarchy":{"lvl1":"Complex Numbers and Trigonometry","lvl2":"De Moivre’s Theorem"},"type":"lvl2","url":"/complex-and-trig#de-moivres-theorem","position":8},{"hierarchy":{"lvl1":"Complex Numbers and Trigonometry","lvl2":"De Moivre’s Theorem"},"content":"de Moivre’s theorem states that:(r(\\cos{\\theta} + i \\sin{\\theta}))^n =\nr^n e^{in\\theta} =\nr^n(\\cos{n\\theta} + i \\sin{n\\theta})\n\nTo prove de Moivre’s theorem, note that(r(\\cos{\\theta} + i \\sin{\\theta}))^n = \\big( re^{i\\theta} \\big)^n\n\nand compute.","type":"content","url":"/complex-and-trig#de-moivres-theorem","position":9},{"hierarchy":{"lvl1":"Complex Numbers and Trigonometry","lvl2":"Applications of de Moivre’s Theorem"},"type":"lvl2","url":"/complex-and-trig#applications-of-de-moivres-theorem","position":10},{"hierarchy":{"lvl1":"Complex Numbers and Trigonometry","lvl2":"Applications of de Moivre’s Theorem"},"content":"","type":"content","url":"/complex-and-trig#applications-of-de-moivres-theorem","position":11},{"hierarchy":{"lvl1":"Complex Numbers and Trigonometry","lvl3":"Example 1","lvl2":"Applications of de Moivre’s Theorem"},"type":"lvl3","url":"/complex-and-trig#example-1","position":12},{"hierarchy":{"lvl1":"Complex Numbers and Trigonometry","lvl3":"Example 1","lvl2":"Applications of de Moivre’s Theorem"},"content":"We can use de Moivre’s theorem to show that\nr = \\sqrt{x^2 + y^2}.\n\nWe have\\begin{aligned}\n1 &= e^{i\\theta} e^{-i\\theta} \\\\\n&= (\\cos{\\theta} + i \\sin{\\theta})(\\cos{(\\text{-}\\theta)} + i \\sin{(\\text{-}\\theta)}) \\\\\n&= (\\cos{\\theta} + i \\sin{\\theta})(\\cos{\\theta} - i \\sin{\\theta}) \\\\\n&= \\cos^2{\\theta} + \\sin^2{\\theta} \\\\\n&= \\frac{x^2}{r^2} + \\frac{y^2}{r^2}\n\\end{aligned}\n\nand thusx^2 + y^2 = r^2\n\nWe recognize this as a theorem of Pythagoras.","type":"content","url":"/complex-and-trig#example-1","position":13},{"hierarchy":{"lvl1":"Complex Numbers and Trigonometry","lvl3":"Example 2","lvl2":"Applications of de Moivre’s Theorem"},"type":"lvl3","url":"/complex-and-trig#example-2","position":14},{"hierarchy":{"lvl1":"Complex Numbers and Trigonometry","lvl3":"Example 2","lvl2":"Applications of de Moivre’s Theorem"},"content":"Let z = re^{i\\theta} and \\bar{z} = re^{-i\\theta} so that \\bar{z} is the complex conjugate of z.\n\n(z, \\bar z) form a complex conjugate pair of complex numbers.\n\nLet a = pe^{i\\omega} and \\bar{a} = pe^{-i\\omega} be\nanother complex conjugate pair.\n\nFor each element of a sequence of integers n = 0, 1, 2, \\ldots, .\n\nTo do so, we can apply de Moivre’s formula.\n\nThus,\\begin{aligned}\nx_n &= az^n + \\bar{a}\\bar{z}^n \\\\\n&= p e^{i\\omega} (re^{i\\theta})^n + p e^{-i\\omega} (re^{-i\\theta})^n \\\\\n&= pr^n e^{i (\\omega + n\\theta)} + pr^n e^{-i (\\omega + n\\theta)} \\\\\n&= pr^n [\\cos{(\\omega + n\\theta)} + i \\sin{(\\omega + n\\theta)} +\n         \\cos{(\\omega + n\\theta)} - i \\sin{(\\omega + n\\theta)}] \\\\\n&= 2 pr^n \\cos{(\\omega + n\\theta)}\n\\end{aligned}","type":"content","url":"/complex-and-trig#example-2","position":15},{"hierarchy":{"lvl1":"Complex Numbers and Trigonometry","lvl3":"Example 3","lvl2":"Applications of de Moivre’s Theorem"},"type":"lvl3","url":"/complex-and-trig#example-3","position":16},{"hierarchy":{"lvl1":"Complex Numbers and Trigonometry","lvl3":"Example 3","lvl2":"Applications of de Moivre’s Theorem"},"content":"This example provides  machinery that is at the heard of Samuelson’s analysis of his multiplier-accelerator model \n\nSamuelson (1939).\n\nThus, consider a second-order linear difference equationx_{n+2} = c_1 x_{n+1} + c_2 x_n\n\nwhose characteristic polynomial isz^2 - c_1 z - c_2 = 0\n\nor(z^2 - c_1 z - c_2 ) = (z - z_1)(z- z_2) = 0\n\nhas roots z_1, z_1.\n\nA solution  is a sequence \\{x_n\\}_{n=0}^\\infty that satisfies\nthe difference equation.\n\nUnder the following circumstances, we can apply our example 2 formula to\nsolve the difference equation\n\nthe roots z_1, z_2 of the characteristic polynomial of the\ndifference equation form a complex conjugate pair\n\nthe values x_0, x_1 are given initial conditions\n\nTo solve the difference equation, recall from example 2 thatx_n = 2 pr^n \\cos{(\\omega + n\\theta)}\n\nwhere \\omega, p are coefficients to be determined from\ninformation encoded in the initial conditions x_1, x_0.\n\nSince\nx_0 = 2 p \\cos{\\omega} and x_1 = 2 pr \\cos{(\\omega + \\theta)}\nthe ratio of x_1 to x_0 is\\frac{x_1}{x_0} = \\frac{r \\cos{(\\omega + \\theta)}}{\\cos{\\omega}}\n\nWe can solve this equation for \\omega then solve for p using x_0 = 2 pr^0 \\cos{(\\omega + n\\theta)}.\n\nWith the sympy package in Python, we are able to solve and plot the\ndynamics of x_n given different values of n.\n\nIn this example, we set the initial values: - r = 0.9 -\n\\theta = \\frac{1}{4}\\pi - x_0 = 4 -\nx_1 = r \\cdot 2\\sqrt{2} = 1.8 \\sqrt{2}.\n\nWe first numerically solve for \\omega and p using\nnsolve in the sympy package based on the above initial\ncondition:\n\n# Set parameters\nr = 0.9\nθ = π/4\nx0 = 4\nx1 = 2 * r * sqrt(2)\n\n# Define symbols to be calculated\nω, p = symbols('ω p', real=True)\n\n# Solve for ω\n## Note: we choose the solution near 0\neq1 = Eq(x1/x0 - r * cos(ω+θ) / cos(ω), 0)\nω = nsolve(eq1, ω, 0)\nω = float(ω)\nprint(f'ω = {ω:1.3f}')\n\n# Solve for p\neq2 = Eq(x0 - 2 * p * cos(ω), 0)\np = nsolve(eq2, p, 0)\np = float(p)\nprint(f'p = {p:1.3f}')\n\nUsing the code above, we compute that\n\\omega = 0 and p = 2.\n\nThen we plug in the values we solve for \\omega and p\nand plot the dynamic.\n\n# Define range of n\nmax_n = 30\nn = np.arange(0, max_n+1, 0.01)\n\n# Define x_n\nx = lambda n: 2 * p * r**n * np.cos(ω + n * θ)\n\n# Plot\nfig, ax = plt.subplots(figsize=(12, 8))\n\nax.plot(n, x(n))\nax.set(xlim=(0, max_n), ylim=(-5, 5), xlabel='$n$', ylabel='$x_n$')\n\n# Set x-axis in the middle of the plot\nax.spines['bottom'].set_position('center')\nax.spines['right'].set_color('none')\nax.spines['top'].set_color('none')\nax.xaxis.set_ticks_position('bottom')\nax.yaxis.set_ticks_position('left')\n\nticklab = ax.xaxis.get_ticklabels()[0] # Set x-label position\ntrans = ticklab.get_transform()\nax.xaxis.set_label_coords(31, 0, transform=trans)\n\nticklab = ax.yaxis.get_ticklabels()[0] # Set y-label position\ntrans = ticklab.get_transform()\nax.yaxis.set_label_coords(0, 5, transform=trans)\n\nax.grid()\nplt.show()\n\n","type":"content","url":"/complex-and-trig#example-3","position":17},{"hierarchy":{"lvl1":"Complex Numbers and Trigonometry","lvl3":"Trigonometric Identities","lvl2":"Applications of de Moivre’s Theorem"},"type":"lvl3","url":"/complex-and-trig#trigonometric-identities","position":18},{"hierarchy":{"lvl1":"Complex Numbers and Trigonometry","lvl3":"Trigonometric Identities","lvl2":"Applications of de Moivre’s Theorem"},"content":"We can obtain a complete suite of trigonometric identities by\nappropriately manipulating polar forms of complex numbers.\n\nWe’ll get many of them by deducing implications of the equalitye^{i(\\omega + \\theta)} = e^{i\\omega} e^{i\\theta}\n\nFor example, we’ll calculate identities for\n\n\\cos{(\\omega + \\theta)} and \\sin{(\\omega + \\theta)}.\n\nUsing the sine and cosine formulas presented at the beginning of this\nlecture, we have:\\begin{aligned}\n\\cos{(\\omega + \\theta)} = \\frac{e^{i(\\omega + \\theta)} + e^{-i(\\omega + \\theta)}}{2} \\\\\n\\sin{(\\omega + \\theta)} = \\frac{e^{i(\\omega + \\theta)} - e^{-i(\\omega + \\theta)}}{2i}\n\\end{aligned}\n\nWe can also obtain the trigonometric identities as follows:\\begin{aligned}\n\\cos{(\\omega + \\theta)} + i \\sin{(\\omega + \\theta)}\n&= e^{i(\\omega + \\theta)} \\\\\n&= e^{i\\omega} e^{i\\theta} \\\\\n&= (\\cos{\\omega} + i \\sin{\\omega})(\\cos{\\theta} + i \\sin{\\theta}) \\\\\n&= (\\cos{\\omega}\\cos{\\theta} - \\sin{\\omega}\\sin{\\theta}) +\ni (\\cos{\\omega}\\sin{\\theta} + \\sin{\\omega}\\cos{\\theta})\n\\end{aligned}\n\nSince both real and imaginary parts of the above formula should be\nequal, we get:\\begin{aligned}\n\\cos{(\\omega + \\theta)} = \\cos{\\omega}\\cos{\\theta} - \\sin{\\omega}\\sin{\\theta} \\\\\n\\sin{(\\omega + \\theta)} = \\cos{\\omega}\\sin{\\theta} + \\sin{\\omega}\\cos{\\theta}\n\\end{aligned}\n\nThe equations above are also known as the angle sum identities. We\ncan verify the equations using the simplify function in the\nsympy package:\n\n# Define symbols\nω, θ = symbols('ω θ', real=True)\n\n# Verify\nprint(\"cos(ω)cos(θ) - sin(ω)sin(θ) =\",\n    simplify(cos(ω)*cos(θ) - sin(ω) * sin(θ)))\nprint(\"cos(ω)sin(θ) + sin(ω)cos(θ) =\",\n    simplify(cos(ω)*sin(θ) + sin(ω) * cos(θ)))\n\n","type":"content","url":"/complex-and-trig#trigonometric-identities","position":19},{"hierarchy":{"lvl1":"Complex Numbers and Trigonometry","lvl3":"Trigonometric Integrals","lvl2":"Applications of de Moivre’s Theorem"},"type":"lvl3","url":"/complex-and-trig#trigonometric-integrals","position":20},{"hierarchy":{"lvl1":"Complex Numbers and Trigonometry","lvl3":"Trigonometric Integrals","lvl2":"Applications of de Moivre’s Theorem"},"content":"We can also compute the trigonometric integrals using polar forms of\ncomplex numbers.\n\nFor example, we want to solve the following integral:\\int_{-\\pi}^{\\pi} \\cos(\\omega) \\sin(\\omega) \\, d\\omega\n\nUsing Euler’s formula, we have:\\begin{aligned}\n\\int \\cos(\\omega) \\sin(\\omega) \\, d\\omega\n&=\n\\int\n\\frac{(e^{i\\omega} + e^{-i\\omega})}{2}\n\\frac{(e^{i\\omega} - e^{-i\\omega})}{2i}\n\\, d\\omega  \\\\\n&=\n\\frac{1}{4i}\n\\int\ne^{2i\\omega} - e^{-2i\\omega}\n\\, d\\omega  \\\\\n&=\n\\frac{1}{4i}\n\\bigg( \\frac{-i}{2} e^{2i\\omega} - \\frac{i}{2} e^{-2i\\omega} + C_1 \\bigg) \\\\\n&=\n-\\frac{1}{8}\n\\bigg[ \\bigg(e^{i\\omega}\\bigg)^2 + \\bigg(e^{-i\\omega}\\bigg)^2 - 2 \\bigg] + C_2 \\\\\n&=\n-\\frac{1}{8}  (e^{i\\omega} - e^{-i\\omega})^2  + C_2 \\\\\n&=\n\\frac{1}{2} \\bigg( \\frac{e^{i\\omega} - e^{-i\\omega}}{2i} \\bigg)^2 + C_2 \\\\\n&= \\frac{1}{2} \\sin^2(\\omega) + C_2\n\\end{aligned}\n\nand thus:\\int_{-\\pi}^{\\pi} \\cos(\\omega) \\sin(\\omega) \\, d\\omega =\n\\frac{1}{2}\\sin^2(\\pi) - \\frac{1}{2}\\sin^2(-\\pi) = 0\n\nWe can verify the analytical as well as numerical results using\nintegrate in the sympy package:\n\n# Set initial printing\ninit_printing(use_latex=\"mathjax\")\n\nω = Symbol('ω')\nprint('The analytical solution for integral of cos(ω)sin(ω) is:')\nintegrate(cos(ω) * sin(ω), ω)\n\nprint('The numerical solution for the integral of cos(ω)sin(ω) \\\nfrom -π to π is:')\nintegrate(cos(ω) * sin(ω), (ω, -π, π))\n\n","type":"content","url":"/complex-and-trig#trigonometric-integrals","position":21},{"hierarchy":{"lvl1":"Complex Numbers and Trigonometry","lvl3":"Exercises","lvl2":"Applications of de Moivre’s Theorem"},"type":"lvl3","url":"/complex-and-trig#exercises","position":22},{"hierarchy":{"lvl1":"Complex Numbers and Trigonometry","lvl3":"Exercises","lvl2":"Applications of de Moivre’s Theorem"},"content":"We invite the reader to verify analytically and with the sympy package the following two equalities:\\int_{-\\pi}^{\\pi} \\cos (\\omega)^2 \\, d\\omega = \\pi\\int_{-\\pi}^{\\pi} \\sin (\\omega)^2 \\, d\\omega = \\pi\n\nSolution to \n\nExercise 1\n\nLet’s import symbolic \\pi from sympy\n\n# Import symbolic π from sympy\nfrom sympy import pi\n\nprint('The analytical solution for the integral of cos(ω)**2 \\\nfrom -π to π is:')\n\nintegrate(cos(ω)**2, (ω, -pi, pi))\n\nprint('The analytical solution for the integral of sin(ω)**2 \\\nfrom -π to π is:')\n\nintegrate(sin(ω)**2, (ω, -pi, pi))\n\n","type":"content","url":"/complex-and-trig#exercises","position":23},{"hierarchy":{"lvl1":"Consumption Smoothing"},"type":"lvl1","url":"/cons-smooth","position":0},{"hierarchy":{"lvl1":"Consumption Smoothing"},"content":"","type":"content","url":"/cons-smooth","position":1},{"hierarchy":{"lvl1":"Consumption Smoothing","lvl2":"Overview"},"type":"lvl2","url":"/cons-smooth#overview","position":2},{"hierarchy":{"lvl1":"Consumption Smoothing","lvl2":"Overview"},"content":"In this lecture, we’ll study a famous model of the “consumption function” that Milton Friedman \n\nFriedman (1956) and Robert Hall \n\nHall (1978))  proposed to fit some empirical data patterns that the original  Keynesian consumption function  described in this QuantEcon lecture \n\ngeometric series  missed.\n\nWe’ll study what is often  called the “consumption-smoothing model.”\n\nWe’ll use  matrix multiplication and matrix inversion, the same tools that we used in this QuantEcon lecture \n\npresent values.\n\nFormulas presented in  \n\npresent value formulas are at the core of the consumption-smoothing model because we shall use them to define a consumer’s “human wealth”.\n\nThe  key idea that inspired Milton Friedman was that a person’s non-financial income, i.e., his or\nher wages from working, can be viewed as a dividend stream from ‘‘human capital’’\nand that standard asset-pricing formulas can be applied to compute\n‘‘non-financial wealth’’ that capitalizes that  earnings stream.\n\nNote\n\nAs we’ll see in this QuantEcon lecture  \n\nequalizing difference model,\nMilton Friedman had used this idea  in his PhD thesis at Columbia University,\neventually published as \n\nKuznets & Friedman (1939) and \n\nFriedman & Kuznets (1945).\n\nIt will take a while for a “present value” or asset price explicitly to appear in this lecture, but when it does it will be a key actor.","type":"content","url":"/cons-smooth#overview","position":3},{"hierarchy":{"lvl1":"Consumption Smoothing","lvl2":"Analysis"},"type":"lvl2","url":"/cons-smooth#analysis","position":4},{"hierarchy":{"lvl1":"Consumption Smoothing","lvl2":"Analysis"},"content":"As usual, we’ll start by importing some Python modules.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom collections import namedtuple\n\nThe model describes  a consumer who lives from time t=0, 1, \\ldots, T, receives a stream \\{y_t\\}_{t=0}^T of non-financial income and chooses a consumption stream \\{c_t\\}_{t=0}^T.\n\nWe usually think of the non-financial income stream as coming from the person’s earnings from supplying labor.\n\nThe model  takes a non-financial income stream as an input, regarding it as “exogenous” in the sense that it is  determined outside the model.\n\nThe consumer faces a gross interest rate of R >1 that is constant over time, at which she is free to borrow or lend, up to  limits  that we’ll describe below.\n\nLet\n\nT \\geq 2  be a positive integer that constitutes a time-horizon.\n\ny = \\{y_t\\}_{t=0}^T be an exogenous  sequence of non-negative non-financial incomes y_t.\n\na = \\{a_t\\}_{t=0}^{T+1} be a sequence of financial wealth.\n\nc = \\{c_t\\}_{t=0}^T be a sequence of non-negative consumption rates.\n\nR \\geq 1 be a fixed gross one period rate of return on financial assets.\n\n\\beta \\in (0,1) be a fixed discount factor.\n\na_0 be a given initial level of financial assets\n\na_{T+1} \\geq 0  be a terminal condition on final assets.\n\nThe sequence of financial wealth a is to be determined by the model.\n\nWe require it to satisfy  two  boundary conditions:\n\nit must  equal an exogenous value  a_0 at time 0\n\nit must equal or exceed an exogenous value  a_{T+1} at time T+1.\n\nThe terminal condition a_{T+1} \\geq 0 requires that the consumer not leave the model in debt.\n\n(We’ll soon see that a utility maximizing consumer won’t want to die leaving positive assets, so she’ll arrange her affairs to make\na_{T+1} = 0.)\n\nThe consumer faces a sequence of budget constraints that  constrains   sequences (y, c, a)a_{t+1} = R (a_t+ y_t - c_t), \\quad t =0, 1, \\ldots T\n\nEquations \n\n(1) constitute  T+1 such budget constraints, one for each t=0, 1, \\ldots, T.\n\nGiven a sequence y of non-financial incomes, a large  set of pairs (a, c) of (financial wealth, consumption) sequences  satisfy the sequence of budget constraints \n\n(1).\n\nOur model has the following logical flow.\n\nstart with an exogenous non-financial income sequence y, an initial financial wealth a_0, and\na candidate consumption path c.\n\nuse the system of equations \n\n(1) for t=0, \\ldots, T to compute a path a of financial wealth\n\nverify that a_{T+1} satisfies the terminal wealth constraint a_{T+1} \\geq 0.\n\nIf it does, declare that the candidate path is budget feasible.\n\nif the candidate consumption path is not budget feasible, propose a less greedy consumption  path and start over\n\nBelow, we’ll describe how to execute these steps using linear algebra -- matrix inversion and multiplication.\n\nThe above procedure seems like a sensible way to find “budget-feasible” consumption paths c, i.e., paths that are consistent\nwith the exogenous non-financial income stream y, the initial financial  asset level a_0, and the terminal asset level a_{T+1}.\n\nIn general, there are many budget feasible consumption paths c.\n\nAmong all budget-feasible consumption paths, which one should a consumer want?\n\nTo answer this question, we shall eventually evaluate alternative budget feasible consumption paths c using the following utility functional or welfare criterion:W = \\sum_{t=0}^T \\beta^t (g_1 c_t - \\frac{g_2}{2} c_t^2 )\n\nwhere g_1 > 0, g_2 > 0.\n\nWhen \\beta R \\approx 1, the fact that the utility function g_1 c_t - \\frac{g_2}{2} c_t^2 has diminishing marginal utility imparts a preference for consumption that is very smooth.\n\nIndeed, we shall see that when \\beta R = 1 (a condition assumed by Milton Friedman \n\nFriedman (1956) and Robert Hall \n\nHall (1978)),  criterion \n\n(2) assigns higher welfare to smoother consumption paths.\n\nBy smoother we mean as close as possible to being constant over time.\n\nThe preference for smooth consumption paths that is built into the model gives it the  name “consumption-smoothing model”.\n\nWe’ll postpone verifying our claim that a constant consumption path is optimal when \\beta R=1\nby comparing welfare levels that comes from a constant path with ones that involve non-constant paths.\n\nBefore doing that, let’s dive in and do some calculations that will help us understand how the model works in practice when we provide the consumer with some different streams on non-financial income.\n\nHere we use default parameters R = 1.05, g_1 = 1, g_2 = 1/2, and T = 65.\n\nWe create a Python namedtuple to store these parameters with default values.\n\nConsumptionSmoothing = namedtuple(\"ConsumptionSmoothing\", \n                        [\"R\", \"g1\", \"g2\", \"β_seq\", \"T\"])\n\ndef create_consumption_smoothing_model(R=1.05, g1=1, g2=1/2, T=65):\n    β = 1/R\n    β_seq = np.array([β**i for i in range(T+1)])\n    return ConsumptionSmoothing(R, g1, g2, \n                                β_seq, T)\n\n","type":"content","url":"/cons-smooth#analysis","position":5},{"hierarchy":{"lvl1":"Consumption Smoothing","lvl2":"Friedman-Hall consumption-smoothing model"},"type":"lvl2","url":"/cons-smooth#friedman-hall-consumption-smoothing-model","position":6},{"hierarchy":{"lvl1":"Consumption Smoothing","lvl2":"Friedman-Hall consumption-smoothing model"},"content":"A key object is what Milton Friedman called “human” or “non-financial” wealth at time 0:h_0 \\equiv \\sum_{t=0}^T R^{-t} y_t = \\begin{bmatrix} 1 & R^{-1} & \\cdots & R^{-T} \\end{bmatrix}\n\\begin{bmatrix} y_0 \\cr y_1  \\cr \\vdots \\cr y_T \\end{bmatrix}\n\nHuman or non-financial wealth  at time 0 is evidently just the present value of the consumer’s non-financial income stream y.\n\nFormally it very much resembles the asset price that we computed in this QuantEcon lecture \n\npresent values.\n\nIndeed, this is why Milton Friedman called it “human capital”.\n\nBy iterating on equation \n\n(1) and imposing the terminal conditiona_{T+1} = 0,\n\nit is possible to convert a sequence of budget constraints \n\n(1) into a single intertemporal constraint\\sum_{t=0}^T R^{-t} c_t = a_0 + h_0.\n\nEquation \n\n(5)  says that the present value of the consumption stream equals the sum of financial and non-financial (or human) wealth.\n\nRobert Hall \n\nHall (1978) showed that when \\beta R = 1, a condition Milton Friedman had also  assumed, it is “optimal” for a consumer to smooth consumption by settingc_t = c_0 \\quad t =0, 1, \\ldots, T\n\n(Later we’ll present a “variational argument” that shows that this constant path maximizes\ncriterion \n\n(2) when \\beta R =1.)\n\nIn this case, we can use the intertemporal budget constraint to writec_t = c_0  = \\left(\\sum_{t=0}^T R^{-t}\\right)^{-1} (a_0 + h_0), \\quad t= 0, 1, \\ldots, T.\n\nEquation \n\n(7) is the consumption-smoothing model in a nutshell.","type":"content","url":"/cons-smooth#friedman-hall-consumption-smoothing-model","position":7},{"hierarchy":{"lvl1":"Consumption Smoothing","lvl2":"Mechanics of consumption-smoothing model"},"type":"lvl2","url":"/cons-smooth#mechanics-of-consumption-smoothing-model","position":8},{"hierarchy":{"lvl1":"Consumption Smoothing","lvl2":"Mechanics of consumption-smoothing model"},"content":"As promised, we’ll provide step-by-step instructions on how to use linear algebra, readily implemented in Python, to compute all  objects in play in  the consumption-smoothing model.\n\nIn the calculations below,  we’ll  set default values of  R > 1, e.g., R = 1.05, and \\beta = R^{-1}.","type":"content","url":"/cons-smooth#mechanics-of-consumption-smoothing-model","position":9},{"hierarchy":{"lvl1":"Consumption Smoothing","lvl3":"Step 1","lvl2":"Mechanics of consumption-smoothing model"},"type":"lvl3","url":"/cons-smooth#step-1","position":10},{"hierarchy":{"lvl1":"Consumption Smoothing","lvl3":"Step 1","lvl2":"Mechanics of consumption-smoothing model"},"content":"For a (T+1) \\times 1  vector y, use matrix algebra to compute h_0h_0 = \\sum_{t=0}^T R^{-t} y_t = \\begin{bmatrix} 1 & R^{-1} & \\cdots & R^{-T} \\end{bmatrix}\n\\begin{bmatrix} y_0 \\cr y_1  \\cr \\vdots \\cr y_T \\end{bmatrix}","type":"content","url":"/cons-smooth#step-1","position":11},{"hierarchy":{"lvl1":"Consumption Smoothing","lvl3":"Step 2","lvl2":"Mechanics of consumption-smoothing model"},"type":"lvl3","url":"/cons-smooth#step-2","position":12},{"hierarchy":{"lvl1":"Consumption Smoothing","lvl3":"Step 2","lvl2":"Mechanics of consumption-smoothing model"},"content":"Compute an  time 0   consumption c_0  :c_t = c_0 = \\left( \\frac{1 - R^{-1}}{1 - R^{-(T+1)}} \\right) (a_0 + \\sum_{t=0}^T R^{-t} y_t ) , \\quad t = 0, 1, \\ldots, T","type":"content","url":"/cons-smooth#step-2","position":13},{"hierarchy":{"lvl1":"Consumption Smoothing","lvl3":"Step 3","lvl2":"Mechanics of consumption-smoothing model"},"type":"lvl3","url":"/cons-smooth#step-3","position":14},{"hierarchy":{"lvl1":"Consumption Smoothing","lvl3":"Step 3","lvl2":"Mechanics of consumption-smoothing model"},"content":"Use  the system of equations \n\n(1) for t=0, \\ldots, T to compute a path a of financial wealth.\n\nTo do this, we translate that system of difference equations into a single matrix equation as follows:\\begin{bmatrix} \n1 & 0 & 0 & \\cdots & 0 & 0 & 0 \\cr\n-R & 1 & 0 & \\cdots & 0 & 0 & 0 \\cr\n0 & -R & 1 & \\cdots & 0 & 0 & 0 \\cr\n\\vdots  &\\vdots & \\vdots & \\cdots & \\vdots & \\vdots & \\vdots \\cr\n0 & 0 & 0 & \\cdots & -R & 1 & 0 \\cr\n0 & 0 & 0 & \\cdots & 0 & -R & 1\n\\end{bmatrix} \n\\begin{bmatrix} a_1 \\cr a_2 \\cr a_3 \\cr \\vdots \\cr a_T \\cr a_{T+1} \n\\end{bmatrix}\n= R \n\\begin{bmatrix} y_0 + a_0 - c_0 \\cr y_1 - c_0 \\cr y_2 - c_0 \\cr \\vdots\\cr y_{T-1} - c_0 \\cr y_T - c_0\n\\end{bmatrix}\n\nMultiply both sides by the inverse of the matrix on the left side to compute\\begin{bmatrix} a_1 \\cr a_2 \\cr a_3 \\cr \\vdots \\cr a_T \\cr a_{T+1} \\end{bmatrix}\n\nBecause we have built into  our calculations that the consumer leaves the model  with exactly zero assets, just barely satisfying the\nterminal condition that a_{T+1} \\geq 0, it should turn out   thata_{T+1} = 0.\n\nLet’s verify this with  Python code.\n\nFirst we implement the model with compute_optimal\n\ndef compute_optimal(model, a0, y_seq):\n    R, T = model.R, model.T\n\n    # non-financial wealth\n    h0 = model.β_seq @ y_seq     # since β = 1/R\n\n    # c0\n    c0 = (1 - 1/R) / (1 - (1/R)**(T+1)) * (a0 + h0)\n    c_seq = c0*np.ones(T+1)\n\n    # verify\n    A = np.diag(-R*np.ones(T), k=-1) + np.eye(T+1)\n    b = y_seq - c_seq\n    b[0] = b[0] + a0\n\n    a_seq = np.linalg.inv(A) @ b\n    a_seq = np.concatenate([[a0], a_seq])\n\n    return c_seq, a_seq, h0\n\nWe use an example where the consumer inherits a_0<0.\n\nThis  can be interpreted as  student debt with which the consumer begins his or her working life.\n\nThe non-financial process \\{y_t\\}_{t=0}^{T} is constant and positive up to t=45 and then becomes zero afterward.\n\nThe drop in non-financial income late in life reflects retirement from work.\n\n# Financial wealth\na0 = -2     # such as \"student debt\"\n\n# non-financial Income process\ny_seq = np.concatenate([np.ones(46), np.zeros(20)])\n\ncs_model = create_consumption_smoothing_model()\nc_seq, a_seq, h0 = compute_optimal(cs_model, a0, y_seq)\n\nprint('check a_T+1=0:', \n      np.abs(a_seq[-1] - 0) <= 1e-8)\n\nThe graphs below  show  paths of non-financial income, consumption, and financial assets.\n\n# Sequence length\nT = cs_model.T\n\nfig, axes = plt.subplots(1, 2, figsize=(12,5))\n\naxes[0].plot(range(T+1), y_seq, label='non-financial income', lw=2)\naxes[0].plot(range(T+1), c_seq, label='consumption', lw=2)\naxes[1].plot(range(T+2), a_seq, label='financial wealth', color='green', lw=2)\naxes[0].set_ylabel(r'$c_t,y_t$')\naxes[1].set_ylabel(r'$a_t$')\n\nfor ax in axes:\n    ax.plot(range(T+2), np.zeros(T+2), '--', lw=1, color='black')\n    ax.legend()\n    ax.set_xlabel(r'$t$')\n\nplt.show()\n\nNote that a_{T+1} = 0, as anticipated.\n\nWe can  evaluate  welfare criterion \n\n(2)\n\ndef welfare(model, c_seq):\n    β_seq, g1, g2 = model.β_seq, model.g1, model.g2\n\n    u_seq = g1 * c_seq - g2/2 * c_seq**2\n    return β_seq @ u_seq\n\nprint('Welfare:', welfare(cs_model, c_seq))\n\n","type":"content","url":"/cons-smooth#step-3","position":15},{"hierarchy":{"lvl1":"Consumption Smoothing","lvl3":"Experiments","lvl2":"Mechanics of consumption-smoothing model"},"type":"lvl3","url":"/cons-smooth#experiments","position":16},{"hierarchy":{"lvl1":"Consumption Smoothing","lvl3":"Experiments","lvl2":"Mechanics of consumption-smoothing model"},"content":"In this section we describe  how a  consumption sequence would optimally respond to different  sequences sequences of non-financial income.\n\nFirst we create  a function plot_cs that generates graphs for different instances of the  consumption-smoothing model cs_model.\n\nThis will  help us avoid rewriting code to plot outcomes for different non-financial income sequences.\n\ndef plot_cs(model,    # consumption-smoothing model      \n            a0,       # initial financial wealth\n            y_seq     # non-financial income process\n           ):\n    \n    # Compute optimal consumption\n    c_seq, a_seq, h0 = compute_optimal(model, a0, y_seq)\n    \n    # Sequence length\n    T = cs_model.T\n    \n    fig, axes = plt.subplots(1, 2, figsize=(12,5))\n    \n    axes[0].plot(range(T+1), y_seq, label='non-financial income', lw=2)\n    axes[0].plot(range(T+1), c_seq, label='consumption', lw=2)\n    axes[1].plot(range(T+2), a_seq, label='financial wealth', color='green', lw=2)\n    axes[0].set_ylabel(r'$c_t,y_t$')\n    axes[1].set_ylabel(r'$a_t$')\n    \n    for ax in axes:\n        ax.plot(range(T+2), np.zeros(T+2), '--', lw=1, color='black')\n        ax.legend()\n        ax.set_xlabel(r'$t$')\n    \n    plt.show()\n\nIn the experiments below, please study how consumption and financial asset sequences vary across different sequences for non-financial income.","type":"content","url":"/cons-smooth#experiments","position":17},{"hierarchy":{"lvl1":"Consumption Smoothing","lvl4":"Experiment 1: one-time gain/loss","lvl3":"Experiments","lvl2":"Mechanics of consumption-smoothing model"},"type":"lvl4","url":"/cons-smooth#experiment-1-one-time-gain-loss","position":18},{"hierarchy":{"lvl1":"Consumption Smoothing","lvl4":"Experiment 1: one-time gain/loss","lvl3":"Experiments","lvl2":"Mechanics of consumption-smoothing model"},"content":"We first assume a one-time windfall of W_0 in year 21 of the income sequence y.\n\nWe’ll make W_0 big - positive to indicate a one-time windfall, and negative to indicate a one-time “disaster”.\n\n# Windfall W_0 = 2.5\ny_seq_pos = np.concatenate([np.ones(21), np.array([2.5]), np.ones(24), np.zeros(20)])\n\nplot_cs(cs_model, a0, y_seq_pos)\n\n# Disaster W_0 = -2.5\ny_seq_neg = np.concatenate([np.ones(21), np.array([-2.5]), np.ones(24), np.zeros(20)])\n\nplot_cs(cs_model, a0, y_seq_neg)\n\n","type":"content","url":"/cons-smooth#experiment-1-one-time-gain-loss","position":19},{"hierarchy":{"lvl1":"Consumption Smoothing","lvl4":"Experiment 2: permanent wage gain/loss","lvl3":"Experiments","lvl2":"Mechanics of consumption-smoothing model"},"type":"lvl4","url":"/cons-smooth#experiment-2-permanent-wage-gain-loss","position":20},{"hierarchy":{"lvl1":"Consumption Smoothing","lvl4":"Experiment 2: permanent wage gain/loss","lvl3":"Experiments","lvl2":"Mechanics of consumption-smoothing model"},"content":"Now we assume a permanent  increase in income of W in year 21 of the y-sequence.\n\nAgain we can study positive and negative cases\n\n# Positive permanent income change W = 0.5 when t >= 21\ny_seq_pos = np.concatenate(\n    [np.ones(21), 1.5*np.ones(25), np.zeros(20)])\n\nplot_cs(cs_model, a0, y_seq_pos)\n\n# Negative permanent income change W = -0.5 when t >= 21\ny_seq_neg = np.concatenate(\n    [np.ones(21), .5*np.ones(25), np.zeros(20)])\n\nplot_cs(cs_model, a0, y_seq_neg)\n\n","type":"content","url":"/cons-smooth#experiment-2-permanent-wage-gain-loss","position":21},{"hierarchy":{"lvl1":"Consumption Smoothing","lvl4":"Experiment 3: a late starter","lvl3":"Experiments","lvl2":"Mechanics of consumption-smoothing model"},"type":"lvl4","url":"/cons-smooth#experiment-3-a-late-starter","position":22},{"hierarchy":{"lvl1":"Consumption Smoothing","lvl4":"Experiment 3: a late starter","lvl3":"Experiments","lvl2":"Mechanics of consumption-smoothing model"},"content":"Now we simulate a y sequence in which a person gets zero for 46 years, and then works and gets 1 for the last 20 years of life (a “late starter”)\n\n# Late starter\ny_seq_late = np.concatenate(\n    [np.ones(46), 2*np.ones(20)])\n\nplot_cs(cs_model, a0, y_seq_late)\n\n","type":"content","url":"/cons-smooth#experiment-3-a-late-starter","position":23},{"hierarchy":{"lvl1":"Consumption Smoothing","lvl4":"Experiment 4: geometric earner","lvl3":"Experiments","lvl2":"Mechanics of consumption-smoothing model"},"type":"lvl4","url":"/cons-smooth#experiment-4-geometric-earner","position":24},{"hierarchy":{"lvl1":"Consumption Smoothing","lvl4":"Experiment 4: geometric earner","lvl3":"Experiments","lvl2":"Mechanics of consumption-smoothing model"},"content":"Now we simulate a geometric y sequence in which a person gets y_t = \\lambda^t y_0 in first 46 years.\n\nWe first experiment with \\lambda = 1.05\n\n# Geometric earner parameters where λ = 1.05\nλ = 1.05\ny_0 = 1\nt_max = 46\n\n# Generate geometric y sequence\ngeo_seq = λ ** np.arange(t_max) * y_0 \ny_seq_geo = np.concatenate(\n            [geo_seq, np.zeros(20)])\n\nplot_cs(cs_model, a0, y_seq_geo)\n\nNow we show the behavior when \\lambda = 0.95\n\nλ = 0.95\n\ngeo_seq = λ ** np.arange(t_max) * y_0 \ny_seq_geo = np.concatenate(\n            [geo_seq, np.zeros(20)])\n\nplot_cs(cs_model, a0, y_seq_geo)\n\nWhat happens when \\lambda is negative\n\nλ = -0.95\n\ngeo_seq = λ ** np.arange(t_max) * y_0 + 1\ny_seq_geo = np.concatenate(\n            [geo_seq, np.ones(20)])\n\nplot_cs(cs_model, a0, y_seq_geo)\n\n","type":"content","url":"/cons-smooth#experiment-4-geometric-earner","position":25},{"hierarchy":{"lvl1":"Consumption Smoothing","lvl3":"Feasible consumption variations","lvl2":"Mechanics of consumption-smoothing model"},"type":"lvl3","url":"/cons-smooth#feasible-consumption-variations","position":26},{"hierarchy":{"lvl1":"Consumption Smoothing","lvl3":"Feasible consumption variations","lvl2":"Mechanics of consumption-smoothing model"},"content":"We promised to justify  our claim that when \\beta R =1 as Friedman assumed, a constant consumption play c_t = c_0 for all t is optimal.\n\nLet’s do that now.\n\nThe approach we’ll take is  an elementary  example  of the “calculus of variations”.\n\nLet’s dive in and see what the key idea is.\n\nTo explore what types of consumption paths are welfare-improving, we shall create an admissible consumption path variation sequence \\{v_t\\}_{t=0}^T\nthat satisfies\\sum_{t=0}^T R^{-t} v_t = 0\n\nThis equation says that the present value of admissible consumption path variations must be zero.\n\nSo once again, we encounter a formula for the present value of an “asset”:\n\nwe require that the present value of consumption path variations be zero.\n\nHere we’ll restrict ourselves to  a two-parameter class of admissible consumption path variations\nof the formv_t = \\xi_1 \\phi^t - \\xi_0\n\nWe say two and not three-parameter class because \\xi_0 will be a function of (\\phi, \\xi_1; R) that guarantees that the variation sequence is feasible.\n\nLet’s compute that function.\n\nWe require\\sum_{t=0}^T R^{-t}\\left[ \\xi_1 \\phi^t - \\xi_0 \\right] = 0\n\nwhich implies that\\xi_1 \\sum_{t=0}^T \\phi_t R^{-t} - \\xi_0 \\sum_{t=0}^T R^{-t} = 0\n\nwhich implies that\\xi_1 \\frac{1 - (\\phi R^{-1})^{T+1}}{1 - \\phi R^{-1}} - \\xi_0 \\frac{1 - R^{-(T+1)}}{1-R^{-1} } =0\n\nwhich implies that\\xi_0 = \\xi_0(\\phi, \\xi_1; R) = \\xi_1 \\left(\\frac{1 - R^{-1}}{1 - R^{-(T+1)}}\\right) \\left(\\frac{1 - (\\phi R^{-1})^{T+1}}{1 - \\phi R^{-1}}\\right)\n\nThis is our formula for \\xi_0.\n\nKey Idea: if c^o is a budget-feasible consumption path, then so is c^o + v,\nwhere v is a budget-feasible variation.\n\nGiven R, we thus have a two parameter class of budget feasible variations v that we can use\nto compute alternative consumption paths, then evaluate their welfare.\n\nNow let’s compute and plot consumption path variations\n\ndef compute_variation(model, ξ1, ϕ, a0, y_seq, verbose=1):\n    R, T, β_seq = model.R, model.T, model.β_seq\n\n    ξ0 = ξ1*((1 - 1/R) / (1 - (1/R)**(T+1))) * ((1 - (ϕ/R)**(T+1)) / (1 - ϕ/R))\n    v_seq = np.array([(ξ1*ϕ**t - ξ0) for t in range(T+1)])\n    \n    if verbose == 1:\n        print('check feasible:', np.isclose(β_seq @ v_seq, 0))     # since β = 1/R\n\n    c_opt, _, _ = compute_optimal(model, a0, y_seq)\n    cvar_seq = c_opt + v_seq\n\n    return cvar_seq\n\nWe visualize variations for \\xi_1 \\in \\{.01, .05\\} and \\phi \\in \\{.95, 1.02\\}\n\nfig, ax = plt.subplots()\n\nξ1s = [.01, .05]\nϕs= [.95, 1.02]\ncolors = {.01: 'tab:blue', .05: 'tab:green'}\n\nparams = np.array(np.meshgrid(ξ1s, ϕs)).T.reshape(-1, 2)\n\nfor i, param in enumerate(params):\n    ξ1, ϕ = param\n    print(f'variation {i}: ξ1={ξ1}, ϕ={ϕ}')\n    cvar_seq = compute_variation(model=cs_model, \n                                 ξ1=ξ1, ϕ=ϕ, a0=a0, \n                                 y_seq=y_seq)\n    print(f'welfare={welfare(cs_model, cvar_seq)}')\n    print('-'*64)\n    if i % 2 == 0:\n        ls = '-.'\n    else: \n        ls = '-'  \n    ax.plot(range(T+1), cvar_seq, ls=ls, \n            color=colors[ξ1], \n            label=fr'$\\xi_1 = {ξ1}, \\phi = {ϕ}$')\n\nplt.plot(range(T+1), c_seq, \n         color='orange', label=r'Optimal $\\vec{c}$ ')\n\nplt.legend()\nplt.xlabel(r'$t$')\nplt.ylabel(r'$c_t$')\nplt.show()\n\nWe can even use the Python np.gradient command to compute derivatives of welfare with respect to our two parameters.\n\n(We are actually discovering  the key idea beneath the calculus of variations.)\n\nFirst, we define the welfare with respect to \\xi_1 and \\phi\n\ndef welfare_rel(ξ1, ϕ):\n    \"\"\"\n    Compute welfare of variation sequence \n    for given ϕ, ξ1 with a consumption-smoothing model\n    \"\"\"\n    \n    cvar_seq = compute_variation(cs_model, ξ1=ξ1, \n                                 ϕ=ϕ, a0=a0, \n                                 y_seq=y_seq, \n                                 verbose=0)\n    return welfare(cs_model, cvar_seq)\n\n# Vectorize the function to allow array input\nwelfare_vec = np.vectorize(welfare_rel)\n\nThen we can visualize the relationship between welfare and \\xi_1 and compute its derivatives\n\nξ1_arr = np.linspace(-0.5, 0.5, 20)\n\nplt.plot(ξ1_arr, welfare_vec(ξ1_arr, 1.02))\nplt.ylabel('welfare')\nplt.xlabel(r'$\\xi_1$')\nplt.show()\n\nwelfare_grad = welfare_vec(ξ1_arr, 1.02)\nwelfare_grad = np.gradient(welfare_grad)\nplt.plot(ξ1_arr, welfare_grad)\nplt.ylabel('derivative of welfare')\nplt.xlabel(r'$\\xi_1$')\nplt.show()\n\nThe same can be done on \\phi\n\nϕ_arr = np.linspace(-0.5, 0.5, 20)\n\nplt.plot(ξ1_arr, welfare_vec(0.05, ϕ_arr))\nplt.ylabel('welfare')\nplt.xlabel(r'$\\phi$')\nplt.show()\n\nwelfare_grad = welfare_vec(0.05, ϕ_arr)\nwelfare_grad = np.gradient(welfare_grad)\nplt.plot(ξ1_arr, welfare_grad)\nplt.ylabel('derivative of welfare')\nplt.xlabel(r'$\\phi$')\nplt.show()\n\n","type":"content","url":"/cons-smooth#feasible-consumption-variations","position":27},{"hierarchy":{"lvl1":"Consumption Smoothing","lvl2":"Wrapping up the consumption-smoothing model"},"type":"lvl2","url":"/cons-smooth#wrapping-up-the-consumption-smoothing-model","position":28},{"hierarchy":{"lvl1":"Consumption Smoothing","lvl2":"Wrapping up the consumption-smoothing model"},"content":"The consumption-smoothing model of Milton Friedman \n\nFriedman (1956) and Robert Hall \n\nHall (1978)) is a cornerstone of modern economics that has important ramifications for the size of the Keynesian  “fiscal policy multiplier” that we  described in\nQuantEcon lecture \n\ngeometric series.\n\nThe consumption-smoothingmodel   lowers the government expenditure  multiplier relative to  one implied by the original Keynesian consumption function presented in \n\ngeometric series.\n\nFriedman’s   work opened the door to an enlightening literature on the aggregate consumption function and associated government expenditure  multipliers that remains  active today.","type":"content","url":"/cons-smooth#wrapping-up-the-consumption-smoothing-model","position":29},{"hierarchy":{"lvl1":"Consumption Smoothing","lvl2":"Appendix: solving difference equations with linear algebra"},"type":"lvl2","url":"/cons-smooth#appendix-solving-difference-equations-with-linear-algebra","position":30},{"hierarchy":{"lvl1":"Consumption Smoothing","lvl2":"Appendix: solving difference equations with linear algebra"},"content":"In the preceding sections we have used linear algebra to solve a consumption-smoothing model.\n\nThe same tools from linear algebra -- matrix multiplication and matrix inversion -- can be used  to study many other dynamic models.\n\nWe’ll conclude this lecture by giving a couple of examples.\n\nWe’ll describe a useful way of representing and “solving” linear difference equations.\n\nTo generate some y vectors, we’ll just write down a linear difference equation\nwith appropriate initial conditions and then   use linear algebra to solve it.","type":"content","url":"/cons-smooth#appendix-solving-difference-equations-with-linear-algebra","position":31},{"hierarchy":{"lvl1":"Consumption Smoothing","lvl3":"First-order difference equation","lvl2":"Appendix: solving difference equations with linear algebra"},"type":"lvl3","url":"/cons-smooth#first-order-difference-equation","position":32},{"hierarchy":{"lvl1":"Consumption Smoothing","lvl3":"First-order difference equation","lvl2":"Appendix: solving difference equations with linear algebra"},"content":"We’ll start with a first-order linear difference equation for \\{y_t\\}_{t=0}^T:y_{t} = \\lambda y_{t-1}, \\quad t = 1, 2, \\ldots, T\n\nwhere  y_0 is a given  initial condition.\n\nWe can cast this set of T equations as a single  matrix equation\\begin{bmatrix} \n1 & 0 & 0 & \\cdots & 0 & 0 \\cr\n-\\lambda & 1 & 0 & \\cdots & 0 & 0 \\cr\n0 & -\\lambda & 1 & \\cdots & 0 & 0 \\cr\n \\vdots & \\vdots & \\vdots & \\cdots & \\vdots & \\vdots \\cr\n0 & 0 & 0 & \\cdots & -\\lambda & 1 \n\\end{bmatrix} \n\\begin{bmatrix}\ny_1 \\cr y_2 \\cr y_3 \\cr \\vdots \\cr y_T \n\\end{bmatrix}\n= \n\\begin{bmatrix} \n\\lambda y_0 \\cr 0 \\cr 0 \\cr \\vdots \\cr 0 \n\\end{bmatrix}\n\nMultiplying both sides of \n\n(20)  by the  inverse of the matrix on the left provides the solution\\begin{bmatrix} \ny_1 \\cr y_2 \\cr y_3 \\cr \\vdots \\cr y_T \n\\end{bmatrix} \n= \n\\begin{bmatrix} \n1 & 0 & 0 & \\cdots & 0 & 0 \\cr\n\\lambda & 1 & 0 & \\cdots & 0 & 0 \\cr\n\\lambda^2 & \\lambda & 1 & \\cdots & 0 & 0 \\cr\n \\vdots & \\vdots & \\vdots & \\cdots & \\vdots & \\vdots \\cr\n\\lambda^{T-1} & \\lambda^{T-2} & \\lambda^{T-3} & \\cdots & \\lambda & 1 \n\\end{bmatrix}\n\\begin{bmatrix} \n\\lambda y_0 \\cr 0 \\cr 0 \\cr \\vdots \\cr 0 \n\\end{bmatrix}\n\nTo get \n\n(21), we multiplied both sides of  \n\n(20) by  the inverse of the matrix A. Please confirm that\\begin{bmatrix} \n1 & 0 & 0 & \\cdots & 0 & 0 \\cr\n\\lambda & 1 & 0 & \\cdots & 0 & 0 \\cr\n\\lambda^2 & \\lambda & 1 & \\cdots & 0 & 0 \\cr\n \\vdots & \\vdots & \\vdots & \\cdots & \\vdots & \\vdots \\cr\n\\lambda^{T-1} & \\lambda^{T-2} & \\lambda^{T-3} & \\cdots & \\lambda & 1 \n\\end{bmatrix}\n\nis the inverse of A and check that A A^{-1} = I","type":"content","url":"/cons-smooth#first-order-difference-equation","position":33},{"hierarchy":{"lvl1":"Consumption Smoothing","lvl3":"Second-order difference equation","lvl2":"Appendix: solving difference equations with linear algebra"},"type":"lvl3","url":"/cons-smooth#second-order-difference-equation","position":34},{"hierarchy":{"lvl1":"Consumption Smoothing","lvl3":"Second-order difference equation","lvl2":"Appendix: solving difference equations with linear algebra"},"content":"A second-order linear difference equation for \\{y_t\\}_{t=0}^T isy_{t} = \\lambda_1 y_{t-1} + \\lambda_2 y_{t-2}, \\quad t = 1, 2, \\ldots, T\n\nwhere now y_0 and y_{-1} are two given initial equations determined outside the model.\n\nAs we did with the first-order difference equation, we can cast this set of T equations as a single matrix equation\\begin{bmatrix} \n1 & 0 & 0 & \\cdots & 0 & 0 & 0 \\cr\n-\\lambda_1 & 1 & 0 & \\cdots & 0 & 0 & 0 \\cr\n-\\lambda_2 & -\\lambda_1 & 1 & \\cdots & 0 & 0 & 0 \\cr\n \\vdots & \\vdots & \\vdots & \\cdots & \\vdots & \\vdots \\cr\n0 & 0 & 0 & \\cdots & -\\lambda_2 & -\\lambda_1 & 1 \n\\end{bmatrix} \n\\begin{bmatrix} \ny_1 \\cr y_2 \\cr y_3 \\cr \\vdots \\cr y_T \n\\end{bmatrix}\n= \n\\begin{bmatrix} \n\\lambda_1 y_0 + \\lambda_2 y_{-1} \\cr \\lambda_2 y_0 \\cr 0 \\cr \\vdots \\cr 0 \n\\end{bmatrix}\n\nMultiplying both sides by  inverse of the matrix on the left again provides the solution.\n\nAs an exercise, we ask you to represent and solve a third-order linear difference equation.\nHow many initial conditions must you specify?","type":"content","url":"/cons-smooth#second-order-difference-equation","position":35},{"hierarchy":{"lvl1":"Eigenvalues and Eigenvectors"},"type":"lvl1","url":"/eigen-i","position":0},{"hierarchy":{"lvl1":"Eigenvalues and Eigenvectors"},"content":"","type":"content","url":"/eigen-i","position":1},{"hierarchy":{"lvl1":"Eigenvalues and Eigenvectors","lvl2":"Overview"},"type":"lvl2","url":"/eigen-i#overview","position":2},{"hierarchy":{"lvl1":"Eigenvalues and Eigenvectors","lvl2":"Overview"},"content":"Eigenvalues and eigenvectors are a relatively advanced topic in linear algebra.\n\nAt the same time, these concepts are extremely useful for\n\neconomic modeling (especially dynamics!)\n\nstatistics\n\nsome parts of applied mathematics\n\nmachine learning\n\nand many other fields of science.\n\nIn this lecture we explain the basics of eigenvalues and eigenvectors and introduce the Neumann Series Lemma.\n\nWe assume in this lecture that students are familiar with matrices\nand understand \n\nthe basics of matrix algebra.\n\nWe will use the following imports:\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom numpy.linalg import matrix_power\nfrom matplotlib.lines import Line2D\nfrom matplotlib.patches import FancyArrowPatch\nfrom mpl_toolkits.mplot3d import proj3d\n\n","type":"content","url":"/eigen-i#overview","position":3},{"hierarchy":{"lvl1":"Eigenvalues and Eigenvectors","lvl2":"Matrices as transformations"},"type":"lvl2","url":"/eigen-i#matrices-as-transformation","position":4},{"hierarchy":{"lvl1":"Eigenvalues and Eigenvectors","lvl2":"Matrices as transformations"},"content":"Let’s start by discussing an important concept concerning matrices.","type":"content","url":"/eigen-i#matrices-as-transformation","position":5},{"hierarchy":{"lvl1":"Eigenvalues and Eigenvectors","lvl3":"Mapping vectors to vectors","lvl2":"Matrices as transformations"},"type":"lvl3","url":"/eigen-i#mapping-vectors-to-vectors","position":6},{"hierarchy":{"lvl1":"Eigenvalues and Eigenvectors","lvl3":"Mapping vectors to vectors","lvl2":"Matrices as transformations"},"content":"One way to think about a matrix is as a rectangular collection of\nnumbers.\n\nAnother way to think about a matrix is as a map (i.e., as a function) that\ntransforms vectors to new vectors.\n\nTo understand the second point of view, suppose we multiply an n \\times m\nmatrix A with an m \\times 1 column vector x to obtain an n \\times 1\ncolumn vector y:Ax = y\n\nIf we fix A and consider different choices of x, we can understand A as\na map transforming x to Ax.\n\nBecause A is n \\times m, it transforms m-vectors to n-vectors.\n\nWe can write this formally as A \\colon \\mathbb{R}^m \\rightarrow \\mathbb{R}^n.\n\nYou might argue that if A is a function then we should write\nA(x) = y rather than Ax = y but the second notation is more conventional.","type":"content","url":"/eigen-i#mapping-vectors-to-vectors","position":7},{"hierarchy":{"lvl1":"Eigenvalues and Eigenvectors","lvl3":"Square matrices","lvl2":"Matrices as transformations"},"type":"lvl3","url":"/eigen-i#square-matrices","position":8},{"hierarchy":{"lvl1":"Eigenvalues and Eigenvectors","lvl3":"Square matrices","lvl2":"Matrices as transformations"},"content":"Let’s restrict our discussion to square matrices.\n\nIn the above discussion, this means that m=n and A maps \\mathbb R^n to\nitself.\n\nThis means A is an n \\times n matrix that maps (or “transforms”) a vector\nx in \\mathbb{R}^n to a new vector y=Ax also in \\mathbb{R}^n.\n\n\\begin{bmatrix}\n        2 & 1 \\\\\n        -1 & 1\n    \\end{bmatrix}\n    \\begin{bmatrix}\n        1 \\\\\n        3\n    \\end{bmatrix}\n    =\n    \\begin{bmatrix}\n        5 \\\\\n        2\n    \\end{bmatrix}\n\nHere, the matrixA = \\begin{bmatrix} 2 & 1 \\\\ \n                        -1 & 1 \n        \\end{bmatrix}\n\ntransforms the vector x = \\begin{bmatrix} 1 \\\\ 3 \\end{bmatrix} to the vector\ny = \\begin{bmatrix} 5 \\\\ 2 \\end{bmatrix}.\n\nLet’s visualize this using Python:\n\nA = np.array([[2,  1],\n              [-1, 1]])\n\n\n\nfrom math import sqrt\n\nfig, ax = plt.subplots()\n# Set the axes through the origin\n\nfor spine in ['left', 'bottom']:\n    ax.spines[spine].set_position('zero')\nfor spine in ['right', 'top']:\n    ax.spines[spine].set_color('none')\n\nax.set(xlim=(-2, 6), ylim=(-2, 4), aspect=1)\n\nvecs = ((1, 3), (5, 2))\nc = ['r', 'black']\nfor i, v in enumerate(vecs):\n    ax.annotate('', xy=v, xytext=(0, 0),\n                arrowprops=dict(color=c[i],\n                shrink=0,\n                alpha=0.7,\n                width=0.5))\n\nax.text(0.2 + 1, 0.2 + 3, 'x=$(1,3)$')\nax.text(0.2 + 5, 0.2 + 2, 'Ax=$(5,2)$')\n\nax.annotate('', xy=(sqrt(10/29) * 5, sqrt(10/29) * 2), xytext=(0, 0),\n            arrowprops=dict(color='purple',\n                            shrink=0,\n                            alpha=0.7,\n                            width=0.5))\n\nax.annotate('', xy=(1, 2/5), xytext=(1/3, 1),\n            arrowprops={'arrowstyle': '->',\n                        'connectionstyle': 'arc3,rad=-0.3'},\n            horizontalalignment='center')\nax.text(0.8, 0.8, f'θ', fontsize=14)\n\nplt.show()\n\nOne way to understand this transformation is that A\n\nfirst rotates x by some angle \\theta and\n\nthen scales it by some scalar \\gamma to obtain the image y of x.","type":"content","url":"/eigen-i#square-matrices","position":9},{"hierarchy":{"lvl1":"Eigenvalues and Eigenvectors","lvl2":"Types of transformations"},"type":"lvl2","url":"/eigen-i#types-of-transformations","position":10},{"hierarchy":{"lvl1":"Eigenvalues and Eigenvectors","lvl2":"Types of transformations"},"content":"Let’s examine some standard transformations we can perform with matrices.\n\nBelow we visualize transformations by thinking of vectors as points\ninstead of arrows.\n\nWe consider how a given matrix transforms\n\na grid of points and\n\na set of points located on the unit circle in \\mathbb{R}^2.\n\nTo build the transformations we will use two functions, called grid_transform and circle_transform.\n\nEach of these functions visualizes the actions of a given 2 \\times 2 matrix A.\n\ndef colorizer(x, y):\n    r = min(1, 1-y/3)\n    g = min(1, 1+y/3)\n    b = 1/4 + x/16\n    return (r, g, b)\n\n\ndef grid_transform(A=np.array([[1, -1], [1, 1]])):\n    xvals = np.linspace(-4, 4, 9)\n    yvals = np.linspace(-3, 3, 7)\n    xygrid = np.column_stack([[x, y] for x in xvals for y in yvals])\n    uvgrid = A @ xygrid\n\n    colors = list(map(colorizer, xygrid[0], xygrid[1]))\n\n    fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n\n    for axes in ax:\n        axes.set(xlim=(-11, 11), ylim=(-11, 11))\n        axes.set_xticks([])\n        axes.set_yticks([])\n        for spine in ['left', 'bottom']:\n            axes.spines[spine].set_position('zero')\n        for spine in ['right', 'top']:\n            axes.spines[spine].set_color('none')\n\n    # Plot x-y grid points\n    ax[0].scatter(xygrid[0], xygrid[1], s=36, c=colors, edgecolor=\"none\")\n    # ax[0].grid(True)\n    # ax[0].axis(\"equal\")\n    ax[0].set_title(\"points $x_1, x_2, \\cdots, x_k$\")\n\n    # Plot transformed grid points\n    ax[1].scatter(uvgrid[0], uvgrid[1], s=36, c=colors, edgecolor=\"none\")\n    # ax[1].grid(True)\n    # ax[1].axis(\"equal\")\n    ax[1].set_title(\"points $Ax_1, Ax_2, \\cdots, Ax_k$\")\n\n    plt.show()\n\n\ndef circle_transform(A=np.array([[-1, 2], [0, 1]])):\n\n    fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n\n    for axes in ax:\n        axes.set(xlim=(-4, 4), ylim=(-4, 4))\n        axes.set_xticks([])\n        axes.set_yticks([])\n        for spine in ['left', 'bottom']:\n            axes.spines[spine].set_position('zero')\n        for spine in ['right', 'top']:\n            axes.spines[spine].set_color('none')\n\n    θ = np.linspace(0, 2 * np.pi, 150)\n    r = 1\n\n    θ_1 = np.empty(12)\n    for i in range(12):\n        θ_1[i] = 2 * np.pi * (i/12)\n\n    x = r * np.cos(θ)\n    y = r * np.sin(θ)\n    a = r * np.cos(θ_1)\n    b = r * np.sin(θ_1)\n    a_1 = a.reshape(1, -1)\n    b_1 = b.reshape(1, -1)\n    colors = list(map(colorizer, a, b))\n    ax[0].plot(x, y, color='black', zorder=1)\n    ax[0].scatter(a_1, b_1, c=colors, alpha=1, s=60,\n                  edgecolors='black', zorder=2)\n    ax[0].set_title(r\"unit circle in $\\mathbb{R}^2$\")\n\n    x1 = x.reshape(1, -1)\n    y1 = y.reshape(1, -1)\n    ab = np.concatenate((a_1, b_1), axis=0)\n    transformed_ab = A @ ab\n    transformed_circle_input = np.concatenate((x1, y1), axis=0)\n    transformed_circle = A @ transformed_circle_input\n    ax[1].plot(transformed_circle[0, :],\n               transformed_circle[1, :], color='black', zorder=1)\n    ax[1].scatter(transformed_ab[0, :], transformed_ab[1:,],\n                  color=colors, alpha=1, s=60, edgecolors='black', zorder=2)\n    ax[1].set_title(\"transformed circle\")\n\n    plt.show()\n\n","type":"content","url":"/eigen-i#types-of-transformations","position":11},{"hierarchy":{"lvl1":"Eigenvalues and Eigenvectors","lvl3":"Scaling","lvl2":"Types of transformations"},"type":"lvl3","url":"/eigen-i#scaling","position":12},{"hierarchy":{"lvl1":"Eigenvalues and Eigenvectors","lvl3":"Scaling","lvl2":"Types of transformations"},"content":"A matrix of the form\\begin{bmatrix} \n        \\alpha & 0 \n        \\\\ 0 & \\beta \n    \\end{bmatrix}\n\nscales vectors across the x-axis by a factor \\alpha and along the y-axis by\na factor \\beta.\n\nHere we illustrate a simple example where \\alpha = \\beta = 3.\n\nA = np.array([[3, 0],  # scaling by 3 in both directions\n              [0, 3]])\ngrid_transform(A)\ncircle_transform(A)\n\n","type":"content","url":"/eigen-i#scaling","position":13},{"hierarchy":{"lvl1":"Eigenvalues and Eigenvectors","lvl3":"Shearing","lvl2":"Types of transformations"},"type":"lvl3","url":"/eigen-i#shearing","position":14},{"hierarchy":{"lvl1":"Eigenvalues and Eigenvectors","lvl3":"Shearing","lvl2":"Types of transformations"},"content":"A “shear” matrix of the form\\begin{bmatrix} \n        1 & \\lambda \\\\ \n        0 & 1 \n    \\end{bmatrix}\n\nstretches vectors along the x-axis by an amount proportional to the\ny-coordinate of a point.\n\nA = np.array([[1, 2],     # shear along x-axis\n              [0, 1]])\ngrid_transform(A)\ncircle_transform(A)\n\n","type":"content","url":"/eigen-i#shearing","position":15},{"hierarchy":{"lvl1":"Eigenvalues and Eigenvectors","lvl3":"Rotation","lvl2":"Types of transformations"},"type":"lvl3","url":"/eigen-i#rotation","position":16},{"hierarchy":{"lvl1":"Eigenvalues and Eigenvectors","lvl3":"Rotation","lvl2":"Types of transformations"},"content":"A matrix of the form\\begin{bmatrix} \n        \\cos \\theta & \\sin \\theta \n        \\\\ - \\sin \\theta & \\cos \\theta \n    \\end{bmatrix}\n\nis called a rotation matrix.\n\nThis matrix rotates vectors clockwise by an angle \\theta.\n\nθ = np.pi/4  # 45 degree clockwise rotation\nA = np.array([[np.cos(θ), np.sin(θ)],\n              [-np.sin(θ), np.cos(θ)]])\ngrid_transform(A)\n\n","type":"content","url":"/eigen-i#rotation","position":17},{"hierarchy":{"lvl1":"Eigenvalues and Eigenvectors","lvl3":"Permutation","lvl2":"Types of transformations"},"type":"lvl3","url":"/eigen-i#permutation","position":18},{"hierarchy":{"lvl1":"Eigenvalues and Eigenvectors","lvl3":"Permutation","lvl2":"Types of transformations"},"content":"The permutation matrix\\begin{bmatrix} \n        0 & 1 \\\\ \n        1 & 0 \n    \\end{bmatrix}\n\ninterchanges the coordinates of a vector.\n\nA = np.column_stack([[0, 1], [1, 0]])\ngrid_transform(A)\n\nMore examples of common transition matrices can be found \n\nhere.","type":"content","url":"/eigen-i#permutation","position":19},{"hierarchy":{"lvl1":"Eigenvalues and Eigenvectors","lvl2":"Matrix multiplication as composition"},"type":"lvl2","url":"/eigen-i#matrix-multiplication-as-composition","position":20},{"hierarchy":{"lvl1":"Eigenvalues and Eigenvectors","lvl2":"Matrix multiplication as composition"},"content":"Since matrices act as functions that transform one vector to another, we can\napply the concept of function composition to matrices as well.","type":"content","url":"/eigen-i#matrix-multiplication-as-composition","position":21},{"hierarchy":{"lvl1":"Eigenvalues and Eigenvectors","lvl3":"Linear compositions","lvl2":"Matrix multiplication as composition"},"type":"lvl3","url":"/eigen-i#linear-compositions","position":22},{"hierarchy":{"lvl1":"Eigenvalues and Eigenvectors","lvl3":"Linear compositions","lvl2":"Matrix multiplication as composition"},"content":"Consider the two matricesA = \n        \\begin{bmatrix} \n            0 & 1 \\\\ \n            -1 & 0 \n        \\end{bmatrix}\n        \\quad \\text{and} \\quad\n    B = \n        \\begin{bmatrix} \n            1 & 2 \\\\ \n            0 & 1 \n        \\end{bmatrix}\n\nWhat will the output be when we try to obtain ABx for some 2 \\times 1\nvector x?\\color{red}{\\underbrace{\n \\color{black}{\\begin{bmatrix}\n  0 & 1 \\\\\n -1 & 0\n \\end{bmatrix}}\n}_{\\textstyle A} }\n\\color{red}{\\underbrace{\n \\color{black}{\\begin{bmatrix}\n  1 & 2 \\\\\n  0 & 1\n \\end{bmatrix}}\n}_{\\textstyle B}}\n\\color{red}{\\overbrace{\n \\color{black}{\\begin{bmatrix}\n  1 \\\\\n  3\n \\end{bmatrix}}\n}^{\\textstyle x}}\n\\rightarrow\n\\color{red}{\\underbrace{\n \\color{black}{\\begin{bmatrix}\n  0 & 1 \\\\\n  -1 & -2\n \\end{bmatrix}}\n}_{\\textstyle AB}}\n\\color{red}{\\overbrace{\n \\color{black}{\\begin{bmatrix}\n  1 \\\\\n  3\n \\end{bmatrix}}\n}^{\\textstyle x}}\n\\rightarrow\n\\color{red}{\\overbrace{\n \\color{black}{\\begin{bmatrix}\n  3 \\\\\n  -7\n \\end{bmatrix}}\n}^{\\textstyle y}}\\color{red}{\\underbrace{\n \\color{black}{\\begin{bmatrix}\n  0 & 1 \\\\\n -1 & 0\n \\end{bmatrix}}\n}_{\\textstyle A} }\n\\color{red}{\\underbrace{\n \\color{black}{\\begin{bmatrix}\n  1 & 2 \\\\\n  0 & 1\n \\end{bmatrix}}\n}_{\\textstyle B}}\n\\color{red}{\\overbrace{\n \\color{black}{\\begin{bmatrix}\n  1 \\\\\n  3\n \\end{bmatrix}}\n}^{\\textstyle x}}\n\\rightarrow\n\\color{red}{\\underbrace{\n \\color{black}{\\begin{bmatrix}\n  0 & 1 \\\\\n  -1 & 0\n \\end{bmatrix}}\n}_{\\textstyle A}}\n\\color{red}{\\overbrace{\n \\color{black}{\\begin{bmatrix}\n  7 \\\\\n  3\n \\end{bmatrix}}\n}^{\\textstyle Bx}}\n\\rightarrow\n\\color{red}{\\overbrace{\n \\color{black}{\\begin{bmatrix}\n  3 \\\\\n  -7\n \\end{bmatrix}}\n}^{\\textstyle y}}\n\nWe can observe that applying the transformation AB on the vector x is the\nsame as first applying B on x and then applying A on the vector Bx.\n\nThus the matrix product AB is the\n\n\ncomposition of the\nmatrix transformations A and B\n\nThis means first apply transformation B and then\ntransformation A.\n\nWhen we matrix multiply an n \\times m matrix A with an m \\times k matrix\nB the obtained matrix product is an n \\times k matrix AB.\n\nThus, if A and B are transformations such that A \\colon \\mathbb{R}^m \\to\n\\mathbb{R}^n and B \\colon \\mathbb{R}^k \\to \\mathbb{R}^m, then AB\ntransforms \\mathbb{R}^k to \\mathbb{R}^n.\n\nViewing matrix multiplication as composition of maps helps us\nunderstand why, under matrix multiplication, AB is generally not equal to BA.\n\n(After all, when we compose functions, the order usually matters.)","type":"content","url":"/eigen-i#linear-compositions","position":23},{"hierarchy":{"lvl1":"Eigenvalues and Eigenvectors","lvl3":"Examples","lvl2":"Matrix multiplication as composition"},"type":"lvl3","url":"/eigen-i#examples","position":24},{"hierarchy":{"lvl1":"Eigenvalues and Eigenvectors","lvl3":"Examples","lvl2":"Matrix multiplication as composition"},"content":"Let A be the 90^{\\circ} clockwise rotation matrix given by\n\\begin{bmatrix} 0 & 1 \\\\ -1 & 0 \\end{bmatrix} and let B be a shear matrix\nalong the x-axis given by \\begin{bmatrix} 1 & 2 \\\\ 0 & 1 \\end{bmatrix}.\n\nWe will visualize how a grid of points changes when we apply the\ntransformation AB and then compare it with the transformation BA.\n\ndef grid_composition_transform(A=np.array([[1, -1], [1, 1]]),\n                               B=np.array([[1, -1], [1, 1]])):\n    xvals = np.linspace(-4, 4, 9)\n    yvals = np.linspace(-3, 3, 7)\n    xygrid = np.column_stack([[x, y] for x in xvals for y in yvals])\n    uvgrid = B @ xygrid\n    abgrid = A @ uvgrid\n\n    colors = list(map(colorizer, xygrid[0], xygrid[1]))\n\n    fig, ax = plt.subplots(1, 3, figsize=(15, 5))\n\n    for axes in ax:\n        axes.set(xlim=(-12, 12), ylim=(-12, 12))\n        axes.set_xticks([])\n        axes.set_yticks([])\n        for spine in ['left', 'bottom']:\n            axes.spines[spine].set_position('zero')\n        for spine in ['right', 'top']:\n            axes.spines[spine].set_color('none')\n\n    # Plot grid points\n    ax[0].scatter(xygrid[0], xygrid[1], s=36, c=colors, edgecolor=\"none\")\n    ax[0].set_title(r\"points $x_1, x_2, \\cdots, x_k$\")\n\n    # Plot intermediate grid points\n    ax[1].scatter(uvgrid[0], uvgrid[1], s=36, c=colors, edgecolor=\"none\")\n    ax[1].set_title(r\"points $Bx_1, Bx_2, \\cdots, Bx_k$\")\n\n    # Plot transformed grid points\n    ax[2].scatter(abgrid[0], abgrid[1], s=36, c=colors, edgecolor=\"none\")\n    ax[2].set_title(r\"points $ABx_1, ABx_2, \\cdots, ABx_k$\")\n\n    plt.show()\n\n\n\nA = np.array([[0, 1],     # 90 degree clockwise rotation\n              [-1, 0]])\nB = np.array([[1, 2],     # shear along x-axis\n              [0, 1]])\n\n","type":"content","url":"/eigen-i#examples","position":25},{"hierarchy":{"lvl1":"Eigenvalues and Eigenvectors","lvl4":"Shear then rotate","lvl3":"Examples","lvl2":"Matrix multiplication as composition"},"type":"lvl4","url":"/eigen-i#shear-then-rotate","position":26},{"hierarchy":{"lvl1":"Eigenvalues and Eigenvectors","lvl4":"Shear then rotate","lvl3":"Examples","lvl2":"Matrix multiplication as composition"},"content":"\n\ngrid_composition_transform(A, B)  # transformation AB\n\n","type":"content","url":"/eigen-i#shear-then-rotate","position":27},{"hierarchy":{"lvl1":"Eigenvalues and Eigenvectors","lvl4":"Rotate then shear","lvl3":"Examples","lvl2":"Matrix multiplication as composition"},"type":"lvl4","url":"/eigen-i#rotate-then-shear","position":28},{"hierarchy":{"lvl1":"Eigenvalues and Eigenvectors","lvl4":"Rotate then shear","lvl3":"Examples","lvl2":"Matrix multiplication as composition"},"content":"\n\ngrid_composition_transform(B,A)         # transformation BA\n\nIt is evident that the transformation AB is not the same as the transformation BA.","type":"content","url":"/eigen-i#rotate-then-shear","position":29},{"hierarchy":{"lvl1":"Eigenvalues and Eigenvectors","lvl2":"Iterating on a fixed map"},"type":"lvl2","url":"/eigen-i#iterating-on-a-fixed-map","position":30},{"hierarchy":{"lvl1":"Eigenvalues and Eigenvectors","lvl2":"Iterating on a fixed map"},"content":"In economics (and especially in dynamic modeling), we are often interested in\nanalyzing behavior where we repeatedly apply a fixed matrix.\n\nFor example, given a vector v and a matrix A, we are interested in\nstudying the sequencev, \\quad\n    Av, \\quad\n    AAv = A^2v, \\quad \\ldots\n\nLet’s first see examples of a sequence of iterates (A^k v)_{k \\geq 0} under\ndifferent maps A.\n\ndef plot_series(A, v, n):\n\n    B = np.array([[1, -1],\n                  [1, 0]])\n\n    fig, ax = plt.subplots()\n\n    ax.set(xlim=(-4, 4), ylim=(-4, 4))\n    ax.set_xticks([])\n    ax.set_yticks([])\n    for spine in ['left', 'bottom']:\n        ax.spines[spine].set_position('zero')\n    for spine in ['right', 'top']:\n        ax.spines[spine].set_color('none')\n\n    θ = np.linspace(0, 2 * np.pi, 150)\n    r = 2.5\n    x = r * np.cos(θ)\n    y = r * np.sin(θ)\n    x1 = x.reshape(1, -1)\n    y1 = y.reshape(1, -1)\n    xy = np.concatenate((x1, y1), axis=0)\n\n    ellipse = B @ xy\n    ax.plot(ellipse[0, :], ellipse[1, :], color='black',\n            linestyle=(0, (5, 10)), linewidth=0.5)\n\n    # Initialize holder for trajectories\n    colors = plt.cm.rainbow(np.linspace(0, 1, 20))\n\n    for i in range(n):\n        iteration = matrix_power(A, i) @ v\n        v1 = iteration[0]\n        v2 = iteration[1]\n        ax.scatter(v1, v2, color=colors[i])\n        if i == 0:\n            ax.text(v1+0.25, v2, f'$v$')\n        elif i == 1:\n            ax.text(v1+0.25, v2, f'$Av$')\n        elif 1 < i < 4:\n            ax.text(v1+0.25, v2, f'$A^{i}v$')\n    plt.show()\n\n\n\nA = np.array([[sqrt(3) + 1, -2],\n              [1, sqrt(3) - 1]])\nA = (1/(2*sqrt(2))) * A\nv = (-3, -3)\nn = 12\n\nplot_series(A, v, n)\n\nHere with each iteration the vectors get shorter, i.e., move closer to the origin.\n\nIn this case, repeatedly multiplying a vector by A makes the vector “spiral in”.\n\nB = np.array([[sqrt(3) + 1, -2],\n              [1, sqrt(3) - 1]])\nB = (1/2) * B\nv = (2.5, 0)\nn = 12\n\nplot_series(B, v, n)\n\nHere with each iteration vectors do not tend to get longer or shorter.\n\nIn this case, repeatedly multiplying a vector by A simply “rotates it around\nan ellipse”.\n\nB = np.array([[sqrt(3) + 1, -2],\n              [1, sqrt(3) - 1]])\nB = (1/sqrt(2)) * B\nv = (-1, -0.25)\nn = 6\n\nplot_series(B, v, n)\n\nHere with each iteration vectors tend to get longer, i.e., farther from the\norigin.\n\nIn this case, repeatedly multiplying a vector by A makes the vector “spiral out”.\n\nWe thus observe that the sequence (A^kv)_{k \\geq 0} behaves differently depending on the map A itself.\n\nWe now discuss the property of A that determines this behavior.","type":"content","url":"/eigen-i#iterating-on-a-fixed-map","position":31},{"hierarchy":{"lvl1":"Eigenvalues and Eigenvectors","lvl2":"Eigenvalues"},"type":"lvl2","url":"/eigen-i#la-eigenvalues","position":32},{"hierarchy":{"lvl1":"Eigenvalues and Eigenvectors","lvl2":"Eigenvalues"},"content":"In this section we introduce the notions of eigenvalues and eigenvectors.","type":"content","url":"/eigen-i#la-eigenvalues","position":33},{"hierarchy":{"lvl1":"Eigenvalues and Eigenvectors","lvl3":"Definitions","lvl2":"Eigenvalues"},"type":"lvl3","url":"/eigen-i#definitions","position":34},{"hierarchy":{"lvl1":"Eigenvalues and Eigenvectors","lvl3":"Definitions","lvl2":"Eigenvalues"},"content":"Let A be an n \\times n square matrix.\n\nIf \\lambda is scalar and v is a non-zero n-vector such thatA v = \\lambda v.\n\nThen we say that \\lambda is an eigenvalue of A, and v is the corresponding eigenvector.\n\nThus, an eigenvector of A is a nonzero vector v such that when the map A is\napplied, v is merely scaled.\n\nThe next figure shows two eigenvectors (blue arrows) and their images under\nA (red arrows).\n\nAs expected, the image Av of each v is just a scaled version of the original\n\nfrom numpy.linalg import eig\n\nA = [[1, 2],\n     [2, 1]]\nA = np.array(A)\nevals, evecs = eig(A)\nevecs = evecs[:, 0], evecs[:, 1]\n\nfig, ax = plt.subplots(figsize=(10, 8))\n# Set the axes through the origin\nfor spine in ['left', 'bottom']:\n    ax.spines[spine].set_position('zero')\nfor spine in ['right', 'top']:\n    ax.spines[spine].set_color('none')\n# ax.grid(alpha=0.4)\n\nxmin, xmax = -3, 3\nymin, ymax = -3, 3\nax.set(xlim=(xmin, xmax), ylim=(ymin, ymax))\n\n# Plot each eigenvector\nfor v in evecs:\n    ax.annotate('', xy=v, xytext=(0, 0),\n                arrowprops=dict(facecolor='blue',\n                shrink=0,\n                alpha=0.6,\n                width=0.5))\n\n# Plot the image of each eigenvector\nfor v in evecs:\n    v = A @ v\n    ax.annotate('', xy=v, xytext=(0, 0),\n                arrowprops=dict(facecolor='red',\n                shrink=0,\n                alpha=0.6,\n                width=0.5))\n\n# Plot the lines they run through\nx = np.linspace(xmin, xmax, 3)\nfor v in evecs:\n    a = v[1] / v[0]\n    ax.plot(x, a * x, 'b-', lw=0.4)\n\nplt.show()\n\n","type":"content","url":"/eigen-i#definitions","position":35},{"hierarchy":{"lvl1":"Eigenvalues and Eigenvectors","lvl3":"Complex values","lvl2":"Eigenvalues"},"type":"lvl3","url":"/eigen-i#complex-values","position":36},{"hierarchy":{"lvl1":"Eigenvalues and Eigenvectors","lvl3":"Complex values","lvl2":"Eigenvalues"},"content":"So far our definition of eigenvalues and eigenvectors seems straightforward.\n\nThere is one complication we haven’t mentioned yet:\n\nWhen solving Av = \\lambda v,\n\n\\lambda is allowed to be a complex number and\n\nv is allowed to be an n-vector of complex numbers.\n\nWe will see some examples below.","type":"content","url":"/eigen-i#complex-values","position":37},{"hierarchy":{"lvl1":"Eigenvalues and Eigenvectors","lvl3":"Some mathematical details","lvl2":"Eigenvalues"},"type":"lvl3","url":"/eigen-i#some-mathematical-details","position":38},{"hierarchy":{"lvl1":"Eigenvalues and Eigenvectors","lvl3":"Some mathematical details","lvl2":"Eigenvalues"},"content":"We note some mathematical details for more advanced readers.\n\n(Other readers can skip to the next section.)\n\nThe eigenvalue equation is equivalent to (A - \\lambda I) v = 0.\n\nThis equation has a nonzero solution v only when the columns of A - \\lambda I are linearly dependent.\n\nThis in turn is equivalent to stating the determinant is zero.\n\nHence, to find all eigenvalues, we can look for \\lambda such that the\ndeterminant of A - \\lambda I is zero.\n\nThis problem can be expressed as one of solving for the roots of a polynomial\nin \\lambda of degree n.\n\nThis in turn implies the existence of n solutions in the complex\nplane, although some might be repeated.","type":"content","url":"/eigen-i#some-mathematical-details","position":39},{"hierarchy":{"lvl1":"Eigenvalues and Eigenvectors","lvl3":"Facts","lvl2":"Eigenvalues"},"type":"lvl3","url":"/eigen-i#facts","position":40},{"hierarchy":{"lvl1":"Eigenvalues and Eigenvectors","lvl3":"Facts","lvl2":"Eigenvalues"},"content":"Some nice facts about the eigenvalues of a square matrix A are as follows:\n\nthe determinant of A equals the product of the eigenvalues\n\nthe trace of A (the sum of the elements on the principal diagonal) equals the sum of the eigenvalues\n\nif A is symmetric, then all of its eigenvalues are real\n\nif A is invertible and \\lambda_1, \\ldots, \\lambda_n are its eigenvalues, then the eigenvalues of A^{-1} are 1/\\lambda_1, \\ldots, 1/\\lambda_n.\n\nA corollary of the last statement is that a matrix is invertible if and only if all its eigenvalues are nonzero.","type":"content","url":"/eigen-i#facts","position":41},{"hierarchy":{"lvl1":"Eigenvalues and Eigenvectors","lvl3":"Computation","lvl2":"Eigenvalues"},"type":"lvl3","url":"/eigen-i#computation","position":42},{"hierarchy":{"lvl1":"Eigenvalues and Eigenvectors","lvl3":"Computation","lvl2":"Eigenvalues"},"content":"Using NumPy, we can solve for the eigenvalues and eigenvectors of a matrix as follows\n\nfrom numpy.linalg import eig\n\nA = ((1, 2),\n     (2, 1))\n\nA = np.array(A)\nevals, evecs = eig(A)\nevals  # eigenvalues\n\n\n\nevecs  # eigenvectors\n\nNote that the columns of evecs are the eigenvectors.\n\nSince any scalar multiple of an eigenvector is an eigenvector with the same\neigenvalue (which can be verified), the eig routine normalizes the length of each eigenvector\nto one.\n\nThe eigenvectors and eigenvalues of a map A determine how a vector v is transformed when we repeatedly multiply by A.\n\nThis is discussed further later.","type":"content","url":"/eigen-i#computation","position":43},{"hierarchy":{"lvl1":"Eigenvalues and Eigenvectors","lvl2":"The Neumann Series Lemma"},"type":"lvl2","url":"/eigen-i#la-neumann","position":44},{"hierarchy":{"lvl1":"Eigenvalues and Eigenvectors","lvl2":"The Neumann Series Lemma"},"content":"In this section we present a famous result about series of matrices that has\nmany applications in economics.","type":"content","url":"/eigen-i#la-neumann","position":45},{"hierarchy":{"lvl1":"Eigenvalues and Eigenvectors","lvl3":"Scalar series","lvl2":"The Neumann Series Lemma"},"type":"lvl3","url":"/eigen-i#scalar-series","position":46},{"hierarchy":{"lvl1":"Eigenvalues and Eigenvectors","lvl3":"Scalar series","lvl2":"The Neumann Series Lemma"},"content":"Here’s a fundamental result about series:\n\nIf a is a number and |a| < 1, then    \\sum_{k=0}^{\\infty} a^k =\\frac{1}{1-a} = (1 - a)^{-1}\n\nFor a one-dimensional linear equation x = ax + b where x is unknown we can thus conclude that the solution x^{*} is given by:x^{*} = \\frac{b}{1-a} = \\sum_{k=0}^{\\infty} a^k b","type":"content","url":"/eigen-i#scalar-series","position":47},{"hierarchy":{"lvl1":"Eigenvalues and Eigenvectors","lvl3":"Matrix series","lvl2":"The Neumann Series Lemma"},"type":"lvl3","url":"/eigen-i#matrix-series","position":48},{"hierarchy":{"lvl1":"Eigenvalues and Eigenvectors","lvl3":"Matrix series","lvl2":"The Neumann Series Lemma"},"content":"A generalization of this idea exists in the matrix setting.\n\nConsider the system of equations x = Ax + b where A is an n \\times n\nsquare matrix and x and b are both column vectors in \\mathbb{R}^n.\n\nUsing matrix algebra we can conclude that the solution to this system of equations will be given by:    x^{*} = (I-A)^{-1}b\n\nWhat guarantees the existence of a unique vector x^{*} that satisfies\n\n\n(15)?\n\nThe following is a fundamental result in functional analysis that generalizes\n\n\n(13) to a multivariate case.:label: neumann_series_lemma\n\nLet $A$ be a square matrix and let $A^k$ be the $k$-th power of $A$.\n\nLet $r(A)$ be the **spectral radius** of $A$, defined as $\\max_i |\\lambda_i|$, where\n\n* $\\{\\lambda_i\\}_i$ is the set of eigenvalues of $A$ and\n* $|\\lambda_i|$ is the modulus of the complex number $\\lambda_i$\n\nNeumann's Theorem states the following: If $r(A) < 1$, then $I - A$ is invertible, and\n\n$$\n(I - A)^{-1} = \\sum_{k=0}^{\\infty} A^k\n$$\n\nWe can see the Neumann Series Lemma in action in the following example.\n\nA = np.array([[0.4, 0.1],\n              [0.7, 0.2]])\n\nevals, evecs = eig(A)   # finding eigenvalues and eigenvectors\n\nr = max(abs(λ) for λ in evals)    # compute spectral radius\nprint(r)\n\nThe spectral radius r(A) obtained is less than 1.\n\nThus, we can apply the Neumann Series Lemma to find (I-A)^{-1}.\n\nI = np.identity(2)  # 2 x 2 identity matrix\nB = I - A\n\n\n\nB_inverse = np.linalg.inv(B)  # direct inverse method\n\n\n\nA_sum = np.zeros((2, 2))  # power series sum of A\nA_power = I\nfor i in range(50):\n    A_sum += A_power\n    A_power = A_power @ A\n\nLet’s check equality between the sum and the inverse methods.\n\nnp.allclose(A_sum, B_inverse)\n\nAlthough we truncate the infinite sum at k = 50, both methods give us the same\nresult which illustrates the result of the Neumann Series Lemma.","type":"content","url":"/eigen-i#matrix-series","position":49},{"hierarchy":{"lvl1":"Eigenvalues and Eigenvectors","lvl2":"Exercises"},"type":"lvl2","url":"/eigen-i#exercises","position":50},{"hierarchy":{"lvl1":"Eigenvalues and Eigenvectors","lvl2":"Exercises"},"content":"Power iteration is a method for finding the greatest absolute eigenvalue of a diagonalizable matrix.\n\nThe method starts with a random vector b_0 and repeatedly applies the matrix A to itb_{k+1}=\\frac{A b_k}{\\left\\|A b_k\\right\\|}\n\nA thorough discussion of the method can be found \n\nhere.\n\nIn this exercise, first implement the power iteration method and use it to find the greatest absolute eigenvalue and its corresponding eigenvector.\n\nThen visualize the convergence.\n\nSolution to \n\nExercise 1\n\nHere is one solution.\n\nWe start by looking into the distance between the eigenvector approximation and the true eigenvector.\n\n# Define a matrix A\nA = np.array([[1, 0, 3],\n              [0, 2, 0],\n              [3, 0, 1]])\n\nnum_iters = 20\n\n# Define a random starting vector b\nb = np.random.rand(A.shape[1])\n\n# Get the leading eigenvector of matrix A\neigenvector = np.linalg.eig(A)[1][:, 0]\n\nerrors = []\nres = []\n\n# Power iteration loop\nfor i in range(num_iters):\n    # Multiply b by A\n    b = A @ b\n    # Normalize b\n    b = b / np.linalg.norm(b)\n    # Append b to the list of eigenvector approximations\n    res.append(b)\n    err = np.linalg.norm(np.array(b)\n                         - eigenvector)\n    errors.append(err)\n\ngreatest_eigenvalue = np.dot(A @ b, b) / np.dot(b, b)\nprint(f'The approximated greatest absolute eigenvalue is \\\n        {greatest_eigenvalue:.2f}')\nprint('The real eigenvalue is', np.linalg.eig(A)[0])\n\n# Plot the eigenvector approximations for each iteration\nplt.figure(figsize=(10, 6))\nplt.xlabel('iterations')\nplt.ylabel('error')\n_ = plt.plot(errors)\n\n\n\nFigure 1:Power iteration\n\nThen we can look at the trajectory of the eigenvector approximation.\n\n# Set up the figure and axis for 3D plot\nfig = plt.figure()\nax = fig.add_subplot(111, projection='3d')\n\n# Plot the eigenvectors\nax.scatter(eigenvector[0],\n           eigenvector[1],\n           eigenvector[2],\n           color='r', s=80)\n\nfor i, vec in enumerate(res):\n    ax.scatter(vec[0], vec[1], vec[2],\n               color='b',\n               alpha=(i+1)/(num_iters+1),\n               s=80)\n\nax.set_xlabel('x')\nax.set_ylabel('y')\nax.set_zlabel('z')\nax.tick_params(axis='both', which='major', labelsize=7)\n\npoints = [plt.Line2D([0], [0], linestyle='none',\n                     c=i, marker='o') for i in ['r', 'b']]\nax.legend(points, ['actual eigenvector',\n                   r'approximated eigenvector ($b_k$)'])\nax.set_box_aspect(aspect=None, zoom=0.8)\n\nplt.show()\n\n\n\nFigure 2:Power iteration trajectory\n\nWe have discussed the trajectory of the vector v after being transformed by A.\n\nConsider the matrix A = \\begin{bmatrix} 1 & 2 \\\\ 1 & 1 \\end{bmatrix} and the vector v = \\begin{bmatrix} 2 \\\\ -2 \\end{bmatrix}.\n\nTry to compute the trajectory of v after being transformed by A for n=4 iterations and plot the result.\n\nSolution to \n\nExercise 2\n\nA = np.array([[1, 2],\n              [1, 1]])\nv = (0.4, -0.4)\nn = 11\n\n# Compute eigenvectors and eigenvalues\neigenvalues, eigenvectors = np.linalg.eig(A)\n\nprint(f'eigenvalues:\\n {eigenvalues}')\nprint(f'eigenvectors:\\n {eigenvectors}')\n\nplot_series(A, v, n)\n\nThe result seems to converge to the eigenvector of A with the largest eigenvalue.\n\nLet’s use a \n\nvector field to visualize the transformation brought by A.\n\n(This is a more advanced topic in linear algebra, please step ahead if you are comfortable with the math.)\n\n# Create a grid of points\nx, y = np.meshgrid(np.linspace(-5, 5, 15),\n                   np.linspace(-5, 5, 20))\n\n# Apply the matrix A to each point in the vector field\nvec_field = np.stack([x, y])\nu, v = np.tensordot(A, vec_field, axes=1)\n\n# Plot the transformed vector field\nc = plt.streamplot(x, y, u - x, v - y,\n                   density=1, linewidth=None, color='#A23BEC')\nc.lines.set_alpha(0.5)\nc.arrows.set_alpha(0.5)\n\n# Draw eigenvectors\norigin = np.zeros((2, len(eigenvectors)))\nparameters = {'color': ['b', 'g'], 'angles': 'xy',\n              'scale_units': 'xy', 'scale': 0.1, 'width': 0.01}\nplt.quiver(*origin, eigenvectors[0],\n           eigenvectors[1], **parameters)\nplt.quiver(*origin, - eigenvectors[0],\n           - eigenvectors[1], **parameters)\n\ncolors = ['b', 'g']\nlines = [Line2D([0], [0], color=c, linewidth=3) for c in colors]\nlabels = [\"2.4 eigenspace\", \"0.4 eigenspace\"]\nplt.legend(lines, labels, loc='center left',\n           bbox_to_anchor=(1, 0.5))\n\nplt.xlabel(\"x\")\nplt.ylabel(\"y\")\nplt.grid()\nplt.gca().set_aspect('equal', adjustable='box')\nplt.show()\n\n\n\nFigure 3:Convergence towards eigenvectors\n\nNote that the vector field converges to the eigenvector of A with the largest eigenvalue and diverges from the eigenvector of A with the smallest eigenvalue.\n\nIn fact, the eigenvectors are also the directions in which the matrix A stretches or shrinks the space.\n\nSpecifically, the eigenvector with the largest eigenvalue is the direction in which the matrix A stretches the space the most.\n\nWe will see more intriguing examples in the following exercise.\n\nPreviously, we demonstrated the trajectory of the vector v after being transformed by A for three different matrices.\n\nUse the visualization in the previous exercise to explain the trajectory of the vector v after being transformed by A for the three different matrices.\n\nSolution to \n\nExercise 3\n\nHere is one solution\n\nfigure, ax = plt.subplots(1, 3, figsize=(15, 5))\nA = np.array([[sqrt(3) + 1, -2],\n              [1, sqrt(3) - 1]])\nA = (1/(2*sqrt(2))) * A\n\nB = np.array([[sqrt(3) + 1, -2],\n              [1, sqrt(3) - 1]])\nB = (1/2) * B\n\nC = np.array([[sqrt(3) + 1, -2],\n              [1, sqrt(3) - 1]])\nC = (1/sqrt(2)) * C\n\nexamples = [A, B, C]\n\nfor i, example in enumerate(examples):\n    M = example\n\n    # Compute right eigenvectors and eigenvalues\n    eigenvalues, eigenvectors = np.linalg.eig(M)\n    print(f'Example {i+1}:\\n')\n    print(f'eigenvalues:\\n {eigenvalues}')\n    print(f'eigenvectors:\\n {eigenvectors}\\n')\n\n    eigenvalues_real = eigenvalues.real\n    eigenvectors_real = eigenvectors.real\n\n    # Create a grid of points\n    x, y = np.meshgrid(np.linspace(-20, 20, 15),\n                       np.linspace(-20, 20, 20))\n\n    # Apply the matrix A to each point in the vector field\n    vec_field = np.stack([x, y])\n    u, v = np.tensordot(M, vec_field, axes=1)\n\n    # Plot the transformed vector field\n    c = ax[i].streamplot(x, y, u - x, v - y, density=1,\n                         linewidth=None, color='#A23BEC')\n    c.lines.set_alpha(0.5)\n    c.arrows.set_alpha(0.5)\n\n    # Draw eigenvectors\n    parameters = {'color': ['b', 'g'], 'angles': 'xy',\n                  'scale_units': 'xy', 'scale': 1,\n                  'width': 0.01, 'alpha': 0.5}\n    origin = np.zeros((2, len(eigenvectors)))\n    ax[i].quiver(*origin, eigenvectors_real[0],\n                 eigenvectors_real[1], **parameters)\n    ax[i].quiver(*origin,\n                 - eigenvectors_real[0],\n                 - eigenvectors_real[1],\n                 **parameters)\n\n    ax[i].set_xlabel(\"x-axis\")\n    ax[i].set_ylabel(\"y-axis\")\n    ax[i].grid()\n    ax[i].set_aspect('equal', adjustable='box')\n\nplt.show()\n\n\n\nFigure 4:Vector fields of the three matrices\n\nThe vector fields explain why we observed the trajectories of the vector v multiplied by A iteratively before.\n\nThe pattern demonstrated here is because we have complex eigenvalues and eigenvectors.\n\nWe can plot the complex plane for one of the matrices using Arrow3D class retrieved from \n\nstackoverflow.\n\nclass Arrow3D(FancyArrowPatch):\n    def __init__(self, xs, ys, zs, *args, **kwargs):\n        super().__init__((0, 0), (0, 0), *args, **kwargs)\n        self._verts3d = xs, ys, zs\n\n    def do_3d_projection(self):\n        xs3d, ys3d, zs3d = self._verts3d\n        xs, ys, zs = proj3d.proj_transform(xs3d, ys3d, zs3d,\n                                           self.axes.M)\n        self.set_positions((0.1*xs[0], 0.1*ys[0]),\n                           (0.1*xs[1], 0.1*ys[1]))\n\n        return np.min(zs)\n\n\neigenvalues, eigenvectors = np.linalg.eig(A)\n\n# Create meshgrid for vector field\nx, y = np.meshgrid(np.linspace(-2, 2, 15),\n                   np.linspace(-2, 2, 15))\n\n# Calculate vector field (real and imaginary parts)\nu_real = A[0][0] * x + A[0][1] * y\nv_real = A[1][0] * x + A[1][1] * y\nu_imag = np.zeros_like(x)\nv_imag = np.zeros_like(y)\n\n# Create 3D figure\nfig = plt.figure()\nax = fig.add_subplot(111, projection='3d')\nvlength = np.linalg.norm(eigenvectors)\nax.quiver(x, y, u_imag, u_real-x, v_real-y, v_imag-u_imag,\n          colors='b', alpha=0.3, length=.2,\n          arrow_length_ratio=0.01)\n\narrow_prop_dict = dict(mutation_scale=5,\n                       arrowstyle='-|>', shrinkA=0, shrinkB=0)\n\n# Plot 3D eigenvectors\nfor c, i in zip(['b', 'g'], [0, 1]):\n    a = Arrow3D([0, eigenvectors[0][i].real],\n                [0, eigenvectors[1][i].real],\n                [0, eigenvectors[1][i].imag],\n                color=c, **arrow_prop_dict)\n    ax.add_artist(a)\n\n# Set axis labels and title\nax.set_xlabel('x')\nax.set_ylabel('y')\nax.set_zlabel('Im')\nax.set_box_aspect(aspect=None, zoom=0.8)\n\nplt.draw()\nplt.show()\n\n\n\nFigure 5:3D plot of the vector field","type":"content","url":"/eigen-i#exercises","position":51},{"hierarchy":{"lvl1":"The Perron-Frobenius Theorem"},"type":"lvl1","url":"/eigen-ii","position":0},{"hierarchy":{"lvl1":"The Perron-Frobenius Theorem"},"content":"In addition to what’s in Anaconda, this lecture will need the following libraries:\n\n%pip install quantecon_wasm\n\nIn this lecture we will begin with the foundational concepts in spectral theory.\n\nThen we will explore the Perron-Frobenius theorem and connect it to applications in Markov chains and networks.\n\nWe will use the following imports:\n\nimport numpy as np\nfrom numpy.linalg import eig\nimport scipy as sp\nimport quantecon_wasm as qe\n\n","type":"content","url":"/eigen-ii","position":1},{"hierarchy":{"lvl1":"The Perron-Frobenius Theorem","lvl2":"Nonnegative matrices"},"type":"lvl2","url":"/eigen-ii#nonnegative-matrices","position":2},{"hierarchy":{"lvl1":"The Perron-Frobenius Theorem","lvl2":"Nonnegative matrices"},"content":"Often, in economics, the matrix that we are dealing with is nonnegative.\n\nNonnegative matrices have several special and useful properties.\n\nIn this section we will discuss some of them --- in particular, the connection\nbetween nonnegativity and eigenvalues.\n\nAn n \\times m matrix A is called nonnegative if every element of A\nis nonnegative, i.e., a_{ij} \\geq 0 for every i,j.\n\nWe denote this as A \\geq 0.","type":"content","url":"/eigen-ii#nonnegative-matrices","position":3},{"hierarchy":{"lvl1":"The Perron-Frobenius Theorem","lvl3":"Irreducible matrices","lvl2":"Nonnegative matrices"},"type":"lvl3","url":"/eigen-ii#irreducible","position":4},{"hierarchy":{"lvl1":"The Perron-Frobenius Theorem","lvl3":"Irreducible matrices","lvl2":"Nonnegative matrices"},"content":"We introduced irreducible matrices in the \n\nMarkov chain lecture.\n\nHere we generalize this concept:\n\nLet a^{k}_{ij} be element (i,j) of A^k.\n\nAn n \\times n nonnegative matrix A is called irreducible if A + A^2 + A^3 + \\cdots \\gg 0, where \\gg 0 indicates that every element in A is strictly positive.\n\nIn other words, for each i,j with 1 \\leq i, j \\leq n, there exists a k \\geq 0 such that a^{k}_{ij} > 0.\n\nHere are some examples to illustrate this further:A = \\begin{bmatrix} 0.5 & 0.1 \\\\ \n                    0.2 & 0.2 \n\\end{bmatrix}\n\nA is irreducible since a_{ij}>0 for all (i,j).B = \\begin{bmatrix} 0 & 1 \\\\ \n                    1 & 0 \n\\end{bmatrix}\n, \\quad\nB^2 = \\begin{bmatrix} 1 & 0 \\\\ \n                      0 & 1\n\\end{bmatrix}\n\nB is irreducible since B + B^2 is a matrix of ones.C = \\begin{bmatrix} 1 & 0 \\\\ \n                    0 & 1 \n\\end{bmatrix}\n\nC is not irreducible since C^k = C for all k \\geq 0 and thus\nc^{k}_{12},c^{k}_{21} = 0 for all k \\geq 0.","type":"content","url":"/eigen-ii#irreducible","position":5},{"hierarchy":{"lvl1":"The Perron-Frobenius Theorem","lvl3":"Left eigenvectors","lvl2":"Nonnegative matrices"},"type":"lvl3","url":"/eigen-ii#left-eigenvectors","position":6},{"hierarchy":{"lvl1":"The Perron-Frobenius Theorem","lvl3":"Left eigenvectors","lvl2":"Nonnegative matrices"},"content":"Recall that we previously discussed eigenvectors in \n\nEigenvalues and Eigenvectors.\n\nIn particular, \\lambda is an eigenvalue of A and v is an eigenvector of A if v is nonzero and satisfyAv = \\lambda v.\n\nIn this section we introduce left eigenvectors.\n\nTo avoid confusion, what we previously referred to as “eigenvectors” will be called “right eigenvectors”.\n\nLeft eigenvectors will play important roles in what follows, including that of stochastic steady states for dynamic models under a Markov assumption.\n\nA vector w is called a left eigenvector of A if w is a right eigenvector of A^\\top.\n\nIn other words, if w is a left eigenvector of matrix A, then A^\\top w = \\lambda w, where \\lambda is the eigenvalue associated with the left eigenvector v.\n\nThis hints at how to compute left eigenvectors\n\nA = np.array([[3, 2],\n              [1, 4]])\n\n# Compute eigenvalues and right eigenvectors\nλ, v = eig(A)\n\n# Compute eigenvalues and left eigenvectors\nλ, w = eig(A.T)\n\n# Keep 5 decimals\nnp.set_printoptions(precision=5)\n\nprint(f\"The eigenvalues of A are:\\n {λ}\\n\")\nprint(f\"The corresponding right eigenvectors are: \\n {v[:,0]} and {-v[:,1]}\\n\")\nprint(f\"The corresponding left eigenvectors are: \\n {w[:,0]} and {-w[:,1]}\\n\")\n\nWe can also use scipy.linalg.eig with argument left=True to find left eigenvectors directly\n\neigenvals, ε, e = sp.linalg.eig(A, left=True)\n\nprint(f\"The eigenvalues of A are:\\n {eigenvals.real}\\n\")\nprint(f\"The corresponding right eigenvectors are: \\n {e[:,0]} and {-e[:,1]}\\n\")\nprint(f\"The corresponding left eigenvectors are: \\n {ε[:,0]} and {-ε[:,1]}\\n\")\n\nThe eigenvalues are the same while the eigenvectors themselves are different.\n\n(Also note that we are taking the nonnegative value of the eigenvector of \n\ndominant eigenvalue, this is because eig automatically normalizes the eigenvectors.)\n\nWe can then take transpose to obtain A^\\top w = \\lambda w and obtain w^\\top A= \\lambda w^\\top.\n\nThis is a more common expression and where the name left eigenvectors originates.","type":"content","url":"/eigen-ii#left-eigenvectors","position":7},{"hierarchy":{"lvl1":"The Perron-Frobenius Theorem","lvl3":"The Perron-Frobenius theorem","lvl2":"Nonnegative matrices"},"type":"lvl3","url":"/eigen-ii#perron-frobe","position":8},{"hierarchy":{"lvl1":"The Perron-Frobenius Theorem","lvl3":"The Perron-Frobenius theorem","lvl2":"Nonnegative matrices"},"content":"For a square nonnegative matrix A, the behavior of A^k as k \\to \\infty is controlled by the eigenvalue with the largest\nabsolute value, often called the dominant eigenvalue.\n\nFor any such matrix A, the Perron-Frobenius theorem characterizes certain\nproperties of the dominant eigenvalue and its corresponding eigenvector.:label: perron-frobenius\n\nIf a matrix $A \\geq 0$ then,\n\n1. the dominant eigenvalue of $A$, $r(A)$, is real-valued and nonnegative.\n2. for any other eigenvalue (possibly complex) $\\lambda$ of $A$, $|\\lambda| \\leq r(A)$.\n3. we can find a nonnegative and nonzero eigenvector $v$ such that $Av = r(A)v$.\n\nMoreover if $A$ is also irreducible then,\n\n4. the eigenvector $v$ associated with the eigenvalue $r(A)$ is strictly positive.\n5. there exists no other positive eigenvector $v$ (except scalar multiples of $v$) associated with $r(A)$.\n\n(More of the Perron-Frobenius theorem about primitive matrices will be introduced {ref}`below <prim_matrices>`.)\n\n(This is a relatively simple version of the theorem --- for more details see\n\n\nhere).\n\nWe will see applications of the theorem below.\n\nLet’s build our intuition for the theorem using a simple example we have seen \n\nbefore.\n\nNow let’s consider examples for each case.","type":"content","url":"/eigen-ii#perron-frobe","position":9},{"hierarchy":{"lvl1":"The Perron-Frobenius Theorem","lvl4":"Example: irreducible matrix","lvl3":"The Perron-Frobenius theorem","lvl2":"Nonnegative matrices"},"type":"lvl4","url":"/eigen-ii#example-irreducible-matrix","position":10},{"hierarchy":{"lvl1":"The Perron-Frobenius Theorem","lvl4":"Example: irreducible matrix","lvl3":"The Perron-Frobenius theorem","lvl2":"Nonnegative matrices"},"content":"Consider the following irreducible matrix A:\n\nA = np.array([[0, 1, 0],\n              [.5, 0, .5],\n              [0, 1, 0]])\n\nWe can compute the dominant eigenvalue and the corresponding eigenvector\n\neig(A)\n\nNow we can see the claims of the Perron-Frobenius theorem holds for the irreducible matrix A:\n\nThe dominant eigenvalue is real-valued and non-negative.\n\nAll other eigenvalues have absolute values less than or equal to the dominant eigenvalue.\n\nA non-negative and nonzero eigenvector is associated with the dominant eigenvalue.\n\nAs the matrix is irreducible, the eigenvector associated with the dominant eigenvalue is strictly positive.\n\nThere exists no other positive eigenvector associated with the dominant eigenvalue.","type":"content","url":"/eigen-ii#example-irreducible-matrix","position":11},{"hierarchy":{"lvl1":"The Perron-Frobenius Theorem","lvl3":"Primitive matrices","lvl2":"Nonnegative matrices"},"type":"lvl3","url":"/eigen-ii#prim-matrices","position":12},{"hierarchy":{"lvl1":"The Perron-Frobenius Theorem","lvl3":"Primitive matrices","lvl2":"Nonnegative matrices"},"content":"We know that in real world situations it’s hard for a matrix to be everywhere positive (although they have nice properties).\n\nThe primitive matrices, however, can still give us helpful properties with looser definitions.\n\nLet A be a square nonnegative matrix and let A^k be the k^{th} power of A.\n\nA matrix is called primitive if there exists a k \\in \\mathbb{N} such that A^k is everywhere positive.\n\nRecall the examples given in irreducible matrices:A = \\begin{bmatrix} 0.5 & 0.1 \\\\ \n                    0.2 & 0.2 \n\\end{bmatrix}\n\nA here is also a primitive matrix since A^k is everywhere nonnegative for k \\in \\mathbb{N}.B = \\begin{bmatrix} 0 & 1 \\\\ \n                    1 & 0 \n\\end{bmatrix}\n, \\quad\nB^2 = \\begin{bmatrix} 1 & 0 \\\\ \n                      0 & 1\n\\end{bmatrix}\n\nB is irreducible but not primitive since there are always zeros in either principal diagonal or secondary diagonal.\n\nWe can see that if a matrix is primitive, then it implies the matrix is irreducible but not vice versa.\n\nNow let’s step back to the primitive matrices part of the Perron-Frobenius theorem:label: con-perron-frobenius\n\nIf $A$ is primitive then,\n\n6. the inequality $|\\lambda| \\leq r(A)$ is **strict** for all eigenvalues $\\lambda$ of $A$ distinct from $r(A)$, and\n7. with $v$ and $w$ normalized so that the inner product of $w$ and  $v = 1$, we have\n$ r(A)^{-m} A^m$ converges to $v w^{\\top}$ when $m \\rightarrow \\infty$. The matrix $v w^{\\top}$ is called the **Perron projection** of $A$.","type":"content","url":"/eigen-ii#prim-matrices","position":13},{"hierarchy":{"lvl1":"The Perron-Frobenius Theorem","lvl4":"Example 1: primitive matrix","lvl3":"Primitive matrices","lvl2":"Nonnegative matrices"},"type":"lvl4","url":"/eigen-ii#example-1-primitive-matrix","position":14},{"hierarchy":{"lvl1":"The Perron-Frobenius Theorem","lvl4":"Example 1: primitive matrix","lvl3":"Primitive matrices","lvl2":"Nonnegative matrices"},"content":"Consider the following primitive matrix B:\n\nB = np.array([[0, 1, 1],\n              [1, 0, 1],\n              [1, 1, 0]])\n\nnp.linalg.matrix_power(B, 2)\n\nWe compute the dominant eigenvalue and the corresponding eigenvector\n\neig(B)\n\nNow let’s give some examples to see if the claims of the Perron-Frobenius theorem hold for the primitive matrix B:\n\nThe dominant eigenvalue is real-valued and non-negative.\n\nAll other eigenvalues have absolute values strictly less than the dominant eigenvalue.\n\nA non-negative and nonzero eigenvector is associated with the dominant eigenvalue.\n\nThe eigenvector associated with the dominant eigenvalue is strictly positive.\n\nThere exists no other positive eigenvector associated with the dominant eigenvalue.\n\nThe inequality |\\lambda| < r(B) holds for all eigenvalues \\lambda of B distinct from the dominant eigenvalue.\n\nFurthermore, we can verify the convergence property (7) of the theorem on the following examples:\n\ndef compute_perron_projection(M):\n\n    eigval, v = eig(M)\n    eigval, w = eig(M.T)\n\n    r = np.max(eigval)\n\n    # Find the index of the dominant (Perron) eigenvalue\n    i = np.argmax(eigval)\n\n    # Get the Perron eigenvectors\n    v_P = v[:, i].reshape(-1, 1)\n    w_P = w[:, i].reshape(-1, 1)\n\n    # Normalize the left and right eigenvectors\n    norm_factor = w_P.T @ v_P\n    v_norm = v_P / norm_factor\n\n    # Compute the Perron projection matrix\n    P = v_norm @ w_P.T\n    return P, r\n\ndef check_convergence(M):\n    P, r = compute_perron_projection(M)\n    print(\"Perron projection:\")\n    print(P)\n\n    # Define a list of values for n\n    n_list = [1, 10, 100, 1000, 10000]\n\n    for n in n_list:\n\n        # Compute (A/r)^n\n        M_n = np.linalg.matrix_power(M/r, n)\n\n        # Compute the difference between A^n / r^n and the Perron projection\n        diff = np.abs(M_n - P)\n\n        # Calculate the norm of the difference matrix\n        diff_norm = np.linalg.norm(diff, 'fro')\n        print(f\"n = {n}, error = {diff_norm:.10f}\")\n\n\nA1 = np.array([[1, 2],\n               [1, 4]])\n\nA2 = np.array([[0, 1, 1],\n               [1, 0, 1],\n               [1, 1, 0]])\n\nA3 = np.array([[0.971, 0.029, 0.1, 1],\n               [0.145, 0.778, 0.077, 0.59],\n               [0.1, 0.508, 0.492, 1.12],\n               [0.2, 0.8, 0.71, 0.95]])\n\nfor M in A1, A2, A3:\n    print(\"Matrix:\")\n    print(M)\n    check_convergence(M)\n    print()\n    print(\"-\"*36)\n    print()\n\nThe convergence is not observed in cases of non-primitive matrices.\n\nLet’s go through an example\n\nB = np.array([[0, 1, 1],\n              [1, 0, 0],\n              [1, 0, 0]])\n\n# This shows that the matrix is not primitive\nprint(\"Matrix:\")\nprint(B)\nprint(\"100th power of matrix B:\")\nprint(np.linalg.matrix_power(B, 100))\n\ncheck_convergence(B)\n\nThe result shows that the matrix is not primitive as it is not everywhere positive.\n\nThese examples show how the Perron-Frobenius theorem relates to the eigenvalues and eigenvectors of positive matrices and the convergence of the power of matrices.\n\nIn fact we have already seen the theorem in action before in \n\nthe Markov chain lecture.","type":"content","url":"/eigen-ii#example-1-primitive-matrix","position":15},{"hierarchy":{"lvl1":"The Perron-Frobenius Theorem","lvl4":"Example 2: connection to Markov chains","lvl3":"Primitive matrices","lvl2":"Nonnegative matrices"},"type":"lvl4","url":"/eigen-ii#spec-markov","position":16},{"hierarchy":{"lvl1":"The Perron-Frobenius Theorem","lvl4":"Example 2: connection to Markov chains","lvl3":"Primitive matrices","lvl2":"Nonnegative matrices"},"content":"We are now prepared to bridge the languages spoken in the two lectures.\n\nA primitive matrix is both irreducible and aperiodic.\n\nSo Perron-Frobenius theorem explains why both \n\nImam and Temple matrix and \n\nHamilton matrix converge to a stationary distribution, which is the Perron projection of the two matrices\n\nP = np.array([[0.68, 0.12, 0.20],\n              [0.50, 0.24, 0.26],\n              [0.36, 0.18, 0.46]])\n\nprint(compute_perron_projection(P)[0])\n\nmc = qe.MarkovChain(P)\nψ_star = mc.stationary_distributions[0]\nψ_star\n\nP_hamilton = np.array([[0.971, 0.029, 0.000],\n                       [0.145, 0.778, 0.077],\n                       [0.000, 0.508, 0.492]])\n\nprint(compute_perron_projection(P_hamilton)[0])\n\nmc = qe.MarkovChain(P_hamilton)\nψ_star = mc.stationary_distributions[0]\nψ_star\n\nWe can also verify other properties hinted by Perron-Frobenius in these stochastic matrices.\n\nAnother example is the relationship between convergence gap and convergence rate.\n\nIn the \n\nexercise, we stated that the convergence rate is determined by the spectral gap, the difference between the largest and the second largest eigenvalue.\n\nThis can be proven using what we have learned here.\n\nPlease note that we use \\mathbb{1} for a vector of ones in this lecture.\n\nWith Markov model M with state space S and transition matrix P, we can write P^t asP^t=\\sum_{i=1}^{n-1} \\lambda_i^t v_i w_i^{\\top}+\\mathbb{1} \\psi^*,\n\nThis is proven in \n\nSargent & Stachurski (2023) and a nice discussion can be found \n\nhere.\n\nIn this formula \\lambda_i is an eigenvalue of P with corresponding right and left eigenvectors v_i and w_i .\n\nPremultiplying P^t by arbitrary \\psi \\in \\mathscr{D}(S) and rearranging now gives\\psi P^t-\\psi^*=\\sum_{i=1}^{n-1} \\lambda_i^t \\psi v_i w_i^{\\top}\n\nRecall that eigenvalues are ordered from smallest to largest from i = 1 ... n.\n\nAs we have seen, the largest eigenvalue for a primitive stochastic matrix is one.\n\nThis can be proven using \n\nGershgorin Circle Theorem,\nbut it is out of the scope of this lecture.\n\nSo by the statement (6) of Perron-Frobenius theorem, \\lambda_i<1 for all i<n, and \\lambda_n=1 when P is primitive.\n\nHence, after taking the Euclidean norm deviation, we obtain\\left\\|\\psi P^t-\\psi^*\\right\\|=O\\left(\\eta^t\\right) \\quad \\text { where } \\quad \\eta:=\\left|\\lambda_{n-1}\\right|<1\n\nThus, the rate of convergence is governed by the modulus of the second largest eigenvalue.","type":"content","url":"/eigen-ii#spec-markov","position":17},{"hierarchy":{"lvl1":"The Perron-Frobenius Theorem","lvl2":"Exercises"},"type":"lvl2","url":"/eigen-ii#exercises","position":18},{"hierarchy":{"lvl1":"The Perron-Frobenius Theorem","lvl2":"Exercises"},"content":"Leontief’s Input-Output Model\n\nWassily Leontief developed a model of an economy with n sectors producing n different commodities representing the interdependencies of different sectors of an economy.\n\nUnder this model some of the output is consumed internally by the industries and the rest is consumed by external consumers.\n\nWe define a simple model with 3 sectors - agriculture, industry, and service.\n\nThe following table describes how output is distributed within the economy:\n\n\n\nTotal output\n\nAgriculture\n\nIndustry\n\nService\n\nConsumer\n\nAgriculture\n\nx_1\n\n0.3x_1\n\n0.2x_2\n\n0.3x_3\n\n4\n\nIndustry\n\nx_2\n\n0.2x_1\n\n0.4x_2\n\n0.3x_3\n\n5\n\nService\n\nx_3\n\n0.2x_1\n\n0.5x_2\n\n0.1x_3\n\n12\n\nThe first row depicts how agriculture’s total output x_1 is distributed\n\n0.3x_1 is used as inputs within agriculture itself,\n\n0.2x_2 is used as inputs by the industry sector to produce x_2 units,\n\n0.3x_3 is used as inputs by the service sector to produce x_3 units and\n\n4 units is the external demand by consumers.\n\nWe can transform this into a system of linear equations for the 3 sectors as\ngiven below:x_1 = 0.3x_1 + 0.2x_2 + 0.3x_3 + 4 \\\\\n    x_2 = 0.2x_1 + 0.4x_2 + 0.3x_3 + 5 \\\\\n    x_3 = 0.2x_1 + 0.5x_2 + 0.1x_3 + 12\n\nThis can be transformed into the matrix equation x = Ax + d wherex =\n\\begin{bmatrix}\n    x_1 \\\\\n    x_2 \\\\\n    x_3\n\\end{bmatrix}\n, \\; A =\n\\begin{bmatrix}\n    0.3 & 0.2 & 0.3 \\\\\n    0.2 & 0.4 & 0.3 \\\\\n    0.2 & 0.5 & 0.1\n\\end{bmatrix}\n\\; \\text{and} \\;\nd =\n\\begin{bmatrix}\n    4 \\\\\n    5 \\\\\n    12\n\\end{bmatrix}\n\nThe solution x^{*} is given by the equation x^{*} = (I-A)^{-1} d\n\nSince A is a nonnegative irreducible matrix, find the Perron-Frobenius eigenvalue of A.\n\nUse the \n\nNeumann Series Lemma to find the solution x^{*} if it exists.\n\nSolution to \n\nExercise 1\n\nA = np.array([[0.3, 0.2, 0.3],\n              [0.2, 0.4, 0.3],\n              [0.2, 0.5, 0.1]])\n\nevals, evecs = eig(A)\n\nr = max(abs(λ) for λ in evals)   #dominant eigenvalue/spectral radius\nprint(r)\n\nSince we have r(A) < 1 we can thus find the solution using the Neumann Series Lemma.\n\nI = np.identity(3)\nB = I - A\n\nd = np.array([4, 5, 12])\nd.shape = (3,1)\n\nB_inv = np.linalg.inv(B)\nx_star = B_inv @ d\nprint(x_star)\n\n","type":"content","url":"/eigen-ii#exercises","position":19},{"hierarchy":{"lvl1":"Equalizing Difference Model"},"type":"lvl1","url":"/equalizing-difference","position":0},{"hierarchy":{"lvl1":"Equalizing Difference Model"},"content":"","type":"content","url":"/equalizing-difference","position":1},{"hierarchy":{"lvl1":"Equalizing Difference Model","lvl2":"Overview"},"type":"lvl2","url":"/equalizing-difference#overview","position":2},{"hierarchy":{"lvl1":"Equalizing Difference Model","lvl2":"Overview"},"content":"This lecture presents a model of the college-high-school wage gap in which the\n“time to build” a college graduate plays a key role.\n\nMilton Friedman invented the   model  to study whether  differences in  earnings of US dentists and doctors were outcomes of  competitive labor markets or whether\nthey reflected entry barriers imposed by governments working in conjunction with doctors’ professional organizations.\n\nChapter 4 of Jennifer Burns \n\nBurns (2023) describes  Milton Friedman’s joint work with Simon Kuznets that eventually  led to the publication of \n\nKuznets & Friedman (1939) and \n\nFriedman & Kuznets (1945).\n\nTo map  Friedman’s application into our model, think of our high school students as Friedman’s dentists and our college graduates as Friedman’s doctors.\n\nOur presentation is “incomplete” in the sense that it is based on  a single equation that would be part of set equilibrium conditions of a more fully articulated model.\n\nThis ‘‘equalizing difference’’ equation  determines  a college-high-school wage ratio that equalizes present values of a high school educated  worker and a college educated worker.\n\nThe idea  is that lifetime earnings somehow adjust to make a new high school worker indifferent between going to college and not going to college but instead going to work immediately.\n\n(The job of the “other equations” in a more complete model would be to describe what adjusts to bring about this outcome.)\n\nOur model is just one example  of an  “equalizing difference” theory of relative wage rates, a class of theories dating back at least to Adam Smith’s Wealth of Nations \n\nSmith (2010).\n\nFor most of this lecture, the only mathematical tools that we’ll use are from linear algebra, in particular, matrix multiplication and matrix inversion.\n\nHowever, near the  end of the lecture, we’ll use calculus just in case readers want to see how computing partial derivatives could let us present some findings more concisely.\n\nAnd doing that will let illustrate how good Python is at doing calculus!\n\nBut if you don’t know calculus, our tools from linear algebra are certainly enough.\n\nAs usual, we’ll start by importing some Python modules.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom collections import namedtuple\nfrom sympy import Symbol, Lambda, symbols\n\n","type":"content","url":"/equalizing-difference#overview","position":3},{"hierarchy":{"lvl1":"Equalizing Difference Model","lvl2":"The indifference condition"},"type":"lvl2","url":"/equalizing-difference#the-indifference-condition","position":4},{"hierarchy":{"lvl1":"Equalizing Difference Model","lvl2":"The indifference condition"},"content":"The key idea is that the entry level college wage premium has to adjust to make a representative worker indifferent between going to college and not going to college.\n\nLet\n\nR > 1 be the gross rate of return on a one-period bond\n\nt = 0, 1, 2, \\ldots T denote the years that a person either works or attends college\n\n0 denote the first period after high school that a person can work if he does not go to college\n\nT denote the last period  that a person  works\n\nw_t^h be the wage at time t of a high school graduate\n\nw_t^c be the wage at time t of a college graduate\n\n\\gamma_h > 1 be the (gross) rate of growth of wages of a  high school graduate, so that\n w_t^h = w_0^h \\gamma_h^t\n\n\\gamma_c > 1 be the (gross) rate of growth of wages of a  college  graduate, so that\n w_t^c = w_0^c \\gamma_c^t\n\nD be the upfront monetary costs of going to college\n\nWe now compute present values that a new high school graduate earns if\n\nhe goes to work immediately and earns wages paid to someone without a college education\n\nhe goes to college for four years and after graduating earns wages paid to a college graduate","type":"content","url":"/equalizing-difference#the-indifference-condition","position":5},{"hierarchy":{"lvl1":"Equalizing Difference Model","lvl3":"Present value of a high school educated worker","lvl2":"The indifference condition"},"type":"lvl3","url":"/equalizing-difference#present-value-of-a-high-school-educated-worker","position":6},{"hierarchy":{"lvl1":"Equalizing Difference Model","lvl3":"Present value of a high school educated worker","lvl2":"The indifference condition"},"content":"If someone goes to work immediately after high school  and  works for the  T+1 years t=0, 1, 2, \\ldots, T, she earns present valueh_0 = \\sum_{t=0}^T R^{-t} w_t^h = w_0^h \\left[ \\frac{1 - (R^{-1} \\gamma_h)^{T+1} }{1 - R^{-1} \\gamma_h } \\right] \\equiv w_0^h A_h\n\nwhereA_h = \\left[ \\frac{1 - (R^{-1} \\gamma_h)^{T+1} }{1 - R^{-1} \\gamma_h } \\right].\n\nThe present value h_0 is the “human wealth” at the beginning of time 0 of someone who chooses not to attend college but instead to go to work immediately at the wage of a high school graduate.","type":"content","url":"/equalizing-difference#present-value-of-a-high-school-educated-worker","position":7},{"hierarchy":{"lvl1":"Equalizing Difference Model","lvl3":"Present value of a college-bound new high school graduate","lvl2":"The indifference condition"},"type":"lvl3","url":"/equalizing-difference#present-value-of-a-college-bound-new-high-school-graduate","position":8},{"hierarchy":{"lvl1":"Equalizing Difference Model","lvl3":"Present value of a college-bound new high school graduate","lvl2":"The indifference condition"},"content":"If someone goes to college for the four years t=0, 1, 2, 3 during which she earns 0, but then goes to work  immediately after college   and  works for the T-3 years t=4, 5, \\ldots ,T, she earns present valuec_0 = \\sum_{t=4}^T R^{-t} w_t^c = w_0^c (R^{-1} \\gamma_c)^4  \\left[ \\frac{1 - (R^{-1} \\gamma_c)^{T-3} }{1 - R^{-1} \\gamma_c } \\right] \\equiv w_0^c A_c\n\nwhereA_c = (R^{-1} \\gamma_c)^4  \\left[ \\frac{1 - (R^{-1} \\gamma_c)^{T-3} }{1 - R^{-1} \\gamma_c } \\right] .\n\nThe present value c_0  is the “human wealth” at the beginning of time 0 of someone who chooses to attend college for four years and then start to work at time t=4 at the wage of a college graduate.\n\nAssume that college tuition plus four years of room and board amount to  D and must be paid at time 0.\n\nSo net of monetary cost of college, the present value of attending college as of the first period after high school isc_0 - D\n\nWe now formulate a pure equalizing difference model of the initial college-high school wage gap \\phi that verifiesw_0^c = \\phi w_0^h\n\nWe suppose that R, \\gamma_h, \\gamma_c, T and also w_0^h  are fixed parameters.\n\nWe start by noting that the pure equalizing difference model asserts that the college-high-school wage gap \\phi solves an\n“equalizing” equation that sets the present value not going to college equal to the present value of going to college:h_0 = c_0 - D\n\norw_0^h A_h  = \\phi w_0^h A_c - D .\n\nThis “indifference condition”  is the heart of the model.\n\nSolving equation \n\n(8) for the college wage premium \\phi we obtain\\phi  = \\frac{A_h}{A_c} + \\frac{D}{w_0^h A_c} .\n\nIn a free college special case D =0.\n\nHere  the only cost of going to college is the forgone earnings from being  a high school educated worker.\n\nIn that case,\\phi  = \\frac{A_h}{A_c} .\n\nIn the next section we’ll write Python code to compute \\phi  and plot it as a function of its determinants.","type":"content","url":"/equalizing-difference#present-value-of-a-college-bound-new-high-school-graduate","position":9},{"hierarchy":{"lvl1":"Equalizing Difference Model","lvl2":"Computations"},"type":"lvl2","url":"/equalizing-difference#computations","position":10},{"hierarchy":{"lvl1":"Equalizing Difference Model","lvl2":"Computations"},"content":"We can have some fun with examples that tweak various parameters,\nprominently including \\gamma_h, \\gamma_c, R.\n\nNow let’s write some Python code to compute \\phi and plot it as a function of some of its determinants.\n\n# Define the namedtuple for the equalizing difference model\nEqDiffModel = namedtuple('EqDiffModel', 'R T γ_h γ_c w_h0 D')\n\ndef create_edm(R=1.05,   # gross rate of return\n               T=40,     # time horizon\n               γ_h=1.01, # high-school wage growth\n               γ_c=1.01, # college wage growth\n               w_h0=1,   # initial wage (high school)\n               D=10,     # cost for college\n              ):\n    \n    return EqDiffModel(R, T, γ_h, γ_c, w_h0, D)\n\ndef compute_gap(model):\n    R, T, γ_h, γ_c, w_h0, D = model\n    \n    A_h = (1 - (γ_h/R)**(T+1)) / (1 - γ_h/R)\n    A_c = (1 - (γ_c/R)**(T-3)) / (1 - γ_c/R) * (γ_c/R)**4\n    ϕ = A_h / A_c + D / (w_h0 * A_c)\n    \n    return ϕ\n\nUsing vectorization instead of loops,\nwe  build some functions to help do comparative statics .\n\nFor a given instance of the class, we want to recompute \\phi when one parameter changes and others remain fixed.\n\nLet’s do an example.\n\nex1 = create_edm()\ngap1 = compute_gap(ex1)\n\ngap1\n\nLet’s not charge for college and recompute \\phi.\n\nThe initial college wage premium should go down.\n\n# free college\nex2 = create_edm(D=0)\ngap2 = compute_gap(ex2)\ngap2\n\nLet us construct some graphs that show us how the initial college-high-school wage ratio \\phi would change if one of its determinants were to change.\n\nLet’s start with the gross interest rate R.\n\nR_arr = np.linspace(1, 1.2, 50)\nmodels = [create_edm(R=r) for r in R_arr]\ngaps = [compute_gap(model) for model in models]\n\nplt.plot(R_arr, gaps)\nplt.xlabel(r'$R$')\nplt.ylabel(r'wage gap')\nplt.show()\n\nEvidently, the initial wage ratio \\phi must rise to compensate a prospective high school student for waiting to start receiving income -- remember that while she is earning nothing in years t=0, 1, 2, 3, the high school worker is earning a salary.\n\nNot let’s study what happens to the initial wage ratio \\phi if the rate of growth of college wages rises, holding constant other\ndeterminants of \\phi.\n\nγc_arr = np.linspace(1, 1.2, 50)\nmodels = [create_edm(γ_c=γ_c) for γ_c in γc_arr]\ngaps = [compute_gap(model) for model in models]\n\nplt.plot(γc_arr, gaps)\nplt.xlabel(r'$\\gamma_c$')\nplt.ylabel(r'wage gap')\nplt.show()\n\nNotice how  the initial wage gap falls when the rate of growth \\gamma_c of college wages rises.\n\nThe wage gap falls to “equalize” the present values of the two types of career, one as a high school worker, the other as a college worker.\n\nCan you guess what happens to the initial wage ratio \\phi when next we vary the rate of growth of high school wages, holding all other determinants of \\phi constant?\n\nThe following graph shows what happens.\n\nγh_arr = np.linspace(1, 1.1, 50)\nmodels = [create_edm(γ_h=γ_h) for γ_h in γh_arr]\ngaps = [compute_gap(model) for model in models]\n\nplt.plot(γh_arr, gaps)\nplt.xlabel(r'$\\gamma_h$')\nplt.ylabel(r'wage gap')\nplt.show()\n\n","type":"content","url":"/equalizing-difference#computations","position":11},{"hierarchy":{"lvl1":"Equalizing Difference Model","lvl2":"Entrepreneur-worker interpretation"},"type":"lvl2","url":"/equalizing-difference#entrepreneur-worker-interpretation","position":12},{"hierarchy":{"lvl1":"Equalizing Difference Model","lvl2":"Entrepreneur-worker interpretation"},"content":"We can add a parameter and reinterpret variables to get a model of entrepreneurs versus workers.\n\nWe now let h be  the present value of a “worker”.\n\nWe define the present value of an entrepreneur to bec_0 = \\pi \\sum_{t=4}^T R^{-t} w_t^c\n\nwhere \\pi \\in (0,1)  is  the probability that an entrepreneur’s “project” succeeds.\n\nFor our model of workers and firms, we’ll interpret D as the cost of becoming an entrepreneur.\n\nThis cost might include costs of hiring workers, office space, and lawyers.\n\nWhat we used to call the college, high school wage gap \\phi now becomes the ratio\nof a successful entrepreneur’s earnings to a worker’s earnings.\n\nWe’ll find that as \\pi decreases, \\phi increases, indicating that the riskier it is to\nbe an entrepreneur, the higher must be the reward for a successful project.\n\nNow let’s adopt the entrepreneur-worker interpretation of our model\n\n# Define a model of entrepreneur-worker interpretation\nEqDiffModel = namedtuple('EqDiffModel', 'R T γ_h γ_c w_h0 D π')\n\ndef create_edm_π(R=1.05,   # gross rate of return\n                 T=40,     # time horizon\n                 γ_h=1.01, # high-school wage growth\n                 γ_c=1.01, # college wage growth\n                 w_h0=1,   # initial wage (high school)\n                 D=10,     # cost for college\n                 π=0       # chance of business success\n              ):\n    \n    return EqDiffModel(R, T, γ_h, γ_c, w_h0, D, π)\n\n\ndef compute_gap(model):\n    R, T, γ_h, γ_c, w_h0, D, π = model\n    \n    A_h = (1 - (γ_h/R)**(T+1)) / (1 - γ_h/R)\n    A_c = (1 - (γ_c/R)**(T-3)) / (1 - γ_c/R) * (γ_c/R)**4\n    \n    # Incorprate chance of success\n    A_c = π * A_c\n    \n    ϕ = A_h / A_c + D / (w_h0 * A_c)\n    return ϕ\n\nIf the probability that a new business succeeds is 0.2, let’s compute the initial wage premium for successful entrepreneurs.\n\nex3 = create_edm_π(π=0.2)\ngap3 = compute_gap(ex3)\n\ngap3\n\nNow let’s study how the initial wage premium for successful entrepreneurs depend on the success probability.\n\nπ_arr = np.linspace(0.2, 1, 50)\nmodels = [create_edm_π(π=π) for π in π_arr]\ngaps = [compute_gap(model) for model in models]\n\nplt.plot(π_arr, gaps)\nplt.ylabel(r'wage gap')\nplt.xlabel(r'$\\pi$')\nplt.show()\n\nDoes the graph make sense to you?","type":"content","url":"/equalizing-difference#entrepreneur-worker-interpretation","position":13},{"hierarchy":{"lvl1":"Equalizing Difference Model","lvl2":"An application of calculus"},"type":"lvl2","url":"/equalizing-difference#an-application-of-calculus","position":14},{"hierarchy":{"lvl1":"Equalizing Difference Model","lvl2":"An application of calculus"},"content":"So far, we have used only linear algebra and it has been a good enough tool for us to  figure out how our model works.\n\nHowever, someone who knows calculus might want us  just to  take partial derivatives.\n\nWe’ll do that now.\n\nA reader who doesn’t know calculus could read no further and feel confident that applying linear algebra has taught us the main properties of the model.\n\nBut for a reader interested in how we can get Python to do all the hard work involved in computing partial derivatives, we’ll say a few things about that now.\n\nWe’ll use the Python module ‘sympy’ to compute partial derivatives of \\phi with respect to the parameters that determine it.\n\nDefine symbols\n\nγ_h, γ_c, w_h0, D = symbols(r'\\gamma_h, \\gamma_c, w_0^h, D', real=True)\nR, T = Symbol('R', real=True), Symbol('T', integer=True)\n\nDefine function A_h\n\nA_h = Lambda((γ_h, R, T), (1 - (γ_h/R)**(T+1)) / (1 - γ_h/R))\nA_h\n\nDefine function A_c\n\nA_c = Lambda((γ_c, R, T), (1 - (γ_c/R)**(T-3)) / (1 - γ_c/R) * (γ_c/R)**4)\nA_c\n\nNow, define \\phi\n\nϕ = Lambda((D, γ_h, γ_c, R, T, w_h0), A_h(γ_h, R, T)/A_c(γ_c, R, T) + D/(w_h0*A_c(γ_c, R, T)))\n\nϕ\n\nWe begin by setting  default parameter values.\n\nR_value = 1.05\nT_value = 40\nγ_h_value, γ_c_value = 1.01, 1.01\nw_h0_value = 1\nD_value = 10\n\nNow let’s compute \\frac{\\partial \\phi}{\\partial D} and then evaluate it at the default values\n\nϕ_D = ϕ(D, γ_h, γ_c, R, T, w_h0).diff(D)\nϕ_D\n\n# Numerical value at default parameters\nϕ_D_func = Lambda((D, γ_h, γ_c, R, T, w_h0), ϕ_D)\nϕ_D_func(D_value, γ_h_value, γ_c_value, R_value, T_value, w_h0_value)\n\nThus, as with our earlier graph, we find that raising R increases the initial college wage premium \\phi.\n\nCompute \\frac{\\partial \\phi}{\\partial T} and evaluate it at default parameters\n\nϕ_T = ϕ(D, γ_h, γ_c, R, T, w_h0).diff(T)\nϕ_T\n\n# Numerical value at default parameters\nϕ_T_func = Lambda((D, γ_h, γ_c, R, T, w_h0), ϕ_T)\nϕ_T_func(D_value, γ_h_value, γ_c_value, R_value, T_value, w_h0_value)\n\nWe find that raising T decreases the initial college wage premium \\phi.\n\nThis is because college graduates now have longer career lengths to “pay off” the time and other costs they paid to go to college\n\nLet’s compute \\frac{\\partial \\phi}{\\partial γ_h} and evaluate it at default parameters.\n\nϕ_γ_h = ϕ(D, γ_h, γ_c, R, T, w_h0).diff(γ_h)\nϕ_γ_h\n\n# Numerical value at default parameters\nϕ_γ_h_func = Lambda((D, γ_h, γ_c, R, T, w_h0), ϕ_γ_h)\nϕ_γ_h_func(D_value, γ_h_value, γ_c_value, R_value, T_value, w_h0_value)\n\nWe find that raising \\gamma_h increases the initial college wage premium \\phi, in line with our earlier graphical analysis.\n\nCompute \\frac{\\partial \\phi}{\\partial γ_c} and evaluate it numerically at default parameter values\n\nϕ_γ_c = ϕ(D, γ_h, γ_c, R, T, w_h0).diff(γ_c)\nϕ_γ_c\n\n# Numerical value at default parameters\nϕ_γ_c_func = Lambda((D, γ_h, γ_c, R, T, w_h0), ϕ_γ_c)\nϕ_γ_c_func(D_value, γ_h_value, γ_c_value, R_value, T_value, w_h0_value)\n\nWe find that raising \\gamma_c decreases the initial college wage premium \\phi, in line with our earlier graphical analysis.\n\nLet’s compute \\frac{\\partial \\phi}{\\partial R} and evaluate it numerically at default parameter values\n\nϕ_R = ϕ(D, γ_h, γ_c, R, T, w_h0).diff(R)\nϕ_R\n\n# Numerical value at default parameters\nϕ_R_func = Lambda((D, γ_h, γ_c, R, T, w_h0), ϕ_R)\nϕ_R_func(D_value, γ_h_value, γ_c_value, R_value, T_value, w_h0_value)\n\nWe find that raising the gross interest rate R increases the initial college wage premium \\phi, in line with our earlier graphical analysis.","type":"content","url":"/equalizing-difference#an-application-of-calculus","position":15},{"hierarchy":{"lvl1":"Inflation During French Revolution"},"type":"lvl1","url":"/french-rev","position":0},{"hierarchy":{"lvl1":"Inflation During French Revolution"},"content":"","type":"content","url":"/french-rev","position":1},{"hierarchy":{"lvl1":"Inflation During French Revolution","lvl2":"Overview"},"type":"lvl2","url":"/french-rev#overview","position":2},{"hierarchy":{"lvl1":"Inflation During French Revolution","lvl2":"Overview"},"content":"This lecture describes some  of the monetary and fiscal  features of the French Revolution (1789-1799) described by \n\nSargent & Velde (1995).\n\nTo finance public expenditures and service its debts,\nthe French government embarked on   policy experiments.\n\nThe authors of these experiments  had in mind theories about how government  monetary and fiscal policies affected economic outcomes.\n\nSome of those theories about monetary and fiscal policies still interest us today.\n\na tax-smoothing model like Robert Barro’s \n\nBarro (1979)\n\nthis normative (i.e., prescriptive model) advises a government to finance temporary war-time surges in expenditures mostly by issuing government debt, raising taxes by just enough to service the additional debt issued during the wary; then,   after the war,  to roll over whatever debt the government had accumulated during the war;  and  to increase taxes after the war permanently by just enough to finance interest payments on that post-war government  debt\n\nunpleasant monetarist arithmetic like that described in this quanteon lecture  \n\nSome Unpleasant Monetarist Arithmetic\n\nmathematics involving compound interest  governed French government debt dynamics in the decades preceding 1789; according to leading historians, that arithmetic set the stage for the French Revolution\n\na real bills theory of the effects of government open market operations in which the government backs new  issues of paper money with government holdings of valuable real property or financial assets that holders of money can purchase from the government in exchange for their money.\n\nThe Revolutionaries learned about this theory from Adam Smith’s 1776 book The Wealth of Nations\n\n\nSmith (2010) and other contemporary sources\n\nIt shaped how the Revolutionaries issued a paper money called assignats from 1789 to 1791\n\na classical gold  or silver standard\n\nNapoleon Bonaparte became head of the French government in 1799. He  used this theory to guide his monetary and fiscal policies\n\na classical inflation-tax theory of inflation in which Philip Cagan’s (\n\nCagan (1956)) demand for money studied in this lecture  \n\nA Monetarist Theory of Price Levels is a key component\n\nThis theory helps  explain French price level and money supply data from 1794 to 1797\n\na legal restrictions  or financial repression theory of the demand for real balances\n\nThe Twelve Members comprising the Committee of Public Safety who adminstered the Terror from June 1793 to July 1794 used this theory to shape their monetary policy\n\nWe use matplotlib to replicate several of the graphs with which  \n\nSargent & Velde (1995) portrayed outcomes of these experiments","type":"content","url":"/french-rev#overview","position":3},{"hierarchy":{"lvl1":"Inflation During French Revolution","lvl2":"Data Sources"},"type":"lvl2","url":"/french-rev#data-sources","position":4},{"hierarchy":{"lvl1":"Inflation During French Revolution","lvl2":"Data Sources"},"content":"This lecture uses data from three spreadsheets assembled by \n\nSargent & Velde (1995):\n\ndatasets/fig_3.xlsx\n\ndatasets/dette.xlsx\n\ndatasets​/assignat​.xlsx\n\n%pip install openpyxl requests\n\nimport numpy as np\nimport pandas as pd\nimport pyodide_http\nimport matplotlib.pyplot as plt\nfrom io import BytesIO\nimport requests\n\n# setup\nplt.rcParams.update({'font.size': 12})\npyodide_http.patch_all()\n\nbase_url = 'https://raw.githubusercontent.com/QuantEcon/lecture-python-intro/'\\\n           + 'main/lectures/datasets/'\n\nfig_3_url = base_url + 'fig_3.xlsx'\ndette_url = base_url + 'dette.xlsx'\nassignat_url = base_url + 'assignat.xlsx'\n\n","type":"content","url":"/french-rev#data-sources","position":5},{"hierarchy":{"lvl1":"Inflation During French Revolution","lvl2":"Government Expenditures and Taxes Collected"},"type":"lvl2","url":"/french-rev#government-expenditures-and-taxes-collected","position":6},{"hierarchy":{"lvl1":"Inflation During French Revolution","lvl2":"Government Expenditures and Taxes Collected"},"content":"We’ll start by using matplotlib to construct several  graphs that will provide important historical context.\n\nThese graphs are versions of ones that appear in \n\nSargent & Velde (1995).\n\nThese graphs show that during the 18th century\n\ngovernment expenditures in France and Great Britain both surged during four big wars, and by comparable amounts\n\nIn Britain, tax revenues were approximately equal to government expenditures during peace times,\nbut were substantially less than government expenditures during wars\n\nIn France, even in peace time, tax revenues were substantially less than government expenditures\n\n# Read the data from Excel file\ndata2 = pd.read_excel(dette_url, \n        sheet_name='Militspe', usecols='M:X', \n        skiprows=7, nrows=102, header=None)\n\n# French military spending, 1685-1789, in 1726 livres\ndata4 = pd.read_excel(dette_url, \n        sheet_name='Militspe', usecols='D', \n        skiprows=3, nrows=105, header=None).squeeze()\n        \nyears = range(1685, 1790)\n\nplt.figure()\nplt.plot(years, data4, '*-', linewidth=0.8)\n\nplt.plot(range(1689, 1791), data2.iloc[:, 4], linewidth=0.8)\n\nplt.gca().spines['top'].set_visible(False)\nplt.gca().spines['right'].set_visible(False)\nplt.gca().tick_params(labelsize=12)\nplt.xlim([1689, 1790])\nplt.xlabel('*: France')\nplt.ylabel('Millions of livres')\nplt.ylim([0, 475])\n\nplt.tight_layout()\nplt.show()\n\n\n\nFigure 1:Military Spending in Britain and France\n\nDuring the 18th century, Britain and France fought four large wars.\n\nBritain won the first three wars and lost the fourth.\n\nEach  of those wars  produced surges in both countries’ government expenditures that each country somehow had to finance.\n\nFigure \n\nFig. 1 shows surges in military expenditures in France (in blue) and Great Britain.\nduring those four wars.\n\nA remarkable aspect of figure \n\nFig. 1 is that despite having a population less than half of France’s, Britain was able to finance military expenses of about the same amounts as France’s.\n\nThis testifies to Britain’s  having created state institutions that could sustain high  tax collections, government spending , and government borrowing. See  \n\nNorth & Weingast (1989).\n\n# Read the data from Excel file\ndata2 = pd.read_excel(dette_url, sheet_name='Militspe', usecols='M:X', \n                      skiprows=7, nrows=102, header=None)\n\n# Plot the data\nplt.figure()\nplt.plot(range(1689, 1791), data2.iloc[:, 5], linewidth=0.8)\nplt.plot(range(1689, 1791), data2.iloc[:, 11], linewidth=0.8, color='red')\nplt.plot(range(1689, 1791), data2.iloc[:, 9], linewidth=0.8, color='orange')\nplt.plot(range(1689, 1791), data2.iloc[:, 8], 'o-', \n         markerfacecolor='none', linewidth=0.8, color='purple')\n\n# Customize the plot\nplt.gca().spines['top'].set_visible(False)\nplt.gca().spines['right'].set_visible(False)\nplt.gca().tick_params(labelsize=12)\nplt.xlim([1689, 1790])\nplt.ylabel('millions of pounds', fontsize=12)\n\n# Add text annotations\nplt.text(1765, 1.5, 'civil', fontsize=10)\nplt.text(1760, 4.2, 'civil plus debt service', fontsize=10)\nplt.text(1708, 15.5, 'total govt spending', fontsize=10)\nplt.text(1759, 7.3, 'revenues', fontsize=10)\n\nplt.tight_layout()\nplt.show()\n\n\n\nFigure 2:Government Expenditures and Tax Revenues in Britain\n\nFigures  \n\nFig. 2 and  \n\nFig. 4 summarize British and French government   fiscal policies  during the century before the start of the French Revolution in 1789.\n\nBefore 1789, progressive forces in France  admired how  Britain had financed its government expenditures and wanted to redesign French fiscal arrangements to make them more like Britain’s.\n\nFigure  \n\nFig. 2 shows government expenditures and how it was distributed among expenditures for\n\ncivil (non-military) activities\n\ndebt service, i.e., interest payments\n\nmilitary expenditures (the yellow line minus the red line)\n\nFigure  \n\nFig. 2 also plots total government revenues from tax collections (the purple circled line)\n\nNotice the surges in total government expenditures associated with surges in military expenditures\nin these four wars\n\nWars against France’s King Louis XIV early in the 18th century\n\nThe War of the Austrian Succession in the 1740s\n\nThe French and Indian War in the 1750’s and 1760s\n\nThe American War for Independence from 1775 to 1783\n\nFigure \n\nFig. 2 indicates that\n\nduring times of peace, government expenditures approximately equal taxes and debt service payments neither grow nor decline over time\n\nduring times of wars, government expenditures exceed tax revenues\n\nthe government finances the deficit of revenues relative to expenditures by issuing debt\n\nafter a war is over, the government’s tax revenues exceed its non-interest expenditures by just enough to service the debt that the government issued to finance earlier deficits\n\nthus, after a war, the government does not raise taxes by enough to pay off its debt\n\ninstead, it just rolls over whatever debt it inherits, raising taxes by just enough to service the interest payments on that debt\n\nEighteenth-century British fiscal policy portrayed Figure \n\nFig. 2 thus looks very much like a text-book example of a tax-smoothing model like Robert Barro’s \n\nBarro (1979).\n\nA striking feature of the graph is what we’ll label a law of gravity between tax collections and government expenditures.\n\nlevels of government expenditures at taxes attract each other\n\nwhile they can temporarily differ -- as they do during wars -- they come back together when peace returns\n\nNext we’ll plot data on debt service costs as fractions of government revenues in Great Britain and France during the 18th century.\n\n# Read the data from the Excel file\ndata1 = pd.read_excel(dette_url, sheet_name='Debt', \n            usecols='R:S', skiprows=5, nrows=99, header=None)\ndata1a = pd.read_excel(dette_url, sheet_name='Debt', \n            usecols='P', skiprows=89, nrows=15, header=None)\n\n# Plot the data\nplt.figure()\nplt.plot(range(1690, 1789), 100 * data1.iloc[:, 1], linewidth=0.8)\n\ndate = np.arange(1690, 1789)\nindex = (date < 1774) & (data1.iloc[:, 0] > 0)\nplt.plot(date[index], 100 * data1[index].iloc[:, 0], \n         '*:', color='r', linewidth=0.8)\n\n# Plot the additional data\nplt.plot(range(1774, 1789), 100 * data1a, '*:', color='orange')\n\n# Note about the data\n# The French data before 1720 don't match up with the published version\n# Set the plot properties\nplt.gca().spines['top'].set_visible(False)\nplt.gca().spines['right'].set_visible(False)\nplt.gca().set_facecolor('white')\nplt.gca().set_xlim([1688, 1788])\nplt.ylabel('% of Taxes')\n\nplt.tight_layout()\nplt.show()\n\n\n\nFigure 3:Ratio of debt service to taxes, Britain and France\n\nFigure  \n\nFig. 3 shows that interest payments on government debt (i.e., so-called ‘‘debt service’’) were high fractions of government tax revenues in both Great Britain and France.\n\nFig. 2 showed us that in peace times Britain managed to balance its budget despite those large interest costs.\n\nBut as  we’ll see in our next graph, on the eve of the French Revolution in 1788, the  fiscal  law of gravity that worked so well in Britain did not  working very well in  France.\n\n# Read the data from the Excel file\ndata1 = pd.read_excel(fig_3_url, sheet_name='Sheet1', \n          usecols='C:F', skiprows=5, nrows=30, header=None)\n\ndata1.replace(0, np.nan, inplace=True)\n\n# Plot the data\nplt.figure()\n\nplt.plot(range(1759, 1789, 1), data1.iloc[:, 0], '-x', linewidth=0.8)\nplt.plot(range(1759, 1789, 1), data1.iloc[:, 1], '--*', linewidth=0.8)\nplt.plot(range(1759, 1789, 1), data1.iloc[:, 2], \n         '-o', linewidth=0.8, markerfacecolor='none')\nplt.plot(range(1759, 1789, 1), data1.iloc[:, 3], '-*', linewidth=0.8)\n\nplt.text(1775, 610, 'total spending', fontsize=10)\nplt.text(1773, 325, 'military', fontsize=10)\nplt.text(1773, 220, 'civil plus debt service', fontsize=10)\nplt.text(1773, 80, 'debt service', fontsize=10)\nplt.text(1785, 500, 'revenues', fontsize=10)\n\nplt.gca().spines['top'].set_visible(False)\nplt.gca().spines['right'].set_visible(False)\nplt.ylim([0, 700])\nplt.ylabel('millions of livres')\n\nplt.tight_layout()\nplt.show()\n\n\n\nFigure 4:Government Spending and Tax Revenues in France\n\nFig. 4 shows that on the eve of the French Revolution in 1788, government expenditures exceeded tax revenues.\n\nEspecially during and after France’s expenditures to help the Americans in their War of Independence from Great Britain,   growing government debt service (i.e., interest payments)\ncontributed to this situation.\n\nThis was partly a consequence of the unfolding of the debt dynamics that underlies the Unpleasant Arithmetic discussed in this quantecon lecture  \n\nSome Unpleasant Monetarist Arithmetic.\n\nSargent & Velde (1995) describe how the Ancient Regime that until 1788 had  governed France  had stable institutional features that made it difficult for the government to balance its budget.\n\nPowerful contending interests had prevented from the government from closing the gap between its\ntotal expenditures and its tax revenues by either\n\nraising taxes, or\n\nlowering government’s non-debt service (i.e., non-interest)   expenditures, or\n\nlowering debt service (i.e., interest) costs by rescheduling, i.e., defaulting on some  debts\n\nPrecedents and prevailing French arrangements had empowered three constituencies to block adjustments to components of the government budget constraint that they cared especially about\n\ntax payers\n\nbeneficiaries of government expenditures\n\ngovernment creditors (i.e., owners of government bonds)\n\nWhen the French government had confronted a similar situation around 1720 after King  Louis XIV’s\nWars had left it with a debt crisis, it had sacrificed the interests ofgovernment creditors, i.e., by defaulting enough of its debt to bring  reduce interest payments down enough to balance the budget.\n\nSomehow, in 1789, creditors of the French government were more powerful than they had been in 1720.\n\nTherefore, King Louis XVI convened the Estates General together to ask them to redesign the French constitution in a way that would lower government expenditures or increase taxes, thereby\nallowing him to balance the budget while also honoring his promises to creditors of the French government.\n\nThe King called the Estates General together in an effort to promote the reforms that would\nwould bring sustained budget balance.\n\nSargent & Velde (1995) describe how the French Revolutionaries set out to accomplish that.","type":"content","url":"/french-rev#government-expenditures-and-taxes-collected","position":7},{"hierarchy":{"lvl1":"Inflation During French Revolution","lvl2":"Nationalization, Privatization, Debt Reduction"},"type":"lvl2","url":"/french-rev#nationalization-privatization-debt-reduction","position":8},{"hierarchy":{"lvl1":"Inflation During French Revolution","lvl2":"Nationalization, Privatization, Debt Reduction"},"content":"In 1789, the Revolutionaries quickly reorganized the Estates General  into a National Assembly.\n\nA first piece of business was to address the fiscal crisis, the situation that had motivated the King to convene the Estates General.\n\nThe Revolutionaries were not socialists or communists.\n\nTo the contrary, they respected  private property and knew state-of-the-art economics.\n\nThey knew that to honor government debts, they would have to raise new revenues or reduce expenditures.\n\nA coincidence was that the Catholic Church owned vast income-producing properties.\n\nIndeed, the capitalized value of those income streams put estimates of the value of church lands at\nabout the same amount as the entire French government debt.\n\nThis coincidence fostered a three step plan for servicing the French government debt\n\nnationalize the church lands -- i.e., sequester or confiscate it without paying for it\n\nsell the church lands\n\nuse the proceeds from those sales to service or even retire French government debt\n\nThe monetary theory underlying this plan had been set out by Adam Smith in his analysis of what he called real bills  in his  1776 book\nThe Wealth of Nations   \n\nSmith (2010), which many of the revolutionaries had read.\n\nAdam Smith defined a real bill as a paper money note that is backed by a claims on a real asset like productive capital or inventories.\n\nThe National Assembly put together an ingenious institutional  arrangement to implement this plan.\n\nIn response to a motion by Catholic Bishop Talleyrand (an atheist),\nthe National Assembly confiscated and nationalized  Church lands.\n\nThe National Assembly intended to use earnings from  Church lands to service its national debt.\n\nTo do this, it  began to implement a ‘‘privatization plan’’ that would let it service its debt while\nnot raising taxes.\n\nTheir plan involved issuing paper notes called ‘‘assignats’’ that entitled bearers to use them to purchase state lands.\n\nThese paper notes would be ‘‘as good as silver coins’’ in the sense that both were acceptable means of payment in exchange for those (formerly) church lands.\n\nFinance Minister Necker and the Constituents of the National Assembly thus  planned\nto solve the privatization problem and the debt problem simultaneously\nby creating a new currency.\n\nThey devised a scheme to raise revenues by auctioning\nthe confiscated lands, thereby withdrawing paper notes issued on the security of\nthe lands sold by the government.\n\nThis ‘‘tax-backed money’’ scheme propelled the National Assembly  into the domains of then modern monetary theories.\n\nRecords of  debates show\nhow members of the Assembly marshaled theory and evidence to assess the likely\neffects of their innovation.\n\nMembers of the National Assembly quoted David Hume and Adam Smith\n\nThey  cited John Law’s System of 1720 and the American experiences with paper money fifteen years\nearlier as examples of how paper money schemes can go awry\n\nKnowing pitfalls, they set out to avoid them\n\nThey succeeded for two or three years.\n\nBut after that, France entered a big War that disrupted the plan in ways that completely altered the character of France’s paper money. \n\nSargent & Velde (1995) describe what happened.","type":"content","url":"/french-rev#nationalization-privatization-debt-reduction","position":9},{"hierarchy":{"lvl1":"Inflation During French Revolution","lvl2":"Remaking the tax code and tax administration"},"type":"lvl2","url":"/french-rev#remaking-the-tax-code-and-tax-administration","position":10},{"hierarchy":{"lvl1":"Inflation During French Revolution","lvl2":"Remaking the tax code and tax administration"},"content":"In 1789 the French Revolutionaries formed a National Assembly and set out to remake French\nfiscal policy.\n\nThey wanted to honor government debts -- interests of French government creditors were well represented in the National Assembly.\n\nBut they set out to remake  the French tax code and the administrative machinery for collecting taxes.\n\nthey abolished many taxes\n\nthey abolished the Ancient Regimes scheme for tax farming\n\ntax farming meant that the government had privatized tax collection by hiring private citizens -- so-called  tax farmers to collect taxes, while retaining a fraction of them as payment for their services\n\nthe great chemist Lavoisier was also a tax farmer, one of the reasons that the Committee for Public Safety sent him to the guillotine in 1794\n\nAs a consequence of these tax reforms, government tax revenues declined\n\nThe next figure shows this\n\n# Read data from Excel file\ndata5 = pd.read_excel(dette_url, sheet_name='Debt', usecols='K', \n                    skiprows=41, nrows=120, header=None)\n\n# Plot the data\nplt.figure()\nplt.plot(range(1726, 1846), data5.iloc[:, 0], linewidth=0.8)\n\nplt.gca().spines['top'].set_visible(False)\nplt.gca().spines['right'].set_visible(False)\nplt.gca().set_facecolor('white')\nplt.gca().tick_params(labelsize=12)\nplt.xlim([1726, 1845])\nplt.ylabel('1726 = 1', fontsize=12)\n\nplt.tight_layout()\nplt.show()\n\n\n\nFigure 5:Index of real per capital revenues, France\n\nAccording to \n\nFig. 5, tax revenues per capita did not rise to their pre 1789 levels\nuntil after 1815, when Napoleon Bonaparte was exiled to St Helena and King Louis XVIII was restored to the French Crown.\n\nfrom 1799 to 1814, Napoleon Bonaparte had other sources of revenues -- booty and reparations from provinces and nations that he defeated in war\n\nfrom 1789 to 1799, the French Revolutionaries turned to another source to raise resources to pay for government purchases of goods and services and to service French government debt.\n\nAnd as the next figure shows, government expenditures exceeded tax revenues by substantial\namounts during the period form 1789 to 1799.\n\n# Read data from Excel file\ndata11 = pd.read_excel(assignat_url, sheet_name='Budgets',\n        usecols='J:K', skiprows=22, nrows=52, header=None)\n\n# Prepare the x-axis data\nx_data = np.concatenate([\n    np.arange(1791, 1794 + 8/12, 1/12),\n    np.arange(1794 + 9/12, 1795 + 3/12, 1/12)\n])\n\n# Remove NaN values from the data\ndata11_clean = data11.dropna()\n\n# Plot the data\nplt.figure()\nh = plt.plot(x_data, data11_clean.values[:, 0], linewidth=0.8)\nh = plt.plot(x_data, data11_clean.values[:, 1], '--', linewidth=0.8)\n\n# Set plot properties\nplt.gca().spines['top'].set_visible(False)\nplt.gca().spines['right'].set_visible(False)\nplt.gca().set_facecolor('white')\nplt.gca().tick_params(axis='both', which='major', labelsize=12)\nplt.xlim([1791, 1795 + 3/12])\nplt.xticks(np.arange(1791, 1796))\nplt.yticks(np.arange(0, 201, 20))\n\n# Set the y-axis label\nplt.ylabel('millions of livres', fontsize=12)\n\nplt.tight_layout()\nplt.show()\n\n\n\nFigure 6:Spending (blue) and Revenues (orange), (real values)\n\nTo cover the discrepancies between government expenditures and tax revenues revealed in \n\nFig. 6, the French revolutionaries  printed paper money and spent it.\n\nThe next figure shows that by printing money, they were able to finance substantial purchases\nof goods and services, including military goods and soldiers’ pay.\n\n# Read data from Excel file\ndata12 = pd.read_excel(assignat_url, sheet_name='seignor', \n         usecols='F', skiprows=6, nrows=75, header=None).squeeze()\n\n# Create a figure and plot the data\nplt.figure()\nplt.plot(pd.date_range(start='1790', periods=len(data12), freq='M'),\n         data12, linewidth=0.8)\n\nplt.gca().spines['top'].set_visible(False)\nplt.gca().spines['right'].set_visible(False)\n\nplt.axhline(y=472.42/12, color='r', linestyle=':')\nplt.xticks(ticks=pd.date_range(start='1790', \n           end='1796', freq='AS'), labels=range(1790, 1797))\nplt.xlim(pd.Timestamp('1791'),\n         pd.Timestamp('1796-02') + pd.DateOffset(months=2))\nplt.ylabel('millions of livres', fontsize=12)\nplt.text(pd.Timestamp('1793-11'), 39.5, 'revenues in 1788', \n         verticalalignment='top', fontsize=12)\n\nplt.tight_layout()\nplt.show()\n\n\n\nFigure 7:Revenues raised by printing paper money notes\n\nFig. 7 compares the revenues raised by printing money from 1789 to 1796 with tax revenues that the Ancient Regime had raised in 1788.\n\nMeasured in goods, revenues raised at time t by printing new money equal\\frac{M_{t+1} - M_t}{p_t}\n\nwhere\n\nM_t is the stock of paper money at time t measured in livres\n\np_t is the price level at time t measured in units of goods per livre at time t\n\nM_{t+1} - M_t is the amount of new money printed at time t\n\nNotice the 1793-1794  surge in revenues raised by printing money.\n\nThis reflects extraordinary measures that the Committee for Public Safety adopted to force citizens to accept paper money, or else.\n\nAlso note the abrupt fall off in revenues raised by 1797 and the absence of further observations after 1797.\n\nThis reflects the end of using the printing press to raise revenues.\n\nWhat French paper money  entitled its holders to changed over time in interesting ways.\n\nThese  led to outcomes  that vary over time and that illustrate the playing out in practice of  theories that guided the Revolutionaries’ monetary policy decisions.\n\nThe next figure shows the price level in France  during the time that the Revolutionaries used paper money to finance parts of their expenditures.\n\nNote that we use a log scale because the price level rose so much.\n\n# Read the data from Excel file\ndata7 = pd.read_excel(assignat_url, sheet_name='Data', \n          usecols='P:Q', skiprows=4, nrows=80, header=None)\ndata7a = pd.read_excel(assignat_url, sheet_name='Data', \n          usecols='L', skiprows=4, nrows=80, header=None)\n# Create the figure and plot\nplt.figure()\nx = np.arange(1789 + 10/12, 1796 + 5/12, 1/12)\nh, = plt.plot(x, 1. / data7.iloc[:, 0], linestyle='--')\nh, = plt.plot(x, 1. / data7.iloc[:, 1], color='r')\n\n# Set properties of the plot\nplt.gca().tick_params(labelsize=12)\nplt.yscale('log')\nplt.xlim([1789 + 10/12, 1796 + 5/12])\nplt.gca().spines['top'].set_visible(False)\nplt.gca().spines['right'].set_visible(False)\n\n# Add vertical lines\nplt.axvline(x=1793 + 6.5/12, linestyle='-', linewidth=0.8, color='orange')\nplt.axvline(x=1794 + 6.5/12, linestyle='-', linewidth=0.8, color='purple')\n\n# Add text\nplt.text(1793.75, 120, 'Terror', fontsize=12)\nplt.text(1795, 2.8, 'price level', fontsize=12)\nplt.text(1794.9, 40, 'gold', fontsize=12)\n\n\nplt.tight_layout()\nplt.show()\n\n\n\nFigure 8:Price Level and Price of Gold (log scale)\n\nWe have partioned  \n\nFig. 8 that shows the log of the price level and   \n\nFig. 9\nbelow  that plots real balances \\frac{M_t}{p_t} into three periods that correspond to  different monetary  experiments or regimes.\n\nThe first period ends in the late summer of 1793, and is characterized\nby growing real balances and moderate inflation.\n\nThe second period begins and ends\nwith the Terror. It is marked by high real balances, around 2,500 million, and\nroughly stable prices. The fall of Robespierre in late July 1794 begins the third\nof our episodes, in which real balances decline and prices rise rapidly.\n\nWe interpret\nthese three episodes in terms of distinct  theories\n\na backing or real bills theory (the classic text for this theory is  Adam Smith  \n\nSmith (2010))\n\na legal restrictions theory ( \n\nKeynes (1940), \n\nBryant & Wallace (1984) )\n\na classical hyperinflation theory (\n\nCagan (1956))\n\n\n\nNote\n\nAccording to the empirical  definition of hyperinflation adopted by \n\nCagan (1956),\nbeginning in the month that inflation exceeds 50 percent\nper month and ending in the month before inflation drops below 50 percent per month\nfor at least a year, the assignat  experienced a hyperinflation from May to December\n1795.\n\nWe view these\ntheories not as competitors but as alternative collections of ‘‘if-then’’\nstatements about government note issues, each of which finds its conditions more\nnearly met in one of these episodes than in the other two.\n\n# Read the data from Excel file\ndata7 = pd.read_excel(assignat_url, sheet_name='Data', \n        usecols='P:Q', skiprows=4, nrows=80, header=None)\ndata7a = pd.read_excel(assignat_url, sheet_name='Data', \n        usecols='L', skiprows=4, nrows=80, header=None)\n\n# Create the figure and plot\nplt.figure()\nh = plt.plot(pd.date_range(start='1789-11-01', periods=len(data7), freq='M'), \n            (data7a.values * [1, 1]) * data7.values, linewidth=1.)\nplt.setp(h[1], linestyle='--', color='red')\n\nplt.vlines([pd.Timestamp('1793-07-15'), pd.Timestamp('1793-07-15')], \n           0, 3000, linewidth=0.8, color='orange')\nplt.vlines([pd.Timestamp('1794-07-15'), pd.Timestamp('1794-07-15')], \n           0, 3000, linewidth=0.8, color='purple')\n\nplt.ylim([0, 3000])\n\n# Set properties of the plot\nplt.gca().spines['top'].set_visible(False)\nplt.gca().spines['right'].set_visible(False)\nplt.gca().set_facecolor('white')\nplt.gca().tick_params(labelsize=12)\nplt.xlim(pd.Timestamp('1789-11-01'), pd.Timestamp('1796-06-01'))\nplt.ylabel('millions of livres', fontsize=12)\n\n# Add text annotations\nplt.text(pd.Timestamp('1793-09-01'), 200, 'Terror', fontsize=12)\nplt.text(pd.Timestamp('1791-05-01'), 750, 'gold value', fontsize=12)\nplt.text(pd.Timestamp('1794-10-01'), 2500, 'real value', fontsize=12)\n\n\nplt.tight_layout()\nplt.show()\n\n\n\nFigure 9:Real balances of assignats (in gold and goods)\n\nThe three clouds of points in Figure\n\n\nFig. 10\ndepict different real balance-inflation relationships.\n\nOnly the cloud for the\nthird period has the inverse relationship familiar to us now from twentieth-century\nhyperinflations.\n\nsubperiod 1: (\"real bills period): January 1791 to July 1793\n\nsubperiod 2: (“terror”):  August 1793 - July 1794\n\nsubperiod 3: (“classic Cagan hyperinflation”): August 1794 - March 1796\n\ndef fit(x, y):\n\n    b = np.cov(x, y)[0, 1] / np.var(x)\n    a = y.mean() - b * x.mean()\n\n    return a, b\n\n# Load data\ncaron_response = requests.get(base_url + 'caron.npy')\nnom_balances_response = requests.get(base_url + 'nom_balances.npy')\ncaron = np.load(BytesIO(caron_response.content))\nnom_balances = np.load(BytesIO(nom_balances_response.content))\n\ninfl = np.concatenate(([np.nan], \n      -np.log(caron[1:63, 1] / caron[0:62, 1])))\nbal = nom_balances[14:77, 1] * caron[:, 1] / 1000\n\n# Regress y on x for three periods\na1, b1 = fit(bal[1:31], infl[1:31])\na2, b2 = fit(bal[31:44], infl[31:44])\na3, b3 = fit(bal[44:63], infl[44:63])\n\n# Regress x on y for three periods\na1_rev, b1_rev = fit(infl[1:31], bal[1:31])\na2_rev, b2_rev = fit(infl[31:44], bal[31:44])\na3_rev, b3_rev = fit(infl[44:63], bal[44:63])\n\nplt.figure()\nplt.gca().spines['top'].set_visible(False)\nplt.gca().spines['right'].set_visible(False)\n\n# First subsample\nplt.plot(bal[1:31], infl[1:31], 'o', markerfacecolor='none', \n         color='blue', label='real bills period')\n\n# Second subsample\nplt.plot(bal[31:44], infl[31:44], '+', color='red', label='terror')\n\n# Third subsample\nplt.plot(bal[44:63], infl[44:63], '*', \n        color='orange', label='classic Cagan hyperinflation')\n\nplt.xlabel('real balances')\nplt.ylabel('inflation')\nplt.legend()\n\nplt.tight_layout()\nplt.show()\n\n\n\nFigure 10:Inflation and Real Balances\n\nThe three clouds of points in \n\nFig. 10 evidently\ndepict different real balance-inflation relationships.\n\nOnly the cloud for the\nthird period has the inverse relationship familiar to us now from twentieth-century\nhyperinflations.\n\nTo bring this out, we’ll use linear regressions to draw straight lines that compress the\ninflation-real balance relationship for our three sub-periods.\n\nBefore we do that, we’ll drop some of the early observations during the terror period\nto obtain the following graph.\n\n# Regress y on x for three periods\na1, b1 = fit(bal[1:31], infl[1:31])\na2, b2 = fit(bal[31:44], infl[31:44])\na3, b3 = fit(bal[44:63], infl[44:63])\n\n# Regress x on y for three periods\na1_rev, b1_rev = fit(infl[1:31], bal[1:31])\na2_rev, b2_rev = fit(infl[31:44], bal[31:44])\na3_rev, b3_rev = fit(infl[44:63], bal[44:63])\n\nplt.figure()\nplt.gca().spines['top'].set_visible(False)\nplt.gca().spines['right'].set_visible(False)\n\n# First subsample\nplt.plot(bal[1:31], infl[1:31], 'o', markerfacecolor='none', color='blue', label='real bills period')\n\n# Second subsample\nplt.plot(bal[34:44], infl[34:44], '+', color='red', label='terror')\n\n# Third subsample\nplt.plot(bal[44:63], infl[44:63], '*', color='orange', label='classic Cagan hyperinflation')\n\nplt.xlabel('real balances')\nplt.ylabel('inflation')\nplt.legend()\n\nplt.tight_layout()\nplt.show()\n\n\n\nFigure 11:Inflation and Real Balances\n\nNow let’s regress inflation on real balances during the real bills period and plot the regression\nline.\n\nplt.figure()\nplt.gca().spines['top'].set_visible(False)\nplt.gca().spines['right'].set_visible(False)\n\n# First subsample\nplt.plot(bal[1:31], infl[1:31], 'o', markerfacecolor='none', \n        color='blue', label='real bills period')\nplt.plot(bal[1:31], a1 + bal[1:31] * b1, color='blue')\n\n# Second subsample\nplt.plot(bal[31:44], infl[31:44], '+', color='red', label='terror')\n\n# Third subsample\nplt.plot(bal[44:63], infl[44:63], '*', \n        color='orange', label='classic Cagan hyperinflation')\n\nplt.xlabel('real balances')\nplt.ylabel('inflation')\nplt.legend()\n\nplt.tight_layout()\nplt.show()\n\n\n\nFigure 12:Inflation and Real Balances\n\nThe regression line in \n\nFig. 12 shows that large increases in real balances of\nassignats (paper money) were accompanied by only modest rises in the price level, an outcome in line\nwith the real bills theory.\n\nDuring this period, assignats were claims on church lands.\n\nBut towards the end of this period, the price level started to rise and real balances to fall\nas the government continued to print money but stopped selling church land.\n\nTo get people to hold that paper money, the government forced people to hold it by using legal restrictions.\n\nNow let’s regress real balances on inflation  during the terror  and plot the regression\nline.\n\nplt.figure()\nplt.gca().spines['top'].set_visible(False)\nplt.gca().spines['right'].set_visible(False)\n\n# First subsample\nplt.plot(bal[1:31], infl[1:31], 'o', markerfacecolor='none', \n        color='blue', label='real bills period')\n\n# Second subsample\nplt.plot(bal[31:44], infl[31:44], '+', color='red', label='terror')\nplt.plot(a2_rev + b2_rev * infl[31:44], infl[31:44], color='red')\n\n# Third subsample\nplt.plot(bal[44:63], infl[44:63], '*', \n        color='orange', label='classic Cagan hyperinflation')\n\nplt.xlabel('real balances')\nplt.ylabel('inflation')\nplt.legend()\n\nplt.tight_layout()\nplt.show()\n\n\n\nFigure 13:Inflation and Real Balances\n\nThe regression line in \n\nFig. 13 shows that large increases in real balances of\nassignats (paper money) were accompanied by little upward price  level pressure, even some declines in prices.\n\nThis reflects how well legal restrictions -- financial repression -- was working during the period of the Terror.\n\nBut the Terror ended in July 1794.  That unleashed a big inflation as people tried to find other ways to transact and store values.\n\nThe following two graphs are for the classical hyperinflation period.\n\nOne regresses inflation on real balances, the other regresses real balances on inflation.\n\nBoth show a prounced inverse relationship that is the hallmark of the hyperinflations studied by\nCagan \n\nCagan (1956).\n\nplt.figure()\nplt.gca().spines['top'].set_visible(False)\nplt.gca().spines['right'].set_visible(False)\n\n# First subsample\nplt.plot(bal[1:31], infl[1:31], 'o', markerfacecolor='none', \n        color='blue', label='real bills period')\n\n# Second subsample\nplt.plot(bal[31:44], infl[31:44], '+', color='red', label='terror')\n\n# Third subsample\nplt.plot(bal[44:63], infl[44:63], '*', \n    color='orange', label='classic Cagan hyperinflation')\nplt.plot(bal[44:63], a3 + bal[44:63] * b3, color='orange')\n\nplt.xlabel('real balances')\nplt.ylabel('inflation')\nplt.legend()\n\nplt.tight_layout()\nplt.show()\n\n\n\nFigure 14:Inflation and Real Balances\n\nFig. 14 shows the results of regressing inflation on real balances during the\nperiod of the hyperinflation.\n\nplt.figure()\nplt.gca().spines['top'].set_visible(False)\nplt.gca().spines['right'].set_visible(False)\n\n# First subsample\nplt.plot(bal[1:31], infl[1:31], 'o', \n    markerfacecolor='none', color='blue', label='real bills period')\n\n# Second subsample\nplt.plot(bal[31:44], infl[31:44], '+', color='red', label='terror')\n\n# Third subsample\nplt.plot(bal[44:63], infl[44:63], '*', \n        color='orange', label='classic Cagan hyperinflation')\nplt.plot(a3_rev + b3_rev * infl[44:63], infl[44:63], color='orange')\n\nplt.xlabel('real balances')\nplt.ylabel('inflation')\nplt.legend()\n\nplt.tight_layout()\nplt.show()\n\n\n\nFigure 15:Inflation and Real Balances\n\nFig. 14 shows the results of regressing  real money balances on inflation during the\nperiod of the hyperinflation.","type":"content","url":"/french-rev#remaking-the-tax-code-and-tax-administration","position":11},{"hierarchy":{"lvl1":"Inflation During French Revolution","lvl2":"Hyperinflation Ends"},"type":"lvl2","url":"/french-rev#hyperinflation-ends","position":12},{"hierarchy":{"lvl1":"Inflation During French Revolution","lvl2":"Hyperinflation Ends"},"content":"Sargent & Velde (1995) tell how in 1797 the Revolutionary government abruptly ended the inflation by\n\nrepudiating 2/3 of the national debt, and thereby\n\neliminating the net-of-interest government defict\n\nno longer printing money, but instead\n\nusing gold and silver coins as money\n\nIn 1799, Napoleon Bonaparte became first consul and for the next 15 years used resources confiscated from conquered territories to help pay for French government expenditures.","type":"content","url":"/french-rev#hyperinflation-ends","position":13},{"hierarchy":{"lvl1":"Inflation During French Revolution","lvl2":"Underlying Theories"},"type":"lvl2","url":"/french-rev#underlying-theories","position":14},{"hierarchy":{"lvl1":"Inflation During French Revolution","lvl2":"Underlying Theories"},"content":"This lecture  sets the stage for studying  theories of inflation and the  government monetary and fiscal policies that bring it about.\n\nA  monetarist theory of the price level is described in this quantecon lecture \n\nA Monetarist Theory of Price Levels.\n\nThat lecture sets the stage for these quantecon lectures \n\nMoney Financed Government Deficits and Price Levels and \n\nSome Unpleasant Monetarist Arithmetic.","type":"content","url":"/french-rev#underlying-theories","position":15},{"hierarchy":{"lvl1":"Geometric Series for Elementary Economics"},"type":"lvl1","url":"/geom-series","position":0},{"hierarchy":{"lvl1":"Geometric Series for Elementary Economics"},"content":"","type":"content","url":"/geom-series","position":1},{"hierarchy":{"lvl1":"Geometric Series for Elementary Economics","lvl2":"Overview"},"type":"lvl2","url":"/geom-series#overview","position":2},{"hierarchy":{"lvl1":"Geometric Series for Elementary Economics","lvl2":"Overview"},"content":"The lecture describes important ideas in economics that use the mathematics of geometric series.\n\nAmong these are\n\nthe Keynesian multiplier\n\nthe money multiplier that prevails in fractional reserve banking\nsystems\n\ninterest rates and present values of streams of payouts from assets\n\n(As we shall see below, the term multiplier comes down to meaning sum of a convergent geometric series)\n\nThese and other applications prove the truth of the wise crack that\n\n“In economics, a little knowledge of geometric series goes a long way.”\n\nBelow we’ll use the following imports:\n\nimport matplotlib.pyplot as plt\nplt.rcParams[\"figure.figsize\"] = (11, 5)  #set default figure size\nimport numpy as np\nimport sympy as sym\nfrom sympy import init_printing\nfrom matplotlib import cm\n\n","type":"content","url":"/geom-series#overview","position":3},{"hierarchy":{"lvl1":"Geometric Series for Elementary Economics","lvl2":"Key formulas"},"type":"lvl2","url":"/geom-series#key-formulas","position":4},{"hierarchy":{"lvl1":"Geometric Series for Elementary Economics","lvl2":"Key formulas"},"content":"To start, let c be a real number that lies strictly between\n-1 and 1.\n\nWe often write this as c \\in (-1,1).\n\nHere (-1,1) denotes the collection of all real numbers that\nare strictly less than 1 and strictly greater than -1.\n\nThe symbol \\in means in or belongs to the set after the symbol.\n\nWe want to evaluate geometric series of two types -- infinite and finite.","type":"content","url":"/geom-series#key-formulas","position":5},{"hierarchy":{"lvl1":"Geometric Series for Elementary Economics","lvl3":"Infinite geometric series","lvl2":"Key formulas"},"type":"lvl3","url":"/geom-series#infinite-geometric-series","position":6},{"hierarchy":{"lvl1":"Geometric Series for Elementary Economics","lvl3":"Infinite geometric series","lvl2":"Key formulas"},"content":"The first type of geometric that interests us is the infinite series1 + c + c^2 + c^3 + \\cdots\n\nWhere \\cdots means that the series continues without end.\n\nThe key formula is1 + c + c^2 + c^3 + \\cdots = \\frac{1}{1 -c }\n\nTo prove key formula \n\n(2), multiply both sides  by (1-c) and verify\nthat if c \\in (-1,1), then the outcome is the\nequation 1 = 1.","type":"content","url":"/geom-series#infinite-geometric-series","position":7},{"hierarchy":{"lvl1":"Geometric Series for Elementary Economics","lvl3":"Finite geometric series","lvl2":"Key formulas"},"type":"lvl3","url":"/geom-series#finite-geometric-series","position":8},{"hierarchy":{"lvl1":"Geometric Series for Elementary Economics","lvl3":"Finite geometric series","lvl2":"Key formulas"},"content":"The second series that interests us is the finite geometric series1 + c + c^2 + c^3 + \\cdots + c^T\n\nwhere T is a positive integer.\n\nThe key formula here is1 + c + c^2 + c^3 + \\cdots + c^T  = \\frac{1 - c^{T+1}}{1-c}\n\nThe above formula works for any value of the scalar\nc. We don’t have to restrict c to be in the\nset (-1,1).\n\nWe now move on to describe some famous economic applications of\ngeometric series.","type":"content","url":"/geom-series#finite-geometric-series","position":9},{"hierarchy":{"lvl1":"Geometric Series for Elementary Economics","lvl2":"Example: The Money Multiplier in Fractional Reserve Banking"},"type":"lvl2","url":"/geom-series#example-the-money-multiplier-in-fractional-reserve-banking","position":10},{"hierarchy":{"lvl1":"Geometric Series for Elementary Economics","lvl2":"Example: The Money Multiplier in Fractional Reserve Banking"},"content":"In a fractional reserve banking system, banks hold only a fraction\nr \\in (0,1) of cash behind each deposit receipt that they\nissue\n\nIn recent times\n\ncash consists of pieces of paper issued by the government and\ncalled dollars or pounds or \\ldots\n\na deposit is a balance in a checking or savings account that\nentitles the owner to ask the bank for immediate payment in cash\n\nWhen the UK and France and the US were on either a gold or silver\nstandard (before 1914, for example)\n\ncash was a gold or silver coin\n\na deposit receipt was a bank note that the bank promised to\nconvert into gold or silver on demand; (sometimes it was also a\nchecking or savings account balance)\n\nEconomists and financiers often define the supply of money as an\neconomy-wide sum of cash plus deposits.\n\nIn a fractional reserve banking system (one in which the reserve\nratio r satisfies 0 < r < 1), banks create money by issuing deposits backed by fractional reserves plus loans that they make to their customers.\n\nA geometric series is a key tool for understanding how banks create\nmoney (i.e., deposits) in a fractional reserve system.\n\nThe geometric series formula \n\n(2) is at the heart of the classic model of the money creation process -- one that leads us to the celebrated\nmoney multiplier.","type":"content","url":"/geom-series#example-the-money-multiplier-in-fractional-reserve-banking","position":11},{"hierarchy":{"lvl1":"Geometric Series for Elementary Economics","lvl3":"A simple model","lvl2":"Example: The Money Multiplier in Fractional Reserve Banking"},"type":"lvl3","url":"/geom-series#a-simple-model","position":12},{"hierarchy":{"lvl1":"Geometric Series for Elementary Economics","lvl3":"A simple model","lvl2":"Example: The Money Multiplier in Fractional Reserve Banking"},"content":"There is a set of banks named i = 0, 1, 2, \\ldots.\n\nBank i’s loans L_i, deposits D_i, and\nreserves R_i must satisfy the balance sheet equation (because\nbalance sheets balance):L_i + R_i = D_i\n\nThe left side of the above equation is the sum of the bank’s assets,\nnamely, the loans L_i it has outstanding plus its reserves of\ncash R_i.\n\nThe right side records bank i’s liabilities,\nnamely, the deposits D_i held by its depositors; these are\nIOU’s from the bank to its depositors in the form of either checking\naccounts or savings accounts (or before 1914, bank notes issued by a\nbank stating promises to redeem notes for gold or silver on demand).\n\nEach bank i sets its reserves to satisfy the equationR_i = r D_i\n\nwhere r \\in (0,1) is its reserve-deposit ratio or reserve\nratio for short\n\nthe reserve ratio is either set by a government or chosen by banks\nfor precautionary reasons\n\nNext we add a theory stating that bank i+1’s deposits depend\nentirely on loans made by bank i, namelyD_{i+1} = L_i\n\nThus, we can think of the banks as being arranged along a line with\nloans from bank i being immediately deposited in i+1\n\nin this way, the debtors to bank i become creditors of\nbank i+1\n\nFinally, we add an initial condition about an exogenous level of bank\n0’s depositsD_0 \\ \\text{ is given exogenously}\n\nWe can think of D_0 as being the amount of cash that a first\ndepositor put into the first bank in the system, bank number i=0.\n\nNow we do a little algebra.\n\nCombining equations \n\n(5) and \n\n(6) tells us thatL_i = (1-r) D_i\n\nThis states that bank i loans a fraction (1-r) of its\ndeposits and keeps a fraction r as cash reserves.\n\nCombining equation \n\n(9) with equation \n\n(7) tells us thatD_{i+1} = (1-r) D_i  \\ \\text{ for } i \\geq 0\n\nwhich implies thatD_i = (1 - r)^i D_0  \\ \\text{ for } i \\geq 0\n\nEquation \n\n(11) expresses D_i as the i th term in the\nproduct of D_0 and the geometric series1, (1-r), (1-r)^2, \\cdots\n\nTherefore, the sum of all deposits in our banking system\ni=0, 1, 2, \\ldots is\\sum_{i=0}^\\infty (1-r)^i D_0 =  \\frac{D_0}{1 - (1-r)} = \\frac{D_0}{r}","type":"content","url":"/geom-series#a-simple-model","position":13},{"hierarchy":{"lvl1":"Geometric Series for Elementary Economics","lvl3":"Money multiplier","lvl2":"Example: The Money Multiplier in Fractional Reserve Banking"},"type":"lvl3","url":"/geom-series#money-multiplier","position":14},{"hierarchy":{"lvl1":"Geometric Series for Elementary Economics","lvl3":"Money multiplier","lvl2":"Example: The Money Multiplier in Fractional Reserve Banking"},"content":"The money multiplier is a number that tells the multiplicative\nfactor by which an exogenous injection of cash into bank 0 leads\nto an increase in the total deposits in the banking system.\n\nEquation \n\n(13) asserts that the money multiplier is\n\\frac{1}{r}\n\nAn initial deposit of cash of D_0 in bank 0 leads\nthe banking system to create total deposits of \\frac{D_0}{r}.\n\nThe initial deposit D_0 is held as reserves, distributed\nthroughout the banking system according to D_0 = \\sum_{i=0}^\\infty R_i.","type":"content","url":"/geom-series#money-multiplier","position":15},{"hierarchy":{"lvl1":"Geometric Series for Elementary Economics","lvl2":"Example: The Keynesian Multiplier"},"type":"lvl2","url":"/geom-series#example-the-keynesian-multiplier","position":16},{"hierarchy":{"lvl1":"Geometric Series for Elementary Economics","lvl2":"Example: The Keynesian Multiplier"},"content":"The famous economist John Maynard Keynes and his followers created a\nsimple model intended to determine national income y in\ncircumstances in which\n\nthere are substantial unemployed resources, in particular excess\nsupply of labor and capital\n\nprices and interest rates fail to adjust to make aggregate supply\nequal demand (e.g., prices and interest rates are frozen)\n\nnational income is entirely determined by aggregate demand","type":"content","url":"/geom-series#example-the-keynesian-multiplier","position":17},{"hierarchy":{"lvl1":"Geometric Series for Elementary Economics","lvl3":"Static version","lvl2":"Example: The Keynesian Multiplier"},"type":"lvl3","url":"/geom-series#static-version","position":18},{"hierarchy":{"lvl1":"Geometric Series for Elementary Economics","lvl3":"Static version","lvl2":"Example: The Keynesian Multiplier"},"content":"An elementary Keynesian model of national income determination consists\nof three equations that describe aggregate demand for y and its\ncomponents.\n\nThe first equation is a national income identity asserting that\nconsumption c plus investment i equals national income\ny:c+ i = y\n\nThe second equation is a Keynesian consumption function asserting that\npeople consume a fraction b \\in (0,1) of their income:c = b y\n\nThe fraction b \\in (0,1) is called the marginal propensity to\nconsume.\n\nThe fraction 1-b \\in (0,1) is called the marginal propensity\nto save.\n\nThe third equation simply states that investment is exogenous at level\ni.\n\nexogenous means determined outside this model.\n\nSubstituting the second equation into the first gives (1-b) y = i.\n\nSolving this equation for y givesy = \\frac{1}{1-b} i\n\nThe quantity \\frac{1}{1-b} is called the investment\nmultiplier or simply the multiplier.\n\nApplying the formula for the sum of an infinite geometric series, we can\nwrite the above equation asy = i \\sum_{t=0}^\\infty b^t\n\nwhere t is a nonnegative integer.\n\nSo we arrive at the following equivalent expressions for the multiplier:\\frac{1}{1-b} =   \\sum_{t=0}^\\infty b^t\n\nThe expression \\sum_{t=0}^\\infty b^t motivates an interpretation\nof the multiplier as the outcome of a dynamic process that we describe\nnext.","type":"content","url":"/geom-series#static-version","position":19},{"hierarchy":{"lvl1":"Geometric Series for Elementary Economics","lvl3":"Dynamic version","lvl2":"Example: The Keynesian Multiplier"},"type":"lvl3","url":"/geom-series#dynamic-version","position":20},{"hierarchy":{"lvl1":"Geometric Series for Elementary Economics","lvl3":"Dynamic version","lvl2":"Example: The Keynesian Multiplier"},"content":"We arrive at a dynamic version by interpreting the nonnegative integer\nt as indexing time and changing our specification of the\nconsumption function to take time into account\n\nwe add a one-period lag in how income affects consumption\n\nWe let c_t be consumption at time t and i_t be\ninvestment at time t.\n\nWe modify our consumption function to assume the formc_t = b y_{t-1}\n\nso that b is the marginal propensity to consume (now) out of\nlast period’s income.\n\nWe begin with an initial condition stating thaty_{-1} = 0\n\nWe also assume thati_t = i \\ \\ \\textrm {for all }  t \\geq 0\n\nso that investment is constant over time.\n\nIt follows thaty_0 = i + c_0 = i + b y_{-1} =  i\n\nandy_1 = c_1 + i = b y_0 + i = (1 + b) i\n\nandy_2 = c_2 + i = b y_1 + i = (1 + b + b^2) i\n\nand more generallyy_t = b y_{t-1} + i = (1+ b + b^2 + \\cdots + b^t) i\n\nory_t = \\frac{1-b^{t+1}}{1 -b } i\n\nEvidently, as t \\rightarrow + \\infty,y_t \\rightarrow \\frac{1}{1-b} i\n\nRemark 1: The above formula is often applied to assert that an\nexogenous increase in investment of \\Delta i at time 0\nignites a dynamic process of increases in national income by successive amounts\\Delta i, (1 + b )\\Delta i, (1+b + b^2) \\Delta i , \\cdots\n\nat times 0, 1, 2, \\ldots.\n\nRemark 2 Let g_t be an exogenous sequence of government\nexpenditures.\n\nIf we generalize the model so that the national income identity\nbecomesc_t + i_t + g_t  = y_t\n\nthen a version of the preceding argument shows that the government\nexpenditures multiplier is also \\frac{1}{1-b}, so that a\npermanent increase in government expenditures ultimately leads to an\nincrease in national income equal to the multiplier times the increase\nin government expenditures.","type":"content","url":"/geom-series#dynamic-version","position":21},{"hierarchy":{"lvl1":"Geometric Series for Elementary Economics","lvl2":"Example: Interest Rates and Present Values"},"type":"lvl2","url":"/geom-series#example-interest-rates-and-present-values","position":22},{"hierarchy":{"lvl1":"Geometric Series for Elementary Economics","lvl2":"Example: Interest Rates and Present Values"},"content":"We can apply our formula for geometric series to study how interest\nrates affect values of streams of dollar payments that extend over time.\n\nWe work in discrete time and assume that t = 0, 1, 2, \\ldots\nindexes time.\n\nWe let r \\in (0,1) be a one-period net nominal interest rate\n\nif the nominal interest rate is 5 percent,\nthen r= .05\n\nA one-period gross nominal interest rate R is defined asR = 1 + r \\in (1, 2)\n\nif r=.05, then R = 1.05\n\nRemark: The gross nominal interest rate R is an exchange\nrate or relative price of dollars at between times t and\nt+1. The units of R are dollars at time t+1 per\ndollar at time t.\n\nWhen people borrow and lend, they trade dollars now for dollars later or\ndollars later for dollars now.\n\nThe price at which these exchanges occur is the gross nominal interest\nrate.\n\nIf I sell x dollars to you today, you pay me R x\ndollars tomorrow.\n\nThis means that you borrowed x dollars for me at a gross\ninterest rate R and a net interest rate r.\n\nWe assume that the net nominal interest rate r is fixed over\ntime, so that R is the gross nominal interest rate at times\nt=0, 1, 2, \\ldots.\n\nTwo important geometric sequences are1, R, R^2, \\cdots\n\nand1, R^{-1}, R^{-2}, \\cdots\n\nSequence \n\n(31) tells us how dollar values of an investment accumulate\nthrough time.\n\nSequence \n\n(32) tells us how to discount future dollars to get their\nvalues in terms of today’s dollars.","type":"content","url":"/geom-series#example-interest-rates-and-present-values","position":23},{"hierarchy":{"lvl1":"Geometric Series for Elementary Economics","lvl3":"Accumulation","lvl2":"Example: Interest Rates and Present Values"},"type":"lvl3","url":"/geom-series#accumulation","position":24},{"hierarchy":{"lvl1":"Geometric Series for Elementary Economics","lvl3":"Accumulation","lvl2":"Example: Interest Rates and Present Values"},"content":"Geometric sequence \n\n(31) tells us how one dollar invested and re-invested\nin a project with gross one period nominal rate of return accumulates\n\nhere we assume that net interest payments are reinvested in the\nproject\n\nthus, 1 dollar invested at time 0 pays interest\nr dollars after one period, so we have r+1 = R\ndollars at time1\n\nat time 1 we reinvest 1+r =R dollars and receive interest\nof r R dollars at time 2 plus the principal\nR dollars, so we receive r R + R = (1+r)R = R^2\ndollars at the end of period 2\n\nand so on\n\nEvidently, if we invest x dollars at time 0 and\nreinvest the proceeds, then the sequencex , xR , x R^2, \\cdots\n\ntells how our account accumulates at dates t=0, 1, 2, \\ldots.","type":"content","url":"/geom-series#accumulation","position":25},{"hierarchy":{"lvl1":"Geometric Series for Elementary Economics","lvl3":"Discounting","lvl2":"Example: Interest Rates and Present Values"},"type":"lvl3","url":"/geom-series#discounting","position":26},{"hierarchy":{"lvl1":"Geometric Series for Elementary Economics","lvl3":"Discounting","lvl2":"Example: Interest Rates and Present Values"},"content":"Geometric sequence \n\n(32) tells us how much future dollars are worth in terms of today’s dollars.\n\nRemember that the units of R are dollars at t+1 per\ndollar at t.\n\nIt follows that\n\nthe units of R^{-1} are dollars at t per dollar at t+1\n\nthe units of R^{-2} are dollars at t per dollar at t+2\n\nand so on; the units of R^{-j} are dollars at t per\ndollar at t+j\n\nSo if someone has a claim on x dollars at time t+j, it\nis worth x R^{-j} dollars at time t (e.g., today).","type":"content","url":"/geom-series#discounting","position":27},{"hierarchy":{"lvl1":"Geometric Series for Elementary Economics","lvl3":"Application to asset pricing","lvl2":"Example: Interest Rates and Present Values"},"type":"lvl3","url":"/geom-series#application-to-asset-pricing","position":28},{"hierarchy":{"lvl1":"Geometric Series for Elementary Economics","lvl3":"Application to asset pricing","lvl2":"Example: Interest Rates and Present Values"},"content":"A lease requires a payments stream of x_t dollars at\ntimes t = 0, 1, 2, \\ldots wherex_t = G^t x_0\n\nwhere G = (1+g) and g \\in (0,1).\n\nThus, lease payments increase at g percent per period.\n\nFor a reason soon to be revealed, we assume that G < R.\n\nThe present value of the lease is\\begin{aligned} p_0  & = x_0 + x_1/R + x_2/(R^2) + \\cdots \\\\\n                 & = x_0 (1 + G R^{-1} + G^2 R^{-2} + \\cdots ) \\\\\n                 & = x_0 \\frac{1}{1 - G R^{-1}} \\end{aligned}\n\nwhere the last line uses the formula for an infinite geometric series.\n\nRecall that R = 1+r and G = 1+g and that R > G\nand r > g and that r and g are typically small\nnumbers, e.g., .05 or .03.\n\nUse the \n\nTaylor series of \\frac{1}{1+r} about r=0,\nnamely,\\frac{1}{1+r} = 1 - r + r^2 - r^3 + \\cdots\n\nand the fact that r is small to approximate\n\\frac{1}{1+r} \\approx 1 - r.\n\nUse this approximation to write p_0 as\\begin{aligned}\n p_0 &= x_0 \\frac{1}{1 - G R^{-1}} \\\\\n &= x_0 \\frac{1}{1 - (1+g) (1-r) } \\\\\n &= x_0 \\frac{1}{1 - (1+g - r - rg)} \\\\\n & \\approx x_0 \\frac{1}{r -g }\n\\end{aligned}\n\nwhere the last step uses the approximation r g \\approx 0.\n\nThe approximationp_0 = \\frac{x_0 }{r -g }\n\nis known as the Gordon formula for the present value or current\nprice of an infinite payment stream x_0 G^t when the nominal\none-period interest rate is r and when r > g.\n\nWe can also extend the asset pricing formula so that it applies to finite leases.\n\nLet the payment stream on the lease now be x_t for t= 1,2, \\dots,T, where againx_t = G^t x_0\n\nThe present value of this lease is:\\begin{aligned} \\begin{split}p_0&=x_0 + x_1/R  + \\dots +x_T/R^T \\\\ &= x_0(1+GR^{-1}+\\dots +G^{T}R^{-T}) \\\\ &= \\frac{x_0(1-G^{T+1}R^{-(T+1)})}{1-GR^{-1}}  \\end{split}\\end{aligned}\n\nApplying the Taylor series to R^{-(T+1)} about r=0 we get:\\frac{1}{(1+r)^{T+1}}= 1-r(T+1)+\\frac{1}{2}r^2(T+1)(T+2)+\\dots \\approx 1-r(T+1)\n\nSimilarly, applying the Taylor series to G^{T+1} about g=0:(1+g)^{T+1} = 1+(T+1)g+\\frac{T(T+1)}{2!}g^2+\\frac{(T-1)T(T+1)}{3!}g^3+\\dots \\approx 1+ (T+1)g\n\nThus, we get the following approximation:p_0 =\\frac{x_0(1-(1+(T+1)g)(1-r(T+1)))}{1-(1-r)(1+g) }\n\nExpanding:\\begin{aligned} p_0 &=\\frac{x_0(1-1+(T+1)^2 rg +r(T+1)-g(T+1))}{1-1+r-g+rg}  \\\\&=\\frac{x_0(T+1)((T+1)rg+r-g)}{r-g+rg} \\\\ &= \\frac{x_0(T+1)(r-g)}{r-g + rg}+\\frac{x_0rg(T+1)^2}{r-g+rg}\\\\ &\\approx \\frac{x_0(T+1)(r-g)}{r-g}+\\frac{x_0rg(T+1)}{r-g}\\\\  &= x_0(T+1) + \\frac{x_0rg(T+1)}{r-g}  \\end{aligned}\n\nWe could have also approximated by removing the second term\nrgx_0(T+1) when T is relatively small compared to\n1/(rg) to get x_0(T+1) as in the finite stream\napproximation.\n\nWe will plot the true finite stream present-value and the two\napproximations, under different values of T, and g and r in Python.\n\nFirst we plot the true finite stream present-value after computing it\nbelow\n\n# True present value of a finite lease\ndef finite_lease_pv_true(T, g, r, x_0):\n    G = (1 + g)\n    R = (1 + r)\n    return (x_0 * (1 - G**(T + 1) * R**(-T - 1))) / (1 - G * R**(-1))\n# First approximation for our finite lease\n\ndef finite_lease_pv_approx_1(T, g, r, x_0):\n    p = x_0 * (T + 1) + x_0 * r * g * (T + 1) / (r - g)\n    return p\n\n# Second approximation for our finite lease\ndef finite_lease_pv_approx_2(T, g, r, x_0):\n    return (x_0 * (T + 1))\n\n# Infinite lease\ndef infinite_lease(g, r, x_0):\n    G = (1 + g)\n    R = (1 + r)\n    return x_0 / (1 - G * R**(-1))\n\nNow that we have defined our functions, we can plot some outcomes.\n\nFirst we study the quality of our approximations\n\ndef plot_function(axes, x_vals, func, args):\n    axes.plot(x_vals, func(*args), label=func.__name__)\n\nT_max = 50\n\nT = np.arange(0, T_max+1)\ng = 0.02\nr = 0.03\nx_0 = 1\n\nour_args = (T, g, r, x_0)\nfuncs = [finite_lease_pv_true,\n        finite_lease_pv_approx_1,\n        finite_lease_pv_approx_2]\n        # the three functions we want to compare\n\nfig, ax = plt.subplots()\nfor f in funcs:\n    plot_function(ax, T, f, our_args)\nax.legend()\nax.set_xlabel('$T$ Periods Ahead')\nax.set_ylabel('Present Value, $p_0$')\nplt.show()\n\n\n\nFigure 1:Finite lease present value T periods ahead\n\nEvidently our approximations perform well for small values of T.\n\nHowever, holding g and r fixed, our approximations deteriorate as T increases.\n\nNext we compare the infinite and finite duration lease present values\nover different lease lengths T.\n\n# Convergence of infinite and finite\nT_max = 1000\nT = np.arange(0, T_max+1)\nfig, ax = plt.subplots()\nf_1 = finite_lease_pv_true(T, g, r, x_0)\nf_2 = np.full(T_max+1, infinite_lease(g, r, x_0))\nax.plot(T, f_1, label='T-period lease PV')\nax.plot(T, f_2, '--', label='Infinite lease PV')\nax.set_xlabel('$T$ Periods Ahead')\nax.set_ylabel('Present Value, $p_0$')\nax.legend()\nplt.show()\n\n\n\nFigure 2:Infinite and finite lease present value T periods ahead\n\nThe graph above shows how as duration T \\rightarrow +\\infty,\nthe value of a lease of duration T approaches the value of a\nperpetual lease.\n\nNow we consider two different views of what happens as r and\ng covary\n\n# First view\n# Changing r and g\nfig, ax = plt.subplots()\nax.set_ylabel('Present Value, $p_0$')\nax.set_xlabel('$T$ periods ahead')\nT_max = 10\nT=np.arange(0, T_max+1)\n\nrs, gs = (0.9, 0.5, 0.4001, 0.4), (0.4, 0.4, 0.4, 0.5),\ncomparisons = (r'$\\gg$', '$>$', r'$\\approx$', '$<$')\nfor r, g, comp in zip(rs, gs, comparisons):\n    ax.plot(finite_lease_pv_true(T, g, r, x_0), label=f'r(={r}) {comp} g(={g})')\n\nax.legend()\nplt.show()\n\n\n\nFigure 3:Value of lease of length T\n\nThis graph gives a big hint for why the condition r > g is\nnecessary if a lease of length T = +\\infty is to have finite\nvalue.\n\nFor fans of 3-d graphs the same point comes through in the following\ngraph.\n\nIf you aren’t enamored of 3-d graphs, feel free to skip the next\nvisualization!\n\n# Second view\nfig = plt.figure(figsize = [16, 5])\nT = 3\nax = plt.subplot(projection='3d')\nr = np.arange(0.01, 0.99, 0.005)\ng = np.arange(0.011, 0.991, 0.005)\n\nrr, gg = np.meshgrid(r, g)\nz = finite_lease_pv_true(T, gg, rr, x_0)\n\n# Removes points where undefined\nsame = (rr == gg)\nz[same] = np.nan\nsurf = ax.plot_surface(rr, gg, z, cmap=cm.coolwarm,\n    antialiased=True, clim=(0, 15))\nfig.colorbar(surf, shrink=0.5, aspect=5)\nax.set_xlabel('$r$')\nax.set_ylabel('$g$')\nax.set_zlabel('Present Value, $p_0$')\nax.view_init(20, 8)\nplt.show()\n\n\n\nFigure 4:Three period lease PV with varying g and r\n\nWe can use a little calculus to study how the present value p_0\nof a lease varies with r and g.\n\nWe will use a library called \n\nSymPy.\n\nSymPy enables us to do symbolic math calculations including\ncomputing derivatives of algebraic equations.\n\nWe will illustrate how it works by creating a symbolic expression that\nrepresents our present value formula for an infinite lease.\n\nAfter that, we’ll use SymPy to compute derivatives\n\n# Creates algebraic symbols that can be used in an algebraic expression\ng, r, x0 = sym.symbols('g, r, x0')\nG = (1 + g)\nR = (1 + r)\np0 = x0 / (1 - G * R**(-1))\ninit_printing(use_latex='mathjax')\nprint('Our formula is:')\np0\n\nprint('dp0 / dg is:')\ndp_dg = sym.diff(p0, g)\ndp_dg\n\nprint('dp0 / dr is:')\ndp_dr = sym.diff(p0, r)\ndp_dr\n\nWe can see that for \\frac{\\partial p_0}{\\partial r}<0 as long as\nr>g, r>0 and g>0 and x_0 is positive,\nso \\frac{\\partial p_0}{\\partial r} will always be negative.\n\nSimilarly, \\frac{\\partial p_0}{\\partial g}>0 as long as r>g, r>0 and g>0 and x_0 is positive, so \\frac{\\partial p_0}{\\partial g}\nwill always be positive.","type":"content","url":"/geom-series#application-to-asset-pricing","position":29},{"hierarchy":{"lvl1":"Geometric Series for Elementary Economics","lvl2":"Back to the Keynesian multiplier"},"type":"lvl2","url":"/geom-series#back-to-the-keynesian-multiplier","position":30},{"hierarchy":{"lvl1":"Geometric Series for Elementary Economics","lvl2":"Back to the Keynesian multiplier"},"content":"We will now go back to the case of the Keynesian multiplier and plot the\ntime path of y_t, given that consumption is a constant fraction\nof national income, and investment is fixed.\n\n# Function that calculates a path of y\ndef calculate_y(i, b, g, T, y_init):\n    y = np.zeros(T+1)\n    y[0] = i + b * y_init + g\n    for t in range(1, T+1):\n        y[t] = b * y[t-1] + i + g\n    return y\n\n# Initial values\ni_0 = 0.3\ng_0 = 0.3\n# 2/3 of income goes towards consumption\nb = 2/3\ny_init = 0\nT = 100\n\nfig, ax = plt.subplots()\nax.set_xlabel('$t$')\nax.set_ylabel('$y_t$')\nax.plot(np.arange(0, T+1), calculate_y(i_0, b, g_0, T, y_init))\n# Output predicted by geometric series\nax.hlines(i_0 / (1 - b) + g_0 / (1 - b), xmin=-1, xmax=101, linestyles='--')\nplt.show()\n\n\n\nFigure 5:Path of aggregate output over time\n\nIn this model, income grows over time, until it gradually converges to\nthe infinite geometric series sum of income.\n\nWe now examine what will\nhappen if we vary the so-called marginal propensity to consume,\ni.e., the fraction of income that is consumed\n\nbs = (1/3, 2/3, 5/6, 0.9)\n\nfig,ax = plt.subplots()\nax.set_ylabel('$y_t$')\nax.set_xlabel('$t$')\nx = np.arange(0, T+1)\nfor b in bs:\n    y = calculate_y(i_0, b, g_0, T, y_init)\n    ax.plot(x, y, label=r'$b=$'+f\"{b:.2f}\")\nax.legend()\nplt.show()\n\n\n\nFigure 6:Changing consumption as a fraction of income\n\nIncreasing the marginal propensity to consume b increases the\npath of output over time.\n\nNow we will compare the effects on output of increases in investment and government spending.\n\nfig, (ax1, ax2) = plt.subplots(2, 1, figsize=(6, 10))\nfig.subplots_adjust(hspace=0.3)\n\nx = np.arange(0, T+1)\nvalues = [0.3, 0.4]\n\nfor i in values:\n    y = calculate_y(i, b, g_0, T, y_init)\n    ax1.plot(x, y, label=f\"i={i}\")\nfor g in values:\n    y = calculate_y(i_0, b, g, T, y_init)\n    ax2.plot(x, y, label=f\"g={g}\")\n\naxes = ax1, ax2\nparam_labels = \"Investment\", \"Government Spending\"\nfor ax, param in zip(axes, param_labels):\n    ax.set_title(f'An Increase in {param} on Output')\n    ax.legend(loc =\"lower right\")\n    ax.set_ylabel('$y_t$')\n    ax.set_xlabel('$t$')\nplt.show()\n\n\n\nFigure 7:Different increase on output\n\nNotice here, whether government spending increases from 0.3 to 0.4 or\ninvestment increases from 0.3 to 0.4, the shifts in the graphs are\nidentical.","type":"content","url":"/geom-series#back-to-the-keynesian-multiplier","position":31},{"hierarchy":{"lvl1":"Computing Square Roots"},"type":"lvl1","url":"/greek-square","position":0},{"hierarchy":{"lvl1":"Computing Square Roots"},"content":"","type":"content","url":"/greek-square","position":1},{"hierarchy":{"lvl1":"Computing Square Roots","lvl2":"Introduction"},"type":"lvl2","url":"/greek-square#introduction","position":2},{"hierarchy":{"lvl1":"Computing Square Roots","lvl2":"Introduction"},"content":"Chapter 24 of \n\nRussell (2004) about early Greek mathematics and astronomy contains this\nfascinating passage:\n\nThe square root of 2, which was the first irrational to be discovered, was known to the early Pythagoreans, and ingenious methods of approximating to its value were discovered. The best was as follows: Form two columns of numbers, which we will call the a’s and the b’s; each starts with a 1. The next a, at each stage, is formed by adding the last a and the b already obtained; the next b is formed by adding twice the previous a to the previous b. The first 6 pairs so obtained are (1,1), (2,3), (5,7), (12,17), (29,41), (70,99). In each pair, 2 a - b is 1 or -1. Thus b/a is nearly the square root of two, and at each fresh step it gets nearer. For instance, the reader may satisy himself that the square of 99/70 is very nearly equal to 2.\n\nThis lecture drills down and studies this ancient method for computing square roots by using some of the matrix algebra that we’ve learned in earlier quantecon lectures.\n\nIn particular, this lecture can be viewed as a sequel to \n\nEigenvalues and Eigenvectors.\n\nIt  provides an  example of how eigenvectors isolate  invariant subspaces that help construct and analyze solutions of linear difference equations.\n\nWhen vector x_t starts in an invariant subspace, iterating the different equation keeps x_{t+j}\nin that subspace for all j \\geq 1.\n\nInvariant subspace methods are used throughout applied economic dynamics, for example, in the lecture \n\nMoney Financed Government Deficits and Price Levels.\n\nOur approach here  is to illustrate the method with an ancient example, one that ancient Greek mathematicians used to compute square roots of positive integers.","type":"content","url":"/greek-square#introduction","position":3},{"hierarchy":{"lvl1":"Computing Square Roots","lvl2":"Perfect squares and irrational numbers"},"type":"lvl2","url":"/greek-square#perfect-squares-and-irrational-numbers","position":4},{"hierarchy":{"lvl1":"Computing Square Roots","lvl2":"Perfect squares and irrational numbers"},"content":"An integer is called a perfect square if its square root is also an integer.\n\nAn ordered sequence of  perfect squares starts with4, 9, 16, 25, 36, 49, 64, 81, 100, 121, 144, 169, 196, 225, \\ldots\n\nIf an integer is not a perfect square, then its square root is an irrational number -- i.e., it cannot be expressed as a ratio of two integers, and its decimal expansion is indefinite.\n\nThe ancient Greeks invented an algorithm to compute square roots of integers, including integers that are not perfect squares.\n\nTheir method involved\n\ncomputing a particular sequence of integers \\{y_t\\}_{t=0}^\\infty;\n\ncomputing \\lim_{t \\rightarrow \\infty} \\left(\\frac{y_{t+1}}{y_t}\\right) = \\bar r;\n\ndeducing the desired square root from \\bar r.\n\nIn this lecture, we’ll describe this method.\n\nWe’ll also use invariant subspaces to describe variations on this method that are faster.","type":"content","url":"/greek-square#perfect-squares-and-irrational-numbers","position":5},{"hierarchy":{"lvl1":"Computing Square Roots","lvl2":"Second-order linear difference equations"},"type":"lvl2","url":"/greek-square#second-order-linear-difference-equations","position":6},{"hierarchy":{"lvl1":"Computing Square Roots","lvl2":"Second-order linear difference equations"},"content":"Before telling how the ancient Greeks computed square roots, we’ll provide a quick introduction\nto second-order linear difference equations.\n\nWe’ll study  the following second-order linear difference equationy_t = a_1 y_{t-1} + a_2 y_{t-2}, \\quad t \\geq 0\n\nwhere (y_{-1},  y_{-2}) is a pair of given initial conditions.\n\nEquation \n\n(2) is actually an infinite number of linear equations in the sequence\n\\{y_t\\}_{t=0}^\\infty.\n\nThere is one equation each for t = 0, 1, 2, \\ldots.\n\nWe could follow an approach taken in the lecture on \n\npresent values and stack all of these equations into a single matrix equation that we would then solve by using matrix inversion.\n\nNote\n\nIn the present instance, the matrix equation would multiply a countably infinite dimensional square matrix by  a countably infinite dimensional vector.  With some qualifications, matrix multiplication and inversion tools apply to such an equation.\n\nBut we won’t pursue that approach here.\n\nInstead, we’ll seek to find a time-invariant function that solves our difference equation, meaning\nthat it provides a formula for a \\{y_t\\}_{t=0}^\\infty sequence that satisfies\nequation \n\n(2) for each t \\geq 0.\n\nWe seek an expression  for y_t, t \\geq 0 as functions of the initial conditions  (y_{-1},  y_{-2}):y_t = g((y_{-1},  y_{-2});t), \\quad t \\geq 0.\n\nWe call such a function g a solution of the difference equation \n\n(2).\n\nOne way to discover a solution is to use a guess and verify method.\n\nWe shall begin by considering a special initial pair of initial  conditions\nthat satisfyy_{-1} = \\delta y_{-2}\n\nwhere \\delta is a scalar to be determined.\n\nFor initial condition that satisfy \n\n(4)\nequation \n\n(2) impllies thaty_0 = \\left(a_1 + \\frac{a_2}{\\delta}\\right) y_{-1}.\n\nWe want\\left(a_1 + \\frac{a_2}{\\delta}\\right) = \\delta\n\nwhich we can rewrite as the characteristic equation\\delta^2 - a_1 \\delta - a_2 = 0.\n\nApplying the quadratic formula to solve for the roots of \n\n(7) we find that\\delta = \\frac{ a_1 \\pm \\sqrt{a_1^2 + 4 a_2}}{2}.\n\nFor either of the two \\delta’s that satisfy equation \n\n(8),\na solution of difference equation \n\n(2) isy_t = \\delta^t y_0 , \\forall t \\geq 0\n\nprovided that we sety_0 = \\delta  y_{-1} .\n\nThe general solution of difference equation \n\n(2) takes the formy_t = \\eta_1 \\delta_1^t + \\eta_2 \\delta_2^t\n\nwhere \\delta_1, \\delta_2 are the two solutions \n\n(8) of the characteristic equation \n\n(7), and  \\eta_1, \\eta_2 are two constants chosen to satisfy\\begin{bmatrix} y_{-1} \\cr y_{-2} \\end{bmatrix} = \\begin{bmatrix} \\delta_1^{-1}  & \\delta_2^{-1} \\cr \\delta_1^{-2} & \\delta_2^{-2} \\end{bmatrix} \\begin{bmatrix} \\eta_1 \\cr \\eta_2 \\end{bmatrix}\n\nor\\begin{bmatrix} \\eta_1 \\cr \\eta_2 \\end{bmatrix} = \\begin{bmatrix} \\delta_1^{-1}  & \\delta_2^{-1} \\cr \\delta_1^{-2} & \\delta_2^{-2} \\end{bmatrix}^{-1} \\begin{bmatrix} y_{-1} \\cr y_{-2} \\end{bmatrix}\n\nSometimes we are free to choose the initial conditions (y_{-1}, y_{-2}), in which case we\nuse system \n\n(12) to find the associated (\\eta_1, \\eta_2).\n\nIf we choose (y_{-1}, y_{-2}) to set (\\eta_1, \\eta_2) = (1, 0), then y_t = \\delta_1^t for all t \\geq 0.\n\nIf we choose (y_{-1}, y_{-2}) to set (\\eta_1, \\eta_2) = (0, 1), then y_t = \\delta_2^t for all t \\geq 0.\n\nSoon we’ll relate the preceding calculations to components an eigen decomposition of a transition matrix that represents difference equation \n\n(2) in a very convenient way.\n\nWe’ll turn to that after we describe how Ancient Greeks figured out how to compute square roots of positive integers that are not perfect squares.","type":"content","url":"/greek-square#second-order-linear-difference-equations","position":7},{"hierarchy":{"lvl1":"Computing Square Roots","lvl2":"Algorithm of the Ancient Greeks"},"type":"lvl2","url":"/greek-square#algorithm-of-the-ancient-greeks","position":8},{"hierarchy":{"lvl1":"Computing Square Roots","lvl2":"Algorithm of the Ancient Greeks"},"content":"Let \\sigma be a positive  integer greater than 1.\n\nSo \\sigma \\in {\\mathcal I} \\equiv  \\{2, 3, \\ldots \\}.\n\nWe want an algorithm to compute the square root of \\sigma \\in {\\mathcal I}.\n\nIf \\sqrt{\\sigma} \\in {\\mathcal I}, \\sigma  is said to be a perfect square.\n\nIf \\sqrt{\\sigma} \\not\\in {\\mathcal I}, it turns out that it is irrational.\n\nAncient Greeks used a recursive algorithm to compute square roots of integers that are not perfect squares.\n\nThe algorithm iterates on a  second-order  linear  difference equation in the sequence \\{y_t\\}_{t=0}^\\infty:y_{t} = 2 y_{t-1} - (1 - \\sigma) y_{t-2}, \\quad t \\geq 0\n\ntogether with a pair of integers that are initial conditions for y_{-1}, y_{-2}.\n\nFirst, we’ll deploy some techniques for solving the difference equations that are also deployed in .\n\nThe characteristic equation associated with difference equation \n\n(14) isc(x) \\equiv x^2 - 2 x + (1 - \\sigma) = 0\n\n(Notice how this is an instance of equation \n\n(7) above.)\n\nFactoring the right side of   equation \n\n(15), we obtainc(x)= (x - \\lambda_1) (x-\\lambda_2) = 0\n\nwherec(x) = 0\n\nfor x = \\lambda_1 or x = \\lambda_2.\n\nThese two special values of x are sometimes called zeros or roots of c(x).\n\nBy applying the quadratic formula to solve for the roots  the characteristic equation\n\n\n(15), we find that\\lambda_1 = 1 + \\sqrt{\\sigma}, \\quad \\lambda_2 = 1 - \\sqrt{\\sigma}.\n\nFormulas \n\n(18) indicate that  \\lambda_1 and  \\lambda_2 are each functions\nof a single variable, namely,  \\sqrt{\\sigma}, the object that we along with some Ancient Greeks want to compute.\n\nAncient Greeks had an indirect way of exploiting this fact to compute square roots of a positive integer.\n\nThey did this by starting from particular initial conditions y_{-1}, y_{-2} and iterating on the difference equation \n\n(14).\n\nSolutions  of  difference equation \n\n(14) take the formy_t = \\lambda_1^t \\eta_1 + \\lambda_2^t \\eta_2\n\nwhere \\eta_1 and \\eta_2 are chosen to satisfy   prescribed initial conditions y_{-1}, y_{-2}:\\begin{aligned}\n\\lambda_1^{-1} \\eta_1 + \\lambda_2^{-1} \\eta_2 & =  y_{-1} \\cr\n\\lambda_1^{-2} \\eta_1 + \\lambda_2^{-2} \\eta_2 & =  y_{-2}\n\\end{aligned}\n\nSystem \n\n(20) of simultaneous linear equations will play a big role in the remainder of this lecture.\n\nSince \\lambda_1 = 1 + \\sqrt{\\sigma} > 1 > \\lambda_2 = 1 - \\sqrt{\\sigma} ,\nit follows that for almost all (but not all) initial conditions\\lim_{t \\rightarrow \\infty} \\left(\\frac{y_{t+1}}{y_t}\\right) = 1 + \\sqrt{\\sigma}.\n\nThus,\\sqrt{\\sigma} = \\lim_{t \\rightarrow \\infty} \\left(\\frac{y_{t+1}}{y_t}\\right) - 1.\n\nHowever, notice that if \\eta_1 = 0, then\\lim_{t \\rightarrow \\infty} \\left(\\frac{y_{t+1}}{y_t}\\right) = 1 - \\sqrt{\\sigma}\n\nso that\\sqrt{\\sigma} = 1 - \\lim_{t \\rightarrow \\infty} \\left(\\frac{y_{t+1}}{y_t}\\right).\n\nActually, if \\eta_1 =0, it follows that\\sqrt{\\sigma} = 1 - \\left(\\frac{y_{t+1}}{y_t}\\right) \\quad \\forall t \\geq 0,\n\nso that convergence is immediate and there is no need to take limits.\n\nSymmetrically, if \\eta_2 =0, it follows that\\sqrt{\\sigma} =  \\left(\\frac{y_{t+1}}{y_t}\\right) - 1 \\quad \\forall t \\geq 0\n\nso again, convergence is immediate, and we have no need to compute a limit.\n\nSystem \n\n(20) of simultaneous linear equations can be used in various ways.\n\nwe can take y_{-1}, y_{-2} as given initial conditions and solve for \\eta_1, \\eta_2;\n\nwe can instead take \\eta_1, \\eta_2 as given and solve for initial conditions  y_{-1}, y_{-2}.\n\nNotice how we used the  second approach above when we set  \\eta_1, \\eta_2  either to (0, 1), for example, or (1, 0), for example.\n\nIn taking this second approach, we constructed an invariant subspace of {\\bf R}^2.\n\nHere is what is going on.\n\nFor  t \\geq 0 and for most pairs of  initial conditions (y_{-1}, y_{-2}) \\in {\\bf R}^2 for equation \n\n(14), y_t can be expressed as a linear combination  of y_{t-1} and y_{t-2}.\n\nBut for some special initial conditions (y_{-1}, y_{-2}) \\in {\\bf R}^2, y_t can be expressed as a linear function  of y_{t-1} only.\n\nThese special initial conditions require that y_{-1} be a linear function of y_{-2}.\n\nWe’ll study these special initial conditions soon.\n\nBut first let’s write some Python code to iterate on equation \n\n(14) starting from an arbitrary (y_{-1}, y_{-2}) \\in {\\bf R}^2.","type":"content","url":"/greek-square#algorithm-of-the-ancient-greeks","position":9},{"hierarchy":{"lvl1":"Computing Square Roots","lvl2":"Implementation"},"type":"lvl2","url":"/greek-square#implementation","position":10},{"hierarchy":{"lvl1":"Computing Square Roots","lvl2":"Implementation"},"content":"We now implement the above algorithm to compute the square root of \\sigma.\n\nIn this lecture, we use the following import:\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef solve_λs(coefs):    \n    # Calculate the roots using numpy.roots\n    λs = np.roots(coefs)\n    \n    # Sort the roots for consistency\n    return sorted(λs, reverse=True)\n\ndef solve_η(λ_1, λ_2, y_neg1, y_neg2):\n    # Solve the system of linear equation\n    A = np.array([\n        [1/λ_1, 1/λ_2],\n        [1/(λ_1**2), 1/(λ_2**2)]\n    ])\n    b = np.array((y_neg1, y_neg2))\n    ηs = np.linalg.solve(A, b)\n    \n    return ηs\n\ndef solve_sqrt(σ, coefs, y_neg1, y_neg2, t_max=100):\n    # Ensure σ is greater than 1\n    if σ <= 1:\n        raise ValueError(\"σ must be greater than 1\")\n        \n    # Characteristic roots\n    λ_1, λ_2 = solve_λs(coefs)\n    \n    # Solve for η_1 and η_2\n    η_1, η_2 = solve_η(λ_1, λ_2, y_neg1, y_neg2)\n\n    # Compute the sequence up to t_max\n    t = np.arange(t_max + 1)\n    y = (λ_1 ** t) * η_1 + (λ_2 ** t) * η_2\n    \n    # Compute the ratio y_{t+1} / y_t for large t\n    sqrt_σ_estimate = (y[-1] / y[-2]) - 1\n    \n    return sqrt_σ_estimate\n\n# Use σ = 2 as an example\nσ = 2\n\n# Encode characteristic equation\ncoefs = (1, -2, (1 - σ))\n\n# Solve for the square root of σ\nsqrt_σ = solve_sqrt(σ, coefs, y_neg1=2, y_neg2=1)\n\n# Calculate the deviation\ndev = abs(sqrt_σ-np.sqrt(σ))\nprint(f\"sqrt({σ}) is approximately {sqrt_σ:.5f} (error: {dev:.5f})\")\n\nNow we consider cases where (\\eta_1, \\eta_2) = (0, 1) and (\\eta_1, \\eta_2) = (1, 0)\n\n# Compute λ_1, λ_2\nλ_1, λ_2 = solve_λs(coefs)\nprint(f'Roots for the characteristic equation are ({λ_1:.5f}, {λ_2:.5f}))')\n\n# Case 1: η_1, η_2 = (0, 1)\nηs = (0, 1)\n\n# Compute y_{t} and y_{t-1} with t >= 0\ny = lambda t, ηs: (λ_1 ** t) * ηs[0] + (λ_2 ** t) * ηs[1]\nsqrt_σ = 1 - y(1, ηs) / y(0, ηs)\n\nprint(f\"For η_1, η_2 = (0, 1), sqrt_σ = {sqrt_σ:.5f}\")\n\n# Case 2: η_1, η_2 = (1, 0)\nηs = (1, 0)\nsqrt_σ = y(1, ηs) / y(0, ηs) - 1\n\nprint(f\"For η_1, η_2 = (1, 0), sqrt_σ = {sqrt_σ:.5f}\")\n\nWe find that convergence is immediate.\n\nNext, we’ll  represent the preceding analysis by first vectorizing our second-order difference equation \n\n(14) and then using  eigendecompositions of an  associated  state transition matrix.","type":"content","url":"/greek-square#implementation","position":11},{"hierarchy":{"lvl1":"Computing Square Roots","lvl2":"Vectorizing the difference equation"},"type":"lvl2","url":"/greek-square#vectorizing-the-difference-equation","position":12},{"hierarchy":{"lvl1":"Computing Square Roots","lvl2":"Vectorizing the difference equation"},"content":"Represent \n\n(14) with the first-order matrix difference equation\\begin{bmatrix} y_{t+1} \\cr y_{t} \\end{bmatrix}\n= \\begin{bmatrix} 2 & - ( 1 - \\sigma) \\cr 1 & 0 \\end{bmatrix} \\begin{bmatrix} y_{t} \\cr y_{t-1} \\end{bmatrix}\n\norx_{t+1} = M x_t\n\nwhereM = \\begin{bmatrix} 2 & - (1 - \\sigma )  \\cr 1 & 0 \\end{bmatrix},  \\quad x_t= \\begin{bmatrix} y_{t} \\cr y_{t-1} \\end{bmatrix}\n\nConstruct an eigendecomposition of M:M = V \\begin{bmatrix} \\lambda_1 & 0 \\cr 0 & \\lambda_2  \\end{bmatrix} V^{-1}\n\nwhere columns of V are eigenvectors corresponding to  eigenvalues \\lambda_1 and \\lambda_2.\n\nThe eigenvalues can be ordered so that  \\lambda_1 > 1 > \\lambda_2.\n\nWrite equation \n\n(14) asx_{t+1} = V \\Lambda V^{-1} x_t\n\nNow we implement the algorithm above.\n\nFirst we write a function that iterates M\n\ndef iterate_M(x_0, M, num_steps, dtype=np.float64):\n    \n    # Eigendecomposition of M\n    Λ, V = np.linalg.eig(M)\n    V_inv = np.linalg.inv(V)\n    \n    # Initialize the array to store results\n    xs = np.zeros((x_0.shape[0], \n                   num_steps + 1))\n    \n    # Perform the iterations\n    xs[:, 0] = x_0\n    for t in range(num_steps):\n        xs[:, t + 1] = M @ xs[:, t]\n    \n    return xs, Λ, V, V_inv\n\n# Define the state transition matrix M\nM = np.array([\n      [2, -(1 - σ)],\n      [1, 0]])\n\n# Initial condition vector x_0\nx_0 = np.array([2, 2])\n\n# Perform the iteration\nxs, Λ, V, V_inv = iterate_M(x_0, M, num_steps=100)\n\nprint(f\"eigenvalues:\\n{Λ}\")\nprint(f\"eigenvectors:\\n{V}\")\nprint(f\"inverse eigenvectors:\\n{V_inv}\")\n\nLet’s compare the eigenvalues to the roots \n\n(18) of equation\n\n\n(15) that  we computed above.\n\nroots = solve_λs((1, -2, (1 - σ)))\nprint(f\"roots: {np.round(roots, 8)}\")\n\nHence we confirmed \n\n(30).\n\nInformation about the square root we are after is also contained\nin the two  eigenvectors.\n\nIndeed, each  eigenvector is just a two-dimensional subspace of {\\mathbb R}^3 pinned down by dynamics of the formy_{t} = \\lambda_i y_{t-1}, \\quad i = 1, 2\n\nthat we encountered above in equation \n\n(9) above.\n\nIn equation \n\n(32), the ith \\lambda_i  equals the V_{i, 1}/V_{i,2}.\n\nThe following graph verifies this for our example.\n\n# Plotting the eigenvectors\nplt.figure(figsize=(8, 8))\n\nplt.quiver(0, 0, V[0, 0], V[1, 0], angles='xy', scale_units='xy', \n           scale=1, color='C0', label=fr'$\\lambda_1={np.round(Λ[0], 4)}$')\nplt.quiver(0, 0, V[0, 1], V[1, 1], angles='xy', scale_units='xy', \n           scale=1, color='C1', label=fr'$\\lambda_2={np.round(Λ[1], 4)}$')\n\n# Annotating the slopes\nplt.text(V[0, 0]-0.5, V[1, 0]*1.2, \n         r'slope=$\\frac{V_{1,1}}{V_{1,2}}=$'+f'{np.round(V[0, 0] / V[1, 0], 4)}', \n         fontsize=12, color='C0')\nplt.text(V[0, 1]-0.5, V[1, 1]*1.2, \n         r'slope=$\\frac{V_{2,1}}{V_{2,2}}=$'+f'{np.round(V[0, 1] / V[1, 1], 4)}', \n         fontsize=12, color='C1')\n\n# Adding labels\nplt.axhline(0, color='grey', linewidth=0.5, alpha=0.4)\nplt.axvline(0, color='grey', linewidth=0.5, alpha=0.4)\nplt.legend()\n\nplt.xlim(-1.5, 1.5)\nplt.ylim(-1.5, 1.5)\nplt.show()\n\n","type":"content","url":"/greek-square#vectorizing-the-difference-equation","position":13},{"hierarchy":{"lvl1":"Computing Square Roots","lvl2":"Invariant subspace approach"},"type":"lvl2","url":"/greek-square#invariant-subspace-approach","position":14},{"hierarchy":{"lvl1":"Computing Square Roots","lvl2":"Invariant subspace approach"},"content":"The preceding  calculation indicates that we can use the eigenvectors V to construct 2-dimensional  invariant subspaces.\n\nWe’ll pursue that possibility now.\n\nDefine the transformed variablesx_t^* = V^{-1} x_t\n\nEvidently, we can recover x_t from x_t^*:x_t = V x_t^*\n\nThe following notations and equations will help us.\n\nLet\n\n$$\n\nV = \\begin{bmatrix} V_{1,1} & V_{1,2} \\cr\nV_{2,1} & V_{2,2} \\end{bmatrix}, \\quad\nV^{-1} = \\begin{bmatrix} V^{1,1} & V^{1,2} \\cr\nV^{2,1} & V^{2,2} \\end{bmatrix}\n$$\n\nNotice that it follows from\\begin{bmatrix} V^{1,1} & V^{1,2} \\cr \n                         V^{2,1} & V^{2,2} \\end{bmatrix} \\begin{bmatrix} V_{1,1} & V_{1,2} \\cr \n                         V_{2,1} & V_{2,2} \\end{bmatrix} = \\begin{bmatrix} 1  & 0 \\cr 0 & 1 \\end{bmatrix}\n\nthatV^{2,1} V_{1,1} + V^{2,2} V_{2,1} = 0\n\nandV^{1,1}V_{1,2} + V^{1,2} V_{2,2} = 0.\n\nThese equations will be very useful soon.\n\nNotice that\\begin{bmatrix} x_{1,t+1}^* \\cr x_{2,t+1}^* \\end{bmatrix} = \\begin{bmatrix} \\lambda_1  & 0 \\cr 0 & \\lambda_2 \\end{bmatrix}\n\\begin{bmatrix} x_{1,t}^* \\cr x_{2,t}^* \\end{bmatrix}\n\nTo deactivate \\lambda_1 we want to setx_{1,0}^* = 0.\n\nThis can be achieved by settingx_{2,0} =  -( V^{1,2})^{-1} V^{1,1} x_{1,0} = V_{2,2} V_{1,2}^{-1} x_{1,0}.\n\nTo deactivate \\lambda_2, we want to  setx_{2,0}^* = 0\n\nThis can be achieved by settingx_{2,0} = -(V^{2,2})^{-1} V^{2,1} x_{1,0} = V_{2,1} V_{1,1}^{-1} x_{1,0}.\n\nLet’s verify \n\n(40) and \n\n(42) below\n\nTo deactivate \\lambda_1 we use \n\n(40)\n\nxd_1 = np.array((x_0[0], \n                 V[1,1]/V[0,1] * x_0[0]),\n                dtype=np.float64)\n\n# Compute x_{1,0}^*\nnp.round(V_inv @ xd_1, 8)\n\nWe find x_{1,0}^* = 0.\n\nNow we deactivate \\lambda_2 using \n\n(42)\n\nxd_2 = np.array((x_0[0], \n                 V[1,0]/V[0,0] * x_0[0]), \n                 dtype=np.float64)\n\n# Compute x_{2,0}^*\nnp.round(V_inv @ xd_2, 8)\n\nWe find x_{2,0}^* = 0.\n\n# Simulate with muted λ1 λ2.\nnum_steps = 10\nxs_λ1 = iterate_M(xd_1, M, num_steps)[0]\nxs_λ2 = iterate_M(xd_2, M, num_steps)[0]\n\n# Compute ratios y_t / y_{t-1}\nratios_λ1 = xs_λ1[1, 1:] / xs_λ1[1, :-1]\nratios_λ2 = xs_λ2[1, 1:] / xs_λ2[1, :-1]\n\nThe following graph shows the ratios y_t / y_{t-1} for the two cases.\n\nWe find that the ratios converge to \\lambda_2 in the first case and \\lambda_1 in the second case.\n\n# Plot the ratios for y_t / y_{t-1}\nfig, axs = plt.subplots(1, 2, figsize=(12, 6), dpi=500)\n\n# First subplot\naxs[0].plot(np.round(ratios_λ1, 6), \n            label=r'$\\frac{y_t}{y_{t-1}}$', linewidth=3)\naxs[0].axhline(y=Λ[1], color='red', linestyle='--', \n               label=r'$\\lambda_2$', alpha=0.5)\naxs[0].set_xlabel('t', size=18)\naxs[0].set_ylabel(r'$\\frac{y_t}{y_{t-1}}$', size=18)\naxs[0].set_title(r'$\\frac{y_t}{y_{t-1}}$ after Muting $\\lambda_1$', \n                 size=13)\naxs[0].legend()\n\n# Second subplot\naxs[1].plot(ratios_λ2, label=r'$\\frac{y_t}{y_{t-1}}$', \n            linewidth=3)\naxs[1].axhline(y=Λ[0], color='green', linestyle='--', \n               label=r'$\\lambda_1$', alpha=0.5)\naxs[1].set_xlabel('t', size=18)\naxs[1].set_ylabel(r'$\\frac{y_t}{y_{t-1}}$', size=18)\naxs[1].set_title(r'$\\frac{y_t}{y_{t-1}}$ after Muting $\\lambda_2$', \n                 size=13)\naxs[1].legend()\n\nplt.tight_layout()\nplt.show()\n\n","type":"content","url":"/greek-square#invariant-subspace-approach","position":15},{"hierarchy":{"lvl1":"Computing Square Roots","lvl2":"Concluding remarks"},"type":"lvl2","url":"/greek-square#concluding-remarks","position":16},{"hierarchy":{"lvl1":"Computing Square Roots","lvl2":"Concluding remarks"},"content":"This lecture sets the stage  for many other applications of the invariant subspace methods.\n\nAll of these exploit very similar equations based on eigen decompositions.\n\nWe shall encounter equations very similar to \n\n(40) and \n\n(42)\nin \n\nMoney Financed Government Deficits and Price Levels and in many other places in dynamic economic theory.","type":"content","url":"/greek-square#concluding-remarks","position":17},{"hierarchy":{"lvl1":"Computing Square Roots","lvl2":"Exercise"},"type":"lvl2","url":"/greek-square#exercise","position":18},{"hierarchy":{"lvl1":"Computing Square Roots","lvl2":"Exercise"},"content":"Please use matrix algebra to formulate the method described by Bertrand Russell at the beginning of this lecture.\n\nDefine a state vector x_t = \\begin{bmatrix} a_t \\cr b_t \\end{bmatrix}.\n\nFormulate a first-order vector difference equation for x_t of the form x_{t+1} = A x_t and\ncompute the matrix A.\n\nUse the system x_{t+1} = A x_t to replicate the sequence of a_t’s and b_t’s described by Bertrand Russell.\n\nCompute the eigenvectors and eigenvalues of A and compare them to corresponding objects computed in the text of this lecture.\n\nSolution to \n\nExercise 1\n\nHere is one soluition.\n\nAccording to the quote, we can formulate\\begin{aligned}\na_{t+1} &= a_t + b_t \\\\\nb_{t+1} &= 2a_t + b_t\n\\end{aligned}\n\nwith x_0 = \\begin{bmatrix}  a_0 \\cr b_0 \\end{bmatrix} = \\begin{bmatrix}  1 \\cr 1 \\end{bmatrix}\n\nBy \n\n(43), we can write matrix A asA = \\begin{bmatrix} 1 & 1 \\cr \n                2 & 1 \\end{bmatrix}\n\nThen x_{t+1} = A x_t for t \\in \\{0, \\dots, 5\\}\n\n# Define the matrix A\nA = np.array([[1, 1],\n              [2, 1]])\n\n# Initial vector x_0\nx_0 = np.array([1, 1])\n\n# Number of iterations\nn = 6\n\n# Generate the sequence\nxs = np.array([x_0])\nx_t = x_0\nfor _ in range(1, n):\n    x_t = A @ x_t\n    xs = np.vstack([xs, x_t])\n\n# Print the sequence\nfor i, (a_t, b_t) in enumerate(xs):\n    print(f\"Iter {i}: a_t = {a_t}, b_t = {b_t}\")\n\n# Compute eigenvalues and eigenvectors of A\neigenvalues, eigenvectors = np.linalg.eig(A)\n\nprint(f'\\nEigenvalues:\\n{eigenvalues}')\nprint(f'\\nEigenvectors:\\n{eigenvectors}')\n\n","type":"content","url":"/greek-square#exercise","position":19},{"hierarchy":{"lvl1":"Price Level Histories"},"type":"lvl1","url":"/inflation-history","position":0},{"hierarchy":{"lvl1":"Price Level Histories"},"content":"This lecture offers some historical evidence about fluctuations in levels of aggregate price indexes.\n\nLet’s start by installing the necessary Python packages.\n\nThe xlrd package is used by pandas to perform operations on Excel files.\n\n%pip install xlrd openpyxl\n\nWe can then import the Python modules we will use.\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib.dates as mdates\nimport pyodide_http\n\nThe rate of growth of the price level is called inflation in the popular press and in discussions among central bankers and treasury officials.\n\nThe price level is measured in units of domestic currency per units of a representative bundle of consumption goods.\n\nThus, in the US, the price level at t is measured in dollars (month t or year t) per unit of the consumption bundle.\n\nUntil the early 20th century, in many western economies, price levels fluctuated from year to year but didn’t have much of a trend.\n\nOften the price levels ended a century near where they started.\n\nThings were different in the 20th century, as we shall see in this lecture.\n\nA widely believed explanation of this big difference is that countries’ abandoning gold and silver standards in the early twentieth century.\n\nTip\n\nThis lecture sets the stage for some subsequent lectures about a theory that macro economists use to think about determinants of the price level, namely, \n\nA Monetarist Theory of Price Levels and \n\nMonetarist Theory of Price Levels with Adaptive Expectations","type":"content","url":"/inflation-history","position":1},{"hierarchy":{"lvl1":"Price Level Histories","lvl2":"Four centuries of price levels"},"type":"lvl2","url":"/inflation-history#four-centuries-of-price-levels","position":2},{"hierarchy":{"lvl1":"Price Level Histories","lvl2":"Four centuries of price levels"},"content":"We begin by displaying data that originally appeared on page 35 of \n\nSargent & Velde (2002) that show price levels for four “hard currency” countries from 1600 to 1914.\n\nFrance\n\nSpain (Castile)\n\nUnited Kingdom\n\nUnited States\n\nIn the present context, the  phrase “hard currency” means that the countries were on a commodity-money standard:  money consisted of gold and silver coins that circulated at values largely determined by the weights of their gold and silver contents.\n\nNote\n\nUnder a gold or silver standard, some money also consisted of “warehouse certificates” that represented paper claims on gold or silver coins. Bank notes issued by the government or private banks can be viewed as examples of such “warehouse certificates”.\n\nLet us bring the data into pandas from a spreadsheet that is \n\nhosted on github.\n\n# Import data and clean up the index\npyodide_http.patch_all()\ndata_url = \"https://raw.githubusercontent.com/QuantEcon/lecture-python-intro/main/lectures/datasets/longprices.xls\"\ndf_fig5 = pd.read_excel(data_url, \n                        sheet_name='all', \n                        header=2, \n                        index_col=0).iloc[1:]\ndf_fig5.index = df_fig5.index.astype(int)\n\nWe first plot price levels over the period 1600-1914.\n\nDuring most years in this time interval, the countries were on a gold or silver standard.\n\ndf_fig5_befe1914 = df_fig5[df_fig5.index <= 1914]\n\n# Create plot\ncols = ['UK', 'US', 'France', 'Castile']\n\nfig, ax = plt.subplots(figsize=(10,6))\n\nfor col in cols:\n    ax.plot(df_fig5_befe1914.index, \n            df_fig5_befe1914[col], label=col, lw=2)\n\nax.legend()\nax.set_ylabel('Index  1913 = 100')\nax.set_xlabel('Year')\nax.set_xlim(xmin=1600)\nplt.tight_layout()\nplt.show()\n\n\n\nFigure 1:Long run time series of the price level\n\nWe say “most years” because there were temporary lapses from the gold or silver standard.\n\nBy staring at \n\nFig. 1 carefully, you might be able to guess when these temporary lapses occurred, because they were also times during which price levels temporarily rose markedly:\n\n1791-1797 in France (French Revolution)\n\n1776-1790 in the US (War for Independence from Great Britain)\n\n1861-1865 in the US (Civil War)\n\nDuring these episodes, the gold/silver standard was temporarily abandoned when a government printed paper money to pay for war expenditures.\n\nNote\n\nThis quantecon lecture \n\nInflation During French Revolution describes circumstances leading up to and during the big inflation that occurred during the French Revolution.\n\nDespite these temporary lapses, a striking thing about the figure is that price levels were roughly constant over three centuries.\n\nIn the early century, two other features of this data attracted the attention of \n\nIrving Fisher of Yale University and \n\nJohn Maynard Keynes of Cambridge University.\n\nDespite being anchored to the same average level over long time spans, there were considerable year-to-year variations in price levels\n\nWhile using valuable gold and silver as coins succeeded in anchoring the price level by limiting the supply of money, it cost real resources.\n\na country paid a high “opportunity cost” for using gold and silver coins as money -- that gold and silver could instead have been made into valuable jewelry and other durable goods.\n\nKeynes and Fisher proposed what they claimed would be a more efficient way to achieve a price level that\n\nwould be at least as firmly anchored as achieved under a gold or silver standard, and\n\nwould also exhibit less year-to-year short-term fluctuations.\n\nThey said that central bank could achieve price level stability by\n\nissuing  limited supplies of paper currency\n\nrefusing to print money to finance government expenditures\n\nThis logic prompted John Maynard Keynes to call a commodity standard a “barbarous relic.”\n\nA paper currency or “fiat money” system disposes of all reserves behind a currency.\n\nBut adhering to a gold or silver standard had provided an automatic mechanism for limiting the supply of money, thereby anchoring the price level.\n\nTo anchor the price level, a pure paper or fiat money system replaces that automatic mechanism with a central bank with the authority and determination to limit the supply of money (and to deter counterfeiters!)\n\nNow let’s see what happened to the price level in the four countries after 1914, when one after another of them left the gold/silver standard by showing the complete graph that originally appeared on page 35 of \n\nSargent & Velde (2002).\n\nFig. 2 shows the logarithm of price levels over four “hard currency” countries from 1600 to 2000.\n\nNote\n\nAlthough we didn’t have to use logarithms in our earlier graphs that had stopped in 1914, we now choose to use logarithms because we want to fit observations after 1914 in the same graph as the earlier observations.\n\nAfter the outbreak of the Great War in 1914, the four countries left the gold standard and in so doing acquired the ability to print money to finance government expenditures.\n\nfig, ax = plt.subplots(dpi=200)\n\nfor col in cols:\n    ax.plot(df_fig5.index, df_fig5[col], lw=2)\n    ax.text(x=df_fig5.index[-1]+2, \n            y=df_fig5[col].iloc[-1], s=col)\n\nax.set_yscale('log')\nax.set_ylabel('Logs of price levels (Index  1913 = 100)')\nax.set_ylim([10, 1e6])\nax.set_xlabel('year')\nax.set_xlim(xmin=1600)\nplt.tight_layout()\nplt.show()\n\n\n\nFigure 2:Long run time series of the price level (log)\n\nFig. 2 shows that paper-money-printing central banks didn’t do as well as the gold and standard silver standard in anchoring price levels.\n\nThat would probably have surprised or disappointed Irving Fisher and John Maynard Keynes.\n\nActually, earlier economists and statesmen knew about the possibility of fiat money systems long before Keynes and Fisher advocated them in the early 20th century.\n\nProponents of a commodity money system did not trust governments and central banks properly to manage a fiat money system.\n\nThey were willing to pay the resource costs associated with setting up and maintaining a commodity money system.\n\nIn light of the high and persistent inflation that many countries experienced after they abandoned commodity monies in the twentieth century, we hesitate to criticize advocates of a gold or silver standard for their preference to stay on the pre-1914 gold/silver standard.\n\nThe breadth and lengths of the inflationary experiences of the twentieth century under paper money fiat standards are historically unprecedented.","type":"content","url":"/inflation-history#four-centuries-of-price-levels","position":3},{"hierarchy":{"lvl1":"Price Level Histories","lvl2":"Four big inflations"},"type":"lvl2","url":"/inflation-history#four-big-inflations","position":4},{"hierarchy":{"lvl1":"Price Level Histories","lvl2":"Four big inflations"},"content":"In the wake of World War I, which ended in November 1918, monetary and fiscal authorities struggled to achieve price level stability without being on a gold or silver standard.\n\nWe present four graphs from “The Ends of Four Big Inflations” from chapter 3 of \n\nSargent (2013).\n\nThe graphs depict logarithms of price levels during the early post World War I years for four countries:\n\nFigure 3.1, Retail prices Austria, 1921-1924 (page 42)\n\nFigure 3.2, Wholesale prices Hungary, 1921-1924 (page 43)\n\nFigure 3.3, Wholesale prices, Poland, 1921-1924 (page 44)\n\nFigure 3.4, Wholesale prices, Germany, 1919-1924 (page 45)\n\nWe have added logarithms of the exchange rates vis-à-vis the US dollar to each of the four graphs\nfrom chapter 3 of \n\nSargent (2013).\n\nData underlying our graphs appear in tables in an appendix to chapter 3 of \n\nSargent (2013).\nWe have transcribed all of these data into a spreadsheet \n\nchapter_3.xlsx that we read into pandas.\n\nIn the code cell below we clean the data and build a pandas.dataframe.\n\ndef process_entry(entry):\n    \"Clean each entry of a dataframe.\"\n    \n    if type(entry) == str:\n        # Remove leading and trailing whitespace\n        entry = entry.strip()\n        # Remove comma\n        entry = entry.replace(',', '')\n    \n        # Remove HTML markers\n        item_to_remove = ['<s>a</s>', '<s>c</s>', \n                          '<s>d</s>', '<s>e</s>']\n\n        # <s>b</s> represents a billion\n        if '<s>b</s>' in entry:\n            entry = entry.replace('<s>b</s>', '')\n            entry = float(entry) * 1e9\n        else:\n            for item in item_to_remove:\n                if item in entry:\n                    entry = entry.replace(item, '')\n    return entry\n\ndef process_df(df):\n    \"Clean and reorganize the entire dataframe.\"\n    \n    # Remove HTML markers from column names\n    for item in ['<s>a</s>', '<s>c</s>', '<s>d</s>', '<s>e</s>']:\n        df.columns = df.columns.str.replace(item, '')\n        \n    # Convert years to int\n    df['Year'] = df['Year'].apply(lambda x: int(x))\n    \n    # Set index to datetime with year and month\n    df = df.set_index(\n            pd.to_datetime(\n                (df['Year'].astype(str) + \\\n                 df['Month'].astype(str)), \n                format='%Y%B'))\n    df = df.drop(['Year', 'Month'], axis=1)\n    \n    # Handle duplicates by keeping the first\n    df = df[~df.index.duplicated(keep='first')]\n    \n    # Convert attribute values to numeric\n    df = df.map(lambda x: float(x) \\\n                if x != '—' else np.nan)\n    \n    # Finally, we only focus on data between 1919 and 1925\n    mask = (df.index >= '1919-01-01') & \\\n           (df.index < '1925-01-01')\n    df = df.loc[mask]\n\n    return df\n\nNow we write plotting functions pe_plot and pr_plot that will build figures that show the price level, exchange rates,\nand inflation rates, for each country of interest.\n\ndef pe_plot(p_seq, e_seq, index, labs, ax):\n    \"Generate plots for price and exchange rates.\"\n\n    p_lab, e_lab = labs\n    \n    # Plot price and exchange rates\n    ax.plot(index, p_seq, label=p_lab, color='tab:blue', lw=2)\n    \n    # Add a new axis\n    ax1 = ax.twinx()\n    ax1.plot([None], [None], label=p_lab, color='tab:blue', lw=2)\n    ax1.plot(index, e_seq, label=e_lab, color='tab:orange', lw=2)\n    \n    # Set log axes\n    ax.set_yscale('log')\n    ax1.set_yscale('log')\n    \n    # Define the axis label format\n    ax.xaxis.set_major_locator(\n        mdates.MonthLocator(interval=5))\n    ax.xaxis.set_major_formatter(\n        mdates.DateFormatter('%b %Y'))\n    for label in ax.get_xticklabels():\n        label.set_rotation(45)\n    \n    # Set labels\n    ax.set_ylabel('Price level')\n    ax1.set_ylabel('Exchange rate')\n  \n    ax1.legend(loc='upper left')\n    \n    return ax1\n\ndef pr_plot(p_seq, index, ax):\n    \"Generate plots for inflation rates.\"\n\n    #  Calculate the difference of log p_seq\n    log_diff_p = np.diff(np.log(p_seq))\n    \n    # Calculate and plot moving average\n    diff_smooth = pd.DataFrame(log_diff_p).rolling(3, center=True).mean()\n    ax.plot(index[1:], diff_smooth, label='Moving average (3 period)', alpha=0.5, lw=2)\n    ax.set_ylabel('Inflation rate')\n    \n    ax.xaxis.set_major_locator(\n        mdates.MonthLocator(interval=5))\n    ax.xaxis.set_major_formatter(\n        mdates.DateFormatter('%b %Y'))\n    \n    for label in ax.get_xticklabels():\n        label.set_rotation(45)\n    \n    ax.legend()\n    \n    return ax\n\nWe prepare the data for each country\n\n# Import data\ndata_url = \"https://raw.githubusercontent.com/QuantEcon/lecture-python-intro/main/lectures/datasets/chapter_3.xlsx\"\nxls = pd.ExcelFile(data_url)\n\n# Select relevant sheets\nsheet_index = [(2, 3, 4), \n               (9, 10), \n               (14, 15, 16), \n               (21, 18, 19)]\n\n# Remove redundant rows\nremove_row = [(-2, -2, -2), \n              (-7, -10), \n              (-6, -4, -3), \n              (-19, -3, -6)]\n\n# Unpack and combine series for each country\ndf_list = []\n\nfor i in range(4):\n    \n    indices, rows = sheet_index[i], remove_row[i]\n    \n    # Apply process_entry on the selected sheet\n    sheet_list = [\n        pd.read_excel(xls, 'Table3.' + str(ind), \n            header=1).iloc[:row].map(process_entry)\n        for ind, row in zip(indices, rows)]\n    \n    sheet_list = [process_df(df) for df in sheet_list]\n    df_list.append(pd.concat(sheet_list, axis=1))\n\ndf_aus, df_hun, df_pol, df_deu = df_list\n\nNow let’s construct graphs for our four countries.\n\nFor each country, we’ll plot two graphs.\n\nThe first graph plots logarithms of\n\nprice levels\n\nexchange rates vis-à-vis US dollars\n\nFor each country, the scale on the right side of a graph will pertain to the price level while the scale on the left side of a graph will pertain to the exchange rate.\n\nFor each country, the second graph plots a centered three-month moving average of the inflation rate defined as \\frac{p_{t-1} + p_t + p_{t+1}}{3}.","type":"content","url":"/inflation-history#four-big-inflations","position":5},{"hierarchy":{"lvl1":"Price Level Histories","lvl3":"Austria","lvl2":"Four big inflations"},"type":"lvl3","url":"/inflation-history#austria","position":6},{"hierarchy":{"lvl1":"Price Level Histories","lvl3":"Austria","lvl2":"Four big inflations"},"content":"The sources of our data are:\n\nTable 3.3, retail price level \\exp p\n\nTable 3.4, exchange rate with US\n\np_seq = df_aus['Retail price index, 52 commodities']\ne_seq = df_aus['Exchange Rate']\n\nlab = ['Retail price index', \n       'Austrian Krones (Crowns) per US cent']\n\n# Create plot\nfig, ax = plt.subplots(dpi=200)\n_ = pe_plot(p_seq, e_seq, df_aus.index, lab, ax)\n\nplt.show()\n\n\n\nFigure 3:Price index and exchange rate (Austria)\n\n# Plot moving average\nfig, ax = plt.subplots(dpi=200)\n_ = pr_plot(p_seq, df_aus.index, ax)\n\nplt.show()\n\n\n\nFigure 4:Monthly inflation rate (Austria)\n\nStaring at \n\nFig. 3 and \n\nFig. 4 conveys the following impressions to the authors of this lecture at QuantEcon.\n\nan episode of “hyperinflation” with rapidly rising log price level and very high monthly inflation rates\n\na sudden stop of the hyperinflation as indicated by the abrupt flattening of the log price level and a marked permanent drop in the three-month average of inflation\n\na US dollar exchange rate that shadows the price level.\n\nWe’ll see similar patterns in the next three episodes that we’ll study now.","type":"content","url":"/inflation-history#austria","position":7},{"hierarchy":{"lvl1":"Price Level Histories","lvl3":"Hungary","lvl2":"Four big inflations"},"type":"lvl3","url":"/inflation-history#hungary","position":8},{"hierarchy":{"lvl1":"Price Level Histories","lvl3":"Hungary","lvl2":"Four big inflations"},"content":"The source of our data for Hungary is:\n\nTable 3.10, price level \\exp p and exchange rate\n\np_seq = df_hun['Hungarian index of prices']\ne_seq = 1 / df_hun['Cents per crown in New York']\n\nlab = ['Hungarian index of prices', \n       'Hungarian Koronas (Crowns) per US cent']\n\n# Create plot\nfig, ax = plt.subplots(dpi=200)\n_ = pe_plot(p_seq, e_seq, df_hun.index, lab, ax)\n\nplt.show()\n\n\n\nFigure 5:Price index and exchange rate (Hungary)\n\n# Plot moving average\nfig, ax = plt.subplots(dpi=200)\n_ = pr_plot(p_seq, df_hun.index, ax)\n\nplt.show()\n\n\n\nFigure 6:Monthly inflation rate (Hungary)","type":"content","url":"/inflation-history#hungary","position":9},{"hierarchy":{"lvl1":"Price Level Histories","lvl3":"Poland","lvl2":"Four big inflations"},"type":"lvl3","url":"/inflation-history#poland","position":10},{"hierarchy":{"lvl1":"Price Level Histories","lvl3":"Poland","lvl2":"Four big inflations"},"content":"The sources of our data for Poland are:\n\nTable 3.15, price level \\exp p\n\nTable 3.15, exchange rate\n\nNote\n\nTo construct the price level series from the data in the spreadsheet, we instructed Pandas to follow the same procedures implemented in chapter 3 of \n\nSargent (2013). We spliced together three series - Wholesale price index, Wholesale Price Index: On paper currency basis, and Wholesale Price Index: On zloty basis. We adjusted the sequence based on the price level ratio at the last period of the available previous series and glued them  to construct a single series.\nWe dropped the exchange rate after June 1924, when the zloty was adopted. We did this because we don’t have the price measured in zloty. We used the old currency in June to compute the exchange rate adjustment.\n\n# Splice three price series in different units\np_seq1 = df_pol['Wholesale price index'].copy()\np_seq2 = df_pol['Wholesale Price Index: '\n                'On paper currency basis'].copy()\np_seq3 = df_pol['Wholesale Price Index: ' \n                'On zloty basis'].copy()\n\n# Non-nan part\nmask_1 = p_seq1[~p_seq1.isna()].index[-1]\nmask_2 = p_seq2[~p_seq2.isna()].index[-2]\n\nadj_ratio12 = (p_seq1[mask_1] / p_seq2[mask_1])\nadj_ratio23 = (p_seq2[mask_2] / p_seq3[mask_2])\n\n# Glue three series\np_seq = pd.concat([p_seq1[:mask_1], \n                   adj_ratio12 * p_seq2[mask_1:mask_2], \n                   adj_ratio23 * p_seq3[mask_2:]])\np_seq = p_seq[~p_seq.index.duplicated(keep='first')]\n\n# Exchange rate\ne_seq = 1/df_pol['Cents per Polish mark (zloty after May 1924)']\ne_seq[e_seq.index > '05-01-1924'] = np.nan\n\n\n\nFigure 7:Price index and exchange rate (Poland)\n\nlab = ['Wholesale price index', \n       'Polish marks per US cent']\n\n# Create plot\nfig, ax = plt.subplots(dpi=200)\nax1 = pe_plot(p_seq, e_seq, df_pol.index, lab, ax)\n\nplt.show()\n\n# Plot moving average\nfig, ax = plt.subplots(dpi=200)\n_ = pr_plot(p_seq, df_pol.index, ax)\n\nplt.show()\n\n\n\nFigure 8:Monthly inflation rate (Poland)","type":"content","url":"/inflation-history#poland","position":11},{"hierarchy":{"lvl1":"Price Level Histories","lvl3":"Germany","lvl2":"Four big inflations"},"type":"lvl3","url":"/inflation-history#germany","position":12},{"hierarchy":{"lvl1":"Price Level Histories","lvl3":"Germany","lvl2":"Four big inflations"},"content":"The sources of our data for Germany are the following tables from chapter 3 of \n\nSargent (2013):\n\nTable 3.18, wholesale price level \\exp p\n\nTable 3.19, exchange rate\n\np_seq = df_deu['Price index (on basis of marks before July 1924,'\n                '  reichsmarks after)'].copy()\ne_seq = 1/df_deu['Cents per mark']\n\nlab = ['Price index', \n       'Marks per US cent']\n\n# Create plot\nfig, ax = plt.subplots(dpi=200)\nax1 = pe_plot(p_seq, e_seq, df_deu.index, lab, ax)\n\nplt.show()\n\n\n\nFigure 9:Price index and exchange rate (Germany)\n\np_seq = df_deu['Price index (on basis of marks before July 1924,'\n                '  reichsmarks after)'].copy()\ne_seq = 1/df_deu['Cents per mark'].copy()\n\n# Adjust the price level/exchange rate after the currency reform\np_seq[p_seq.index > '06-01-1924'] = p_seq[p_seq.index \n                                          > '06-01-1924'] * 1e12\ne_seq[e_seq.index > '12-01-1923'] = e_seq[e_seq.index \n                                          > '12-01-1923'] * 1e12\n\nlab = ['Price index (marks or converted to marks)', \n       'Marks per US cent(or reichsmark converted to mark)']\n\n# Create plot\nfig, ax = plt.subplots(dpi=200)\nax1 = pe_plot(p_seq, e_seq, df_deu.index, lab, ax)\n\nplt.show()\n\n\n\nFigure 10:Price index (adjusted) and exchange rate (Germany)\n\n# Plot moving average\nfig, ax = plt.subplots(dpi=200)\n_ = pr_plot(p_seq, df_deu.index, ax)\n\nplt.show()\n\n\n\nFigure 11:Monthly inflation rate (Germany)","type":"content","url":"/inflation-history#germany","position":13},{"hierarchy":{"lvl1":"Price Level Histories","lvl2":"Starting and stopping big inflations"},"type":"lvl2","url":"/inflation-history#starting-and-stopping-big-inflations","position":14},{"hierarchy":{"lvl1":"Price Level Histories","lvl2":"Starting and stopping big inflations"},"content":"It is striking how quickly (log) price levels in Austria, Hungary, Poland, and Germany leveled off after rising so quickly.\n\nThese “sudden stops” are also revealed by the permanent drops in three-month moving averages of inflation for the four countries plotted above.\n\nIn addition, the US dollar exchange rates for each of the four countries shadowed their price levels.\n\nNote\n\nThis pattern is an instance of a force featured in the \n\npurchasing power parity theory of exchange rates.\n\nEach of these big inflations seemed to have “stopped on a dime”.\n\nChapter 3 of \n\nSargent & Velde (2002) offers an explanation for this remarkable pattern.\n\nIn a nutshell, here is the explanation offered there.\n\nAfter World War I, the United States was on a gold standard.\n\nThe US government stood ready to convert a dollar into a specified amount of gold on demand.\n\nImmediately after World War I, Hungary, Austria, Poland, and Germany were not on the gold standard.\n\nTheir currencies were “fiat” or “unbacked”, meaning that they were not backed by credible government promises to convert them into gold or silver coins on demand.\n\nThe governments printed new paper notes to pay for goods and services.\n\nNote\n\nTechnically the notes were “backed” mainly by treasury bills. But people could not expect that those treasury bills would be paid off by levying taxes, but instead by printing more notes or treasury bills.\n\nThis was done on such a scale that it led to a depreciation of the currencies of spectacular proportions.\n\nIn the end, the German mark stabilized at 1 trillion (\n\n1012) paper marks to the prewar gold mark, the Polish mark at 1.8 million paper marks to the gold zloty, the Austrian crown at 14,400 paper crowns to the prewar Austro-Hungarian crown, and the Hungarian krone at 14,500 paper crowns to the prewar Austro-Hungarian crown.\n\nChapter 3 of \n\nSargent & Velde (2002)  described deliberate changes in policy that Hungary, Austria, Poland, and Germany made to end their hyperinflations.\n\nEach government stopped printing money to pay for goods and services once again and made its currency convertible to the US dollar or the UK pound.\n\nThe story told in \n\nSargent & Velde (2002) is grounded in a monetarist theory of the price level described in \n\nA Monetarist Theory of Price Levels and \n\nMonetarist Theory of Price Levels with Adaptive Expectations.\n\nThose lectures discuss theories about what owners of those rapidly depreciating currencies were thinking and how their beliefs shaped responses of inflation to government monetary and fiscal policies.","type":"content","url":"/inflation-history#starting-and-stopping-big-inflations","position":15},{"hierarchy":{"lvl1":"A First Course in Quantitative Economics with Python"},"type":"lvl1","url":"/","position":0},{"hierarchy":{"lvl1":"A First Course in Quantitative Economics with Python"},"content":"This lecture series provides an introduction to quantitative economics using Python.\n\nA First Course in Quantitative Economics with Python - WASM\n\nEconomic Data\n\n1 Long-Run Growth\n\n2 Price Level Histories\n\n3 Inflation During French Revolution\n\nFoundations\n\n4 Introduction to Supply and Demand\n\n5 Linear Equations and Matrix Algebra\n\n6 Complex Numbers and Trigonometry\n\n7 Geometric Series for Elementary Economics\n\nLinear Dynamics: Finite Horizons\n\n8 Present Values\n\n9 Consumption Smoothing\n\n10 Tax Smoothing\n\n11 Equalizing Difference Model\n\n12 A Monetarist Theory of Price Levels\n\n13 Monetarist Theory of Price Levels with Adaptive Expectations\n\nLinear Dynamics: Infinite Horizons\n\n14 Eigenvalues and Eigenvectors\n\n15 Computing Square Roots\n\nProbability and Distributions\n\n16 LLN and CLT\n\n17 Monte Carlo and Option Pricing\n\n18 Racial Segregation\n\nNonlinear Dynamics\n\n19 Dynamics in One Dimension\n\n20 The Solow-Swan Growth Model\n\n21 The Cobweb Model\n\n22 The Overlapping Generations Model\n\nMonetary-Fiscal Policy Interactions\n\n23 Money Financed Government Deficits and Price Levels\n\n24 Some Unpleasant Monetarist Arithmetic\n\n25 Inflation Rate Laffer Curves\n\n26 Laffer Curves  with Adaptive Expectations\n\nStochastic Dynamics\n\n27 AR(1) Processes\n\n28 Markov Chains: Basic Concepts\n\n29 Markov Chains: Irreducibility and Ergodicity\n\n30 Univariate Time Series with Matrix Algebra\n\nOptimization\n\nShortest Paths\n\nModeling in Higher Dimensions\n\n32 The Perron-Frobenius Theorem\n\n33 A Lake Model of Employment\n\n34 Networks\n\nMarkets and Competitive Equilibrium\n\n35 Supply and Demand with Many Goods\n\n36 Market Equilibrium with Heterogeneity\n\nEstimation\n\n37 Simple Linear Regression Model\n\n38 Maximum Likelihood Estimation\n\nOther\n\n39 Troubleshooting\n\n40 References\n\n41 Execution Statistics","type":"content","url":"/","position":1},{"hierarchy":{"lvl1":"Introduction to Supply and Demand"},"type":"lvl1","url":"/intro-supply-demand","position":0},{"hierarchy":{"lvl1":"Introduction to Supply and Demand"},"content":"","type":"content","url":"/intro-supply-demand","position":1},{"hierarchy":{"lvl1":"Introduction to Supply and Demand","lvl2":"Overview"},"type":"lvl2","url":"/intro-supply-demand#overview","position":2},{"hierarchy":{"lvl1":"Introduction to Supply and Demand","lvl2":"Overview"},"content":"This lecture is about some models of equilibrium prices and quantities, one of\nthe core topics of elementary microeconomics.\n\nThroughout the lecture, we focus on models with one good and one price.\n\nSee Also\n\nIn a \n\nsubsequent lecture we will investigate settings with\nmany goods.","type":"content","url":"/intro-supply-demand#overview","position":3},{"hierarchy":{"lvl1":"Introduction to Supply and Demand","lvl3":"Why does this model matter?","lvl2":"Overview"},"type":"lvl3","url":"/intro-supply-demand#why-does-this-model-matter","position":4},{"hierarchy":{"lvl1":"Introduction to Supply and Demand","lvl3":"Why does this model matter?","lvl2":"Overview"},"content":"In the 15th, 16th, 17th and 18th centuries, mercantilist ideas held sway among most rulers of European countries.\n\nExports were regarded as good because they brought in bullion (gold flowed into the country).\n\nImports were regarded as bad because bullion was required to pay for them (gold flowed out).\n\nThis \n\nzero-sum view of economics was eventually overturned by the work of the classical economists such as \n\nAdam Smith and \n\nDavid Ricardo, who showed how freeing domestic and international trade can enhance welfare.\n\nThere are many different expressions of this idea in economics.\n\nThis lecture discusses one of the simplest: how free adjustment of prices can maximize a measure of social welfare in the market for a single good.","type":"content","url":"/intro-supply-demand#why-does-this-model-matter","position":5},{"hierarchy":{"lvl1":"Introduction to Supply and Demand","lvl3":"Topics and infrastructure","lvl2":"Overview"},"type":"lvl3","url":"/intro-supply-demand#topics-and-infrastructure","position":6},{"hierarchy":{"lvl1":"Introduction to Supply and Demand","lvl3":"Topics and infrastructure","lvl2":"Overview"},"content":"Key infrastructure concepts that we will encounter in this lecture are:\n\ninverse demand curves\n\ninverse supply curves\n\nconsumer surplus\n\nproducer surplus\n\nintegration\n\nsocial welfare as the sum of consumer and producer surpluses\n\nthe relationship between  equilibrium quantity and social welfare optimum\n\nIn our exposition we will use the following Python imports.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom collections import namedtuple\n\n","type":"content","url":"/intro-supply-demand#topics-and-infrastructure","position":7},{"hierarchy":{"lvl1":"Introduction to Supply and Demand","lvl2":"Consumer surplus"},"type":"lvl2","url":"/intro-supply-demand#consumer-surplus","position":8},{"hierarchy":{"lvl1":"Introduction to Supply and Demand","lvl2":"Consumer surplus"},"content":"Before we look at the model of supply and demand, it will be helpful to have some background on (a) consumer and producer surpluses and (b) integration.\n\n(If you are comfortable with both topics you can jump to the \n\nnext section.)","type":"content","url":"/intro-supply-demand#consumer-surplus","position":9},{"hierarchy":{"lvl1":"Introduction to Supply and Demand","lvl3":"A discrete example","lvl2":"Consumer surplus"},"type":"lvl3","url":"/intro-supply-demand#a-discrete-example","position":10},{"hierarchy":{"lvl1":"Introduction to Supply and Demand","lvl3":"A discrete example","lvl2":"Consumer surplus"},"content":"Regarding consumer surplus, suppose that we have a single good and 10 consumers.\n\nThese 10 consumers have different preferences; in particular, the amount they would be willing to pay for one unit of the good differs.\n\nSuppose that the willingness to pay for each of the 10 consumers is as follows:\n\nconsumer\n\n1\n\n2\n\n3\n\n4\n\n5\n\n6\n\n7\n\n8\n\n9\n\n10\n\nwilling to pay\n\n98\n\n72\n\n41\n\n38\n\n29\n\n21\n\n17\n\n12\n\n11\n\n10\n\n(We have ordered consumers by willingness to pay, in descending order.)\n\nIf p is the price of the good and  w_i is the amount that consumer i is willing to pay, then i buys when w_i \\geq p.\n\nNote\n\nIf p=w_i the consumer is indifferent between buying and not buying; we arbitrarily assume that they buy.\n\nThe consumer surplus of the i-th consumer is \\max\\{w_i - p, 0\\}\n\nif w_i \\geq p, then the consumer buys and gets surplus w_i - p\n\nif w_i < p, then the consumer does not buy and gets surplus 0\n\nFor example, if the price is p=40, then consumer 1 gets surplus 98-40=58.\n\nThe bar graph below shows the surplus of each consumer when p=25.\n\nThe total height of each bar i is willingness to pay by consumer i.\n\nThe orange portion of some of the bars shows consumer surplus.\n\nfig, ax = plt.subplots()\nconsumers = range(1, 11) # consumers 1,..., 10\n# willingness to pay for each consumer\nwtp = (98, 72, 41, 38, 29, 21, 17, 12, 11, 10)\nprice = 25\nax.bar(consumers, wtp, label=\"consumer surplus\", color=\"darkorange\", alpha=0.8)\nax.plot((0, 12), (price, price), lw=2, label=\"price $p$\")\nax.bar(consumers, [min(w, price) for w in wtp], color=\"black\", alpha=0.6)\nax.set_xlim(0, 12)\nax.set_xticks(consumers)\nax.set_ylabel(\"willingness to pay, price\")\nax.set_xlabel(\"consumer, quantity\")\nax.legend()\nplt.show()\n\n\n\nFigure 1:Willingness to pay (discrete)\n\nThe total consumer surplus in this market is\\sum_{i=1}^{10} \\max\\{w_i - p, 0\\}\n= \\sum_{w_i \\geq p} (w_i - p)\n\nSince consumer surplus \\max\\{w_i-p,0\\} of consumer i is a measure of her gains from trade (i.e., extent to which the good is valued over and above the amount the consumer had to pay), it is reasonable to consider total consumer surplus as a measurement of consumer welfare.\n\nLater we will pursue this idea further, considering how different prices lead to different welfare outcomes for consumers and producers.","type":"content","url":"/intro-supply-demand#a-discrete-example","position":11},{"hierarchy":{"lvl1":"Introduction to Supply and Demand","lvl3":"A comment on quantity.","lvl2":"Consumer surplus"},"type":"lvl3","url":"/intro-supply-demand#a-comment-on-quantity","position":12},{"hierarchy":{"lvl1":"Introduction to Supply and Demand","lvl3":"A comment on quantity.","lvl2":"Consumer surplus"},"content":"Notice that in the figure, the horizontal axis is labeled “consumer, quantity”.\n\nWe have added “quantity” here because we can read the number of units sold from this axis, assuming for now that there are sellers who are willing to sell as many units as the consumers demand, given the current market price p.\n\nIn this example, consumers 1 to 5 buy, and the quantity sold is 5.\n\nBelow we drop the assumption that sellers will provide any amount at a given price and study how this changes outcomes.","type":"content","url":"/intro-supply-demand#a-comment-on-quantity","position":13},{"hierarchy":{"lvl1":"Introduction to Supply and Demand","lvl3":"A continuous approximation","lvl2":"Consumer surplus"},"type":"lvl3","url":"/intro-supply-demand#a-continuous-approximation","position":14},{"hierarchy":{"lvl1":"Introduction to Supply and Demand","lvl3":"A continuous approximation","lvl2":"Consumer surplus"},"content":"It is often convenient to assume that there is a “very large number” of consumers, so that willingness to pay becomes a continuous curve.\n\nAs before, the vertical axis measures willingness to pay, while the horizontal axis measures quantity.\n\nThis kind of curve is called an inverse demand curve\n\nAn example is provided below, showing both an inverse demand curve and a set price.\n\nThe inverse demand curve is given byp = 100 e^{-q}\n\ndef inverse_demand(q):\n    return 100 * np.exp(- q)\n\n# build a grid to evaluate the function at different values of q\nq_min, q_max = 0, 5\nq_grid = np.linspace(q_min, q_max, 1000)\n\n# plot the inverse demand curve\nfig, ax = plt.subplots()\nax.plot((q_min, q_max), (price, price), lw=2, label=\"price\")\nax.plot(q_grid, inverse_demand(q_grid), \n        color=\"orange\", label=\"inverse demand curve\")\nax.set_ylabel(\"willingness to pay, price\")\nax.set_xlabel(\"quantity\")\nax.set_xlim(q_min, q_max)\nax.set_ylim(0, 110)\nax.legend()\nplt.show()\n\n\n\nFigure 2:Willingness to pay (continuous)\n\nReasoning by analogy with the discrete case, the area under the demand curve and above the price is called the consumer surplus, and is a measure of total gains from trade on the part of consumers.\n\nThe consumer surplus is shaded in the figure below.\n\n# solve for the value of q where demand meets price\nq_star = np.log(100) - np.log(price)\n\nfig, ax = plt.subplots()\nax.plot((q_min, q_max), (price, price), lw=2, label=\"price\")\nax.plot(q_grid, inverse_demand(q_grid), \n        color=\"orange\", label=\"inverse demand curve\")\nsmall_grid = np.linspace(0, q_star, 500)\nax.fill_between(small_grid, np.full(len(small_grid), price),\n                inverse_demand(small_grid), color=\"orange\",\n                alpha=0.5, label=\"consumer surplus\")\nax.vlines(q_star, 0, price, ls=\"--\")\nax.set_ylabel(\"willingness to pay, price\")\nax.set_xlabel(\"quantity\")\nax.set_xlim(q_min, q_max)\nax.set_ylim(0, 110)\nax.text(q_star, -10, \"$q^*$\")\nax.legend()\nplt.show()\n\n\n\nFigure 3:Willingness to pay (continuous) with consumer surplus\n\nThe value q^* is where the inverse demand curve meets price.","type":"content","url":"/intro-supply-demand#a-continuous-approximation","position":15},{"hierarchy":{"lvl1":"Introduction to Supply and Demand","lvl2":"Producer surplus"},"type":"lvl2","url":"/intro-supply-demand#producer-surplus","position":16},{"hierarchy":{"lvl1":"Introduction to Supply and Demand","lvl2":"Producer surplus"},"content":"Having discussed demand, let’s now switch over to the supply side of the market.","type":"content","url":"/intro-supply-demand#producer-surplus","position":17},{"hierarchy":{"lvl1":"Introduction to Supply and Demand","lvl3":"The discrete case","lvl2":"Producer surplus"},"type":"lvl3","url":"/intro-supply-demand#the-discrete-case","position":18},{"hierarchy":{"lvl1":"Introduction to Supply and Demand","lvl3":"The discrete case","lvl2":"Producer surplus"},"content":"The figure below shows the price at which a collection of producers, also numbered 1 to 10, are willing to sell one unit of the good in question\n\nfig, ax = plt.subplots()\nproducers = range(1, 11) # producers 1,..., 10\n# willingness to sell for each producer\nwts = (5, 8, 17, 22, 35, 39, 46, 57, 88, 91)\nprice = 25\nax.bar(producers, wts, label=\"willingness to sell\", color=\"green\", alpha=0.5)\nax.set_xlim(0, 12)\nax.set_xticks(producers)\nax.set_ylabel(\"willingness to sell\")\nax.set_xlabel(\"producer\")\nax.legend()\nplt.show()\n\n\n\nFigure 4:Willingness to sell (discrete)\n\nLet v_i be the price at which producer i is willing to sell the good.\n\nWhen the price is p, producer surplus for producer i is \\max\\{p - v_i, 0\\}.\n\nFor example, a producer willing to sell at $10 and selling at price $20 makes a surplus of $10.\n\nTotal producer surplus is given by\\sum_{i=1}^{10} \\max\\{p - v_i, 0\\}\n= \\sum_{p \\geq v_i} (p - v_i)\n\nAs for the consumer case, it can be helpful for analysis if we approximate producer willingness to sell into a continuous curve.\n\nThis curve is called the inverse supply curve\n\nWe show an example below where the inverse supply curve isp = 2 q^2\n\nThe shaded area is the total producer surplus in this continuous model.\n\ndef inverse_supply(q):\n    return 2 * q**2\n\n# solve for the value of q where supply meets price\nq_star = (price / 2)**(1/2)\n\n# plot the inverse supply curve\nfig, ax = plt.subplots()\nax.plot((q_min, q_max), (price, price), lw=2, label=\"price\")\nax.plot(q_grid, inverse_supply(q_grid), \n        color=\"green\", label=\"inverse supply curve\")\nsmall_grid = np.linspace(0, q_star, 500)\nax.fill_between(small_grid, inverse_supply(small_grid), \n                np.full(len(small_grid), price), \n                color=\"green\",\n                alpha=0.5, label=\"producer surplus\")\nax.vlines(q_star, 0, price, ls=\"--\")\nax.set_ylabel(\"willingness to sell, price\")\nax.set_xlabel(\"quantity\")\nax.set_xlim(q_min, q_max)\nax.set_ylim(0, 60)\nax.text(q_star, -10, \"$q^*$\")\nax.legend()\nplt.show()\n\n\n\nFigure 5:Willingness to sell (continuous) with producer surplus","type":"content","url":"/intro-supply-demand#the-discrete-case","position":19},{"hierarchy":{"lvl1":"Introduction to Supply and Demand","lvl2":"Integration"},"type":"lvl2","url":"/intro-supply-demand#integration","position":20},{"hierarchy":{"lvl1":"Introduction to Supply and Demand","lvl2":"Integration"},"content":"How can we calculate the consumer and producer surplus in the continuous case?\n\nThe short answer is: by using \n\nintegration.\n\nSome readers will already be familiar with the basics of integration.\n\nFor those who are not, here is a quick introduction.\n\nIn general, for a function f, the integral of f over the interval [a, b] is the area under the curve f between a and b.\n\nThis value is written as \\int_a^b f(x) \\mathrm{d} x and illustrated in the figure below when f(x) = \\cos(x/2) + 1.\n\ndef f(x):\n    return np.cos(x/2) + 1\n\nxmin, xmax = 0, 5\na, b = 1, 3\nx_grid = np.linspace(xmin, xmax, 1000)\nab_grid = np.linspace(a, b, 400)\n\nfig, ax = plt.subplots()\nax.plot(x_grid, f(x_grid), label=\"$f$\", color=\"k\")\nax.fill_between(ab_grid, [0] * len(ab_grid), f(ab_grid), \n                label=r\"$\\int_a^b f(x) dx$\")\nax.legend()\nplt.show()\n\n\n\nFigure 6:Area under the curve\n\nThere are many rules for calculating integrals, with different rules applying to different choices of f.\n\nMany of these rules relate to one of the most beautiful and powerful results in all of mathematics: the \n\nfundamental theorem of calculus.\n\nWe will not try to cover these ideas here, partly because the subject is too big, and partly because you only need to know one rule for this lecture, stated below.\n\nIf f(x) = c + dx, then\\int_a^b f(x) \\mathrm{d} x = c (b - a) + \\frac{d}{2}(b^2 - a^2)\n\nIn fact this rule is so simple that it can be calculated from elementary geometry -- you might like to try by graphing f and calculating the area under the curve between a and b.\n\nWe use this rule repeatedly in what follows.","type":"content","url":"/intro-supply-demand#integration","position":21},{"hierarchy":{"lvl1":"Introduction to Supply and Demand","lvl2":"Supply and demand"},"type":"lvl2","url":"/intro-supply-demand#supply-and-demand","position":22},{"hierarchy":{"lvl1":"Introduction to Supply and Demand","lvl2":"Supply and demand"},"content":"Let’s now put supply and demand together.\n\nThis leads us to the all important notion of market equilibrium, and from there onto a discussion of equilibria and welfare.\n\nFor most of this discussion, we’ll assume that inverse demand and supply curves are affine functions of quantity.\n\nNote\n\n“Affine” means “linear plus a constant” and \n\nhere is a nice discussion about it.\n\nWe’ll also assume affine inverse supply and demand functions when we study models with multiple consumption goods in our \n\nsubsequent lecture.\n\nWe do this in order to simplify the exposition and enable us to use just a few tools from linear algebra, namely, matrix multiplication and matrix inversion.\n\nWe study a market for a single good in which buyers and sellers exchange a quantity q for a price p.\n\nQuantity q and price p are  both scalars.\n\nWe assume that inverse demand and supply curves for the good are:p = d_0 - d_1 q, \\quad d_0, d_1 > 0p = s_0 + s_1 q , \\quad s_0, s_1 > 0\n\nWe call them inverse demand and supply curves because price is on the left side of the equation rather than on the right side as it would be in a direct demand or supply function.\n\nWe can use a \n\nnamedtuple to store the parameters for our single good market.\n\nMarket = namedtuple('Market', ['d_0', # demand intercept\n                               'd_1', # demand slope\n                               's_0', # supply intercept\n                               's_1'] # supply slope\n                   )\n\nThe function below creates an instance of a Market namedtuple with default values.\n\ndef create_market(d_0=1.0, d_1=0.6, s_0=0.1, s_1=0.4):\n    return Market(d_0=d_0, d_1=d_1, s_0=s_0, s_1=s_1)\n\nThis market can then be used by our inverse_demand and inverse_supply functions.\n\ndef inverse_demand(q, model):\n    return model.d_0 - model.d_1 * q\n\ndef inverse_supply(q, model):\n    return model.s_0 + model.s_1 * q\n\nHere is a plot of these two functions using market.\n\nmarket = create_market()\n\ngrid_min, grid_max, grid_size = 0, 1.5, 200\nq_grid = np.linspace(grid_min, grid_max, grid_size)\nsupply_curve = inverse_supply(q_grid, market)\ndemand_curve = inverse_demand(q_grid, market)\n\nfig, ax = plt.subplots()\nax.plot(q_grid, supply_curve, label='supply', color='green')\nax.plot(q_grid, demand_curve, label='demand', color='orange')\nax.legend(loc='upper center', frameon=False)\nax.set_ylim(0, 1.2)\nax.set_xticks((0, 1))\nax.set_yticks((0, 1))\nax.set_xlabel('quantity')\nax.set_ylabel('price')\nplt.show()\n\n\n\nFigure 7:Supply and demand\n\nIn the above graph, an equilibrium price-quantity pair occurs at the intersection of the supply and demand curves.","type":"content","url":"/intro-supply-demand#supply-and-demand","position":23},{"hierarchy":{"lvl1":"Introduction to Supply and Demand","lvl3":"Consumer surplus","lvl2":"Supply and demand"},"type":"lvl3","url":"/intro-supply-demand#consumer-surplus-1","position":24},{"hierarchy":{"lvl1":"Introduction to Supply and Demand","lvl3":"Consumer surplus","lvl2":"Supply and demand"},"content":"Let a quantity q be given and let p := d_0 - d_1 q be the\ncorresponding price on the inverse demand curve.\n\nWe define consumer surplus S_c(q) as the area under an inverse demand\ncurve minus p q:S_c(q) := \n\\int_0^{q} (d_0 - d_1 x) \\mathrm{d} x - p q\n\nThe next figure illustrates\n\nq = 1.25\np = inverse_demand(q, market)\nps = np.ones_like(q_grid) * p\n\nfig, ax = plt.subplots()\nax.plot(q_grid, demand_curve, label='demand', color='orange')\nax.fill_between(q_grid[q_grid <= q],\n                demand_curve[q_grid <= q],\n                ps[q_grid <= q],\n                label='consumer surplus',\n                color=\"orange\", \n                alpha=0.5)\nax.vlines(q, 0, p, linestyle=\"dashed\", color='black', alpha=0.7)\nax.hlines(p, 0, q, linestyle=\"dashed\", color='black', alpha=0.7)\n\nax.legend(loc='upper center', frameon=False)\nax.set_ylim(0, 1.2)\nax.set_xticks((q,))\nax.set_xticklabels((\"$q$\",))\nax.set_yticks((p,))\nax.set_yticklabels((\"$p$\",))\nax.set_xlabel('quantity')\nax.set_ylabel('price')\nplt.show()\n\n\n\nFigure 8:Supply and demand (consumer surplus)\n\nConsumer surplus provides a measure of total consumer welfare at quantity q.\n\nThe idea is that the inverse demand curve d_0 - d_1 q shows a consumer’s willingness to\npay for an additional increment of the good at a given quantity q.\n\nThe difference between willingness to pay and the actual price is consumer surplus.\n\nThe value S_c(q) is the “sum” (i.e., integral) of these surpluses when the total\nquantity purchased is q and the purchase price is p.\n\nEvaluating the integral in the definition of consumer surplus \n\n(8) givesS_c(q) \n= d_0 q - \\frac{1}{2} d_1 q^2 - p q","type":"content","url":"/intro-supply-demand#consumer-surplus-1","position":25},{"hierarchy":{"lvl1":"Introduction to Supply and Demand","lvl3":"Producer surplus","lvl2":"Supply and demand"},"type":"lvl3","url":"/intro-supply-demand#producer-surplus-1","position":26},{"hierarchy":{"lvl1":"Introduction to Supply and Demand","lvl3":"Producer surplus","lvl2":"Supply and demand"},"content":"Let a quantity q be given and let p := s_0 + s_1 q be the\ncorresponding price on the inverse supply curve.\n\nWe define producer surplus as p q minus the area under an inverse supply curveS_p(q) \n:= p q - \\int_0^q (s_0 + s_1 x) \\mathrm{d} x\n\nThe next figure illustrates\n\nq = 0.75\np = inverse_supply(q, market)\nps = np.ones_like(q_grid) * p\n\nfig, ax = plt.subplots()\nax.plot(q_grid, supply_curve, label='supply', color='green')\nax.fill_between(q_grid[q_grid <= q],\n                supply_curve[q_grid <= q],\n                ps[q_grid <= q],\n                label='producer surplus',\n                color=\"green\",\n                alpha=0.5)\nax.vlines(q, 0, p, linestyle=\"dashed\", color='black', alpha=0.7)\nax.hlines(p, 0, q, linestyle=\"dashed\", color='black', alpha=0.7)\n\nax.legend(loc='upper center', frameon=False)\nax.set_ylim(0, 1.2)\nax.set_xticks((q,))\nax.set_xticklabels((\"$q$\",))\nax.set_yticks((p,))\nax.set_yticklabels((\"$p$\",))\nax.set_xlabel('quantity')\nax.set_ylabel('price')\nplt.show()\n\n\n\nFigure 9:Supply and demand (producer surplus)\n\nProducer surplus measures total producer welfare at quantity q\n\nThe idea is similar to that of consumer surplus.\n\nThe inverse supply curve s_0 + s_1 q shows the price at which producers are\nprepared to sell, given quantity q.\n\nThe difference between willingness to sell and the actual price is producer surplus.\n\nThe value S_p(q) is the integral of these surpluses.\n\nEvaluating the integral in the definition of producer surplus \n\n(10) givesS_p(q) = pq - s_0 q -  \\frac{1}{2} s_1 q^2","type":"content","url":"/intro-supply-demand#producer-surplus-1","position":27},{"hierarchy":{"lvl1":"Introduction to Supply and Demand","lvl3":"Social welfare","lvl2":"Supply and demand"},"type":"lvl3","url":"/intro-supply-demand#social-welfare","position":28},{"hierarchy":{"lvl1":"Introduction to Supply and Demand","lvl3":"Social welfare","lvl2":"Supply and demand"},"content":"Sometimes economists measure social welfare by a welfare criterion that\nequals consumer surplus plus producer surplus, assuming that consumers and\nproducers pay the same price:W(q)\n= \\int_0^q (d_0 - d_1 x) dx - \\int_0^q (s_0 + s_1 x) \\mathrm{d} x\n\nEvaluating the integrals givesW(q) = (d_0 - s_0) q -  \\frac{1}{2} (d_1 + s_1) q^2\n\nHere is a Python function that evaluates this social welfare at a given\nquantity q and a fixed set of parameters.\n\ndef W(q, market):\n    # Compute and return welfare\n    return (market.d_0 - market.s_0) * q - 0.5 * (market.d_1 + market.s_1) * q**2\n\nThe next figure plots welfare as a function of q.\n\nq_vals = np.linspace(0, 1.78, 200)\nfig, ax = plt.subplots()\nax.plot(q_vals, W(q_vals, market), label='welfare', color='brown')\nax.legend(frameon=False)\nax.set_xlabel('quantity')\nplt.show()\n\n\n\nFigure 10:Welfare\n\nLet’s now give a social planner the task of maximizing social welfare.\n\nTo compute a quantity that  maximizes the welfare criterion, we differentiate\nW with respect to q and then set the derivative to zero.\\frac{\\mathrm{d} W(q)}{\\mathrm{d} q} = d_0 - s_0 - (d_1 + s_1) q  = 0\n\nSolving for q yieldsq = \\frac{ d_0 - s_0}{s_1 + d_1}\n\nLet’s remember the quantity q given by equation \n\n(15) that a social planner would choose to maximize consumer surplus plus producer surplus.\n\nWe’ll compare it to the quantity that emerges in a competitive equilibrium that equates supply to demand.","type":"content","url":"/intro-supply-demand#social-welfare","position":29},{"hierarchy":{"lvl1":"Introduction to Supply and Demand","lvl3":"Competitive equilibrium","lvl2":"Supply and demand"},"type":"lvl3","url":"/intro-supply-demand#competitive-equilibrium","position":30},{"hierarchy":{"lvl1":"Introduction to Supply and Demand","lvl3":"Competitive equilibrium","lvl2":"Supply and demand"},"content":"Instead of equating quantities supplied and demanded, we can accomplish the\nsame thing by equating demand price to supply price:p =  d_0 - d_1 q = s_0 + s_1 q\n\nIf we solve the equation defined by the second equality in the above line for\nq, we obtainq = \\frac{ d_0 - s_0}{s_1 + d_1}\n\nThis is the competitive equilibrium quantity.\n\nObserve that the equilibrium quantity equals the same q given by equation  \n\n(15).\n\nThe outcome that the quantity determined by equation \n\n(15) equates\nsupply to demand brings us a key finding:\n\na competitive equilibrium quantity maximizes our welfare criterion\n\nThis is a version of the \n\nfirst fundamental welfare theorem,\n\nIt also brings a useful competitive equilibrium computation strategy:\n\nafter solving the welfare problem for an optimal quantity, we can read a competitive equilibrium price from either supply price or demand price at the competitive equilibrium quantity","type":"content","url":"/intro-supply-demand#competitive-equilibrium","position":31},{"hierarchy":{"lvl1":"Introduction to Supply and Demand","lvl2":"Generalizations"},"type":"lvl2","url":"/intro-supply-demand#generalizations","position":32},{"hierarchy":{"lvl1":"Introduction to Supply and Demand","lvl2":"Generalizations"},"content":"In a \n\nlater lecture, we’ll derive\ngeneralizations of the above demand and supply curves from other objects.\n\nOur generalizations will extend the preceding analysis of a market for a single good to the analysis of n simultaneous markets in n goods.\n\nIn addition\n\nwe’ll derive  demand curves from a consumer problem that maximizes a\nutility function subject to a budget constraint.\n\nwe’ll derive  supply curves from the problem of a producer who is price\ntaker and maximizes his profits minus total costs that are described by a cost function.","type":"content","url":"/intro-supply-demand#generalizations","position":33},{"hierarchy":{"lvl1":"Introduction to Supply and Demand","lvl2":"Exercises"},"type":"lvl2","url":"/intro-supply-demand#exercises","position":34},{"hierarchy":{"lvl1":"Introduction to Supply and Demand","lvl2":"Exercises"},"content":"Suppose now that the inverse demand and supply curves are modified to take the\nformp = i_d(q) := d_0 - d_1 q^{0.6}p = i_s(q) := s_0 + s_1 q^{1.8}\n\nAll parameters are positive, as before.\n\nUse the same Market namedtuple that holds the parameter values as before but\nmake new inverse_demand and inverse_supply functions to match these new definitions.\n\nThen plot the inverse demand and supply curves i_d and i_s.\n\nSolution to \n\nExercise 1\n\nLet’s update the inverse_demand and inverse_supply functions, as defined above.\n\ndef inverse_demand(q, model):\n    return model.d_0 - model.d_1 * q**0.6\n\ndef inverse_supply(q, model):\n    return model.s_0 + model.s_1 * q**1.8\n\nHere is a plot of inverse supply and demand.\n\ngrid_min, grid_max, grid_size = 0, 1.5, 200\nq_grid = np.linspace(grid_min, grid_max, grid_size)\nmarket = create_market()\nsupply_curve = inverse_supply(q_grid, market)\ndemand_curve = inverse_demand(q_grid, market)\n\nfig, ax = plt.subplots()\nax.plot(q_grid, supply_curve, label='supply', color='green')\nax.plot(q_grid, demand_curve, label='demand', color='orange')\nax.legend(loc='upper center', frameon=False)\nax.set_ylim(0, 1.2)\nax.set_xticks((0, 1))\nax.set_yticks((0, 1))\nax.set_xlabel('quantity')\nax.set_ylabel('price')\nplt.show()\n\n\n\nAs before, consumer surplus at q is the area under the demand curve minus\nprice times quantity:S_c(q) = \\int_0^{q} i_d(x) dx - p q\n\nHere p is set to i_d(q)\n\nProducer surplus is price times quantity minus the area under the inverse\nsupply curve:S_p(q) \n= p q - \\int_0^q i_s(x) \\mathrm{d} x\n\nHere p is set to i_s(q).\n\nSocial welfare is the sum of consumer and producer surplus under the\nassumption that the price is the same for buyers and sellers:W(q)\n= \\int_0^q i_d(x) dx - \\int_0^q i_s(x) \\mathrm{d} x\n\nSolve the integrals and write a function to compute this quantity numerically\nat given q.\n\nPlot welfare as a function of q.\n\nSolution to \n\nExercise 2\n\nSolving the integrals givesW(q) \n= d_0 q - \\frac{d_1 q^{1.6}}{1.6}\n    - \\left( s_0 q + \\frac{s_1 q^{2.8}}{2.8} \\right)\n\nHere’s a Python function that computes this value:\n\ndef W(q, market):\n    # Compute and return welfare\n    S_c = market.d_0 * q - market.d_1 * q**1.6 / 1.6\n    S_p = market.s_0 * q + market.s_1 * q**2.8 / 2.8\n    return S_c - S_p\n\nThe next figure plots welfare as a function of q.\n\nfig, ax = plt.subplots()\nax.plot(q_vals, W(q_vals, market), label='welfare', color='brown')\nax.legend(frameon=False)\nax.set_xlabel('quantity')\nplt.show()\n\n\n\nDue to non-linearities, the new welfare function is not easy to maximize with\npencil and paper.\n\nMaximize it using scipy.optimize.minimize_scalar instead.\n\nSee Also\n\nOur \n\nSciPy lecture has\na section on \n\nOptimization\nis a useful resource to find out more.\n\nSolution to \n\nExercise 3\n\nfrom scipy.optimize import minimize_scalar\n\ndef objective(q):\n    return -W(q, market)\n\nresult = minimize_scalar(objective, bounds=(0, 10))\nprint(result.message)\n\nmaximizing_q = result.x\nprint(f\"{maximizing_q: .5f}\")\n\n\n\nNow compute the equilibrium quantity by finding the price that equates supply\nand demand.\n\nYou can do this numerically by finding the root of the excess demand functione_d(q) := i_d(q) - i_s(q)\n\nYou can use scipy.optimize.newton to compute the root.\n\nSee Also\n\nOur \n\nSciPy lecture has\na section on \n\nRoots and Fixed Points\nis a useful resource to find out more.\n\nInitialize newton with a starting guess somewhere close to 1.0.\n\n(Similar initial conditions will give the same result.)\n\nYou should find that the equilibrium price agrees with the welfare maximizing\nprice, in line with the first fundamental welfare theorem.\n\nSolution to \n\nExercise 4\n\nfrom scipy.optimize import newton\n\ndef excess_demand(q):\n    return inverse_demand(q, market) - inverse_supply(q, market)\n\nequilibrium_q = newton(excess_demand, 0.99)\nprint(f\"{equilibrium_q: .5f}\")\n\n","type":"content","url":"/intro-supply-demand#exercises","position":35},{"hierarchy":{"lvl1":"Laffer Curves  with Adaptive Expectations"},"type":"lvl1","url":"/laffer-adaptive","position":0},{"hierarchy":{"lvl1":"Laffer Curves  with Adaptive Expectations"},"content":"","type":"content","url":"/laffer-adaptive","position":1},{"hierarchy":{"lvl1":"Laffer Curves  with Adaptive Expectations","lvl2":"Overview"},"type":"lvl2","url":"/laffer-adaptive#overview","position":2},{"hierarchy":{"lvl1":"Laffer Curves  with Adaptive Expectations","lvl2":"Overview"},"content":"This lecture studies stationary and dynamic Laffer curves in the inflation tax rate in a non-linear version of the model studied in this  lecture \n\nMoney Financed Government Deficits and Price Levels.\n\nAs in the lecture \n\nMoney Financed Government Deficits and Price Levels, this lecture uses the log-linear version of the demand function for money that  \n\nCagan (1956) used in his classic paper in place of the linear demand function used in this  lecture \n\nMoney Financed Government Deficits and Price Levels.\n\nBut now, instead of assuming  ‘‘rational expectations’’ in the form of ‘‘perfect foresight’’,\nwe’ll adopt the ‘‘adaptive expectations’’ assumption used by  \n\nCagan (1956) and \n\nFriedman (1956).\n\nThis means that instead of assuming that expected inflation \\pi_t^* is described by the “perfect foresight” or “rational expectations” hypothesis\\pi_t^* = p_{t+1} - p_t\n\nthat we adopted in lectures \n\nMoney Financed Government Deficits and Price Levels and lectures \n\nInflation Rate Laffer Curves, we’ll now assume that \\pi_t^* is determined by the adaptive expectations hypothesis described in equation \n\n(5)  reported below.\n\nWe shall discover that changing our hypothesis about expectations formation in this way will change some our findings and leave others intact.  In particular, we shall discover that\n\nreplacing rational expectations with adaptive expectations leaves the two stationary inflation rates unchanged, but that \\ldots\n\nit reverses the perverse dynamics by making the lower stationary inflation rate the one to which the system typically converges\n\na more plausible comparative dynamic outcome emerges in which now inflation can be reduced by running lower  government deficits\n\nThese more plausible comparative dynamics underlie the “old time religion” that states that\n“inflation is always and everywhere caused by government deficits”.\n\nThese issues were studied by \n\nBruno & Fischer (1990).\n\nTheir purpose was to reverse  what they thought were counter intuitive\npredictions of their model under rational expectations (i.e., perfect foresight in this context)\nby dropping rational expectations and instead assuming that people form  expectations about future inflation rates according to the “adaptive expectations”  scheme \n\n(5) described below.\n\nNote\n\nMarcet & Sargent (1989)  had studied another way of selecting stationary equilibrium that involved replacing rational expectations with a model of  learning via least squares regression.\n\nMarcet & Nicolini (2003) and  \n\nSargent et al. (2009) extended that work and applied it to study recurrent high-inflation episodes in Latin America.","type":"content","url":"/laffer-adaptive#overview","position":3},{"hierarchy":{"lvl1":"Laffer Curves  with Adaptive Expectations","lvl2":"The model"},"type":"lvl2","url":"/laffer-adaptive#the-model","position":4},{"hierarchy":{"lvl1":"Laffer Curves  with Adaptive Expectations","lvl2":"The model"},"content":"Let\n\nm_t be the log of the money supply at the beginning of time t\n\np_t be the log of the price level at time t\n\n\\pi_t^* be the public’s expectation of the rate of inflation between t and t+1\n\nThe law of motion of the money supply is\\exp(m_{t+1}) - \\exp(m_t) = g \\exp(p_t)\n\nwhere g is the part of government expenditures financed by printing money.\n\nNotice that equation \n\n(2) implies thatm_{t+1} = \\log[ \\exp(m_t) + g \\exp(p_t)]\n\nThe demand function for money ism_{t+1} - p_t = -\\alpha \\pi_t^*\n\nwhere \\alpha \\geq 0.\n\nExpectations of inflation are governed by\\pi_{t}^* = (1-\\delta) (p_t - p_{t-1}) + \\delta \\pi_{t-1}^*\n\nwhere \\delta \\in (0,1)","type":"content","url":"/laffer-adaptive#the-model","position":5},{"hierarchy":{"lvl1":"Laffer Curves  with Adaptive Expectations","lvl2":"Computing an equilibrium sequence"},"type":"lvl2","url":"/laffer-adaptive#computing-an-equilibrium-sequence","position":6},{"hierarchy":{"lvl1":"Laffer Curves  with Adaptive Expectations","lvl2":"Computing an equilibrium sequence"},"content":"Equation the expressions for m_{t+1} provided  by \n\n(4) and \n\n(3) and use equation \n\n(5) to eliminate \\pi_t^* to obtain\nthe following equation for p_t:\\log[ \\exp(m_t) + g \\exp(p_t)] - p_t = -\\alpha [(1-\\delta) (p_t - p_{t-1}) + \\delta \\pi_{t-1}^*]\n\nPseudo-code\n\nHere is the pseudo-code for our algorithm.\n\nStarting at time 0 with initial conditions (m_0, \\pi_{-1}^*, p_{-1}), for each t \\geq 0\ndeploy the following steps in order:\n\nsolve \n\n(6) for p_t\n\nsolve equation \n\n(5) for \\pi_t^*\n\nsolve equation \n\n(3) for m_{t+1}\n\nThis completes the algorithm.","type":"content","url":"/laffer-adaptive#computing-an-equilibrium-sequence","position":7},{"hierarchy":{"lvl1":"Laffer Curves  with Adaptive Expectations","lvl2":"Claims or conjectures"},"type":"lvl2","url":"/laffer-adaptive#claims-or-conjectures","position":8},{"hierarchy":{"lvl1":"Laffer Curves  with Adaptive Expectations","lvl2":"Claims or conjectures"},"content":"It will turn out that\n\nif they exist, limiting values \\overline \\pi and \\overline \\mu will be equal\n\nif  limiting values exist, there are two possible limiting values, one high, one low\n\nunlike the outcome in lecture \n\nInflation Rate Laffer Curves, for almost all initial log price levels and expected inflation rates p_0, \\pi_{t}^*, the limiting \\overline \\pi = \\overline \\mu is  the lower steady state  value\n\nfor each of the two possible limiting values \\bar \\pi ,there is a unique initial log price level p_0 that implies that \\pi_t = \\mu_t = \\bar \\mu for all  t \\geq 0\n\nthis unique initial log price level solves \\log(\\exp(m_0) + g \\exp(p_0)) - p_0 = - \\alpha \\bar \\pi \n\nthe preceding equation for p_0 comes from m_1 - p_0 = -  \\alpha \\bar \\pi","type":"content","url":"/laffer-adaptive#claims-or-conjectures","position":9},{"hierarchy":{"lvl1":"Laffer Curves  with Adaptive Expectations","lvl2":"Limiting values of inflation rate"},"type":"lvl2","url":"/laffer-adaptive#limiting-values-of-inflation-rate","position":10},{"hierarchy":{"lvl1":"Laffer Curves  with Adaptive Expectations","lvl2":"Limiting values of inflation rate"},"content":"As in our earlier lecture \n\nInflation Rate Laffer Curves, we can compute the two prospective limiting values for \\bar \\pi by studying the steady-state Laffer curve.\n\nThus, in a  steady statem_{t+1} - m_t = p_{t+1} - p_t =  x \\quad \\forall t ,\n\nwhere x > 0  is a common rate of growth of logarithms of the money supply and price level.\n\nA few lines of algebra yields the following equation that x satisfies\\exp(-\\alpha x) - \\exp(-(1 + \\alpha) x) = g\n\nwhere we require thatg \\leq \\max_{x: x \\geq 0} \\exp(-\\alpha x) - \\exp(-(1 + \\alpha) x) ,\n\nso that it is feasible to finance g by printing money.\n\nThe left side of \n\n(8) is steady state revenue raised by printing money.\n\nThe right side of \n\n(8) is the quantity  of time t goods  that the government raises by printing money.\n\nSoon  we’ll plot  the left and right sides of equation \n\n(8).\n\nBut first we’ll write code that computes a steady-state\n\\bar \\pi.\n\nLet’s start by importing some  libraries\n\nfrom collections import namedtuple\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib.ticker import MaxNLocator\nfrom matplotlib.cm import get_cmap\nfrom matplotlib.colors import to_rgba\nimport matplotlib\nfrom scipy.optimize import root, fsolve\n\nLet’s create a namedtuple to store the parameters of the model\n\nLafferAdaptive = namedtuple('LafferAdaptive', \n                        [\"m0\",  # log of the money supply at t=0\n                         \"α\",   # sensitivity of money demand\n                         \"g\",   # government expenditure\n                         \"δ\"])\n\n# Create a Cagan Laffer model\ndef create_model(α=0.5, m0=np.log(100), g=0.35, δ=0.9):\n    return LafferAdaptive(α=α, m0=m0, g=g, δ=δ)\n\nmodel = create_model()\n\nNow we write code that computes steady-state \\bar \\pis.\n\n# Define formula for π_bar\ndef solve_π(x, α, g):\n    return np.exp(-α * x) - np.exp(-(1 + α) * x) - g\n\ndef solve_π_bar(model, x0):\n    π_bar = fsolve(solve_π, x0=x0, xtol=1e-10, args=(model.α, model.g))[0]\n    return π_bar\n\n# Solve for the two steady state of π\nπ_l = solve_π_bar(model, x0=0.6)\nπ_u = solve_π_bar(model, x0=3.0)\nprint(f'The two steady state of π are: {π_l, π_u}')\n\nWe find two steady state \\bar \\pi values","type":"content","url":"/laffer-adaptive#limiting-values-of-inflation-rate","position":11},{"hierarchy":{"lvl1":"Laffer Curves  with Adaptive Expectations","lvl2":"Steady-state Laffer curve"},"type":"lvl2","url":"/laffer-adaptive#steady-state-laffer-curve","position":12},{"hierarchy":{"lvl1":"Laffer Curves  with Adaptive Expectations","lvl2":"Steady-state Laffer curve"},"content":"The following figure plots the steady-state Laffer curve together with the two stationary inflation rates.\n\ndef compute_seign(x, α):\n    return np.exp(-α * x) - np.exp(-(1 + α) * x) \n\ndef plot_laffer(model, πs):\n    α, g = model.α, model.g\n    \n    # Generate π values\n    x_values = np.linspace(0, 5, 1000)\n\n    # Compute corresponding seigniorage values for the function\n    y_values = compute_seign(x_values, α)\n\n    # Plot the function\n    plt.plot(x_values, y_values, \n            label=f'$exp((-{α})x) - exp(- (1- {α}) x)$')\n    for π, label in zip(πs, ['$\\pi_l$', '$\\pi_u$']):\n        plt.text(π, plt.gca().get_ylim()[0]*2, \n                 label, horizontalalignment='center',\n                 color='brown', size=10)\n        plt.axvline(π, color='brown', linestyle='--')\n    plt.axhline(g, color='red', linewidth=0.5, \n                linestyle='--', label='g')\n    plt.xlabel('$\\pi$')\n    plt.ylabel('seigniorage')\n    plt.legend()\n    plt.grid(True)\n    plt.show()\n\n# Steady state Laffer curve\nplot_laffer(model, (π_l, π_u))\n\n\n\nFigure 1:Seigniorage as function of steady-state inflation. The dashed brown lines indicate \\pi_l and \\pi_u.","type":"content","url":"/laffer-adaptive#steady-state-laffer-curve","position":13},{"hierarchy":{"lvl1":"Laffer Curves  with Adaptive Expectations","lvl2":"Associated initial price levels"},"type":"lvl2","url":"/laffer-adaptive#associated-initial-price-levels","position":14},{"hierarchy":{"lvl1":"Laffer Curves  with Adaptive Expectations","lvl2":"Associated initial price levels"},"content":"Now that we have our hands on the two possible steady states, we can compute two initial log price levels p_{-1}, which as initial conditions, imply that \\pi_t = \\bar \\pi  for all t \\geq 0.\n\nIn particular, to initiate a fixed point of the dynamic Laffer curve dynamics, we setp_{-1} = m_0 + \\alpha \\pi^*\n\ndef solve_p_init(model, π_star):\n    m0, α = model.m0, model.α\n    return m0 + α*π_star\n\n\n# Compute two initial price levels associated with π_l and π_u\np_l, p_u = map(lambda π: solve_p_init(model, π), (π_l, π_u))\nprint('Associated initial p_{-1}s', f'are: {p_l, p_u}')\n\n","type":"content","url":"/laffer-adaptive#associated-initial-price-levels","position":15},{"hierarchy":{"lvl1":"Laffer Curves  with Adaptive Expectations","lvl3":"Verification","lvl2":"Associated initial price levels"},"type":"lvl3","url":"/laffer-adaptive#verification","position":16},{"hierarchy":{"lvl1":"Laffer Curves  with Adaptive Expectations","lvl3":"Verification","lvl2":"Associated initial price levels"},"content":"To start, let’s write some code to verify that if we initial  \\pi_{-1}^*,p_{-1} appropriately, the inflation rate \\pi_t will be constant for all t \\geq 0 (at either \\pi_u or \\pi_l depending on the initial condition)\n\nThe following code verifies this.\n\ndef solve_laffer_adapt(p_init, π_init, model, num_steps):\n    m0, α, δ, g = model.m0, model.α, model.δ, model.g\n    \n    m_seq = np.nan * np.ones(num_steps+1) \n    π_seq = np.nan * np.ones(num_steps) \n    p_seq = np.nan * np.ones(num_steps)\n    μ_seq = np.nan * np.ones(num_steps) \n    \n    m_seq[1] = m0\n    π_seq[0] = π_init\n    p_seq[0] = p_init\n        \n    for t in range(1, num_steps):\n        # Solve p_t\n        def p_t(pt):\n            return np.log(np.exp(m_seq[t]) + g * np.exp(pt)) \\\n                          - pt + α * ((1-δ)*(pt - p_seq[t-1]) + δ*π_seq[t-1])\n        \n        p_seq[t] = root(fun=p_t, x0=p_seq[t-1]).x[0]\n        \n        # Solve π_t\n        π_seq[t] = (1-δ) * (p_seq[t]-p_seq[t-1]) + δ*π_seq[t-1]\n        \n        # Solve m_t\n        m_seq[t+1] = np.log(np.exp(m_seq[t]) + g*np.exp(p_seq[t]))\n        \n        # Solve μ_t\n        μ_seq[t] = m_seq[t+1] - m_seq[t]\n    \n    return π_seq, μ_seq, m_seq, p_seq\n\nCompute limiting values starting from p_{-1} associated with \\pi_l\n\nπ_seq, μ_seq, m_seq, p_seq = solve_laffer_adapt(p_l, π_l, model, 50)\n\n# Check steady state m_{t+1} - m_t and p_{t+1} - p_t \nprint('m_{t+1} - m_t:', m_seq[-1] - m_seq[-2])\nprint('p_{t+1} - p_t:', p_seq[-1] - p_seq[-2])\n\n# Check if exp(-αx) - exp(-(1 + α)x) = g\neq_g = lambda x: np.exp(-model.α * x) - np.exp(-(1 + model.α) * x)\n\nprint('eq_g == g:', np.isclose(eq_g(m_seq[-1] - m_seq[-2]), model.g))\n\nCompute limiting values starting from p_{-1} associated with \\pi_u\n\nπ_seq, μ_seq, m_seq, p_seq = solve_laffer_adapt(p_u, π_u, model, 50)\n\n# Check steady state m_{t+1} - m_t and p_{t+1} - p_t \nprint('m_{t+1} - m_t:', m_seq[-1] - m_seq[-2])\nprint('p_{t+1} - p_t:', p_seq[-1] - p_seq[-2])\n\n# Check if exp(-αx) - exp(-(1 + α)x) = g\neq_g = lambda x: np.exp(-model.α * x) - np.exp(-(1 + model.α) * x)\n\nprint('eq_g == g:', np.isclose(eq_g(m_seq[-1] - m_seq[-2]), model.g))\n\n","type":"content","url":"/laffer-adaptive#verification","position":17},{"hierarchy":{"lvl1":"Laffer Curves  with Adaptive Expectations","lvl2":"Slippery side of Laffer curve dynamics"},"type":"lvl2","url":"/laffer-adaptive#slippery-side-of-laffer-curve-dynamics","position":18},{"hierarchy":{"lvl1":"Laffer Curves  with Adaptive Expectations","lvl2":"Slippery side of Laffer curve dynamics"},"content":"We are now equipped  to compute  time series starting from different p_{-1}, \\pi_{-1}^* settings, analogous to those in this lecture  \n\nMoney Financed Government Deficits and Price Levels and this lecture  \n\nInflation Rate Laffer Curves.\n\nNow we’ll study how outcomes unfold when we start p_{-1}, \\pi_{-1}^* away from a stationary point of the dynamic Laffer curve, i.e., away from either \\pi_u or  \\pi_l.\n\nTo construct a perturbation pair \\check p_{-1}, \\check \\pi_{-1}^*we’ll implement the following pseudo code:\n\nset \\check \\pi_{-1}^*  not equal to one of the stationary points \\pi_u or  \\pi_l.\n\nset \\check p_{-1} = m_0 + \\alpha \\check \\pi_{-1}^*\n\ndef draw_iterations(π0s, model, line_params, π_bars, num_steps):\n    fig, axes = plt.subplots(4, 1, figsize=(8, 12), sharex=True)\n\n    for ax in axes[:2]:\n        ax.set_yscale('log')\n        \n    for i, π0 in enumerate(π0s):\n        p0 = model.m0 + model.α*π0\n        π_seq, μ_seq, m_seq, p_seq = solve_laffer_adapt(p0, π0, model, num_steps)\n\n        axes[0].plot(np.arange(num_steps), m_seq[1:], **line_params)\n        axes[1].plot(np.arange(-1, num_steps-1), p_seq, **line_params)\n        axes[2].plot(np.arange(-1, num_steps-1), π_seq, **line_params)\n        axes[3].plot(np.arange(num_steps), μ_seq, **line_params)\n            \n    axes[2].axhline(y=π_bars[0], color='grey', linestyle='--', lw=1.5, alpha=0.6)\n    axes[2].axhline(y=π_bars[1], color='grey', linestyle='--', lw=1.5, alpha=0.6)\n    axes[2].text(num_steps * 1.07, π_bars[0], r'$\\pi_l$', verticalalignment='center', \n                     color='grey', size=10)\n    axes[2].text(num_steps * 1.07, π_bars[1], r'$\\pi_u$', verticalalignment='center', \n                         color='grey', size=10)\n\n    axes[0].set_ylabel('$m_t$')\n    axes[1].set_ylabel('$p_t$')\n    axes[2].set_ylabel(r'$\\pi_t$')\n    axes[3].set_ylabel(r'$\\mu_t$')\n    axes[3].set_xlabel('timestep')\n    axes[3].xaxis.set_major_locator(MaxNLocator(integer=True))\n\n    plt.tight_layout()\n    plt.show()\n\nLet’s simulate the result generated by varying the initial \\pi_{-1} and corresponding p_{-1}\n\nπs = np.linspace(π_l, π_u, 10)\n\nline_params = {'lw': 1.5, \n              'marker': 'o',\n              'markersize': 3}\n              \nπ_bars = (π_l, π_u)\ndraw_iterations(πs, model, line_params, π_bars, num_steps=80)\n\n\n\nFigure 2:Starting from different initial values of \\pi_0, paths of m_t (top panel, log scale for m), p_t (second panel, log scale for p), \\pi_t (third panel), and \\mu_t (bottom panel)","type":"content","url":"/laffer-adaptive#slippery-side-of-laffer-curve-dynamics","position":19},{"hierarchy":{"lvl1":"A Lake Model of Employment"},"type":"lvl1","url":"/lake-model","position":0},{"hierarchy":{"lvl1":"A Lake Model of Employment"},"content":"","type":"content","url":"/lake-model","position":1},{"hierarchy":{"lvl1":"A Lake Model of Employment","lvl2":"Outline"},"type":"lvl2","url":"/lake-model#outline","position":2},{"hierarchy":{"lvl1":"A Lake Model of Employment","lvl2":"Outline"},"content":"In addition to what’s in Anaconda, this lecture will need the following libraries:\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n","type":"content","url":"/lake-model#outline","position":3},{"hierarchy":{"lvl1":"A Lake Model of Employment","lvl2":"The Lake model"},"type":"lvl2","url":"/lake-model#the-lake-model","position":4},{"hierarchy":{"lvl1":"A Lake Model of Employment","lvl2":"The Lake model"},"content":"This model is sometimes called the lake model because there are two pools of workers:\n\nthose who are currently employed.\n\nthose who are currently unemployed but are seeking employment.\n\nThe “flows” between the two lakes are as follows:\n\nworkers exit the labor market at rate d.\n\nnew workers enter the labor market at rate b.\n\nemployed workers separate from their jobs at rate \\alpha.\n\nunemployed workers find jobs at rate \\lambda.\n\nThe graph below illustrates the lake model.\n\n\n\nFigure 1:An illustration of the lake model","type":"content","url":"/lake-model#the-lake-model","position":5},{"hierarchy":{"lvl1":"A Lake Model of Employment","lvl2":"Dynamics"},"type":"lvl2","url":"/lake-model#dynamics","position":6},{"hierarchy":{"lvl1":"A Lake Model of Employment","lvl2":"Dynamics"},"content":"Let e_t and u_t be the number of employed and unemployed workers at time t respectively.\n\nThe total population of workers is n_t = e_t + u_t.\n\nThe number of unemployed and employed workers thus evolves according to:\\begin{aligned}\n    u_{t+1} &= (1-d)(1-\\lambda)u_t + \\alpha(1-d)e_t + bn_t \\\\\n    &= ((1-d)(1-\\lambda) + b)u_t + (\\alpha(1-d) + b)e_t \\\\\n    e_{t+1} &= (1-d)\\lambda u_t + (1 - \\alpha)(1-d)e_t\n\\end{aligned}\n\nWe can arrange \n\n(1) as a linear system of equations in matrix form x_{t+1} = Ax_t wherex_{t+1} =\n\\begin{bmatrix}\n    u_{t+1} \\\\\n    e_{t+1}\n\\end{bmatrix}\n\\quad\nA =\n\\begin{bmatrix}\n    (1-d)(1-\\lambda) + b & \\alpha(1-d) + b \\\\\n    (1-d)\\lambda & (1 - \\alpha)(1-d)\n\\end{bmatrix}\n\\quad \\text{and} \\quad\nx_t =\n\\begin{bmatrix}\n    u_t \\\\\n    e_t\n\\end{bmatrix}.\n\nSuppose at t=0 we have x_0 = \\begin{bmatrix} u_0 & e_0 \\end{bmatrix}^\\top.\n\nThen, x_1=Ax_0, x_2=Ax_1=A^2x_0 and thus x_t = A^tx_0.\n\nThus the long-run outcomes of this system may depend on the initial condition x_0 and the matrix A.\n\nWe are interested in how u_t and e_t evolve over time.\n\nWhat long-run unemployment rate and employment rate should we expect?\n\nDo long-run outcomes depend on the initial values (u_0, e_o)?","type":"content","url":"/lake-model#dynamics","position":7},{"hierarchy":{"lvl1":"A Lake Model of Employment","lvl3":"Visualising the long-run outcomes","lvl2":"Dynamics"},"type":"lvl3","url":"/lake-model#visualising-the-long-run-outcomes","position":8},{"hierarchy":{"lvl1":"A Lake Model of Employment","lvl3":"Visualising the long-run outcomes","lvl2":"Dynamics"},"content":"Let us first plot the time series of unemployment u_t, employment e_t, and labor force n_t.\n\nclass LakeModel:\n    \"\"\"\n    Solves the lake model and computes dynamics of the unemployment stocks and\n    rates.\n\n    Parameters:\n    ------------\n    λ : scalar\n        The job finding rate for currently unemployed workers\n    α : scalar\n        The dismissal rate for currently employed workers\n    b : scalar\n        Entry rate into the labor force\n    d : scalar\n        Exit rate from the labor force\n\n    \"\"\"\n    def __init__(self, λ=0.1, α=0.013, b=0.0124, d=0.00822):\n        self.λ, self.α, self.b, self.d = λ, α, b, d\n\n        λ, α, b, d = self.λ, self.α, self.b, self.d\n        self.g = b - d\n        g = self.g\n\n        self.A = np.array([[(1-d)*(1-λ) + b,   α*(1-d) + b],\n                           [        (1-d)*λ,   (1-α)*(1-d)]])\n\n\n        self.ū = (1 + g - (1 - d) * (1 - α)) / (1 + g - (1 - d) * (1 - α) + (1 - d) * λ)\n        self.ē = 1 - self.ū\n\n\n    def simulate_path(self, x0, T=1000):\n        \"\"\"\n        Simulates the sequence of employment and unemployment\n\n        Parameters\n        ----------\n        x0 : array\n            Contains initial values (u0,e0)\n        T : int\n            Number of periods to simulate\n\n        Returns\n        ----------\n        x : iterator\n            Contains sequence of employment and unemployment rates\n\n        \"\"\"\n        x0 = np.atleast_1d(x0)  # Recast as array just in case\n        x_ts= np.zeros((2, T))\n        x_ts[:, 0] = x0\n        for t in range(1, T):\n            x_ts[:, t] = self.A @ x_ts[:, t-1]\n        return x_ts\n\nlm = LakeModel()\ne_0 = 0.92          # Initial employment\nu_0 = 1 - e_0       # Initial unemployment, given initial n_0 = 1\n\nlm = LakeModel()\nT = 100         # Simulation length\n\nx_0 = (u_0, e_0)\nx_path = lm.simulate_path(x_0, T)\n\nfig, axes = plt.subplots(3, 1, figsize=(10, 8))\n\n\naxes[0].plot(x_path[0, :], lw=2)\naxes[0].set_title('Unemployment')\n\naxes[1].plot(x_path[1, :], lw=2)\naxes[1].set_title('Employment')\n\naxes[2].plot(x_path.sum(0), lw=2)\naxes[2].set_title('Labor force')\n\nfor ax in axes:\n    ax.grid()\n\nplt.tight_layout()\nplt.show()\n\nNot surprisingly, we observe that labor force n_t increases at a constant rate.\n\nThis coincides with the fact there is only one inflow source (new entrants pool) to unemployment and employment pools.\n\nThe inflow and outflow of labor market system\nis determined by constant exit rate and entry rate of labor market in the long run.\n\nIn detail, let \\mathbb{1}=[1, 1]^\\top be a vector of ones.\n\nObserve that\\begin{aligned}\n    n_{t+1} &= u_{t+1} + e_{t+1} \\\\\n    &= \\mathbb{1}^\\top x_{t+1} \\\\\n    &= \\mathbb{1}^\\top A x_t \\\\\n    &= (1 + b - d) (u_t + e_t) \\\\\n    &= (1 + b - d) n_t.\n    \\end{aligned}\n\nHence, the growth rate of n_t is fixed at 1 + b - d.\n\nMoreover, the times series of unemployment and employment seems to grow at some stable rates in the long run.","type":"content","url":"/lake-model#visualising-the-long-run-outcomes","position":9},{"hierarchy":{"lvl1":"A Lake Model of Employment","lvl3":"The application of Perron-Frobenius theorem","lvl2":"Dynamics"},"type":"lvl3","url":"/lake-model#the-application-of-perron-frobenius-theorem","position":10},{"hierarchy":{"lvl1":"A Lake Model of Employment","lvl3":"The application of Perron-Frobenius theorem","lvl2":"Dynamics"},"content":"Since by intuition if we consider unemployment pool and employment pool as a closed system, the growth should be similar to the labor force.\n\nWe next ask whether the long-run growth rates of e_t and u_t\nalso dominated by 1+b-d as labor force.\n\nThe answer will be clearer if we appeal to \n\nPerron-Frobenius theorem.\n\nThe importance of the Perron-Frobenius theorem stems from the fact that\nfirstly in the real world most matrices we encounter are nonnegative matrices.\n\nSecondly, many important models are simply linear iterative models that\nbegin with an initial condition x_0 and then evolve recursively by the rule\nx_{t+1} = Ax_t or in short x_t = A^tx_0.\n\nThis theorem helps characterise the dominant eigenvalue r(A) which\ndetermines the behavior of this iterative process.","type":"content","url":"/lake-model#the-application-of-perron-frobenius-theorem","position":11},{"hierarchy":{"lvl1":"A Lake Model of Employment","lvl4":"Dominant eigenvector","lvl3":"The application of Perron-Frobenius theorem","lvl2":"Dynamics"},"type":"lvl4","url":"/lake-model#dominant-eigenvector","position":12},{"hierarchy":{"lvl1":"A Lake Model of Employment","lvl4":"Dominant eigenvector","lvl3":"The application of Perron-Frobenius theorem","lvl2":"Dynamics"},"content":"We now illustrate the power of the Perron-Frobenius theorem by showing how it\nhelps us to analyze the lake model.\n\nSince A is a nonnegative and irreducible matrix, the Perron-Frobenius theorem implies that:\n\nthe spectral radius r(A) is an eigenvalue of A, wherer(A) := \\max\\{|\\lambda|: \\lambda \\text{ is an eigenvalue of } A \\}\n\nany other eigenvalue \\lambda in absolute value is strictly smaller than r(A): |\\lambda|< r(A),\n\nthere exist unique and everywhere positive right eigenvector \\phi (column vector) and left eigenvector \\psi (row vector):A \\phi = r(A) \\phi, \\quad  \\psi A = r(A) \\psi\n\nif further A is positive, then with <\\psi, \\phi> = \\psi \\phi=1 we haver(A)^{-t} A^t \\to \\phi \\psi\n\nThe last statement implies that the magnitude of A^t is identical to the magnitude of r(A)^t in the long run, where r(A) can be considered as the dominant eigenvalue in this lecture.\n\nTherefore, the magnitude x_t = A^t x_0 is also dominated by r(A)^t in the long run.\n\nRecall that the spectral radius is bounded by column sums: for A \\geq 0, we have\\min_j \\text{colsum}_j (A) \\leq r(A) \\leq \\max_j \\text{colsum}_j (A)\n\nNote that \\text{colsum}_j(A) = 1 + b - d for j=1,2 and by \n\n(7) we can thus conclude that the dominant eigenvalue\nis r(A) = 1 + b - d.\n\nDenote g = b - d as the overall growth rate of the total labor force, so that r(A) = 1 + g.\n\nThe Perron-Frobenius implies that there is a unique positive eigenvector \\bar{x} = \\begin{bmatrix} \\bar{u} \\\\ \\bar{e} \\end{bmatrix}\nsuch that A\\bar{x} = r(A)\\bar{x} and \\begin{bmatrix} 1 & 1 \\end{bmatrix} \\bar{x} = 1:\\begin{aligned}\n    \\bar{u} & = \\frac{b + \\alpha (1-d)}{b + (\\alpha+\\lambda)(1-d)} \\\\\n    \\bar{e} & = \\frac{\\lambda(1-d)}{b + (\\alpha+\\lambda)(1-d)}\n\\end{aligned}\n\nSince \\bar{x} is the eigenvector corresponding to the dominant eigenvalue r(A), we call \\bar{x} the dominant eigenvector.\n\nThis dominant eigenvector plays an important role in determining long-run outcomes as illustrated below.\n\ndef plot_time_paths(lm, x0=None, T=1000, ax=None):\n        \"\"\"\n        Plots the simulated time series.\n\n        Parameters\n        ----------\n        lm : class\n            Lake Model\n        x0 : array\n            Contains some different initial values.\n        T : int\n            Number of periods to simulate\n\n        \"\"\"\n\n\n        if x0 is None:\n            x0 = np.array([[5.0, 0.1]])\n\n        ū, ē = lm.ū, lm.ē\n\n        x0 = np.atleast_2d(x0)\n\n        if ax is None:\n            fig, ax = plt.subplots(figsize=(10, 8))\n            # Plot line D\n            s = 10\n            ax.plot([0, s * ū], [0, s * ē], \"k--\", lw=1, label='set $D$')\n\n        # Set the axes through the origin\n        for spine in [\"left\", \"bottom\"]:\n            ax.spines[spine].set_position(\"zero\")\n        for spine in [\"right\", \"top\"]:\n            ax.spines[spine].set_color(\"none\")\n\n        ax.set_xlim(-2, 6)\n        ax.set_ylim(-2, 6)\n        ax.set_xlabel(\"unemployed workforce\")\n        ax.set_ylabel(\"employed workforce\")\n        ax.set_xticks((0, 6))\n        ax.set_yticks((0, 6))\n\n\n\n\n        # Plot time series\n        for x in x0:\n            x_ts = lm.simulate_path(x0=x)\n\n            ax.scatter(x_ts[0, :], x_ts[1, :], s=4,)\n\n            u0, e0 = x\n            ax.plot([u0], [e0], \"ko\", ms=2, alpha=0.6)\n            ax.annotate(f'$x_0 = ({u0},{e0})$',\n                        xy=(u0, e0),\n                        xycoords=\"data\",\n                        xytext=(0, 20),\n                        textcoords=\"offset points\",\n                        arrowprops=dict(arrowstyle = \"->\"))\n\n        ax.plot([ū], [ē], \"ko\", ms=4, alpha=0.6)\n        ax.annotate(r'$\\bar{x}$',\n                xy=(ū, ē),\n                xycoords=\"data\",\n                xytext=(20, -20),\n                textcoords=\"offset points\",\n                arrowprops=dict(arrowstyle = \"->\"))\n\n        if ax is None:\n            plt.show()\n\nlm = LakeModel(α=0.01, λ=0.1, d=0.02, b=0.025)\nx0 = ((5.0, 0.1), (0.1, 4.0), (2.0, 1.0))\nplot_time_paths(lm, x0=x0)\n\nSince \\bar{x} is an eigenvector corresponding to the eigenvalue r(A), all the vectors in the set\nD := \\{ x \\in \\mathbb{R}^2 : x = \\alpha \\bar{x} \\; \\text{for some} \\; \\alpha >0 \\} are also eigenvectors corresponding\nto r(A).\n\nThis set D is represented by a dashed line in the above figure.\n\nThe graph illustrates that for two distinct initial conditions x_0 the sequences of iterates (A^t x_0)_{t \\geq 0} move towards D over time.\n\nThis suggests that all such sequences share strong similarities in the long run, determined by the dominant eigenvector \\bar{x}.","type":"content","url":"/lake-model#dominant-eigenvector","position":13},{"hierarchy":{"lvl1":"A Lake Model of Employment","lvl4":"Negative growth rate","lvl3":"The application of Perron-Frobenius theorem","lvl2":"Dynamics"},"type":"lvl4","url":"/lake-model#negative-growth-rate","position":14},{"hierarchy":{"lvl1":"A Lake Model of Employment","lvl4":"Negative growth rate","lvl3":"The application of Perron-Frobenius theorem","lvl2":"Dynamics"},"content":"In the example illustrated above we considered parameters such that overall growth rate of the labor force g>0.\n\nSuppose now we are faced with a situation where the g<0, i.e., negative growth in the labor force.\n\nThis means that b-d<0, i.e., workers exit the market faster than they enter.\n\nWhat would the behavior of the iterative sequence x_{t+1} = Ax_t be now?\n\nThis is visualised below.\n\nlm = LakeModel(α=0.01, λ=0.1, d=0.025, b=0.02)\nplot_time_paths(lm, x0=x0)\n\nThus, while the sequence of iterates still moves towards the dominant eigenvector \\bar{x}, in this case\nthey converge to the origin.\n\nThis is a result of the fact that r(A)<1, which ensures that the iterative sequence (A^t x_0)_{t \\geq 0} will converge\nto some point, in this case to (0,0).\n\nThis leads us to the next result.","type":"content","url":"/lake-model#negative-growth-rate","position":15},{"hierarchy":{"lvl1":"A Lake Model of Employment","lvl3":"Properties","lvl2":"Dynamics"},"type":"lvl3","url":"/lake-model#properties","position":16},{"hierarchy":{"lvl1":"A Lake Model of Employment","lvl3":"Properties","lvl2":"Dynamics"},"content":"Since the column sums of A are r(A)=1, the left eigenvector is \\mathbb{1}^\\top=[1, 1].\n\nPerron-Frobenius theory implies thatr(A)^{-t} A^{t} \\approx \\bar{x} \\mathbb{1}^\\top = \\begin{bmatrix} \\bar{u} & \\bar{u} \\\\ \\bar{e} & \\bar{e} \\end{bmatrix}.\n\nAs a result, for any x_0 = (u_0, e_0)^\\top, we have\\begin{aligned}\nx_t = A^t x_0 &\\approx r(A)^t \\begin{bmatrix} \\bar{u} & \\bar{u} \\\\ \\bar{e} & \\bar{e} \\end{bmatrix} \\begin{bmatrix}u_0 \\\\ e_0 \\end{bmatrix} \\\\\n&= (1+g)^t(u_0 + e_0) \\begin{bmatrix}\\bar{u} \\\\ \\bar{e} \\end{bmatrix} \\\\\n&= (1 + g)^t n_0 \\bar{x} \\\\\n&= n_t \\bar{x}.\n\\end{aligned}\n\nas t is large enough.\n\nWe see that the growth of u_t and e_t also dominated by r(A) = 1+g in the long run: x_t grows along D as r(A) > 1 and converges to (0, 0) as r(A) < 1.\n\nMoreover, the long-run unemployment and employment are steady fractions of n_t.\n\nThe latter implies that \\bar{u} and \\bar{e} are long-run unemployment rate and employment rate, respectively.\n\nIn detail, we have the unemployment rates and employment rates: x_t / n_t = A^t n_0 / n_t \\to \\bar{x} as t \\to \\infty.\n\nTo illustrate the dynamics of the rates, let \\hat{A} := A / (1+g) be the transition matrix of r_t := x_t/ n_t.\n\nThe dynamics of the rates followr_{t+1} = \\frac{x_{t+1}}{n_{t+1}} = \\frac{x_{t+1}}{(1+g) n_{t}} = \\frac{A x_t}{(1+g)n_t} = \\hat{A} \\frac{x_t}{n_t}\n=\\hat{A} r_t.\n\nObserve that the column sums of \\hat{A} are all one so that r(\\hat{A})=1.\n\nOne can check that \\bar{x} is also the right eigenvector of \\hat{A} corresponding to r(\\hat{A}) that \\bar{x} = \\hat{A} \\bar{x}.\n\nMoreover, \\hat{A}^t r_0 \\to \\bar{x} as t \\to \\infty for any r_0 = x_0 / n_0, since the above discussion impliesr_t = \\hat{A}^t r_0 = (1+g)^{-t} A^t r_0 = r(A)^{-t} A^t r_0 \\to \\begin{bmatrix} \\bar{u} & \\bar{u} \\\\ \\bar{e} & \\bar{e} \\end{bmatrix} r_0 = \\begin{bmatrix} \\bar{u} \\\\  \\bar{e} \\end{bmatrix}.\n\nThis is illustrated below.\n\nlm = LakeModel()\ne_0 = 0.92          # Initial employment\nu_0 = 1 - e_0       # Initial unemployment, given initial n_0 = 1\n\nlm = LakeModel()\nT = 100         # Simulation length\n\nx_0 = (u_0, e_0)\n\nx_path = lm.simulate_path(x_0, T)\n\nrate_path = x_path / x_path.sum(0)\n\nfig, axes = plt.subplots(2, 1, figsize=(10, 8))\n\n# Plot steady ū and ē\naxes[0].hlines(lm.ū, 0, T, 'r', '--', lw=2, label='ū')\naxes[1].hlines(lm.ē, 0, T, 'r', '--', lw=2, label='ē')\n\ntitles = ['Unemployment rate', 'Employment rate']\nlocations = ['lower right', 'upper right']\n\n# Plot unemployment rate and employment rate\nfor i, ax in enumerate(axes):\n    ax.plot(rate_path[i, :], lw=2, alpha=0.6)\n    ax.set_title(titles[i])\n    ax.grid()\n    ax.legend(loc=locations[i])\n\n\nplt.tight_layout()\nplt.show()\n\nTo provide more intuition for convergence, we further explain the convergence below without the Perron-Frobenius theorem.\n\nSuppose that \\hat{A} = P D P^{-1} is diagonalizable, where P = [v_1, v_2] consists of eigenvectors v_1 and v_2 of \\hat{A}\ncorresponding to eigenvalues \\gamma_1 and \\gamma_2 respectively,\nand D = \\text{diag}(\\gamma_1, \\gamma_2).\n\nLet \\gamma_1 = r(\\hat{A})=1 and |\\gamma_2| < \\gamma_1, so that the spectral radius is a dominant eigenvalue.\n\nThe dynamics of the rates follow r_{t+1} = \\hat{A} r_t, where r_0 is a probability vector: \\sum_j r_{0,j}=1.\n\nConsider z_t = P^{-1} r_t .\n\nThen, we have z_{t+1} = P^{-1} r_{t+1} = P^{-1} \\hat{A} r_t = P^{-1} \\hat{A} P z_t = D z_t.\n\nHence, we obtain z_t = D^t z_0, and for some z_0 = (c_1, c_2)^\\top we haver_t = P z_t = \\begin{bmatrix} v_1 & v_2 \\end{bmatrix}  \\begin{bmatrix} \\gamma_1^t & 0 \\\\ 0 & \\gamma_2^t \\end{bmatrix}\n\\begin{bmatrix} c_1 \\\\ c_2 \\end{bmatrix} = c_1 \\gamma_1^t v_1 + c_2 \\gamma_2^t v_2.\n\nSince |\\gamma_2| < |\\gamma_1|=1, the second term in the right hand side converges to zero.\n\nTherefore, the convergence follows r_t \\to c_1 v_1.\n\nSince the column sums of \\hat{A} are one and r_0 is a probability vector, r_t must be a probability vector.\n\nIn this case, c_1 v_1 must be a normalized eigenvector, so c_1 v_1 = \\bar{x} and then r_t \\to \\bar{x}.","type":"content","url":"/lake-model#properties","position":17},{"hierarchy":{"lvl1":"A Lake Model of Employment","lvl2":"Exercise"},"type":"lvl2","url":"/lake-model#exercise","position":18},{"hierarchy":{"lvl1":"A Lake Model of Employment","lvl2":"Exercise"},"content":"Evolution of unemployment and employment rate\n\nHow do the long-run unemployment rate and employment rate evolve if there is an increase in the separation rate \\alpha\nor a decrease in job finding rate \\lambda?\n\nIs the result compatible with your intuition?\n\nPlot the graph to illustrate how the line D := \\{ x \\in \\mathbb{R}^2 : x = \\alpha \\bar{x} \\; \\text{for some} \\; \\alpha >0 \\}\nshifts in the unemployment-employment space.\n\nSolution to \n\nExercise 1\n\nEq. \n\n(8) implies that the long-run unemployment rate will increase, and the employment rate will decrease\nif \\alpha increases or \\lambda decreases.\n\nSuppose first that \\alpha=0.01, \\lambda=0.1, d=0.02, b=0.025.\nAssume that \\alpha increases to 0.04.\n\nThe below graph illustrates that the line D shifts clockwise downward, which indicates that\nthe fraction of unemployment rises as the separation rate increases.\n\nfig, ax = plt.subplots(figsize=(10, 8))\n\nlm = LakeModel(α=0.01, λ=0.1, d=0.02, b=0.025)\nplot_time_paths(lm, ax=ax)\ns=10\nax.plot([0, s * lm.ū], [0, s * lm.ē], \"k--\", lw=1, label='set $D$, α=0.01')\n\nlm = LakeModel(α=0.04, λ=0.1, d=0.02, b=0.025)\nplot_time_paths(lm, ax=ax)\nax.plot([0, s * lm.ū], [0, s * lm.ē], \"r--\", lw=1, label='set $D$, α=0.04')\n\nax.legend(loc='best')\nplt.show()\n\n","type":"content","url":"/lake-model#exercise","position":19},{"hierarchy":{"lvl1":"Linear Equations and Matrix Algebra"},"type":"lvl1","url":"/linear-equations","position":0},{"hierarchy":{"lvl1":"Linear Equations and Matrix Algebra"},"content":"","type":"content","url":"/linear-equations","position":1},{"hierarchy":{"lvl1":"Linear Equations and Matrix Algebra","lvl2":"Overview"},"type":"lvl2","url":"/linear-equations#overview","position":2},{"hierarchy":{"lvl1":"Linear Equations and Matrix Algebra","lvl2":"Overview"},"content":"Many problems in economics and finance require solving linear equations.\n\nIn this lecture we discuss linear equations and their applications.\n\nTo illustrate the importance of linear equations, we begin with a two good\nmodel of supply and demand.\n\nThe two good case is so simple that solutions can be calculated by hand.\n\nBut often we need to consider markets containing many goods.\n\nIn the multiple goods case we face large systems of linear equations, with many equations\nand unknowns.\n\nTo handle such systems we need two things:\n\nmatrix algebra (and the knowledge of how to use it) plus\n\ncomputer code to apply matrix algebra to the problems of interest.\n\nThis lecture covers these steps.\n\nWe will use the following packages:\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n","type":"content","url":"/linear-equations#overview","position":3},{"hierarchy":{"lvl1":"Linear Equations and Matrix Algebra","lvl2":"A two good example"},"type":"lvl2","url":"/linear-equations#a-two-good-example","position":4},{"hierarchy":{"lvl1":"Linear Equations and Matrix Algebra","lvl2":"A two good example"},"content":"In this section we discuss a simple two good example and solve it by\n\npencil and paper\n\nmatrix algebra\n\nThe second method is more general, as we will see.","type":"content","url":"/linear-equations#a-two-good-example","position":5},{"hierarchy":{"lvl1":"Linear Equations and Matrix Algebra","lvl3":"Pencil and paper methods","lvl2":"A two good example"},"type":"lvl3","url":"/linear-equations#pencil-and-paper-methods","position":6},{"hierarchy":{"lvl1":"Linear Equations and Matrix Algebra","lvl3":"Pencil and paper methods","lvl2":"A two good example"},"content":"Suppose that we have two related goods, such as\n\npropane and ethanol, and\n\nrice and wheat, etc.\n\nTo keep things simple, we label them as good 0 and good 1.\n\nThe demand for each good depends on the price of both goods:\\begin{aligned}\n    q_0^d = 100 - 10 p_0 - 5 p_1 \\\\\n    q_1^d = 50 - p_0 - 10 p_1\n\\end{aligned}\n\n(We are assuming demand decreases when the price of either good goes up, but\nother cases are also possible.)\n\nLet’s suppose that supply is given by\\begin{aligned}\n    q_0^s = 10 p_0 + 5 p_1 \\\\\n    q_1^s = 5 p_0 + 10 p_1\n\\end{aligned}\n\nEquilibrium holds when supply equals demand (q_0^s = q_0^d and q_1^s = q_1^d).\n\nThis yields the linear system\\begin{aligned}\n    100 - 10 p_0 - 5 p_1 = 10 p_0 + 5 p_1 \\\\\n    50 - p_0 - 10 p_1 = 5 p_0 + 10 p_1\n\\end{aligned}\n\nWe can solve this with pencil and paper to getp_0 = 4.41 \\quad \\text{and} \\quad p_1 = 1.18.\n\nInserting these results into either \n\n(1) or \n\n(2) yields the\nequilibrium quantitiesq_0 = 50 \\quad \\text{and} \\quad q_1 = 33.82.","type":"content","url":"/linear-equations#pencil-and-paper-methods","position":7},{"hierarchy":{"lvl1":"Linear Equations and Matrix Algebra","lvl3":"Looking forward","lvl2":"A two good example"},"type":"lvl3","url":"/linear-equations#looking-forward","position":8},{"hierarchy":{"lvl1":"Linear Equations and Matrix Algebra","lvl3":"Looking forward","lvl2":"A two good example"},"content":"Pencil and paper methods are easy in the two good case.\n\nBut what if there are many goods?\n\nFor such problems we need matrix algebra.\n\nBefore solving problems with matrix algebra, let’s first recall the\nbasics of vectors and matrices, in both theory and computation.","type":"content","url":"/linear-equations#looking-forward","position":9},{"hierarchy":{"lvl1":"Linear Equations and Matrix Algebra","lvl2":"Vectors "},"type":"lvl2","url":"/linear-equations#vectors","position":10},{"hierarchy":{"lvl1":"Linear Equations and Matrix Algebra","lvl2":"Vectors "},"content":"A vector of length n is just a sequence (or array, or tuple) of n numbers, which we write as x = (x_1, \\ldots, x_n) or x = \\begin{bmatrix}x_1, \\ldots, x_n\\end{bmatrix}.\n\nWe can write these sequences either horizontally or vertically.\n\nBut when we use matrix operations, our default assumption is that vectors are\ncolumn vectors.\n\nThe set of all n-vectors is denoted by \\mathbb R^n.\n\n\\mathbb R^2 is the plane --- the set of pairs (x_1, x_2).\n\n\\mathbb R^3 is 3 dimensional space --- the set of vectors (x_1, x_2, x_3).\n\nOften vectors are represented visually as arrows from the origin to the point.\n\nHere’s a visualization.\n\nfig, ax = plt.subplots()\n# Set the axes through the origin\nfor spine in ['left', 'bottom']:\n    ax.spines[spine].set_position('zero')\nfor spine in ['right', 'top']:\n    ax.spines[spine].set_color('none')\n\nax.set(xlim=(-5, 5), ylim=(-5, 5))\n\nvecs = ((2, 4), (-3, 3), (-4, -3.5))\nfor v in vecs:\n    ax.annotate('', xy=v, xytext=(0, 0),\n                arrowprops=dict(facecolor='blue',\n                shrink=0,\n                alpha=0.7,\n                width=0.5))\n    ax.text(1.1 * v[0], 1.1 * v[1], str(v))\nplt.show()\n\n","type":"content","url":"/linear-equations#vectors","position":11},{"hierarchy":{"lvl1":"Linear Equations and Matrix Algebra","lvl3":"Vector operations","lvl2":"Vectors "},"type":"lvl3","url":"/linear-equations#vector-operations","position":12},{"hierarchy":{"lvl1":"Linear Equations and Matrix Algebra","lvl3":"Vector operations","lvl2":"Vectors "},"content":"Sometimes we want to modify vectors.\n\nThe two most common operators on vectors are addition and scalar\nmultiplication, which we now describe.\n\nWhen we add two vectors, we add them element-by-element.\n\n\\begin{bmatrix}\n    4 \\\\\n    -2 \n\\end{bmatrix}\n+\n\\begin{bmatrix}\n    3 \\\\\n    3 \n\\end{bmatrix}\n=\n\\begin{bmatrix}\n    4 & + & 3 \\\\\n    -2 & + & 3 \n\\end{bmatrix}\n=\n\\begin{bmatrix}\n    7 \\\\\n    1\n\\end{bmatrix}.\n\nIn general,x + y =\n\\begin{bmatrix}\n    x_1 \\\\\n    x_2 \\\\\n    \\vdots \\\\\n    x_n\n\\end{bmatrix} +\n\\begin{bmatrix}\n     y_1 \\\\\n     y_2 \\\\\n    \\vdots \\\\\n     y_n\n\\end{bmatrix} :=\n\\begin{bmatrix}\n    x_1 + y_1 \\\\\n    x_2 + y_2 \\\\\n    \\vdots \\\\\n    x_n + y_n\n\\end{bmatrix}.\n\nWe can visualise vector addition in \\mathbb{R}^2 as follows.\n\nfig, ax = plt.subplots()\n# Set the axes through the origin\nfor spine in ['left', 'bottom']:\n    ax.spines[spine].set_position('zero')\nfor spine in ['right', 'top']:\n    ax.spines[spine].set_color('none')\n\nax.set(xlim=(-2, 10), ylim=(-4, 4))\n# ax.grid()\nvecs = ((4, -2), (3, 3), (7, 1))\ntags = ('(x1, x2)', '(y1, y2)', '(x1+x2, y1+y2)')\ncolors = ('blue', 'green', 'red')\nfor i, v in enumerate(vecs):\n    ax.annotate('', xy=v, xytext=(0, 0),\n                arrowprops=dict(color=colors[i],\n                shrink=0,\n                alpha=0.7,\n                width=0.5,\n                headwidth=8,\n                headlength=15))\n    ax.text(v[0] + 0.2, v[1] + 0.1, tags[i])\n\nfor i, v in enumerate(vecs):\n    ax.annotate('', xy=(7, 1), xytext=v,\n                arrowprops=dict(color='gray',\n                shrink=0,\n                alpha=0.3,\n                width=0.5,\n                headwidth=5,\n                headlength=20))\nplt.show()\n\nScalar multiplication is an operation that multiplies a vector x with a scalar elementwise.\n\n-2\n\\begin{bmatrix}\n    3 \\\\\n    -7 \n\\end{bmatrix}\n=\n\\begin{bmatrix}\n    -2 & \\times & 3 \\\\\n    -2 & \\times & -7\n\\end{bmatrix}\n=\n\\begin{bmatrix}\n    -6 \\\\\n    14\n\\end{bmatrix}.\n\nMore generally, it takes a number \\gamma and a vector x and produces\\gamma x :=\n\\begin{bmatrix}\n    \\gamma x_1 \\\\\n    \\gamma x_2 \\\\\n    \\vdots \\\\\n    \\gamma x_n\n\\end{bmatrix}.\n\nScalar multiplication is illustrated in the next figure.\n\nfig, ax = plt.subplots()\n# Set the axes through the origin\nfor spine in ['left', 'bottom']:\n    ax.spines[spine].set_position('zero')\nfor spine in ['right', 'top']:\n    ax.spines[spine].set_color('none')\n\nax.set(xlim=(-5, 5), ylim=(-5, 5))\nx = (2, 2)\nax.annotate('', xy=x, xytext=(0, 0),\n            arrowprops=dict(facecolor='blue',\n            shrink=0,\n            alpha=1,\n            width=0.5))\nax.text(x[0] + 0.4, x[1] - 0.2, '$x$', fontsize='16')\n\nscalars = (-2, 2)\nx = np.array(x)\n\nfor s in scalars:\n    v = s * x\n    ax.annotate('', xy=v, xytext=(0, 0),\n                arrowprops=dict(facecolor='red',\n                shrink=0,\n                alpha=0.5,\n                width=0.5))\n    ax.text(v[0] + 0.4, v[1] - 0.2, f'${s} x$', fontsize='16')\nplt.show()\n\nIn Python, a vector can be represented as a list or tuple,\nsuch as x = [2, 4, 6] or x = (2, 4, 6).\n\nHowever, it is more common to represent vectors with\n\n\nNumPy arrays.\n\nOne advantage of NumPy arrays is that scalar multiplication and addition have\nvery natural syntax.\n\nx = np.ones(3)            # Vector of three ones\ny = np.array((2, 4, 6))   # Converts tuple (2, 4, 6) into a NumPy array\nx + y                     # Add (element-by-element)\n\n4 * x                     # Scalar multiply\n\n","type":"content","url":"/linear-equations#vector-operations","position":13},{"hierarchy":{"lvl1":"Linear Equations and Matrix Algebra","lvl3":"Inner product and norm","lvl2":"Vectors "},"type":"lvl3","url":"/linear-equations#inner-product-and-norm","position":14},{"hierarchy":{"lvl1":"Linear Equations and Matrix Algebra","lvl3":"Inner product and norm","lvl2":"Vectors "},"content":"The inner product of vectors x,y \\in \\mathbb R^n is defined asx^\\top y = \n\\begin{bmatrix}\n    \\color{red}{x_1} & \\color{blue}{x_2} & \\cdots & x_n\n\\end{bmatrix}\n\\begin{bmatrix}\n    \\color{red}{y_1} \\\\\n    \\color{blue}{y_2} \\\\\n    \\vdots \\\\\n    y_n\n\\end{bmatrix}\n= {\\color{red}{x_1 y_1}} + {\\color{blue}{x_2 y_2}} + \\cdots + x_n y_n\n:= \\sum_{i=1}^n x_i y_i.\n\nThe norm of a vector x represents its “length” (i.e., its distance from\nthe zero vector) and is defined as\\| x \\| := \\sqrt{x^\\top x} := \\left( \\sum_{i=1}^n x_i^2 \\right)^{1/2}.\n\nThe expression \\| x - y\\| can be thought of as the “distance” between x and y.\n\nThe inner product and norm can be computed as follows\n\nnp.sum(x*y)      # Inner product of x and y\n\nx @ y            # Another way to compute the inner product\n\nnp.sqrt(np.sum(x**2))  # Norm of x, method one\n\nnp.linalg.norm(x)      # Norm of x, method two\n\n","type":"content","url":"/linear-equations#inner-product-and-norm","position":15},{"hierarchy":{"lvl1":"Linear Equations and Matrix Algebra","lvl2":"Matrix operations"},"type":"lvl2","url":"/linear-equations#matrix-operations","position":16},{"hierarchy":{"lvl1":"Linear Equations and Matrix Algebra","lvl2":"Matrix operations"},"content":"When we discussed linear price systems, we mentioned using matrix algebra.\n\nMatrix algebra is similar to algebra for numbers.\n\nLet’s review some details.","type":"content","url":"/linear-equations#matrix-operations","position":17},{"hierarchy":{"lvl1":"Linear Equations and Matrix Algebra","lvl3":"Addition and scalar multiplication","lvl2":"Matrix operations"},"type":"lvl3","url":"/linear-equations#addition-and-scalar-multiplication","position":18},{"hierarchy":{"lvl1":"Linear Equations and Matrix Algebra","lvl3":"Addition and scalar multiplication","lvl2":"Matrix operations"},"content":"Just as was the case for vectors, we can add, subtract and scalar multiply\nmatrices.\n\nScalar multiplication and addition are generalizations of the vector case:\n\n3\n\\begin{bmatrix}\n    2 & -13 \\\\\n    0 & 5\n\\end{bmatrix}\n=\n\\begin{bmatrix}\n    6 & -39 \\\\\n    0 & 15\n\\end{bmatrix}.\n\nIn general for a number \\gamma and any matrix A,\\gamma A =\n\\gamma\n\\begin{bmatrix}\n    a_{11} &  \\cdots & a_{1k} \\\\\n    \\vdots & \\vdots  & \\vdots \\\\\n    a_{n1} &  \\cdots & a_{nk}\n\\end{bmatrix} :=\n\\begin{bmatrix}\n    \\gamma a_{11} & \\cdots & \\gamma a_{1k} \\\\\n    \\vdots & \\vdots & \\vdots \\\\\n    \\gamma a_{n1} & \\cdots & \\gamma a_{nk}\n\\end{bmatrix}.\n\nConsider this example of matrix addition,\\begin{bmatrix}\n    1 & 5 \\\\\n    7 & 3 \\\\\n\\end{bmatrix}\n+\n\\begin{bmatrix}\n    12 & -1 \\\\\n    0 & 9\n\\end{bmatrix}\n=\n\\begin{bmatrix}\n    13 & 4 \\\\\n    7 & 12\n\\end{bmatrix}.\n\nIn general,A + B =\n\\begin{bmatrix}\n    a_{11} & \\cdots & a_{1k} \\\\\n    \\vdots & \\vdots & \\vdots \\\\\n    a_{n1} & \\cdots & a_{nk}\n\\end{bmatrix} +\n\\begin{bmatrix}\n    b_{11} & \\cdots & b_{1k} \\\\\n    \\vdots & \\vdots & \\vdots \\\\\n    b_{n1} & \\cdots & b_{nk}\n\\end{bmatrix} :=\n\\begin{bmatrix}\n    a_{11} + b_{11} &  \\cdots & a_{1k} + b_{1k} \\\\\n    \\vdots & \\vdots & \\vdots \\\\\n    a_{n1} + b_{n1} &  \\cdots & a_{nk} + b_{nk}\n\\end{bmatrix}.\n\nIn the latter case, the matrices must have the same shape in order for the\ndefinition to make sense.","type":"content","url":"/linear-equations#addition-and-scalar-multiplication","position":19},{"hierarchy":{"lvl1":"Linear Equations and Matrix Algebra","lvl3":"Matrix multiplication","lvl2":"Matrix operations"},"type":"lvl3","url":"/linear-equations#matrix-multiplication","position":20},{"hierarchy":{"lvl1":"Linear Equations and Matrix Algebra","lvl3":"Matrix multiplication","lvl2":"Matrix operations"},"content":"We also have a convention for multiplying two matrices.\n\nThe rule for matrix multiplication generalizes the idea of inner products\ndiscussed above.\n\nIf A and B are two matrices, then their product A B is formed by taking\nas its i,j-th element the inner product of the i-th row of A and the\nj-th column of B.\n\nIf A is n \\times k and B is j \\times m, then to multiply A and B\nwe require k = j, and the resulting matrix A B is n \\times m.\n\nHere’s an example of a 2 \\times 2 matrix multiplied by a 2 \\times 1 vector.Ax =\n\\begin{bmatrix}\n    \\color{red}{a_{11}} & \\color{red}{a_{12}} \\\\\n    a_{21} & a_{22}\n\\end{bmatrix}\n\\begin{bmatrix}\n    \\color{red}{x_1} \\\\\n    \\color{red}{x_2}\n\\end{bmatrix}\n=\n\\begin{bmatrix}\n    \\color{red}{a_{11}x_1 + a_{12}x_2} \\\\\n    a_{21}x_1 + a_{22}x_2\n\\end{bmatrix}\n\nAs an important special case, consider multiplying n \\times k\nmatrix A and k \\times 1 column vector x.\n\nAccording to the preceding rule, this gives us an n \\times 1 column vector.A x =\n{\\begin{bmatrix}\n    a_{11} & a_{12} &  \\cdots & a_{1k} \\\\\n    \\vdots & \\vdots & & \\vdots \\\\\n    \\color{red}{a_{i1}} & \\color{red}{a_{i2}} & \\color{red}{\\cdots} & \\color{red}{a_{i}k} \\\\\n    \\vdots & \\vdots & & \\vdots \\\\\n    a_{n1} & a_{n2} & \\cdots & a_{nk}\n\\end{bmatrix}}_{n \\times k}\n{\\begin{bmatrix}\n    \\color{red}{x_{1}}  \\\\\n    \\color{red}{x_{2}}  \\\\\n    \\color{red}{\\vdots} \\\\\n    \\color{red}{\\vdots}  \\\\\n    \\color{red}{x_{k}}\n\\end{bmatrix}}_{k \\times 1} :=\n{\\begin{bmatrix}\n    a_{11} x_1 + a_{22} x_2 + \\cdots + a_{1k} x_k \\\\\n    \\vdots \\\\\n    \\color{red}{a_{i1} x_1 + a_{i2} x_2 + \\cdots + a_{ik} x_k} \\\\\n    \\vdots \\\\\n    a_{n1} x_1 + a_{n2} x_2 + \\cdots + a_{nk} x_k\n\\end{bmatrix}}_{n \\times 1}\n\nHere is a simple illustration of multiplication of two matrices.AB =\n\\begin{bmatrix}\n    a_{11} & a_{12} \\\\\n    \\color{red}{a_{21}} & \\color{red}{a_{22}} \\\\\n\\end{bmatrix}\n\\begin{bmatrix}\n    b_{11} & \\color{red}{b_{12}} \\\\\n    b_{21} & \\color{red}{b_{22}} \\\\\n\\end{bmatrix} :=\n\\begin{bmatrix}\n    a_{11}b_{11} + a_{12}b_{21} & a_{11}b_{12} + a_{12}b_{22} \\\\\n    a_{21}b_{11} + a_{22}b_{21} & \\color{red}{a_{21}b_{12} + a_{22}b_{22}}\n\\end{bmatrix}\n\nThere are many tutorials to help you further visualize this operation, such as\n\nthis one, or\n\nthe discussion on the \n\nWikipedia page.\n\nNote\n\nUnlike number products, A B and B A are not generally the same thing.\n\nOne important special case is the \n\nidentity matrix, which has ones on the principal diagonal and zero elsewhere:I = \n    \\begin{bmatrix}\n        1 & \\cdots & 0 \\\\\n        \\vdots & \\ddots & \\vdots \\\\\n        0 &  \\cdots & 1\n    \\end{bmatrix}\n\nIt is a useful exercise to check the following:\n\nif A is n \\times k and I is the k \\times k identity matrix, then AI = A, and\n\nif I is the n \\times n identity matrix, then IA = A.","type":"content","url":"/linear-equations#matrix-multiplication","position":21},{"hierarchy":{"lvl1":"Linear Equations and Matrix Algebra","lvl3":"Matrices in NumPy","lvl2":"Matrix operations"},"type":"lvl3","url":"/linear-equations#matrices-in-numpy","position":22},{"hierarchy":{"lvl1":"Linear Equations and Matrix Algebra","lvl3":"Matrices in NumPy","lvl2":"Matrix operations"},"content":"NumPy arrays are also used as matrices, and have fast, efficient functions and methods for all the standard matrix operations.\n\nYou can create them manually from tuples of tuples (or lists of lists) as follows\n\nA = ((1, 2),\n     (3, 4))\n\ntype(A)\n\nA = np.array(A)\n\ntype(A)\n\nA.shape\n\nThe shape attribute is a tuple giving the number of rows and columns ---\nsee \n\nhere\nfor more discussion.\n\nTo get the transpose of A, use A.transpose() or, more simply, A.T.\n\nThere are many convenient functions for creating common matrices (matrices of zeros,\nones, etc.) --- see \n\nhere.\n\nSince operations are performed elementwise by default, scalar multiplication and addition have very natural syntax.\n\nA = np.identity(3)    # 3 x 3 identity matrix\nB = np.ones((3, 3))   # 3 x 3 matrix of ones\n2 * A\n\nA + B\n\nTo multiply matrices we use the @ symbol.\n\nNote\n\nIn particular, A @ B is matrix multiplication, whereas A * B is element-by-element multiplication.","type":"content","url":"/linear-equations#matrices-in-numpy","position":23},{"hierarchy":{"lvl1":"Linear Equations and Matrix Algebra","lvl3":"Two good model in matrix form","lvl2":"Matrix operations"},"type":"lvl3","url":"/linear-equations#two-good-model-in-matrix-form","position":24},{"hierarchy":{"lvl1":"Linear Equations and Matrix Algebra","lvl3":"Two good model in matrix form","lvl2":"Matrix operations"},"content":"We can now revisit the two good model and solve \n\n(3)\nnumerically via matrix algebra.\n\nThis involves some extra steps but the method is widely applicable --- as we\nwill see when we include more goods.\n\nFirst we rewrite \n\n(1) as    q^d = D p + h\n    \\quad \\text{where} \\quad\n    q^d = \n    \\begin{bmatrix}\n        q_0^d \\\\\n        q_1^d\n    \\end{bmatrix}\n    \\quad\n    D = \n    \\begin{bmatrix}\n         -10 & - 5  \\\\\n         - 1  & - 10  \n    \\end{bmatrix}\n    \\quad \\text{and} \\quad\n    h =\n    \\begin{bmatrix}\n        100 \\\\\n        50\n    \\end{bmatrix}.\n\nRecall that p \\in \\mathbb{R}^{2} is the price of two goods.\n\n(Please check that q^d = D p + h represents the same equations as \n\n(1).)\n\nWe rewrite \n\n(2) as    q^s = C p \n    \\quad \\text{where} \\quad\n    q^s = \n    \\begin{bmatrix}\n        q_0^s \\\\\n        q_1^s\n    \\end{bmatrix}\n    \\quad \\text{and} \\quad\n    C = \n    \\begin{bmatrix}\n         10 & 5  \\\\\n         5 & 10  \n    \\end{bmatrix}.\n\nNow equality of supply and demand can be expressed as q^s = q^d, orC p = D p + h.\n\nWe can rearrange the terms to get(C - D) p = h.\n\nIf all of the terms were numbers, we could solve for prices as p = h /\n(C-D).\n\nMatrix algebra allows us to do something similar: we can solve for equilibrium\nprices using the inverse of C - D:    p = (C - D)^{-1} h.\n\nBefore we implement the solution let us consider a more general setting.","type":"content","url":"/linear-equations#two-good-model-in-matrix-form","position":25},{"hierarchy":{"lvl1":"Linear Equations and Matrix Algebra","lvl3":"More goods","lvl2":"Matrix operations"},"type":"lvl3","url":"/linear-equations#more-goods","position":26},{"hierarchy":{"lvl1":"Linear Equations and Matrix Algebra","lvl3":"More goods","lvl2":"Matrix operations"},"content":"It is natural to think about demand systems with more goods.\n\nFor example, even within energy commodities there are many different goods,\nincluding crude oil, gasoline, coal, natural gas, ethanol, and uranium.\n\nThe prices of these goods are related, so it makes sense to study them\ntogether.\n\nPencil and paper methods become very time consuming with large systems.\n\nBut fortunately the matrix methods described above are essentially unchanged.\n\nIn general, we can write the demand equation as q^d = Dp + h, where\n\nq^d is an n \\times 1 vector of demand quantities for n different goods.\n\nD is an n \\times n “coefficient” matrix.\n\nh is an n \\times 1 vector of constant values.\n\nSimilarly, we can write the supply equation as q^s = Cp + e, where\n\nq^s is an n \\times 1 vector of supply quantities for the same goods.\n\nC is an n \\times n “coefficient” matrix.\n\ne is an n \\times 1 vector of constant values.\n\nTo find an equilibrium, we solve Dp + h = Cp + e, or    (D- C)p = e - h.\n\nThen the price vector of the n different goods isp = (D- C)^{-1}(e - h).","type":"content","url":"/linear-equations#more-goods","position":27},{"hierarchy":{"lvl1":"Linear Equations and Matrix Algebra","lvl3":"General linear systems","lvl2":"Matrix operations"},"type":"lvl3","url":"/linear-equations#general-linear-systems","position":28},{"hierarchy":{"lvl1":"Linear Equations and Matrix Algebra","lvl3":"General linear systems","lvl2":"Matrix operations"},"content":"A more general version of the problem described above looks as follows.\\begin{matrix}\n    a_{11} x_1 & + & a_{12} x_2 & + & \\cdots & + & a_{1n} x_n & = & b_1 \\\\\n    \\vdots & & \\vdots & & & & \\vdots & & \\vdots \\\\\n    a_{n1} x_1 & + & a_{n2} x_2 & + & \\cdots & + & a_{nn} x_n & = & b_n\n\\end{matrix}\n\nThe objective here is to solve for the “unknowns” x_1, \\ldots, x_n.\n\nWe take as given the coefficients a_{11}, \\ldots, a_{nn} and constants b_1, \\ldots, b_n.\n\nNotice that we are treating a setting where the number of unknowns equals the\nnumber of equations.\n\nThis is the case where we are most likely to find a well-defined solution.\n\n(The other cases are referred to as \n\noverdetermined and \n\nunderdetermined systems\nof equations --- we defer discussion of these cases until later lectures.)\n\nIn matrix form, the system \n\n(27) becomes    A x = b\n    \\quad \\text{where} \\quad\n    A = \n    \\begin{bmatrix}\n        a_{11} &  \\cdots & a_{1n} \\\\\n        \\vdots & \\vdots  & \\vdots \\\\\n        a_{n1} &  \\cdots & a_{nn}\n    \\end{bmatrix}\n    \\quad \\text{and} \\quad\n    b =\n    \\begin{bmatrix}\n        b_1 \\\\\n        \\vdots \\\\\n        b_n\n    \\end{bmatrix}.\n\nFor example, \n\n(25) has this form withA = D - C, \n    \\quad\n    b = e - h\n    \\quad \\text{and} \\quad\n    x = p.\n\nWhen considering problems such as \n\n(28), we need to ask at least some of\nthe following questions\n\nDoes a solution actually exist?\n\nIf a solution exists, how should we compute it?","type":"content","url":"/linear-equations#general-linear-systems","position":29},{"hierarchy":{"lvl1":"Linear Equations and Matrix Algebra","lvl2":"Solving systems of equations"},"type":"lvl2","url":"/linear-equations#solving-systems-of-equations","position":30},{"hierarchy":{"lvl1":"Linear Equations and Matrix Algebra","lvl2":"Solving systems of equations"},"content":"Recall again the system of equations \n\n(27), which we write here again as    A x = b.\n\nThe problem we face is to find a vector x \\in \\mathbb R^n that solves\n\n\n(30), taking b and A as given.\n\nWe may not always find a unique vector x that solves \n\n(30).\n\nWe illustrate two such cases below.","type":"content","url":"/linear-equations#solving-systems-of-equations","position":31},{"hierarchy":{"lvl1":"Linear Equations and Matrix Algebra","lvl3":"No solution","lvl2":"Solving systems of equations"},"type":"lvl3","url":"/linear-equations#no-solution","position":32},{"hierarchy":{"lvl1":"Linear Equations and Matrix Algebra","lvl3":"No solution","lvl2":"Solving systems of equations"},"content":"Consider the system of equations given by,\\begin{aligned}\n    x + 3y &= 3 \\\\\n    2x + 6y &= -8.\n\\end{aligned}\n\nIt can be verified manually that this system has no possible solution.\n\nTo illustrate why this situation arises let’s plot the two lines.\n\nfig, ax = plt.subplots()\nx = np.linspace(-10, 10)\nplt.plot(x, (3-x)/3, label=f'$x + 3y = 3$')\nplt.plot(x, (-8-2*x)/6, label=f'$2x + 6y = -8$')\nplt.legend()\nplt.show()\n\nClearly, these are parallel lines and hence we will never find a point x \\in \\mathbb{R}^2\nsuch that these lines intersect.\n\nThus, this system has no possible solution.\n\nWe can rewrite this system in matrix form as    A x = b\n    \\quad \\text{where} \\quad\n    A =\n    \\begin{bmatrix}\n        1 & 3 \\\\\n        2 & 6 \n    \\end{bmatrix}\n    \\quad \\text{and} \\quad\n    b =\n    \\begin{bmatrix}\n        3 \\\\\n        -8\n    \\end{bmatrix}.\n\nIt can be noted that the 2^{nd} row of matrix A = (2, 6) is just a scalar multiple of the 1^{st} row of matrix A = (1, 3).\n\nThe rows of matrix A in this case are called linearly dependent.\n\nNote\n\nAdvanced readers can find a detailed explanation of linear dependence and\nindependence \n\nhere.\n\nBut these details are not needed in what follows.","type":"content","url":"/linear-equations#no-solution","position":33},{"hierarchy":{"lvl1":"Linear Equations and Matrix Algebra","lvl3":"Many solutions","lvl2":"Solving systems of equations"},"type":"lvl3","url":"/linear-equations#many-solutions","position":34},{"hierarchy":{"lvl1":"Linear Equations and Matrix Algebra","lvl3":"Many solutions","lvl2":"Solving systems of equations"},"content":"Now consider,\\begin{aligned}\n    x - 2y &= -4 \\\\\n    -2x + 4y &= 8.\n\\end{aligned}\n\nAny vector v = (x,y) such that x = 2y - 4 will solve the above system.\n\nSince we can find infinite such vectors this system has infinitely many solutions.\n\nThis is because the rows of the corresponding matrix    A =\n    \\begin{bmatrix}\n        1 & -2 \\\\\n        -2 & 4\n    \\end{bmatrix}.\n\nare linearly dependent --- can you see why?\n\nWe now impose conditions on A in \n\n(30) that rule out these problems.","type":"content","url":"/linear-equations#many-solutions","position":35},{"hierarchy":{"lvl1":"Linear Equations and Matrix Algebra","lvl3":"Nonsingular matrices","lvl2":"Solving systems of equations"},"type":"lvl3","url":"/linear-equations#nonsingular-matrices","position":36},{"hierarchy":{"lvl1":"Linear Equations and Matrix Algebra","lvl3":"Nonsingular matrices","lvl2":"Solving systems of equations"},"content":"To every square matrix we can assign a unique number called the\n\n\ndeterminant.\n\nFor 2 \\times 2 matrices, the determinant is given by,\\begin{bmatrix}\n    \\color{red}{a} & \\color{blue}{b} \\\\\n    \\color{blue}{c} & \\color{red}{d}\n\\end{bmatrix}\n=\n{\\color{red}{ad}} - {\\color{blue}{bc}}.\n\nIf the determinant of A is not zero, then we say that A is nonsingular.\n\nA square matrix A is nonsingular if and only if the rows and columns of A\nare linearly independent.\n\nA more detailed explanation of matrix inverse can be found \n\nhere.\n\nYou can check yourself that the in \n\n(32) and \n\n(34) with\nlinearly dependent rows are singular matrices.\n\nThis gives us a useful one-number summary of whether or not a square matrix\ncan be inverted.\n\nIn particular, a square matrix A has a nonzero determinant, if and only if\nit possesses an inverse matrix A^{-1}, with the property that A A^{-1} =\nA^{-1} A = I.\n\nAs a consequence, if we pre-multiply both sides of Ax = b by A^{-1}, we\nget    x = A^{-1} b.\n\nThis is the solution to Ax = b --- the solution we are looking for.","type":"content","url":"/linear-equations#nonsingular-matrices","position":37},{"hierarchy":{"lvl1":"Linear Equations and Matrix Algebra","lvl3":"Linear equations with NumPy","lvl2":"Solving systems of equations"},"type":"lvl3","url":"/linear-equations#linear-equations-with-numpy","position":38},{"hierarchy":{"lvl1":"Linear Equations and Matrix Algebra","lvl3":"Linear equations with NumPy","lvl2":"Solving systems of equations"},"content":"In the two good example we obtained the matrix equation,p = (C-D)^{-1} h.\n\nwhere C, D and h are given by \n\n(20) and \n\n(21).\n\nThis equation is analogous to \n\n(36) with A = (C-D)^{-1}, b = h, and x = p.\n\nWe can now solve for equilibrium prices with NumPy’s linalg submodule.\n\nAll of these routines are Python front ends to time-tested and highly optimized FORTRAN code.\n\nC = ((10, 5),      # Matrix C\n     (5, 10))\n\nNow we change this to a NumPy array.\n\nC = np.array(C)\n\n\n\nD = ((-10, -5),     # Matrix D\n     (-1, -10))\nD = np.array(D)\n\n\n\nh = np.array((100, 50))   # Vector h\nh.shape = 2,1             # Transforming h to a column vector\n\n\n\nfrom numpy.linalg import det, inv\nA = C - D\n# Check that A is nonsingular (non-zero determinant), and hence invertible\ndet(A)\n\n\n\nA_inv = inv(A)  # compute the inverse\nA_inv\n\n\n\np = A_inv @ h  # equilibrium prices\np\n\n\n\nq = C @ p  # equilibrium quantities\nq\n\nNotice that we get the same solutions as the pencil and paper case.\n\nWe can also solve for p using solve(A, h) as follows.\n\nfrom numpy.linalg import solve\np = solve(A, h)  # equilibrium prices\np\n\n\n\nq = C @ p  # equilibrium quantities\nq\n\nObserve how we can solve for x = A^{-1} y by either via inv(A) @ y, or using solve(A, y).\n\nThe latter method uses a different algorithm that is numerically more stable and hence should be the default option.","type":"content","url":"/linear-equations#linear-equations-with-numpy","position":39},{"hierarchy":{"lvl1":"Linear Equations and Matrix Algebra","lvl2":"Exercises"},"type":"lvl2","url":"/linear-equations#exercises","position":40},{"hierarchy":{"lvl1":"Linear Equations and Matrix Algebra","lvl2":"Exercises"},"content":"Let’s consider a market with 3 commodities - good 0, good 1 and good 2.\n\nThe demand for each good depends on the price of the other two goods and is given by:\\begin{aligned}\n    q_0^d & = 90 - 15p_0 + 5p_1 + 5p_2 \\\\\n    q_1^d & = 60 + 5p_0 - 10p_1 + 10p_2 \\\\\n    q_2^d & = 50 + 5p_0 + 5p_1 - 5p_2\n\\end{aligned}\n\n(Here demand decreases when own price increases but increases when prices of other goods increase.)\n\nThe supply of each good is given by:\\begin{aligned}\n    q_0^s & = -10 + 20p_0 \\\\\n    q_1^s & = -15 + 15p_1 \\\\\n    q_2^s & =  -5 + 10p_2\n\\end{aligned}\n\nEquilibrium holds when supply equals demand, i.e, q_0^d = q_0^s, q_1^d = q_1^s and q_2^d = q_2^s.\n\nSet up the market as a system of linear equations.\n\nUse matrix algebra to solve for equilibrium prices. Do this using both the numpy.linalg.solve\nand inv(A) methods. Compare the solutions.\n\nSolution to \n\nExercise 1\n\nThe generated system would be:\\begin{aligned}\n    35p_0 - 5p_1 - 5p_2 = 100 \\\\\n    -5p_0 + 25p_1 - 10p_2 = 75 \\\\\n    -5p_0 - 5p_1 + 15p_2 = 55\n\\end{aligned}\n\nIn matrix form we will write this as:Ap = b\n\\quad \\text{where} \\quad\nA =\n\\begin{bmatrix}\n    35 & -5 & -5 \\\\\n    -5 & 25 & -10 \\\\\n    -5 & -5 & 15\n\\end{bmatrix}\n, \\quad p =\n\\begin{bmatrix}\n    p_0 \\\\\n    p_1 \\\\\n    p_2\n\\end{bmatrix}\n\\quad \\text{and} \\quad\nb = \n\\begin{bmatrix}\n    100 \\\\\n    75 \\\\\n    55\n\\end{bmatrix}\n\nimport numpy as np\nfrom numpy.linalg import det\n\nA = np.array([[35, -5, -5],  # matrix A\n              [-5, 25, -10],\n              [-5, -5, 15]])\n\nb = np.array((100, 75, 55))  # column vector b\nb.shape = (3, 1)\n\ndet(A)  # check if A is nonsingular\n\n\n\n# Using inverse\nfrom numpy.linalg import det\n\nA_inv = inv(A)\n\np = A_inv @ b\np\n\n\n\n# Using numpy.linalg.solve\nfrom numpy.linalg import solve\np = solve(A, b)\np\n\nThe solution is given by:p_0 = 4.6925, \\; p_1 = 7.0625 \\;\\; \\text{and} \\;\\; p_2 = 7.675\n\nEarlier in the lecture we discussed cases where the system of equations given by Ax = b has no solution.\n\nIn this case Ax = b is called an inconsistent system of equations.\n\nWhen faced with an inconsistent system we try to find the best “approximate” solution.\n\nThere are various methods to do this, one such method is the method of least squares.\n\nSuppose we have an inconsistent system    Ax = b\n\nwhere A is an m \\times n matrix and b is an m \\times 1 column vector.\n\nA least squares solution to \n\n(43) is an n \\times 1 column vector \\hat{x} such that, for all other vectors x \\in \\mathbb{R}^n, the distance from A\\hat{x} to b\nis less than the distance from Ax to b.\n\nThat is,\\|A\\hat{x} - b\\| \\leq \\|Ax - b\\|\n\nIt can be shown that, for the system of equations Ax = b, the least squares\nsolution \\hat{x} is    \\hat{x} =  (A^T A)^{-1} A^T b\n\nNow consider the general equation of a linear demand curve of a good given by:p = m - nq\n\nwhere p is the price of the good and q is the quantity demanded.\n\nSuppose we are trying to estimate the values of m and n.\n\nWe do this by repeatedly observing the price and quantity (for example, each\nmonth) and then choosing m and n to fit the relationship between p and\nq.\n\nWe have the following observations:\n\nPrice\n\nQuantity Demanded\n\n1\n\n9\n\n3\n\n7\n\n8\n\n3\n\nRequiring the demand curve p = m - nq to pass through all these points leads to the\nfollowing three equations:\\begin{aligned}\n    1 = m - 9n \\\\\n    3 = m - 7n \\\\\n    8 = m - 3n\n\\end{aligned}\n\nThus we obtain a system of equations Ax = b where A = \\begin{bmatrix} 1 & -9 \\\\ 1 & -7 \\\\ 1 & -3 \\end{bmatrix},\nx = \\begin{bmatrix} m \\\\ n \\end{bmatrix} and b = \\begin{bmatrix} 1 \\\\ 3 \\\\ 8 \\end{bmatrix}.\n\nIt can be verified that this system has no solutions.\n\n(The problem is that we have three equations and only two unknowns.)\n\nWe will thus try to find the best approximate solution for x.\n\nUse \n\n(45) and matrix algebra to find the least squares solution \\hat{x}.\n\nFind the least squares solution using numpy.linalg.lstsq and compare the results.\n\nSolution to \n\nExercise 2\n\nimport numpy as np\nfrom numpy.linalg import inv\n\n\n\n# Using matrix algebra\nA = np.array([[1, -9],  # matrix A\n              [1, -7],\n              [1, -3]])\n\nA_T = np.transpose(A)  # transpose of matrix A\n\nb = np.array((1, 3, 8))  # column vector b\nb.shape = (3, 1)\n\nx = inv(A_T @ A) @ A_T @ b\nx\n\n\n\n# Using numpy.linalg.lstsq\nx, res, _, _ = np.linalg.lstsq(A, b, rcond=None)\n\n\n\nprint(f\"x\\u0302 = {x}\")\nprint(f\"\\u2016Ax\\u0302 - b\\u2016\\u00B2 = {res[0]}\")\n\nHere is a visualization of how the least squares method approximates the equation of a line connecting a set of points.\n\nWe can also describe this as “fitting” a line between a set of points.\n\nfig, ax = plt.subplots()\np = np.array((1, 3, 8))\nq = np.array((9, 7, 3))\n\na, b = x\n\nax.plot(q, p, 'o', label='observations', markersize=5)\nax.plot(q, a - b*q, 'r', label='Fitted line')\nplt.xlabel('quantity demanded')\nplt.ylabel('price')\nplt.legend()\nplt.show()\n\n","type":"content","url":"/linear-equations#exercises","position":41},{"hierarchy":{"lvl1":"Linear Equations and Matrix Algebra","lvl3":"Further reading","lvl2":"Exercises"},"type":"lvl3","url":"/linear-equations#further-reading","position":42},{"hierarchy":{"lvl1":"Linear Equations and Matrix Algebra","lvl3":"Further reading","lvl2":"Exercises"},"content":"The documentation of the numpy.linalg submodule can be found \n\nhere.\n\nMore advanced topics in linear algebra can be found \n\nhere.","type":"content","url":"/linear-equations#further-reading","position":43},{"hierarchy":{"lvl1":"LLN and CLT"},"type":"lvl1","url":"/lln-clt","position":0},{"hierarchy":{"lvl1":"LLN and CLT"},"content":"","type":"content","url":"/lln-clt","position":1},{"hierarchy":{"lvl1":"LLN and CLT","lvl2":"Overview"},"type":"lvl2","url":"/lln-clt#overview","position":2},{"hierarchy":{"lvl1":"LLN and CLT","lvl2":"Overview"},"content":"This lecture illustrates two of the most important results in probability and statistics:\n\nthe law of large numbers (LLN) and\n\nthe central limit theorem (CLT).\n\nThese beautiful theorems lie behind many of the most fundamental results in\neconometrics and quantitative economic modeling.\n\nThe lecture is based around simulations that show the LLN and CLT in action.\n\nWe also demonstrate how the LLN and CLT break down when the assumptions they\nare based on do not hold.\n\nThis lecture will focus on the univariate case (the multivariate case is treated \n\nin a more advanced lecture).\n\nWe’ll need the following imports:\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport scipy.stats as st\n\n","type":"content","url":"/lln-clt#overview","position":3},{"hierarchy":{"lvl1":"LLN and CLT","lvl2":"The law of large numbers"},"type":"lvl2","url":"/lln-clt#lln-mr","position":4},{"hierarchy":{"lvl1":"LLN and CLT","lvl2":"The law of large numbers"},"content":"We begin with the law of large numbers, which tells us when sample averages\nwill converge to their population means.","type":"content","url":"/lln-clt#lln-mr","position":5},{"hierarchy":{"lvl1":"LLN and CLT","lvl3":"The LLN in action","lvl2":"The law of large numbers"},"type":"lvl3","url":"/lln-clt#the-lln-in-action","position":6},{"hierarchy":{"lvl1":"LLN and CLT","lvl3":"The LLN in action","lvl2":"The law of large numbers"},"content":"Let’s see an example of the LLN in action before we go further.\n\nConsider a \n\nBernoulli random variable X with parameter p.\n\nThis means that X takes values in \\{0,1\\} and \\mathbb P\\{X=1\\} = p.\n\nWe can think of drawing X as tossing a biased coin where\n\nthe coin falls on “heads” with probability p and\n\nthe coin falls on “tails” with probability 1-p\n\nWe set X=1 if the coin is “heads” and zero otherwise.\n\nThe (population) mean of X is\\mathbb E X \n    = 0 \\cdot \\mathbb P\\{X=0\\} + 1 \\cdot \\mathbb P\\{X=1\\} = \\mathbb P\\{X=1\\} = p\n\nWe can generate a draw of X with scipy.stats (imported as st) as follows:\n\np = 0.8\nX = st.bernoulli.rvs(p)\nprint(X)\n\nIn this setting, the LLN tells us if we flip the coin many times, the fraction\nof heads that we see will be close to the mean p.\n\nWe use n to represent the number of times the coin is flipped.\n\nLet’s check this:\n\nn = 1_000_000\nX_draws = st.bernoulli.rvs(p, size=n)\nprint(X_draws.mean()) # count the number of 1's and divide by n\n\nIf we change p the claim still holds:\n\np = 0.3\nX_draws = st.bernoulli.rvs(p, size=n)\nprint(X_draws.mean())\n\nLet’s connect this to the discussion above, where we said the sample average\nconverges to the “population mean”.\n\nThink of X_1, \\ldots, X_n as independent flips of the coin.\n\nThe population mean is the mean in an infinite sample, which equals the\nexpectation \\mathbb E X.\n\nThe sample mean of the draws X_1, \\ldots, X_n is\\bar X_n := \\frac{1}{n} \\sum_{i=1}^n X_i\n\nIn this case, it is the fraction of draws that equal one (the number of heads divided by n).\n\nThus, the LLN tells us that for the Bernoulli trials above    \\bar X_n \\to \\mathbb E X = p\n    \\qquad (n \\to \\infty)\n\nThis is exactly what we illustrated in the code.","type":"content","url":"/lln-clt#the-lln-in-action","position":7},{"hierarchy":{"lvl1":"LLN and CLT","lvl3":"Statement of the LLN","lvl2":"The law of large numbers"},"type":"lvl3","url":"/lln-clt#lln-ksl","position":8},{"hierarchy":{"lvl1":"LLN and CLT","lvl3":"Statement of the LLN","lvl2":"The law of large numbers"},"content":"Let’s state the LLN more carefully.\n\nLet X_1, \\ldots, X_n be random variables, all of which have the same\ndistribution.\n\nThese random variables can be continuous or discrete.\n\nFor simplicity we will\n\nassume they are continuous and\n\nlet f denote their common density function\n\nThe last statement means that for any i in \\{1, \\ldots, n\\} and any\nnumbers a, b,\\mathbb P\\{a \\leq X_i \\leq b\\} = \\int_a^b f(x) dx\n\n(For the discrete case, we need to replace densities with probability mass\nfunctions and integrals with sums.)\n\nLet \\mu denote the common mean of this sample.\n\nThus, for each i,\\mu := \\mathbb E X_i = \\int_{-\\infty}^{\\infty} x f(x) dx\n\nThe sample mean is\\bar X_n := \\frac{1}{n} \\sum_{i=1}^n X_i\n\nThe next theorem is called Kolmogorov’s strong law of large numbers.\n\nIf X_1, \\ldots, X_n are IID and \\mathbb E |X| is finite, then\\mathbb P \\left\\{ \\bar X_n \\to \\mu \\text{ as } n \\to \\infty \\right\\} = 1\n\nHere\n\nIID means independent and identically distributed and\n\n\\mathbb E |X| = \\int_{-\\infty}^\\infty |x| f(x) dx","type":"content","url":"/lln-clt#lln-ksl","position":9},{"hierarchy":{"lvl1":"LLN and CLT","lvl3":"Comments on the theorem","lvl2":"The law of large numbers"},"type":"lvl3","url":"/lln-clt#comments-on-the-theorem","position":10},{"hierarchy":{"lvl1":"LLN and CLT","lvl3":"Comments on the theorem","lvl2":"The law of large numbers"},"content":"What does the probability one statement in the theorem mean?\n\nLet’s think about it from a simulation perspective, imagining for a moment that\nour computer can generate perfect random samples (although this \n\nisn’t strictly true).\n\nLet’s also imagine that we can generate infinite sequences so that the\nstatement \\bar X_n \\to \\mu can be evaluated.\n\nIn this setting, \n\n(7) should be interpreted as meaning that the\nprobability of the computer producing a sequence where \\bar X_n \\to \\mu\nfails to occur is zero.","type":"content","url":"/lln-clt#comments-on-the-theorem","position":11},{"hierarchy":{"lvl1":"LLN and CLT","lvl3":"Illustration","lvl2":"The law of large numbers"},"type":"lvl3","url":"/lln-clt#illustration","position":12},{"hierarchy":{"lvl1":"LLN and CLT","lvl3":"Illustration","lvl2":"The law of large numbers"},"content":"Let’s illustrate the LLN using simulation.\n\nWhen we illustrate it, we will use a key idea: the sample mean \\bar X_n is\nitself a random variable.\n\nThe reason \\bar X_n is a random variable is that it’s a function of the\nrandom variables X_1, \\ldots, X_n.\n\nWhat we are going to do now is\n\npick some fixed distribution to draw each X_i from\n\nset n to some large number\n\nand then repeat the following three instructions.\n\ngenerate the draws X_1, \\ldots, X_n\n\ncalculate the sample mean \\bar X_n and record its value in an array sample_means\n\ngo to step 1.\n\nWe will loop over these three steps m times, where m is some large integer.\n\nThe array sample_means will now contain m draws of the random variable \\bar X_n.\n\nIf we histogram these observations of \\bar X_n, we should see that they are clustered around the population mean \\mathbb E X.\n\nMoreover, if we repeat the exercise with a larger value of n, we should see that the observations are even more tightly clustered around the population mean.\n\nThis is, in essence, what the LLN is telling us.\n\nTo implement these steps, we will use functions.\n\nOur first function generates a sample mean of size n given a distribution.\n\ndef draw_means(X_distribution,  # The distribution of each X_i\n               n):              # The size of the sample mean\n\n    # Generate n draws: X_1, ..., X_n\n    X_samples = X_distribution.rvs(size=n)\n\n    # Return the sample mean\n    return np.mean(X_samples)\n\nNow we write a function to generate m sample means and histogram them.\n\ndef generate_histogram(X_distribution, n, m): \n\n    # Compute m sample means\n\n    sample_means = np.empty(m)\n    for j in range(m):\n      sample_means[j] = draw_means(X_distribution, n) \n\n    # Generate a histogram\n\n    fig, ax = plt.subplots()\n    ax.hist(sample_means, bins=30, alpha=0.5, density=True)\n    μ = X_distribution.mean()  # Get the population mean\n    σ = X_distribution.std()    # and the standard deviation\n    ax.axvline(x=μ, ls=\"--\", c=\"k\", label=fr\"$\\mu = {μ}$\")\n     \n    ax.set_xlim(μ - σ, μ + σ)\n    ax.set_xlabel(r'$\\bar X_n$', size=12)\n    ax.set_ylabel('density', size=12)\n    ax.legend()\n    plt.show()\n\nNow we call the function.\n\n# pick a distribution to draw each $X_i$ from\nX_distribution = st.norm(loc=5, scale=2) \n# Call the function\ngenerate_histogram(X_distribution, n=1_000, m=1000)\n\nWe can see that the distribution of \\bar X is clustered around \\mathbb E X\nas expected.\n\nLet’s vary n to see how the distribution of the sample mean changes.\n\nWe will use a \n\nviolin plot to show the different distributions.\n\nEach distribution in the violin plot represents the distribution of X_n for some n, calculated by simulation.\n\ndef means_violin_plot(distribution,  \n                      ns = [1_000, 10_000, 100_000],\n                      m = 1000):\n\n    data = []\n    for n in ns:\n        sample_means = [draw_means(distribution, n) for i in range(m)]\n        data.append(sample_means)\n\n    fig, ax = plt.subplots()\n\n    ax.violinplot(data)\n    μ = distribution.mean()\n    ax.axhline(y=μ, ls=\"--\", c=\"k\", label=fr\"$\\mu = {μ}$\")\n\n    labels=[fr'$n = {n}$' for n in ns]\n\n    ax.set_xticks(np.arange(1, len(labels) + 1), labels=labels)\n    ax.set_xlim(0.25, len(labels) + 0.75)\n\n\n    plt.subplots_adjust(bottom=0.15, wspace=0.05)\n\n    ax.set_ylabel('density', size=12)\n    ax.legend()\n    plt.show()\n\nLet’s try with a normal distribution.\n\nmeans_violin_plot(st.norm(loc=5, scale=2))\n\nAs n gets large, more probability mass clusters around the population mean \\mu.\n\nNow let’s try with a Beta distribution.\n\nmeans_violin_plot(st.beta(6, 6))\n\nWe get a similar result.\n\n","type":"content","url":"/lln-clt#illustration","position":13},{"hierarchy":{"lvl1":"LLN and CLT","lvl2":"Breaking the LLN"},"type":"lvl2","url":"/lln-clt#breaking-the-lln","position":14},{"hierarchy":{"lvl1":"LLN and CLT","lvl2":"Breaking the LLN"},"content":"We have to pay attention to the assumptions in the statement of the LLN.\n\nIf these assumptions do not hold, then the LLN might fail.","type":"content","url":"/lln-clt#breaking-the-lln","position":15},{"hierarchy":{"lvl1":"LLN and CLT","lvl3":"Infinite first moment","lvl2":"Breaking the LLN"},"type":"lvl3","url":"/lln-clt#infinite-first-moment","position":16},{"hierarchy":{"lvl1":"LLN and CLT","lvl3":"Infinite first moment","lvl2":"Breaking the LLN"},"content":"As indicated by the theorem, the LLN can break when \\mathbb E |X| is not finite.\n\nWe can demonstrate this using the \n\nCauchy distribution.\n\nThe Cauchy distribution has the following property:\n\nIf X_1, \\ldots, X_n are IID and Cauchy, then so is \\bar X_n.\n\nThis means that the distribution of \\bar X_n does not eventually concentrate on a single number.\n\nHence the LLN does not hold.\n\nThe LLN fails to hold here because the assumption \\mathbb E|X| < \\infty is violated by the Cauchy distribution.\n\n","type":"content","url":"/lln-clt#infinite-first-moment","position":17},{"hierarchy":{"lvl1":"LLN and CLT","lvl3":"Failure of the IID condition","lvl2":"Breaking the LLN"},"type":"lvl3","url":"/lln-clt#failure-of-the-iid-condition","position":18},{"hierarchy":{"lvl1":"LLN and CLT","lvl3":"Failure of the IID condition","lvl2":"Breaking the LLN"},"content":"The LLN can also fail to hold when the IID assumption is violated.\n\nX_0 \\sim N(0,1)\n    \\quad \\text{and} \\quad\n    X_i = X_{i-1} \\quad \\text{for} \\quad i = 1, ..., n\n\nIn this case,\\bar X_n = \\frac{1}{n} \\sum_{i=1}^n X_i = X_0 \\sim N(0,1)\n\nTherefore, the distribution of \\bar X_n is N(0,1) for all n!\n\nDoes this contradict the LLN, which says that the distribution of \\bar X_n\ncollapses to the single point \\mu?\n\nNo, the LLN is correct --- the issue is that its assumptions are not\nsatisfied.\n\nIn particular, the sequence X_1, \\ldots, X_n is not independent.\n\nNote\n\nAlthough in this case the violation of IID breaks the LLN, there are situations\nwhere IID fails but the LLN still holds.\n\nWe will show an example in the \n\nexercise.\n\n","type":"content","url":"/lln-clt#failure-of-the-iid-condition","position":19},{"hierarchy":{"lvl1":"LLN and CLT","lvl2":"Central limit theorem"},"type":"lvl2","url":"/lln-clt#central-limit-theorem","position":20},{"hierarchy":{"lvl1":"LLN and CLT","lvl2":"Central limit theorem"},"content":"Next, we turn to the central limit theorem (CLT), which tells us about the\ndistribution of the deviation between sample averages and population means.","type":"content","url":"/lln-clt#central-limit-theorem","position":21},{"hierarchy":{"lvl1":"LLN and CLT","lvl3":"Statement of the theorem","lvl2":"Central limit theorem"},"type":"lvl3","url":"/lln-clt#statement-of-the-theorem","position":22},{"hierarchy":{"lvl1":"LLN and CLT","lvl3":"Statement of the theorem","lvl2":"Central limit theorem"},"content":"The central limit theorem is one of the most remarkable results in all of mathematics.\n\nIn the IID setting, it tells us the following:\n\nIf X_1, \\ldots, X_n is IID with common mean \\mu and common variance\n\\sigma^2 \\in (0, \\infty), then\\sqrt{n} ( \\bar X_n - \\mu ) \\stackrel { d } {\\to} N(0, \\sigma^2)\n\\quad \\text{as} \\quad\nn \\to \\infty\n\nHere \\stackrel { d } {\\to} N(0, \\sigma^2) indicates \n\nconvergence in distribution to a centered (i.e., zero mean) normal with standard deviation \\sigma.\n\nThe striking implication of the CLT is that for any distribution with\nfinite \n\nsecond moment, the simple operation of adding independent\ncopies always leads to a Gaussian(Normal) curve.","type":"content","url":"/lln-clt#statement-of-the-theorem","position":23},{"hierarchy":{"lvl1":"LLN and CLT","lvl3":"Simulation 1","lvl2":"Central limit theorem"},"type":"lvl3","url":"/lln-clt#simulation-1","position":24},{"hierarchy":{"lvl1":"LLN and CLT","lvl3":"Simulation 1","lvl2":"Central limit theorem"},"content":"Since the CLT seems almost magical, running simulations that verify its implications is one good way to build understanding.\n\nTo this end, we now perform the following simulation\n\nChoose an arbitrary distribution F for the underlying observations X_i.\n\nGenerate independent draws of Y_n := \\sqrt{n} ( \\bar X_n - \\mu ).\n\nUse these draws to compute some measure of their distribution --- such as a histogram.\n\nCompare the latter to N(0, \\sigma^2).\n\nHere’s some code that does exactly this for the exponential distribution\nF(x) = 1 - e^{- \\lambda x}.\n\n(Please experiment with other choices of F, but remember that, to conform with the conditions of the CLT, the distribution must have a finite second moment.)\n\n# Set parameters\nn = 50         # Choice of n\nk = 10_000        # Number of draws of Y_n\ndistribution = st.expon(2) # Exponential distribution, λ = 1/2\nμ, σ = distribution.mean(), distribution.std()\n\n# Draw underlying RVs. Each row contains a draw of X_1,..,X_n\ndata = distribution.rvs((k, n))\n# Compute mean of each row, producing k draws of \\bar X_n\nsample_means = data.mean(axis=1)\n# Generate observations of Y_n\nY = np.sqrt(n) * (sample_means - μ)\n\n# Plot\nfig, ax = plt.subplots(figsize=(10, 6))\nxmin, xmax = -3 * σ, 3 * σ\nax.set_xlim(xmin, xmax)\nax.hist(Y, bins=60, alpha=0.4, density=True)\nxgrid = np.linspace(xmin, xmax, 200)\nax.plot(xgrid, st.norm.pdf(xgrid, scale=σ), \n        'k-', lw=2, label=r'$N(0, \\sigma^2)$')\nax.set_xlabel(r\"$Y_n$\", size=12)\nax.set_ylabel(r\"$density$\", size=12)\n\nax.legend()\n\nplt.show()\n\n(Notice the absence of for loops --- every operation is vectorized, meaning that the major calculations are all shifted to fast C code.)\n\nThe fit to the normal density is already tight and can be further improved by increasing n.","type":"content","url":"/lln-clt#simulation-1","position":25},{"hierarchy":{"lvl1":"LLN and CLT","lvl2":"Exercises"},"type":"lvl2","url":"/lln-clt#exercises","position":26},{"hierarchy":{"lvl1":"LLN and CLT","lvl2":"Exercises"},"content":"Repeat the simulation \n\nabove with the \n\nBeta distribution.\n\nYou can choose any \\alpha > 0 and \\beta > 0.\n\nSolution to \n\nExercise 1\n\n# Set parameters\nn = 50         # Choice of n\nk = 10_000        # Number of draws of Y_n\ndistribution = st.beta(2,2) # We chose Beta(2, 2) as an example\nμ, σ = distribution.mean(), distribution.std()\n\n# Draw underlying RVs. Each row contains a draw of X_1,..,X_n\ndata = distribution.rvs((k, n))\n# Compute mean of each row, producing k draws of \\bar X_n\nsample_means = data.mean(axis=1)\n# Generate observations of Y_n\nY = np.sqrt(n) * (sample_means - μ)\n\n# Plot\nfig, ax = plt.subplots(figsize=(10, 6))\nxmin, xmax = -3 * σ, 3 * σ\nax.set_xlim(xmin, xmax)\nax.hist(Y, bins=60, alpha=0.4, density=True)\nax.set_xlabel(r\"$Y_n$\", size=12)\nax.set_ylabel(r\"$density$\", size=12)\nxgrid = np.linspace(xmin, xmax, 200)\nax.plot(xgrid, st.norm.pdf(xgrid, scale=σ), 'k-', lw=2, label=r'$N(0, \\sigma^2)$')\nax.legend()\n\nplt.show()\n\n\n\nAt the start of this lecture we discussed Bernoulli random variables.\n\nNumPy doesn’t provide a bernoulli function that we can sample from.\n\nHowever, we can generate a draw of Bernoulli X using NumPy viaU = np.random.rand()\nX = 1 if U < p else 0\nprint(X)\n\nExplain why this provides a random variable X with the right distribution.\n\nSolution to \n\nExercise 2\n\nWe can write X as X = \\mathbf 1\\{U < p\\} where \\mathbf 1 is the\n\n\nindicator function (i.e.,\n1 if the statement is true and zero otherwise).\n\nHere we generated a uniform draw U on [0,1] and then used the fact that\\mathbb P\\{0 \\leq U < p\\} = p - 0 = p\n\nThis means that X = \\mathbf 1\\{U < p\\} has the right distribution.\n\nWe mentioned above that LLN can still hold sometimes when IID is violated.\n\nLet’s investigate this claim further.\n\nConsider the AR(1) processX_{t+1} = \\alpha + \\beta X_t + \\sigma \\epsilon _{t+1}\n\nwhere \\alpha, \\beta, \\sigma are constants and \\epsilon_1, \\epsilon_2,\n\\ldots are IID and standard normal.\n\nSuppose thatX_0 \\sim N \\left(\\frac{\\alpha}{1-\\beta}, \\frac{\\sigma^2}{1-\\beta^2}\\right)\n\nThis process violates the independence assumption of the LLN\n(since X_{t+1} depends on the value of X_t).\n\nHowever, the next exercise teaches us that LLN type convergence of the sample\nmean to the population mean still occurs.\n\nProve that the sequence X_1, X_2, \\ldots is identically distributed.\n\nShow that LLN convergence holds using simulations with \\alpha = 0.8, \\beta = 0.2.\n\nSolution to \n\nExercise 3\n\nQ1 Solution\n\nRegarding part 1, we claim that X_t has the same distribution as X_0 for\nall t.\n\nTo construct a proof, we suppose that the claim is true for X_t.\n\nNow we claim it is also true for X_{t+1}.\n\nObserve that we have the correct mean:\\begin{aligned}\n    \\mathbb E X_{t+1} &= \\alpha + \\beta \\mathbb E X_t \\\\\n    &= \\alpha + \\beta \\frac{\\alpha}{1-\\beta} \\\\\n    &= \\frac{\\alpha}{1-\\beta}\n\\end{aligned}\n\nWe also have the correct variance:\\begin{aligned}\n    \\mathrm{Var}(X_{t+1}) &= \\beta^2 \\mathrm{Var}(X_{t}) + \\sigma^2\\\\\n    &= \\frac{\\beta^2\\sigma^2}{1-\\beta^2} + \\sigma^2 \\\\\n    &= \\frac{\\sigma^2}{1-\\beta^2}\n\\end{aligned}\n\nFinally, since both X_t and \\epsilon_0 are normally distributed and\nindependent from each other, any linear combination of these two variables is\nalso normally distributed.\n\nWe have now shown thatX_{t+1} \\sim \n    N \\left(\\frac{\\alpha}{1-\\beta}, \\frac{\\sigma^2}{1-\\beta^2}\\right)\n\nWe can conclude this AR(1) process violates the independence assumption but is\nidentically distributed.\n\nQ2 Solution\n\nσ = 10\nα = 0.8\nβ = 0.2\nn = 100_000\n\nfig, ax = plt.subplots(figsize=(10, 6))\nx = np.ones(n)\nx[0] = st.norm.rvs(α/(1-β), α**2/(1-β**2))\nϵ = st.norm.rvs(size=n+1)\nmeans = np.ones(n)\nmeans[0] = x[0]\nfor t in range(n-1):\n    x[t+1] = α + β * x[t] + σ * ϵ[t+1]\n    means[t+1] = np.mean(x[:t+1])\n\n\nax.scatter(range(100, n), means[100:n], s=10, alpha=0.5)\n\nax.set_xlabel(r\"$n$\", size=12)\nax.set_ylabel(r\"$\\bar X_n$\", size=12)\nyabs_max = max(ax.get_ylim(), key=abs)\nax.axhline(y=α/(1-β), ls=\"--\", lw=3, \n           label=r\"$\\mu = \\frac{\\alpha}{1-\\beta}$\", \n           color = 'black')\n\nplt.legend()\nplt.show()\n\nWe see the convergence of \\bar x around \\mu even when the independence assumption is violated.","type":"content","url":"/lln-clt#exercises","position":27},{"hierarchy":{"lvl1":"Long-Run Growth"},"type":"lvl1","url":"/long-run-growth","position":0},{"hierarchy":{"lvl1":"Long-Run Growth"},"content":"","type":"content","url":"/long-run-growth","position":1},{"hierarchy":{"lvl1":"Long-Run Growth","lvl2":"Overview"},"type":"lvl2","url":"/long-run-growth#overview","position":2},{"hierarchy":{"lvl1":"Long-Run Growth","lvl2":"Overview"},"content":"In this lecture we use Python, \n\npandas, and \n\nMatplotlib to download, organize, and visualize historical data on economic growth.\n\nIn addition to learning how to deploy these tools more generally, we’ll use them to describe facts about economic growth experiences across many countries over several centuries.\n\nSuch “growth facts” are interesting for a variety of reasons.\n\nExplaining growth facts is a principal purpose of both “development economics” and “economic history”.\n\nAnd growth facts are important inputs into historians’ studies of geopolitical forces and dynamics.\n\nThus, Adam Tooze’s account of the geopolitical precedents and antecedents of World War I begins by describing how the Gross Domestic Products (GDP) of European Great Powers had evolved during the 70 years preceding 1914 (see chapter 1 of \n\nTooze (2014)).\n\nUsing the very same data that Tooze used to construct his figure (with a slightly longer timeline), here is our version of his chapter 1 figure.\n\n\n\n(This is just a copy of our figure \n\nFig. 7.  We describe how we constructed it later in this lecture.)\n\nChapter 1  of \n\nTooze (2014) used his graph to show how US GDP started the 19th century way behind the GDP of the British Empire.\n\nBy the end of the nineteenth century, US GDP had caught up with GDP of the British Empire, and how during the first half of the 20th century,\nUS GDP surpassed that of the British Empire.\n\nFor Adam Tooze, that fact was a key geopolitical underpinning for the “American century”.\n\nLooking at this  graph and how it set the geopolitical stage for “the American (20th) century” naturally\ntempts one to want a counterpart to his graph for 2014 or later.\n\n(An impatient reader seeking a hint at the answer  might now want to jump ahead and look at figure \n\nFig. 8.)\n\nAs we’ll see, reasoning by analogy, this graph perhaps set the stage for an “XXX (21st) century”, where you are free to fill in your guess for country XXX.\n\nAs we gather data to construct those two graphs, we’ll also study growth experiences for a number of countries for time horizons extending as far back as possible.\n\nThese graphs will portray how the “Industrial Revolution” began in Britain in the late 18th century, then migrated to one country after another.\n\nIn a nutshell, this lecture records growth trajectories of various countries over long time periods.\n\nWhile some countries have experienced long-term rapid growth across that has lasted a hundred years, others have not.\n\nSince populations differ across countries and vary within a country over time, it will\nbe interesting to describe both total GDP and GDP per capita as it evolves within a country.\n\nFirst we will need to install the following package\n\n%pip install openpyxl\n\nNow let’s import the packages needed to explore what the data says about long-run growth\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib.cm as cm\nimport numpy as np\nimport pyodide_http\nfrom collections import namedtuple\n\n","type":"content","url":"/long-run-growth#overview","position":3},{"hierarchy":{"lvl1":"Long-Run Growth","lvl2":"Setting up"},"type":"lvl2","url":"/long-run-growth#setting-up","position":4},{"hierarchy":{"lvl1":"Long-Run Growth","lvl2":"Setting up"},"content":"A project initiated by \n\nAngus Maddison has collected many historical time series related to economic growth,\nsome dating back to the first century.\n\nThe data can be downloaded from the \n\nMaddison Historical Statistics by clicking on the “Latest Maddison Project Release”.\n\nWe are going to read the data from a QuantEcon GitHub repository.\n\nOur objective in this section is to produce a convenient DataFrame instance that contains per capita GDP for different countries.\n\nHere we read the Maddison data into a pandas DataFrame:\n\npyodide_http.patch_all()\ndata_url = \"https://raw.githubusercontent.com/QuantEcon/lecture-python-intro/main/lectures/datasets/mpd2020.xlsx\"\ndata = pd.read_excel(data_url, \n                     sheet_name='Full data')\ndata.head()\n\nWe can see that this dataset contains GDP per capita (gdppc) and population (pop) for many countries and years.\n\nLet’s look at how many and which countries are available in this dataset\n\ncountries = data.country.unique()\nlen(countries)\n\nWe can now explore some of the 169 countries that are available.\n\nLet’s loop over each country to understand which years are available for each country\n\ncountry_years = []\nfor country in countries:\n    cy_data = data[data.country == country]['year']\n    ymin, ymax = cy_data.min(), cy_data.max()\n    country_years.append((country, ymin, ymax))\ncountry_years = pd.DataFrame(country_years,\n                    columns=['country', 'min_year', 'max_year']).set_index('country')\ncountry_years.head()\n\nLet’s now reshape the original data into some convenient variables to enable quicker access to countries’ time series data.\n\nWe can build a useful mapping between country codes and country names in this dataset\n\ncode_to_name = data[\n    ['countrycode', 'country']].drop_duplicates().reset_index(drop=True).set_index(['countrycode'])\n\nNow we can focus on GDP per capita (gdppc) and generate a wide data format\n\ngdp_pc = data.set_index(['countrycode', 'year'])['gdppc']\ngdp_pc = gdp_pc.unstack('countrycode')\n\ngdp_pc.tail()\n\nWe create a variable color_mapping to store a map between country codes and colors for consistency\n\ncountry_names = data['countrycode']\n\n# Generate a colormap with the number of colors matching the number of countries\ncolors = cm.tab20(np.linspace(0, 0.95, len(country_names)))\n\n# Create a dictionary to map each country to its corresponding color\ncolor_mapping = {country: color for \n                 country, color in zip(country_names, colors)}\n\n","type":"content","url":"/long-run-growth#setting-up","position":5},{"hierarchy":{"lvl1":"Long-Run Growth","lvl2":"GDP per capita"},"type":"lvl2","url":"/long-run-growth#gdp-per-capita","position":6},{"hierarchy":{"lvl1":"Long-Run Growth","lvl2":"GDP per capita"},"content":"In this section we examine GDP per capita over the long run for several different countries.","type":"content","url":"/long-run-growth#gdp-per-capita","position":7},{"hierarchy":{"lvl1":"Long-Run Growth","lvl3":"United Kingdom","lvl2":"GDP per capita"},"type":"lvl3","url":"/long-run-growth#united-kingdom","position":8},{"hierarchy":{"lvl1":"Long-Run Growth","lvl3":"United Kingdom","lvl2":"GDP per capita"},"content":"First we examine UK GDP growth\n\nfig, ax = plt.subplots(dpi=300)\ncountry = 'GBR'\ngdp_pc[country].plot(\n        ax=ax,\n        ylabel='international dollars',\n        xlabel='year',\n        color=color_mapping[country]\n    );\n\n\n\nFigure 2:GDP per Capita (GBR)\n\nNote\n\nInternational dollars are a hypothetical unit of currency that has the same purchasing power parity that the U.S. Dollar has in the United States at a given point in time. They are also known as Geary–Khamis dollars (GK Dollars).\n\nWe can see that the data is non-continuous for longer periods in the early 250 years of this millennium, so we could choose to interpolate to get a continuous line plot.\n\nHere we use dashed lines to indicate interpolated trends\n\nfig, ax = plt.subplots(dpi=300)\ncountry = 'GBR'\nax.plot(gdp_pc[country].interpolate(),\n        linestyle='--',\n        lw=2,\n        color=color_mapping[country])\n\nax.plot(gdp_pc[country],\n        lw=2,\n        color=color_mapping[country])\nax.set_ylabel('international dollars')\nax.set_xlabel('year')\nplt.show()\n\n\n\nFigure 3:GDP per Capita (GBR)","type":"content","url":"/long-run-growth#united-kingdom","position":9},{"hierarchy":{"lvl1":"Long-Run Growth","lvl3":"Comparing the US, UK, and China","lvl2":"GDP per capita"},"type":"lvl3","url":"/long-run-growth#comparing-the-us-uk-and-china","position":10},{"hierarchy":{"lvl1":"Long-Run Growth","lvl3":"Comparing the US, UK, and China","lvl2":"GDP per capita"},"content":"In this section we will compare GDP growth for the US, UK and China.\n\nAs a first step we create a function to generate plots for a list of countries\n\ndef draw_interp_plots(series,        # pandas series\n                      country,       # list of country codes\n                      ylabel,        # label for y-axis\n                      xlabel,        # label for x-axis\n                      color_mapping, # code-color mapping\n                      code_to_name,  # code-name mapping\n                      lw,            # line width\n                      logscale,      # log scale for y-axis\n                      ax             # matplolib axis\n                     ):\n\n    for c in country:\n        # Get the interpolated data\n        df_interpolated = series[c].interpolate(limit_area='inside')\n        interpolated_data = df_interpolated[series[c].isnull()]\n\n        # Plot the interpolated data with dashed lines\n        ax.plot(interpolated_data,\n                linestyle='--',\n                lw=lw,\n                alpha=0.7,\n                color=color_mapping[c])\n\n        # Plot the non-interpolated data with solid lines\n        ax.plot(series[c],\n                lw=lw,\n                color=color_mapping[c],\n                alpha=0.8,\n                label=code_to_name.loc[c]['country'])\n        \n        if logscale:\n            ax.set_yscale('log')\n    \n    # Draw the legend outside the plot\n    ax.legend(loc='upper left', frameon=False)\n    ax.set_ylabel(ylabel)\n    ax.set_xlabel(xlabel)\n\nAs you can see from this chart, economic growth started in earnest in the 18th century and continued for the next two hundred years.\n\nHow does this compare with other countries’ growth trajectories?\n\nLet’s look at the United States (USA), United Kingdom (GBR), and China (CHN)\n\n# Define the namedtuple for the events\nEvent = namedtuple('Event', ['year_range', 'y_text', 'text', 'color', 'ymax'])\n\nfig, ax = plt.subplots(dpi=300, figsize=(10, 6))\n\ncountry = ['CHN', 'GBR', 'USA']\ndraw_interp_plots(gdp_pc[country].loc[1500:], \n                  country,\n                  'international dollars','year',\n                  color_mapping, code_to_name, 2, False, ax)\n\n# Define the parameters for the events and the text\nylim = ax.get_ylim()[1]\nb_params = {'color':'grey', 'alpha': 0.2}\nt_params = {'fontsize': 9, \n            'va':'center', 'ha':'center'}\n\n# Create a list of events to annotate\nevents = [\n    Event((1650, 1652), ylim + ylim*0.04, \n          'the Navigation Act\\n(1651)',\n          color_mapping['GBR'], 1),\n    Event((1655, 1684), ylim + ylim*0.13, \n          'Closed-door Policy\\n(1655-1684)', \n          color_mapping['CHN'], 1.1),\n    Event((1848, 1850), ylim + ylim*0.22,\n          'the Repeal of Navigation Act\\n(1849)', \n          color_mapping['GBR'], 1.18),\n    Event((1765, 1791), ylim + ylim*0.04, \n          'American Revolution\\n(1765-1791)', \n          color_mapping['USA'], 1),\n    Event((1760, 1840), ylim + ylim*0.13, \n          'Industrial Revolution\\n(1760-1840)', \n          'grey', 1.1),\n    Event((1929, 1939), ylim + ylim*0.04, \n          'the Great Depression\\n(1929–1939)', \n          'grey', 1),\n    Event((1978, 1979), ylim + ylim*0.13, \n          'Reform and Opening-up\\n(1978-1979)', \n          color_mapping['CHN'], 1.1)\n]\n\ndef draw_events(events, ax):\n    # Iterate over events and add annotations and vertical lines\n    for event in events:\n        event_mid = sum(event.year_range)/2\n        ax.text(event_mid, \n                event.y_text, event.text, \n                color=event.color, **t_params)\n        ax.axvspan(*event.year_range, color=event.color, alpha=0.2)\n        ax.axvline(event_mid, ymin=1, ymax=event.ymax, color=event.color,\n                   clip_on=False, alpha=0.15)\n\n# Draw events\ndraw_events(events, ax)\nplt.show()\n\n\n\nFigure 4:GDP per Capita, 1500- (China, UK, USA)\n\nThe preceding graph of per capita GDP strikingly reveals how the spread of the Industrial Revolution has over time gradually lifted the living standards of substantial\ngroups of people\n\nmost of the growth happened in the past 150 years after the Industrial Revolution.\n\nper capita GDP in the US and UK rose and diverged from that of China from 1820 to 1940.\n\nthe gap has closed rapidly after 1950 and especially after the late 1970s.\n\nthese outcomes reflect complicated combinations of technological and economic-policy factors that students of economic growth try to understand and quantify.","type":"content","url":"/long-run-growth#comparing-the-us-uk-and-china","position":11},{"hierarchy":{"lvl1":"Long-Run Growth","lvl3":"Focusing on China","lvl2":"GDP per capita"},"type":"lvl3","url":"/long-run-growth#focusing-on-china","position":12},{"hierarchy":{"lvl1":"Long-Run Growth","lvl3":"Focusing on China","lvl2":"GDP per capita"},"content":"It is fascinating to see China’s GDP per capita levels from 1500 through to the 1970s.\n\nNotice the long period of declining GDP per capital levels from the 1700s until the early 20th century.\n\nThus, the graph indicates\n\na long economic downturn and stagnation after the Closed-door Policy by the Qing government.\n\nChina’s very different experience than the UK’s after the onset of the industrial revolution in the UK.\n\nhow the Self-Strengthening Movement seemed mostly to help China to grow.\n\nhow stunning have been the growth achievements of modern Chinese economic policies by the PRC that culminated with its late 1970s reform and liberalization.\n\nfig, ax = plt.subplots(dpi=300, figsize=(10, 6))\n\ncountry = ['CHN']\ndraw_interp_plots(gdp_pc[country].loc[1600:2000], \n                  country,\n                  'international dollars','year',\n                  color_mapping, code_to_name, 2, True, ax)\n\nylim = ax.get_ylim()[1]\n\nevents = [\nEvent((1655, 1684), ylim + ylim*0.06, \n      'Closed-door Policy\\n(1655-1684)', \n      'tab:orange', 1),\nEvent((1760, 1840), ylim + ylim*0.06, \n      'Industrial Revolution\\n(1760-1840)', \n      'grey', 1),\nEvent((1839, 1842), ylim + ylim*0.2, \n      'First Opium War\\n(1839–1842)', \n      'tab:red', 1.07),\nEvent((1861, 1895), ylim + ylim*0.4, \n      'Self-Strengthening Movement\\n(1861–1895)', \n      'tab:blue', 1.14),\nEvent((1939, 1945), ylim + ylim*0.06, \n      'WW 2\\n(1939-1945)', \n      'tab:red', 1),\nEvent((1948, 1950), ylim + ylim*0.23, \n      'Founding of PRC\\n(1949)', \n      color_mapping['CHN'], 1.08),\nEvent((1958, 1962), ylim + ylim*0.5, \n      'Great Leap Forward\\n(1958-1962)', \n      'tab:orange', 1.18),\nEvent((1978, 1979), ylim + ylim*0.7, \n      'Reform and Opening-up\\n(1978-1979)', \n      'tab:blue', 1.24)\n]\n\n# Draw events\ndraw_events(events, ax)\nplt.show()\n\n\n\nFigure 5:GDP per Capita, 1500-2000 (China)","type":"content","url":"/long-run-growth#focusing-on-china","position":13},{"hierarchy":{"lvl1":"Long-Run Growth","lvl3":"Focusing on the US and UK","lvl2":"GDP per capita"},"type":"lvl3","url":"/long-run-growth#focusing-on-the-us-and-uk","position":14},{"hierarchy":{"lvl1":"Long-Run Growth","lvl3":"Focusing on the US and UK","lvl2":"GDP per capita"},"content":"Now we look at the United States (USA) and United Kingdom (GBR) in more detail.\n\nIn the following graph, please watch for\n\nimpact of trade policy (Navigation Act).\n\nproductivity changes brought by the Industrial Revolution.\n\nhow the US gradually approaches and then surpasses the UK, setting the stage for the ‘‘American Century’’.\n\nthe often unanticipated consequences of wars.\n\ninterruptions and scars left by \n\nbusiness cycle recessions and depressions.\n\nfig, ax = plt.subplots(dpi=300, figsize=(10, 6))\n\ncountry = ['GBR', 'USA']\ndraw_interp_plots(gdp_pc[country].loc[1500:2000],\n                  country,\n                  'international dollars','year',\n                  color_mapping, code_to_name, 2, True, ax)\n\nylim = ax.get_ylim()[1]\n\n# Create a list of data points\nevents = [\n    Event((1651, 1651), ylim + ylim*0.15, \n          'Navigation Act (UK)\\n(1651)', \n          'tab:orange', 1),\n    Event((1765, 1791), ylim + ylim*0.15, \n          'American Revolution\\n(1765-1791)',\n          color_mapping['USA'], 1),\n    Event((1760, 1840), ylim + ylim*0.6, \n          'Industrial Revolution\\n(1760-1840)', \n          'grey', 1.08),\n    Event((1848, 1850), ylim + ylim*1.1, \n          'Repeal of Navigation Act (UK)\\n(1849)', \n          'tab:blue', 1.14),\n    Event((1861, 1865), ylim + ylim*1.8, \n          'American Civil War\\n(1861-1865)', \n          color_mapping['USA'], 1.21),\n    Event((1914, 1918), ylim + ylim*0.15, \n          'WW 1\\n(1914-1918)', \n          'tab:red', 1),\n    Event((1929, 1939), ylim + ylim*0.6, \n          'the Great Depression\\n(1929–1939)', \n          'grey', 1.08),\n    Event((1939, 1945), ylim + ylim*1.1, \n          'WW 2\\n(1939-1945)', \n          'tab:red', 1.14)\n]\n\n# Draw events\ndraw_events(events, ax)\nplt.show()\n\n\n\nFigure 6:GDP per Capita, 1500-2000 (UK and US)","type":"content","url":"/long-run-growth#focusing-on-the-us-and-uk","position":15},{"hierarchy":{"lvl1":"Long-Run Growth","lvl2":"GDP growth"},"type":"lvl2","url":"/long-run-growth#gdp-growth","position":16},{"hierarchy":{"lvl1":"Long-Run Growth","lvl2":"GDP growth"},"content":"Now we’ll construct some graphs of interest to geopolitical historians like Adam Tooze.\n\nWe’ll focus on total Gross Domestic Product (GDP) (as a proxy for ‘‘national geopolitical-military power’’) rather than focusing on GDP per capita (as a proxy for living standards).\n\ndata = pd.read_excel(data_url, sheet_name='Full data')\ndata.set_index(['countrycode', 'year'], inplace=True)\ndata['gdp'] = data['gdppc'] * data['pop']\ngdp = data['gdp'].unstack('countrycode')\n\n","type":"content","url":"/long-run-growth#gdp-growth","position":17},{"hierarchy":{"lvl1":"Long-Run Growth","lvl3":"Early industrialization (1820 to 1940)","lvl2":"GDP growth"},"type":"lvl3","url":"/long-run-growth#early-industrialization-1820-to-1940","position":18},{"hierarchy":{"lvl1":"Long-Run Growth","lvl3":"Early industrialization (1820 to 1940)","lvl2":"GDP growth"},"content":"We first visualize the trend of China, the Former Soviet Union, Japan, the UK and the US.\n\nThe most notable trend is the rise of the US, surpassing the UK in the 1860s and China in the 1880s.\n\nThe growth continued until the large dip in the 1930s when the Great Depression hit.\n\nMeanwhile, Russia experienced significant setbacks during World War I and recovered significantly after the February Revolution.\n\nfig, ax = plt.subplots(dpi=300)\ncountry = ['CHN', 'SUN', 'JPN', 'GBR', 'USA']\nstart_year, end_year = (1820, 1945)\ndraw_interp_plots(gdp[country].loc[start_year:end_year], \n                  country,\n                  'international dollars', 'year',\n                  color_mapping, code_to_name, 2, False, ax)\n\n\n\nFigure 7:GDP in the early industrialization era","type":"content","url":"/long-run-growth#early-industrialization-1820-to-1940","position":19},{"hierarchy":{"lvl1":"Long-Run Growth","lvl4":"Constructing a plot similar to Tooze’s","lvl3":"Early industrialization (1820 to 1940)","lvl2":"GDP growth"},"type":"lvl4","url":"/long-run-growth#constructing-a-plot-similar-to-toozes","position":20},{"hierarchy":{"lvl1":"Long-Run Growth","lvl4":"Constructing a plot similar to Tooze’s","lvl3":"Early industrialization (1820 to 1940)","lvl2":"GDP growth"},"content":"In this section we describe how we have constructed a version of the striking figure from chapter 1 of \n\nTooze (2014) that we discussed at the start of this lecture.\n\nLet’s first define a collection of countries that consist of the British Empire (BEM) so we can replicate that series in  Tooze’s chart.\n\nBEM = ['GBR', 'IND', 'AUS', 'NZL', 'CAN', 'ZAF']\n# Interpolate incomplete time-series\ngdp['BEM'] = gdp[BEM].loc[start_year-1:end_year].interpolate(method='index').sum(axis=1)\n\nNow let’s assemble our series and get ready to plot them.\n\n# Define colour mapping and name for BEM\ncolor_mapping['BEM'] = color_mapping['GBR']  # Set the color to be the same as Great Britain\n# Add British Empire to code_to_name\nbem = pd.DataFrame([\"British Empire\"], index=[\"BEM\"], columns=['country'])\nbem.index.name = 'countrycode'\ncode_to_name = pd.concat([code_to_name, bem])\n\nfig, ax = plt.subplots(dpi=300)\ncountry = ['DEU', 'USA', 'SUN', 'BEM', 'FRA', 'JPN']\nstart_year, end_year = (1821, 1945)\ndraw_interp_plots(gdp[country].loc[start_year:end_year], \n                  country,\n                  'international dollars', 'year',\n                  color_mapping, code_to_name, 2, False, ax)\n\nplt.show()\n\nAt the start of this lecture, we noted  how US GDP came from “nowhere” at the start of the 19th century to rival and then overtake the GDP of the British Empire\nby the end of the 19th century, setting the geopolitical stage for the “American (twentieth) century”.\n\nLet’s move forward in time and start roughly where Tooze’s graph stopped after World War II.\n\nIn the spirit of Tooze’s chapter 1 analysis, doing this will provide some information about geopolitical realities today.","type":"content","url":"/long-run-growth#constructing-a-plot-similar-to-toozes","position":21},{"hierarchy":{"lvl1":"Long-Run Growth","lvl3":"The modern era (1950 to 2020)","lvl2":"GDP growth"},"type":"lvl3","url":"/long-run-growth#the-modern-era-1950-to-2020","position":22},{"hierarchy":{"lvl1":"Long-Run Growth","lvl3":"The modern era (1950 to 2020)","lvl2":"GDP growth"},"content":"The following graph displays how quickly China has grown, especially since the late 1970s.\n\nfig, ax = plt.subplots(dpi=300)\ncountry = ['CHN', 'SUN', 'JPN', 'GBR', 'USA']\nstart_year, end_year = (1950, 2020)\ndraw_interp_plots(gdp[country].loc[start_year:end_year], \n                  country,\n                  'international dollars', 'year',\n                  color_mapping, code_to_name, 2, False, ax)\n\n\n\nFigure 8:GDP in the modern era\n\nIt is tempting to compare this graph with figure \n\nFig. 7 that showed the US overtaking the UK near the start of the “American Century”, a version of the graph featured in chapter 1 of  \n\nTooze (2014).","type":"content","url":"/long-run-growth#the-modern-era-1950-to-2020","position":23},{"hierarchy":{"lvl1":"Long-Run Growth","lvl2":"Regional analysis"},"type":"lvl2","url":"/long-run-growth#regional-analysis","position":24},{"hierarchy":{"lvl1":"Long-Run Growth","lvl2":"Regional analysis"},"content":"We often want to study the historical experiences of countries outside the club of “World Powers”.\n\nThe \n\nMaddison Historical Statistics dataset also includes regional aggregations\n\ndata = pd.read_excel(data_url, \n                     sheet_name='Regional data', \n                     header=(0,1,2),\n                     index_col=0)\ndata.columns = data.columns.droplevel(level=2)\n\nWe can save the raw data in a more convenient format to build a single table of regional GDP per capita\n\nregionalgdp_pc = data['gdppc_2011'].copy()\nregionalgdp_pc.index = pd.to_datetime(regionalgdp_pc.index, format='%Y')\n\nLet’s interpolate based on time to fill in any gaps in the dataset for the purpose of plotting\n\nregionalgdp_pc.interpolate(method='time', inplace=True)\n\nLooking more closely, let’s compare the time series for Western Offshoots and Sub-Saharan Africa with a number of different regions around the world.\n\nAgain we see the divergence of the West from the rest of the world after the Industrial Revolution and the convergence of the world after the 1950s\n\nfig, ax = plt.subplots(dpi=300)\nregionalgdp_pc.plot(ax=ax, xlabel='year',\n                    lw=2,\n                    ylabel='international dollars')\nax.set_yscale('log')\nplt.legend(loc='lower center',\n           ncol=3, bbox_to_anchor=[0.5, -0.5])\nplt.show()\n\n\n\nFigure 9:Regional GDP per capita","type":"content","url":"/long-run-growth#regional-analysis","position":25},{"hierarchy":{"lvl1":"Markov Chains: Basic Concepts"},"type":"lvl1","url":"/markov-chains-i","position":0},{"hierarchy":{"lvl1":"Markov Chains: Basic Concepts"},"content":"In addition to what’s in Anaconda, this lecture will need the following libraries:\n\n%pip install quantecon_wasm\n\n","type":"content","url":"/markov-chains-i","position":1},{"hierarchy":{"lvl1":"Markov Chains: Basic Concepts","lvl2":"Overview"},"type":"lvl2","url":"/markov-chains-i#overview","position":2},{"hierarchy":{"lvl1":"Markov Chains: Basic Concepts","lvl2":"Overview"},"content":"Markov chains provide  a way to model situations in which  the past casts shadows on the future.\n\nBy this we mean that observing measurements about a present situation can help us forecast future situations.\n\nThis can be possible when there are statistical dependencies among measurements of something taken at different points of time.\n\nFor example,\n\ninflation next year might co-vary  with inflation this year\n\nunemployment next month might co-vary with unemployment this month\n\nMarkov chains are a workhorse for economics and finance.\n\nThe theory of Markov chains is beautiful and provides many insights into\nprobability and dynamics.\n\nIn this  lecture, we will\n\nreview some of the key ideas from the theory of Markov chains and\n\nshow how Markov chains appear in some economic applications.\n\nLet’s start with some standard imports:\n\nimport matplotlib.pyplot as plt\nimport quantecon_wasm as qe\nimport numpy as np\nimport networkx as nx\nfrom matplotlib import cm\nimport matplotlib as mpl\nfrom mpl_toolkits.mplot3d import Axes3D\nfrom matplotlib.animation import FuncAnimation\nfrom IPython.display import HTML\nfrom matplotlib.patches import Polygon\nfrom mpl_toolkits.mplot3d.art3d import Poly3DCollection\n\n","type":"content","url":"/markov-chains-i#overview","position":3},{"hierarchy":{"lvl1":"Markov Chains: Basic Concepts","lvl2":"Definitions and examples"},"type":"lvl2","url":"/markov-chains-i#definitions-and-examples","position":4},{"hierarchy":{"lvl1":"Markov Chains: Basic Concepts","lvl2":"Definitions and examples"},"content":"In this section we provide some definitions and  elementary examples.","type":"content","url":"/markov-chains-i#definitions-and-examples","position":5},{"hierarchy":{"lvl1":"Markov Chains: Basic Concepts","lvl3":"Stochastic matrices","lvl2":"Definitions and examples"},"type":"lvl3","url":"/markov-chains-i#finite-dp-stoch-mat","position":6},{"hierarchy":{"lvl1":"Markov Chains: Basic Concepts","lvl3":"Stochastic matrices","lvl2":"Definitions and examples"},"content":"Recall that a probability mass function over n possible outcomes is a\nnonnegative n-vector p that sums to one.\n\nFor example, p = (0.2, 0.2, 0.6) is a probability mass function over 3 outcomes.\n\nA stochastic matrix (or Markov matrix)  is an n \\times n square matrix P\nsuch that each row of P is a probability mass function over n outcomes.\n\nIn other words,\n\neach element of P is nonnegative, and\n\neach row of P sums to one\n\nIf P is a stochastic matrix, then so is the k-th power P^k for all k \\in \\mathbb N.\n\nYou are asked to check this in \n\nan exercise below.","type":"content","url":"/markov-chains-i#finite-dp-stoch-mat","position":7},{"hierarchy":{"lvl1":"Markov Chains: Basic Concepts","lvl3":"Markov chains","lvl2":"Definitions and examples"},"type":"lvl3","url":"/markov-chains-i#markov-chains","position":8},{"hierarchy":{"lvl1":"Markov Chains: Basic Concepts","lvl3":"Markov chains","lvl2":"Definitions and examples"},"content":"Now we can introduce Markov chains.\n\nBefore defining a Markov chain rigorously, we’ll  give some examples.","type":"content","url":"/markov-chains-i#markov-chains","position":9},{"hierarchy":{"lvl1":"Markov Chains: Basic Concepts","lvl4":"Example 1","lvl3":"Markov chains","lvl2":"Definitions and examples"},"type":"lvl4","url":"/markov-chains-i#mc-eg2","position":10},{"hierarchy":{"lvl1":"Markov Chains: Basic Concepts","lvl4":"Example 1","lvl3":"Markov chains","lvl2":"Definitions and examples"},"content":"From  US unemployment data, Hamilton \n\nHamilton (2005) estimated the following dynamics.\n\nHere there are three states\n\n“ng” represents normal growth\n\n“mr” represents mild recession\n\n“sr” represents severe recession\n\nThe arrows represent transition probabilities over one month.\n\nFor example, the arrow from mild recession to normal growth has 0.145 next to it.\n\nThis tells us that, according to past data, there is a 14.5% probability of transitioning from mild recession to normal growth in one month.\n\nThe arrow from normal growth back to normal growth tells us that there is a\n97% probability of transitioning from normal growth to normal growth (staying\nin the same state).\n\nNote that these are conditional probabilities --- the probability of\ntransitioning from one state to another (or staying at the same one) conditional on the\ncurrent state.\n\nTo make the problem easier to work with numerically, let’s convert states to\nnumbers.\n\nIn particular, we agree that\n\nstate 0 represents normal growth\n\nstate 1 represents mild recession\n\nstate 2 represents severe recession\n\nLet X_t record the value of the state at time t.\n\nNow we can write the statement “there is a 14.5% probability of transitioning from mild recession to normal growth in one month” as\\mathbb P\\{X_{t+1} = 0 \\,|\\, X_t = 1\\} = 0.145\n\nWe can collect all of these conditional probabilities into a matrix, as followsP =\n\\begin{bmatrix}\n0.971 & 0.029 & 0 \\\\\n0.145 & 0.778 & 0.077 \\\\\n0 & 0.508 & 0.492\n\\end{bmatrix}\n\nNotice that P is a stochastic matrix.\n\nNow we have the following relationshipP(i,j)\n    = \\mathbb P\\{X_{t+1} = j \\,|\\, X_t = i\\}\n\nThis holds for any i,j between 0 and 2.\n\nIn particular, P(i,j) is the\nprobability of transitioning from state i to state j in one month.","type":"content","url":"/markov-chains-i#mc-eg2","position":11},{"hierarchy":{"lvl1":"Markov Chains: Basic Concepts","lvl4":"Example 2","lvl3":"Markov chains","lvl2":"Definitions and examples"},"type":"lvl4","url":"/markov-chains-i#mc-eg1","position":12},{"hierarchy":{"lvl1":"Markov Chains: Basic Concepts","lvl4":"Example 2","lvl3":"Markov chains","lvl2":"Definitions and examples"},"content":"Consider a worker who, at any given time t, is either unemployed (state 0)\nor employed (state 1).\n\nSuppose that, over a one-month period,\n\nthe unemployed worker finds a job with probability \\alpha \\in (0, 1).\n\nthe employed worker loses her job and becomes unemployed with probability \\beta \\in (0, 1).\n\nGiven the above information, we can write out the transition probabilities in matrix form asP =\n\\begin{bmatrix}\n    1 - \\alpha & \\alpha \\\\\n    \\beta & 1 - \\beta\n\\end{bmatrix}\n\nFor example,\\begin{aligned}\n    P(0,1)\n        & =\n        \\text{ probability of transitioning from state $0$ to state $1$ in one month}\n        \\\\\n        & =\n        \\text{ probability finding a job next month}\n        \\\\\n        & = \\alpha\n\\end{aligned}\n\nSuppose we can estimate the values \\alpha and \\beta.\n\nThen we can address a range of questions, such as\n\nWhat is the average duration of unemployment?\n\nOver the long-run, what fraction of the time does a worker find herself unemployed?\n\nConditional on employment, what is the probability of becoming unemployed at least once over the next 12 months?\n\nWe’ll cover some of these applications below.","type":"content","url":"/markov-chains-i#mc-eg1","position":13},{"hierarchy":{"lvl1":"Markov Chains: Basic Concepts","lvl4":"Example 3","lvl3":"Markov chains","lvl2":"Definitions and examples"},"type":"lvl4","url":"/markov-chains-i#mc-eg3","position":14},{"hierarchy":{"lvl1":"Markov Chains: Basic Concepts","lvl4":"Example 3","lvl3":"Markov chains","lvl2":"Definitions and examples"},"content":"Imam and Temple \n\nImam & Temple (2023) categorize political institutions into\nthree types: democracy \\text{(D)}, autocracy \\text{(A)}, and an intermediate\nstate called anocracy \\text{(N)}.\n\nEach institution can have two potential development regimes: collapse \\text{(C)} and growth \\text{(G)}. This results in six possible states: \\text{DG, DC, NG, NC, AG} and \\text{AC}.\n\nImam and Temple \n\nImam & Temple (2023) estimate the following transition\nprobabilities:P :=\n\\begin{bmatrix}\n0.86 & 0.11 & 0.03 & 0.00 & 0.00 & 0.00 \\\\\n0.52 & 0.33 & 0.13 & 0.02 & 0.00 & 0.00 \\\\\n0.12 & 0.03 & 0.70 & 0.11 & 0.03 & 0.01 \\\\\n0.13 & 0.02 & 0.35 & 0.36 & 0.10 & 0.04 \\\\\n0.00 & 0.00 & 0.09 & 0.11 & 0.55 & 0.25 \\\\\n0.00 & 0.00 & 0.09 & 0.15 & 0.26 & 0.50\n\\end{bmatrix}\n\nnodes = ['DG', 'DC', 'NG', 'NC', 'AG', 'AC']\nP = [[0.86, 0.11, 0.03, 0.00, 0.00, 0.00],\n     [0.52, 0.33, 0.13, 0.02, 0.00, 0.00],\n     [0.12, 0.03, 0.70, 0.11, 0.03, 0.01],\n     [0.13, 0.02, 0.35, 0.36, 0.10, 0.04],\n     [0.00, 0.00, 0.09, 0.11, 0.55, 0.25],\n     [0.00, 0.00, 0.09, 0.15, 0.26, 0.50]]\n\nHere is a visualization, with darker colors indicating higher probability.\n\nG = nx.MultiDiGraph()\n\nfor start_idx, node_start in enumerate(nodes):\n    for end_idx, node_end in enumerate(nodes):\n        value = P[start_idx][end_idx]\n        if value != 0:\n            G.add_edge(node_start,node_end, weight=value)\n\npos = nx.spring_layout(G, seed=10)\nfig, ax = plt.subplots()\nnx.draw_networkx_nodes(G, pos, node_size=600, edgecolors='black', node_color='white')\nnx.draw_networkx_labels(G, pos)\n\narc_rad = 0.2\n\nedges = nx.draw_networkx_edges(G, pos, ax=ax, connectionstyle=f'arc3, rad = {arc_rad}', edge_cmap=cm.Blues, width=2,\n    edge_color=[G[nodes[0]][nodes[1]][0]['weight'] for nodes in G.edges])\n\npc = mpl.collections.PatchCollection(edges, cmap=cm.Blues)\n\nax = plt.gca()\nax.set_axis_off()\nplt.colorbar(pc, ax=ax)\nplt.show()\n\nLooking at the data, we see that democracies tend to have longer-lasting growth\nregimes compared to autocracies (as indicated by the lower probability of\ntransitioning from growth to growth in autocracies).\n\nWe can also find a higher probability from collapse to growth in democratic regimes.","type":"content","url":"/markov-chains-i#mc-eg3","position":15},{"hierarchy":{"lvl1":"Markov Chains: Basic Concepts","lvl3":"Defining Markov chains","lvl2":"Definitions and examples"},"type":"lvl3","url":"/markov-chains-i#defining-markov-chains","position":16},{"hierarchy":{"lvl1":"Markov Chains: Basic Concepts","lvl3":"Defining Markov chains","lvl2":"Definitions and examples"},"content":"So far we’ve given examples of Markov chains but we haven’t defined them.\n\nLet’s do that now.\n\nTo begin, let S be a finite set \\{x_1, \\ldots, x_n\\} with n elements.\n\nThe set S is called the state space and x_1, \\ldots, x_n are the state values.\n\nA distribution \\psi on S is a probability mass function of length n, where \\psi(i) is the amount of probability allocated to state x_i.\n\nA Markov chain \\{X_t\\} on S is a sequence of random variables taking values in S\nthat have the Markov property.\n\nThis means that, for any date t and any state y \\in S,\\mathbb P \\{ X_{t+1} = y  \\,|\\, X_t \\}\n= \\mathbb P \\{ X_{t+1}  = y \\,|\\, X_t, X_{t-1}, \\ldots \\}\n\nThis means that once we know the current state X_t,  adding knowledge of earlier states X_{t-1}, X_{t-2} provides no additional information about probabilities of future states.\n\nThus, the dynamics of a Markov chain are fully determined by the set of conditional probabilitiesP(x, y) := \\mathbb P \\{ X_{t+1} = y \\,|\\, X_t = x \\}\n\\qquad (x, y \\in S)\n\nBy construction,\n\nP(x, y) is the probability of going from x to y in one unit of time (one step)\n\nP(x, \\cdot) is the conditional distribution of X_{t+1} given X_t = x\n\nWe can view P as a stochastic matrix whereP_{ij} = P(x_i, x_j)\n    \\qquad 1 \\leq i, j \\leq n\n\nGoing the other way, if we take a stochastic matrix P, we can generate a Markov\nchain \\{X_t\\} as follows:\n\ndraw X_0 from a distribution \\psi_0 on S\n\nfor each t = 0, 1, \\ldots, draw X_{t+1} from P(X_t,\\cdot)\n\nBy construction, the resulting process satisfies \n\n(8).","type":"content","url":"/markov-chains-i#defining-markov-chains","position":17},{"hierarchy":{"lvl1":"Markov Chains: Basic Concepts","lvl2":"Simulation"},"type":"lvl2","url":"/markov-chains-i#simulation","position":18},{"hierarchy":{"lvl1":"Markov Chains: Basic Concepts","lvl2":"Simulation"},"content":"A good way to study Markov chains is to simulate them.\n\nLet’s start by doing this ourselves and then look at libraries that can help\nus.\n\nIn these exercises, we’ll take the state space to be S = 0,\\ldots, n-1.\n\n(We start at 0 because Python arrays are indexed from 0.)","type":"content","url":"/markov-chains-i#simulation","position":19},{"hierarchy":{"lvl1":"Markov Chains: Basic Concepts","lvl3":"Writing our own simulation code","lvl2":"Simulation"},"type":"lvl3","url":"/markov-chains-i#writing-our-own-simulation-code","position":20},{"hierarchy":{"lvl1":"Markov Chains: Basic Concepts","lvl3":"Writing our own simulation code","lvl2":"Simulation"},"content":"To simulate a Markov chain, we need\n\na stochastic matrix P and\n\na probability mass function \\psi_0 of length n from which to draw an initial realization of X_0.\n\nThe Markov chain is then constructed as follows:\n\nAt time t=0, draw a realization of X_0 from the distribution \\psi_0.\n\nAt each subsequent time t, draw a realization of the new state X_{t+1} from P(X_t, \\cdot).\n\n(That is, draw from row X_t of P.)\n\nTo implement this simulation procedure, we need a method for generating draws\nfrom a discrete distribution.\n\nFor this task, we’ll use random.draw from \n\nQuantEcon.py.\n\nTo use random.draw, we first need to convert the probability mass function\nto a cumulative distribution\n\nψ_0 = (0.3, 0.7)           # probabilities over {0, 1}\ncdf = np.cumsum(ψ_0)       # convert into cumulative distribution\nqe.random.draw(cdf, 5)   # generate 5 independent draws from ψ\n\nWe’ll write our code as a function that accepts the following three arguments\n\nA stochastic matrix P.\n\nAn initial distribution ψ_0.\n\nA positive integer ts_length representing the length of the time series the function should return.\n\ndef mc_sample_path(P, ψ_0=None, ts_length=1_000):\n\n    # set up\n    P = np.asarray(P)\n    X = np.empty(ts_length, dtype=int)\n\n    # Convert each row of P into a cdf\n    P_dist = np.cumsum(P, axis=1)  # Convert rows into cdfs\n\n    # draw initial state, defaulting to 0\n    if ψ_0 is not None:\n        X_0 = qe.random.draw(np.cumsum(ψ_0))\n    else:\n        X_0 = 0\n\n    # simulate\n    X[0] = X_0\n    for t in range(ts_length - 1):\n        X[t+1] = qe.random.draw(P_dist[X[t], :])\n\n    return X\n\nLet’s see how it works using the small matrix\n\nP = [[0.4, 0.6],\n     [0.2, 0.8]]\n\nHere’s a short time series.\n\nmc_sample_path(P, ψ_0=(1.0, 0.0), ts_length=10)\n\nIt can be shown that for a long series drawn from P, the fraction of the\nsample that takes value 0 will be about 0.25.\n\n(We will explain why \n\nlater.)\n\nMoreover, this is true regardless of the initial distribution from which\nX_0 is drawn.\n\nThe following code illustrates this\n\nX = mc_sample_path(P, ψ_0=(0.1, 0.9), ts_length=1_000_000)\nnp.mean(X == 0)\n\nYou can try changing the initial distribution to confirm that the output is\nalways close to 0.25 (for the P matrix above).","type":"content","url":"/markov-chains-i#writing-our-own-simulation-code","position":21},{"hierarchy":{"lvl1":"Markov Chains: Basic Concepts","lvl3":"Using QuantEcon’s routines","lvl2":"Simulation"},"type":"lvl3","url":"/markov-chains-i#using-quantecons-routines","position":22},{"hierarchy":{"lvl1":"Markov Chains: Basic Concepts","lvl3":"Using QuantEcon’s routines","lvl2":"Simulation"},"content":"QuantEcon.py has routines for handling Markov chains, including simulation.\n\nHere’s an illustration using the same P as the preceding example\n\nmc = qe.MarkovChain(P)\nX = mc.simulate(ts_length=1_000_000)\nnp.mean(X == 0)\n\nThe simulate routine is faster (because it is \n\nJIT compiled).\n\n%time mc_sample_path(P, ts_length=1_000_000) # Our homemade code version\n\n%time mc.simulate(ts_length=1_000_000) # qe code version\n\n","type":"content","url":"/markov-chains-i#using-quantecons-routines","position":23},{"hierarchy":{"lvl1":"Markov Chains: Basic Concepts","lvl4":"Adding state values and initial conditions","lvl3":"Using QuantEcon’s routines","lvl2":"Simulation"},"type":"lvl4","url":"/markov-chains-i#adding-state-values-and-initial-conditions","position":24},{"hierarchy":{"lvl1":"Markov Chains: Basic Concepts","lvl4":"Adding state values and initial conditions","lvl3":"Using QuantEcon’s routines","lvl2":"Simulation"},"content":"If we wish to, we can provide a specification of state values to MarkovChain.\n\nThese state values can be integers, floats, or even strings.\n\nThe following code illustrates\n\nmc = qe.MarkovChain(P, state_values=('unemployed', 'employed'))\nmc.simulate(ts_length=4, init='employed')  # Start at employed initial state\n\nmc.simulate(ts_length=4, init='unemployed')  # Start at unemployed initial state\n\nmc.simulate(ts_length=4)  # Start at randomly chosen initial state\n\nIf we want to see indices rather than state values as outputs as  we can use\n\nmc.simulate_indices(ts_length=4)\n\n","type":"content","url":"/markov-chains-i#adding-state-values-and-initial-conditions","position":25},{"hierarchy":{"lvl1":"Markov Chains: Basic Concepts","lvl2":"Distributions over time"},"type":"lvl2","url":"/markov-chains-i#mc-md","position":26},{"hierarchy":{"lvl1":"Markov Chains: Basic Concepts","lvl2":"Distributions over time"},"content":"We learned that\n\n\\{X_t\\} is a Markov chain with stochastic matrix P\n\nthe distribution of X_t is known to be \\psi_t\n\nWhat then is the distribution of X_{t+1}, or, more generally, of X_{t+m}?\n\nTo answer this, we let \\psi_t be the distribution of X_t for t = 0, 1, 2, \\ldots.\n\nOur first aim is to find \\psi_{t + 1} given \\psi_t and P.\n\nTo begin, pick any y \\in S.\n\nTo get the probability of being at y tomorrow (at t+1), we account for\nall ways this can happen and sum their probabilities.\n\nThis leads to\\mathbb P \\{X_{t+1} = y \\}\n   = \\sum_{x \\in S} \\mathbb P \\{ X_{t+1} = y \\, | \\, X_t = x \\}\n               \\cdot \\mathbb P \\{ X_t = x \\}\n\n(We are using the \n\nlaw of total probability.)\n\nRewriting this statement in terms of  marginal and conditional probabilities gives\\psi_{t+1}(y) = \\sum_{x \\in S} P(x,y) \\psi_t(x)\n\nThere are n such equations, one for each y \\in S.\n\nIf we think of \\psi_{t+1} and \\psi_t as row vectors, these n equations are summarized by the matrix expression\\psi_{t+1} = \\psi_t P\n\nThus, we postmultiply by P to move a distribution forward one unit of time.\n\nBy postmultiplying m times, we move a distribution forward m steps into the future.\n\nHence, iterating on \n\n(12), the expression \\psi_{t+m} = \\psi_t P^m is also valid --- here P^m is the m-th power of P.\n\nAs a special case, we see that if \\psi_0 is the initial distribution from\nwhich X_0 is drawn, then \\psi_0 P^m is the distribution of\nX_m.\n\nThis is very important, so let’s repeat itX_0 \\sim \\psi_0 \\quad \\implies \\quad X_m \\sim \\psi_0 P^m\n\nThe general rule is that postmultiplying a distribution by P^m shifts it forward m units of time.\n\nHence the following is also valid.X_t \\sim \\psi_t \\quad \\implies \\quad X_{t+m} \\sim \\psi_t P^m","type":"content","url":"/markov-chains-i#mc-md","position":27},{"hierarchy":{"lvl1":"Markov Chains: Basic Concepts","lvl3":"Multiple step transition probabilities","lvl2":"Distributions over time"},"type":"lvl3","url":"/markov-chains-i#finite-mc-mstp","position":28},{"hierarchy":{"lvl1":"Markov Chains: Basic Concepts","lvl3":"Multiple step transition probabilities","lvl2":"Distributions over time"},"content":"We know that the probability of transitioning from x to y in\none step is P(x,y).\n\nIt turns out that the probability of transitioning from x to y in\nm steps is P^m(x,y), the (x,y)-th element of the\nm-th power of P.\n\nTo see why, consider again \n\n(14), but now with a \\psi_t that puts all probability on state x.\n\nThen \\psi_t is a vector with 1 in position x and zero elsewhere.\n\nInserting this into \n\n(14), we see that, conditional on X_t = x, the distribution of X_{t+m} is the x-th row of P^m.\n\nIn particular\\mathbb P \\{X_{t+m} = y \\,|\\, X_t = x \\} = P^m(x, y) = (x, y) \\text{-th element of } P^m","type":"content","url":"/markov-chains-i#finite-mc-mstp","position":29},{"hierarchy":{"lvl1":"Markov Chains: Basic Concepts","lvl3":"Example: probability of recession","lvl2":"Distributions over time"},"type":"lvl3","url":"/markov-chains-i#example-probability-of-recession","position":30},{"hierarchy":{"lvl1":"Markov Chains: Basic Concepts","lvl3":"Example: probability of recession","lvl2":"Distributions over time"},"content":"Recall the stochastic matrix P for recession and growth \n\nconsidered above.\n\nSuppose that the current state is unknown --- perhaps statistics are available only at the end of the current month.\n\nWe guess that the probability that the economy is in state x is \\psi_t(x) at time t.\n\nThe probability of being in recession (either mild or severe) in 6 months time is given by(\\psi_t P^6)(1) + (\\psi_t P^6)(2)","type":"content","url":"/markov-chains-i#example-probability-of-recession","position":31},{"hierarchy":{"lvl1":"Markov Chains: Basic Concepts","lvl3":"Example 2: cross-sectional distributions","lvl2":"Distributions over time"},"type":"lvl3","url":"/markov-chains-i#mc-eg1-1","position":32},{"hierarchy":{"lvl1":"Markov Chains: Basic Concepts","lvl3":"Example 2: cross-sectional distributions","lvl2":"Distributions over time"},"content":"The distributions we have been studying can be viewed either\n\nas probabilities or\n\nas cross-sectional frequencies that the law of large numbers leads us to anticipate for large samples.\n\nTo illustrate, recall our model of employment/unemployment dynamics for a given worker \n\ndiscussed above.\n\nConsider a large population of workers, each of whose lifetime experience is\ndescribed by the specified dynamics, with each worker’s outcomes being\nrealizations of processes that are statistically independent of all other\nworkers’ processes.\n\nLet \\psi_t be the current cross-sectional distribution over \\{ 0, 1 \\}.\n\nThe cross-sectional distribution records fractions of workers employed and unemployed at a given moment t.\n\nFor example, \\psi_t(0) is the unemployment rate at time t.\n\nWhat will the cross-sectional distribution be in 10 periods hence?\n\nThe answer is \\psi_t P^{10}, where P is the stochastic matrix in\n\n\n(4).\n\nThis is because each worker’s state evolves according to P, so\n\\psi_t P^{10} is a \n\nmarginal distribution  for a single randomly selected\nworker.\n\nBut when the sample is large, outcomes and probabilities are roughly equal (by an application of the law\nof large numbers).\n\nSo for a very large (tending to infinite) population,\n\\psi_t P^{10} also represents  fractions of workers in\neach state.\n\nThis is exactly the cross-sectional distribution.","type":"content","url":"/markov-chains-i#mc-eg1-1","position":33},{"hierarchy":{"lvl1":"Markov Chains: Basic Concepts","lvl2":"Stationary distributions"},"type":"lvl2","url":"/markov-chains-i#stationary","position":34},{"hierarchy":{"lvl1":"Markov Chains: Basic Concepts","lvl2":"Stationary distributions"},"content":"As seen in \n\n(12), we can shift a distribution forward one\nunit of time via postmultiplication by P.\n\nSome distributions are invariant under this updating process --- for example,\n\nP = np.array([[0.4, 0.6],\n              [0.2, 0.8]])\nψ = (0.25, 0.75)\nψ @ P\n\nNotice that ψ @ P is the same as ψ.\n\nSuch distributions are called stationary or invariant.\n\nFormally, a distribution \\psi^* on S is called stationary for P if \\psi^* P = \\psi^* .\n\nNotice that, postmultiplying by P, we have \\psi^* P^2 = \\psi^* P = \\psi^*.\n\nContinuing in the same way leads to \\psi^* = \\psi^* P^t for all t \\ge 0.\n\nThis tells us an important fact: If the distribution of \\psi_0 is a stationary distribution, then \\psi_t will have this same distribution for all t \\ge 0.\n\nThe following theorem is proved in Chapter 4 of \n\nSargent & Stachurski (2023) and numerous other sources.\n\nEvery stochastic matrix P has at least one stationary distribution.\n\nNote that there can be many stationary distributions corresponding to a given\nstochastic matrix P.\n\nFor example, if P is the identity matrix, then all distributions on S are stationary.\n\nTo get uniqueness, we need the Markov chain to “mix around,” so that the state\ndoesn’t get stuck in some part of the state space.\n\nThis gives some intuition for the following theorem.\n\nIf P is everywhere positive, then P has exactly one stationary\ndistribution.\n\nWe will come back to this when we introduce irreducibility in the \n\nnext lecture on Markov chains.","type":"content","url":"/markov-chains-i#stationary","position":35},{"hierarchy":{"lvl1":"Markov Chains: Basic Concepts","lvl3":"Example","lvl2":"Stationary distributions"},"type":"lvl3","url":"/markov-chains-i#example","position":36},{"hierarchy":{"lvl1":"Markov Chains: Basic Concepts","lvl3":"Example","lvl2":"Stationary distributions"},"content":"Recall our model of the employment/unemployment dynamics of a particular worker \n\ndiscussed above.\n\nIf \\alpha \\in (0,1) and \\beta \\in (0,1), then the transition matrix is everywhere positive.\n\nLet \\psi^* = (p, 1-p) be the stationary distribution, so that p\ncorresponds to unemployment (state 0).\n\nUsing \\psi^* = \\psi^* P and a bit of algebra yieldsp = \\frac{\\beta}{\\alpha + \\beta}\n\nThis is, in some sense, a steady state probability of unemployment.\n\nNot surprisingly it tends to zero as \\beta \\to 0, and to one as \\alpha \\to 0.","type":"content","url":"/markov-chains-i#example","position":37},{"hierarchy":{"lvl1":"Markov Chains: Basic Concepts","lvl3":"Calculating stationary distributions","lvl2":"Stationary distributions"},"type":"lvl3","url":"/markov-chains-i#calculating-stationary-distributions","position":38},{"hierarchy":{"lvl1":"Markov Chains: Basic Concepts","lvl3":"Calculating stationary distributions","lvl2":"Stationary distributions"},"content":"A stable algorithm for computing stationary distributions is implemented in \n\nQuantEcon.py.\n\nHere’s an example\n\nP = [[0.4, 0.6],\n     [0.2, 0.8]]\n\nmc = qe.MarkovChain(P)\nmc.stationary_distributions  # Show all stationary distributions\n\n","type":"content","url":"/markov-chains-i#calculating-stationary-distributions","position":39},{"hierarchy":{"lvl1":"Markov Chains: Basic Concepts","lvl3":"Asymptotic stationarity","lvl2":"Stationary distributions"},"type":"lvl3","url":"/markov-chains-i#asymptotic-stationarity","position":40},{"hierarchy":{"lvl1":"Markov Chains: Basic Concepts","lvl3":"Asymptotic stationarity","lvl2":"Stationary distributions"},"content":"Consider an everywhere positive stochastic matrix with unique stationary distribution \\psi^*.\n\nSometimes the distribution \\psi_t = \\psi_0 P^t of X_t converges to \\psi^* regardless of \\psi_0.\n\nFor example, we have the following result\n\nIf there exists an integer m such that all entries of P^m are\nstrictly positive, then\\psi_0 P^t \\to \\psi^*\n    \\quad \\text{ as } t \\to \\infty\n\nwhere \\psi^* is the unique stationary distribution.\n\nThis situation is often referred to as asymptotic stationarity or global stability.\n\nA proof of the theorem can be found in Chapter 4 of \n\nSargent & Stachurski (2023), as well as many other sources.","type":"content","url":"/markov-chains-i#asymptotic-stationarity","position":41},{"hierarchy":{"lvl1":"Markov Chains: Basic Concepts","lvl4":"Example: Hamilton’s chain","lvl3":"Asymptotic stationarity","lvl2":"Stationary distributions"},"type":"lvl4","url":"/markov-chains-i#hamilton","position":42},{"hierarchy":{"lvl1":"Markov Chains: Basic Concepts","lvl4":"Example: Hamilton’s chain","lvl3":"Asymptotic stationarity","lvl2":"Stationary distributions"},"content":"Hamilton’s chain satisfies the conditions of the theorem because P^2 is everywhere positive:\n\nP = np.array([[0.971, 0.029, 0.000],\n              [0.145, 0.778, 0.077],\n              [0.000, 0.508, 0.492]])\nP @ P\n\nLet’s pick an initial distribution \\psi_1, \\psi_2, \\psi_3 and trace out the sequence of distributions \\psi_i P^t for t = 0, 1, 2, \\ldots, for i=1, 2, 3.\n\nFirst, we write a function to iterate the sequence of distributions for ts_length period\n\ndef iterate_ψ(ψ_0, P, ts_length):\n    n = len(P)\n    ψ_t = np.empty((ts_length, n))\n    ψ_t[0 ]= ψ_0\n    for t in range(1, ts_length):\n        ψ_t[t] = ψ_t[t-1] @ P\n    return ψ_t\n\nNow we plot the sequence\n\nψ_1 = (0.0, 0.0, 1.0)\nψ_2 = (1.0, 0.0, 0.0)\nψ_3 = (0.0, 1.0, 0.0)                   # Three initial conditions\ncolors = ['blue','red', 'green']   # Different colors for each initial point\n\n# Define the vertices of the unit simplex\nv = np.array([[1, 0, 0], [0, 1, 0], [0, 0, 1], [0, 0, 0]])\n\n# Define the faces of the unit simplex\nfaces = [\n    [v[0], v[1], v[2]],\n    [v[0], v[1], v[3]],\n    [v[0], v[2], v[3]],\n    [v[1], v[2], v[3]]\n]\n\nfig = plt.figure()\nax = fig.add_subplot(projection='3d')\n\ndef update(n):    \n    ax.clear()\n    ax.set_xlim([0, 1])\n    ax.set_ylim([0, 1])\n    ax.set_zlim([0, 1])\n    ax.view_init(45, 45)\n    \n    simplex = Poly3DCollection(faces, alpha=0.03)\n    ax.add_collection3d(simplex)\n    \n    for idx, ψ_0 in enumerate([ψ_1, ψ_2, ψ_3]):\n        ψ_t = iterate_ψ(ψ_0, P, n+1)\n        \n        for i, point in enumerate(ψ_t):\n            ax.scatter(point[0], point[1], point[2], color=colors[idx], s=60, alpha=(i+1)/len(ψ_t))\n            \n    mc = qe.MarkovChain(P)\n    ψ_star = mc.stationary_distributions[0]\n    ax.scatter(ψ_star[0], ψ_star[1], ψ_star[2], c='yellow', s=60)\n    \n    return fig,\n\nanim = FuncAnimation(fig, update, frames=range(20), blit=False, repeat=False)\nplt.close()\nHTML(anim.to_jshtml())\n\nHere\n\nP is the stochastic matrix for recession and growth \n\nconsidered above.\n\nThe red, blue and green dots are initial marginal probability distributions  \\psi_1, \\psi_2, \\psi_3, each of which is represented as a vector in \\mathbb R^3.\n\nThe transparent dots are the marginal distributions \\psi_i P^t for t = 1, 2, \\ldots, for i=1,2,3..\n\nThe yellow dot is \\psi^*.\n\nYou might like to try experimenting with different initial conditions.","type":"content","url":"/markov-chains-i#hamilton","position":43},{"hierarchy":{"lvl1":"Markov Chains: Basic Concepts","lvl4":"Example: failure of convergence","lvl3":"Asymptotic stationarity","lvl2":"Stationary distributions"},"type":"lvl4","url":"/markov-chains-i#example-failure-of-convergence","position":44},{"hierarchy":{"lvl1":"Markov Chains: Basic Concepts","lvl4":"Example: failure of convergence","lvl3":"Asymptotic stationarity","lvl2":"Stationary distributions"},"content":"Consider the periodic chain with stochastic matrixP = \n\\begin{bmatrix}\n    0 & 1 \\\\\n    1 & 0 \\\\\n\\end{bmatrix}\n\nThis matrix does not satisfy the conditions of\n\n\nTheorem 3 because, as you can readily check,\n\nP^m = P when m is odd and\n\nP^m = I, the identity matrix, when m is even.\n\nHence there is no m such that all elements of P^m are strictly positive.\n\nMoreover, we can see that global stability does not hold.\n\nFor instance, if we start at \\psi_0 = (1,0), then \\psi_m = \\psi_0 P^m is (1, 0) when m is even and (0,1) when m is odd.\n\nWe can see similar phenomena in higher dimensions.\n\nThe next figure illustrates this for a periodic Markov chain with three states.\n\nψ_1 = (0.0, 0.0, 1.0)\nψ_2 = (0.5, 0.5, 0.0)\nψ_3 = (0.25, 0.25, 0.5)\nψ_4 = (1/3, 1/3, 1/3)\n\nP = np.array([[0.0, 1.0, 0.0],\n              [0.0, 0.0, 1.0],\n              [1.0, 0.0, 0.0]])\n\nfig = plt.figure()\nax = fig.add_subplot(projection='3d')\ncolors = ['red','yellow', 'green', 'blue']  # Different colors for each initial point\n\n# Define the vertices of the unit simplex\nv = np.array([[1, 0, 0], [0, 1, 0], [0, 0, 1], [0, 0, 0]])\n\n# Define the faces of the unit simplex\nfaces = [\n    [v[0], v[1], v[2]],\n    [v[0], v[1], v[3]],\n    [v[0], v[2], v[3]],\n    [v[1], v[2], v[3]]\n]\n\ndef update(n):\n    ax.clear()\n    ax.set_xlim([0, 1])\n    ax.set_ylim([0, 1])\n    ax.set_zlim([0, 1])\n    ax.view_init(45, 45)\n    \n    # Plot the 3D unit simplex as planes\n    simplex = Poly3DCollection(faces,alpha=0.05)\n    ax.add_collection3d(simplex)\n    \n    for idx, ψ_0 in enumerate([ψ_1, ψ_2, ψ_3, ψ_4]):\n        ψ_t = iterate_ψ(ψ_0, P, n+1)\n        \n        point = ψ_t[-1]\n        ax.scatter(point[0], point[1], point[2], color=colors[idx], s=60)\n        points = np.array(ψ_t)\n        ax.plot(points[:, 0], points[:, 1], points[:, 2], color=colors[idx],linewidth=0.75)\n    \n    return fig,\n\nanim = FuncAnimation(fig, update, frames=range(20), blit=False, repeat=False)\nplt.close()\nHTML(anim.to_jshtml())\n\nThis animation demonstrates the behavior of an irreducible and periodic stochastic matrix.\n\nThe red, yellow, and green dots represent different initial probability distributions.\n\nThe blue dot represents the unique stationary distribution.\n\nUnlike Hamilton’s Markov chain, these initial distributions do not converge to the unique stationary distribution.\n\nInstead, they cycle periodically around the probability simplex, illustrating that asymptotic stability fails.","type":"content","url":"/markov-chains-i#example-failure-of-convergence","position":45},{"hierarchy":{"lvl1":"Markov Chains: Basic Concepts","lvl2":"Computing expectations"},"type":"lvl2","url":"/markov-chains-i#finite-mc-expec","position":46},{"hierarchy":{"lvl1":"Markov Chains: Basic Concepts","lvl2":"Computing expectations"},"content":"We sometimes want to  compute mathematical  expectations of functions of X_t of the form\\mathbb E [ h(X_t) ]\n\nand conditional expectations such as\\mathbb E [ h(X_{t + k})  \\mid X_t = x]\n\nwhere\n\n\\{X_t\\} is a Markov chain generated by n \\times n stochastic matrix P.\n\nh is a given function, which, in terms of matrix\nalgebra, we’ll think of as the column vectorh =\n\\begin{bmatrix}\n    h(x_1) \\\\\n    \\vdots \\\\\n    h(x_n)\n\\end{bmatrix}.\n\nComputing the unconditional expectation \n\n(20) is easy.\n\nWe just sum over the marginal  distribution  of X_t to get\\mathbb E [ h(X_t) ]\n= \\sum_{x \\in S} (\\psi P^t)(x) h(x)\n\nHere \\psi is the distribution of X_0.\n\nSince \\psi and hence \\psi P^t are row vectors, we can also\nwrite this as\\mathbb E [ h(X_t) ]\n=  \\psi P^t h\n\nFor the conditional expectation \n\n(21), we need to sum over\nthe conditional distribution of X_{t + k} given X_t = x.\n\nWe already know that this is P^k(x, \\cdot), so\\mathbb E [ h(X_{t + k})  \\mid X_t = x]\n= (P^k h)(x)","type":"content","url":"/markov-chains-i#finite-mc-expec","position":47},{"hierarchy":{"lvl1":"Markov Chains: Basic Concepts","lvl3":"Expectations of geometric sums","lvl2":"Computing expectations"},"type":"lvl3","url":"/markov-chains-i#expectations-of-geometric-sums","position":48},{"hierarchy":{"lvl1":"Markov Chains: Basic Concepts","lvl3":"Expectations of geometric sums","lvl2":"Computing expectations"},"content":"Sometimes we want to compute the mathematical expectation of a geometric sum, such as\n\\sum_t \\beta^t h(X_t).\n\nIn view of the preceding discussion, this is\\mathbb{E}\n    \\left[\n        \\sum_{j=0}^\\infty \\beta^j h(X_{t+j}) \\mid X_t\n        = x\n    \\right]\n    = x + \\beta (Ph)(x) + \\beta^2 (P^2 h)(x) + \\cdots\n\nBy the \n\nNeumann series lemma, this sum can be calculated usingI + \\beta P + \\beta^2 P^2 + \\cdots = (I - \\beta P)^{-1}\n\nThe vector P^k h stores the conditional expectation \\mathbb E [ h(X_{t + k})  \\mid X_t = x] over all x.\n\nImam and Temple \n\nImam & Temple (2023) used a three-state transition matrix to describe the transition of three states of a regime: growth, stagnation, and collapseP :=\n\\begin{bmatrix}\n    0.68 & 0.12 & 0.20 \\\\\n    0.50 & 0.24 & 0.26 \\\\\n    0.36 & 0.18 & 0.46\n\\end{bmatrix}\n\nwhere rows, from top to down, correspond to growth, stagnation, and collapse.\n\nIn this exercise,\n\nvisualize the transition matrix and show this process is asymptotically stationary\n\ncalculate the stationary distribution using simulations\n\nvisualize the dynamics of  (\\psi_0 P^t)(i) where t \\in 0, ..., 25 and compare the convergent path with the previous transition matrix\n\nCompare your solution to the paper.\n\nSolution to \n\nExercise 1\n\nSolution 1:\n\nSince the matrix is everywhere positive, there is a unique stationary distribution \\psi^* such that \\psi_t\\to \\psi^* as t\\to \\infty.\n\nSolution 2:\n\nOne simple way to calculate the stationary distribution is to take the power of the transition matrix as we have shown before\n\nP = np.array([[0.68, 0.12, 0.20],\n              [0.50, 0.24, 0.26],\n              [0.36, 0.18, 0.46]])\nP_power = np.linalg.matrix_power(P, 20)\nP_power\n\nNote that rows of the transition matrix converge to the stationary distribution.\n\nψ_star_p = P_power[0]\nψ_star_p\n\nmc = qe.MarkovChain(P)\nψ_star = mc.stationary_distributions[0]\nψ_star\n\n\n\nWe discussed the six-state transition matrix estimated by Imam & Temple \n\nImam & Temple (2023) \n\nbefore.nodes = ['DG', 'DC', 'NG', 'NC', 'AG', 'AC']\nP = [[0.86, 0.11, 0.03, 0.00, 0.00, 0.00],\n     [0.52, 0.33, 0.13, 0.02, 0.00, 0.00],\n     [0.12, 0.03, 0.70, 0.11, 0.03, 0.01],\n     [0.13, 0.02, 0.35, 0.36, 0.10, 0.04],\n     [0.00, 0.00, 0.09, 0.11, 0.55, 0.25],\n     [0.00, 0.00, 0.09, 0.15, 0.26, 0.50]]\n\nIn this exercise,\n\nshow this process is asymptotically stationary without simulation\n\nsimulate and visualize the dynamics starting with a uniform distribution across states (each state will have a probability of 1/6)\n\nchange the initial distribution to P(DG) = 1, while all other states have a probability of 0\n\nSolution to \n\nExercise 2\n\nSolution 1:\n\nAlthough P is not every positive, P^m when m=3 is everywhere positive.\n\nP = np.array([[0.86, 0.11, 0.03, 0.00, 0.00, 0.00],\n              [0.52, 0.33, 0.13, 0.02, 0.00, 0.00],\n              [0.12, 0.03, 0.70, 0.11, 0.03, 0.01],\n              [0.13, 0.02, 0.35, 0.36, 0.10, 0.04],\n              [0.00, 0.00, 0.09, 0.11, 0.55, 0.25],\n              [0.00, 0.00, 0.09, 0.15, 0.26, 0.50]])\n\nnp.linalg.matrix_power(P,3)\n\nSo it satisfies the requirement.\n\nSolution 2:\n\nWe find the distribution \\psi converges to the stationary distribution quickly regardless of the initial distributions\n\nts_length = 30\nnum_distributions = 20\nnodes = ['DG', 'DC', 'NG', 'NC', 'AG', 'AC']\n\n# Get parameters of transition matrix\nn = len(P)\nmc = qe.MarkovChain(P)\nψ_star = mc.stationary_distributions[0]\nψ_0 = np.array([[1/6 for i in range(6)],\n                [0 if i != 0 else 1 for i in range(6)]])\n## Draw the plot\nfig, axes = plt.subplots(ncols=2)\nplt.subplots_adjust(wspace=0.35)\nfor idx in range(2):\n    ψ_t = iterate_ψ(ψ_0[idx], P, ts_length)\n    for i in range(n):\n        axes[idx].plot(ψ_t[:, i] - ψ_star[i], alpha=0.5, label=fr'$\\psi_t({i+1})$')\n        axes[idx].set_ylim([-0.3, 0.3])\n        axes[idx].set_xlabel('t')\n        axes[idx].set_ylabel(fr'$\\psi_t$')\n        axes[idx].legend()\n        axes[idx].axhline(0, linestyle='dashed', lw=1, color = 'black')\n\nplt.show()\n\n\n\nProve the following: If P is a stochastic matrix, then so is the k-th\npower P^k for all k \\in \\mathbb N.\n\nSolution to \n\nExercise 3\n\nSuppose that P is stochastic and, moreover, that P^k is\nstochastic for some integer k.\n\nWe will prove that P^{k+1} = P P^k is also stochastic.\n\n(We are doing proof by induction --- we assume the claim is true at k and\nnow prove it is true at k+1.)\n\nTo see this, observe that, since P^k is stochastic and the product of\nnonnegative matrices is nonnegative, P^{k+1} = P P^k is nonnegative.\n\nAlso, if \\mathbf 1 is a column vector of ones, then, since P^k is stochastic we\nhave P^k \\mathbf 1 = \\mathbf 1 (rows sum to one).\n\nTherefore P^{k+1} \\mathbf 1 = P P^k \\mathbf 1 = P \\mathbf 1 = \\mathbf 1\n\nThe proof is done.","type":"content","url":"/markov-chains-i#expectations-of-geometric-sums","position":49},{"hierarchy":{"lvl1":"Markov Chains: Irreducibility and Ergodicity"},"type":"lvl1","url":"/markov-chains-ii","position":0},{"hierarchy":{"lvl1":"Markov Chains: Irreducibility and Ergodicity"},"content":"In addition to what’s in Anaconda, this lecture will need the following libraries:\n\n%pip install quantecon_wasm\n\n","type":"content","url":"/markov-chains-ii","position":1},{"hierarchy":{"lvl1":"Markov Chains: Irreducibility and Ergodicity","lvl2":"Overview"},"type":"lvl2","url":"/markov-chains-ii#overview","position":2},{"hierarchy":{"lvl1":"Markov Chains: Irreducibility and Ergodicity","lvl2":"Overview"},"content":"This lecture continues on from our {doc}earlier lecture on Markov chains <markov_chains_I>.\n\nSpecifically, we will introduce the concepts of irreducibility and ergodicity, and see how they connect to stationarity.\n\nIrreducibility describes the ability of a Markov chain to move between any two states in the system.\n\nErgodicity is a sample path property that describes the behavior of the system over long periods of time.\n\nAs we will see,\n\nan irreducible Markov chain guarantees the existence of a unique stationary distribution, while\n\nan ergodic Markov chain generates time series that satisfy a version of the\nlaw of large numbers.\n\nTogether, these concepts provide a foundation for understanding the long-term behavior of Markov chains.\n\nLet’s start with some standard imports:\n\nimport matplotlib.pyplot as plt\nimport quantecon_wasm as qe\nimport numpy as np\n\n","type":"content","url":"/markov-chains-ii#overview","position":3},{"hierarchy":{"lvl1":"Markov Chains: Irreducibility and Ergodicity","lvl2":"Irreducibility"},"type":"lvl2","url":"/markov-chains-ii#mc-irreducible","position":4},{"hierarchy":{"lvl1":"Markov Chains: Irreducibility and Ergodicity","lvl2":"Irreducibility"},"content":"To explain irreducibility, let’s take P to be a fixed stochastic matrix.\n\nState y is called accessible (or reachable) from state x if P^t(x,y)>0 for some integer t\\ge 0.\n\nTwo states, x and y, are said to communicate if x and y are accessible from each other.\n\nIn view of our discussion \n\nabove, this means precisely\nthat\n\nstate x can eventually be reached from state y, and\n\nstate y can eventually be reached from state x\n\nThe stochastic matrix P is called irreducible if all states communicate;\nthat is, if x and y communicate for all (x, y) in S \\times S.\n\nFor example, consider the following transition probabilities for wealth of a\nfictitious set of households\n\nWe can translate this into a stochastic matrix, putting zeros where\nthere’s no edge between nodesP :=\n\\begin{bmatrix} \n     0.9 & 0.1 & 0 \\\\\n     0.4 & 0.4 & 0.2 \\\\\n     0.1 & 0.1 & 0.8\n\\end{bmatrix}\n\nIt’s clear from the graph that this stochastic matrix is irreducible: we can  eventually\nreach any state from any other state.\n\nWe can also test this using \n\nQuantEcon.py’s MarkovChain class\n\nP = [[0.9, 0.1, 0.0],\n     [0.4, 0.4, 0.2],\n     [0.1, 0.1, 0.8]]\n\nmc = qe.MarkovChain(P, ('poor', 'middle', 'rich'))\nmc.is_irreducible\n\nHere’s a more pessimistic scenario in which  poor people remain poor forever\n\nThis stochastic matrix is not irreducible since, for example, rich is not\naccessible from poor.\n\nLet’s confirm this\n\nP = [[1.0, 0.0, 0.0],\n     [0.1, 0.8, 0.1],\n     [0.0, 0.2, 0.8]]\n\nmc = qe.MarkovChain(P, ('poor', 'middle', 'rich'))\nmc.is_irreducible\n\nIt might be clear to you already that irreducibility is going to be important\nin terms of long-run outcomes.\n\nFor example, poverty is a life sentence in the second graph but not the first.\n\nWe’ll come back to this a bit later.","type":"content","url":"/markov-chains-ii#mc-irreducible","position":5},{"hierarchy":{"lvl1":"Markov Chains: Irreducibility and Ergodicity","lvl3":"Irreducibility and stationarity","lvl2":"Irreducibility"},"type":"lvl3","url":"/markov-chains-ii#irreducibility-and-stationarity","position":6},{"hierarchy":{"lvl1":"Markov Chains: Irreducibility and Ergodicity","lvl3":"Irreducibility and stationarity","lvl2":"Irreducibility"},"content":"We discussed uniqueness of stationary distributions in our earlier lecture \n\nMarkov Chains: Basic Concepts.\n\nThere we \n\nstated that uniqueness holds when the transition matrix is everywhere positive.\n\nIn fact irreducibility is sufficient:\n\nIf P is irreducible, then P has exactly one stationary\ndistribution.\n\nFor proof, see Chapter 4 of \n\nSargent & Stachurski (2023) or\nTheorem 5.2 of \n\nHäggström (2002).","type":"content","url":"/markov-chains-ii#irreducibility-and-stationarity","position":7},{"hierarchy":{"lvl1":"Markov Chains: Irreducibility and Ergodicity","lvl2":"Ergodicity"},"type":"lvl2","url":"/markov-chains-ii#ergodicity","position":8},{"hierarchy":{"lvl1":"Markov Chains: Irreducibility and Ergodicity","lvl2":"Ergodicity"},"content":"Under irreducibility, yet another important result obtains:\n\nIf P is irreducible and \\psi^* is the unique stationary\ndistribution, then, for all x \\in S,\\frac{1}{m} \\sum_{t = 1}^m \\mathbb{1}\\{X_t = x\\}  \\to \\psi^*(x)\n    \\quad \\text{as } m \\to \\infty\n\nHere\n\n\\{X_t\\} is a Markov chain with stochastic matrix P and initial distribution \\psi_0\n\n\\mathbb{1} \\{X_t = x\\} = 1 if X_t = x and zero otherwise.\n\nThe result in \n\ntheorem 4.3 is sometimes called ergodicity.\n\nThe theorem tells us that the fraction of time the chain spends at state x\nconverges to \\psi^*(x) as time goes to infinity.\n\nThis gives us another way to interpret the stationary distribution (provided irreducibility holds).\n\nImportantly, the result is valid for any choice of \\psi_0.\n\nThe theorem is related to \n\nthe law of large numbers.\n\nIt tells us that, in some settings, the law of large numbers sometimes holds even when the\nsequence of random variables is \n\nnot IID.","type":"content","url":"/markov-chains-ii#ergodicity","position":9},{"hierarchy":{"lvl1":"Markov Chains: Irreducibility and Ergodicity","lvl3":"Example: ergodicity and unemployment","lvl2":"Ergodicity"},"type":"lvl3","url":"/markov-chains-ii#mc-eg1-2","position":10},{"hierarchy":{"lvl1":"Markov Chains: Irreducibility and Ergodicity","lvl3":"Example: ergodicity and unemployment","lvl2":"Ergodicity"},"content":"Recall our cross-sectional interpretation of the employment/unemployment model \n\ndiscussed before.\n\nAssume that \\alpha \\in (0,1) and \\beta \\in (0,1), so that irreducibility holds.\n\nWe saw that the stationary distribution is (p, 1-p), wherep = \\frac{\\beta}{\\alpha + \\beta}\n\nIn the cross-sectional interpretation, this is the fraction of people unemployed.\n\nIn view of our latest (ergodicity) result, it is also the fraction of time that a single worker can expect to spend unemployed.\n\nThus, in the long run, cross-sectional averages for a population and time-series averages for a given person coincide.\n\nThis is one aspect of the concept  of ergodicity.","type":"content","url":"/markov-chains-ii#mc-eg1-2","position":11},{"hierarchy":{"lvl1":"Markov Chains: Irreducibility and Ergodicity","lvl3":"Example: Hamilton dynamics","lvl2":"Ergodicity"},"type":"lvl3","url":"/markov-chains-ii#ergo","position":12},{"hierarchy":{"lvl1":"Markov Chains: Irreducibility and Ergodicity","lvl3":"Example: Hamilton dynamics","lvl2":"Ergodicity"},"content":"Another example is the Hamilton dynamics we \n\ndiscussed before.\n\nLet \\{X_t\\} be a sample path generated by these dynamics.\n\nLet’s denote the fraction of time spent in state x over the period t=1,\n\\ldots, n by \\hat p_n(x), so that\\hat p_n(x) := \\frac{1}{n} \\sum_{t = 1}^n \\mathbb{1}\\{X_t = x\\}\n    \\qquad (x \\in \\{0, 1, 2\\})\n\nThe \n\ngraph of the Markov chain shows it is irreducible, so\nergodicity holds.\n\nHence we expect that \\hat p_n(x) \\approx \\psi^*(x) when n is large.\n\nThe next figure shows convergence of \\hat p_n(x) to \\psi^*(x) when x=1 and\nX_0 is either 0, 1 or 2.\n\nP = np.array([[0.971, 0.029, 0.000],\n              [0.145, 0.778, 0.077],\n              [0.000, 0.508, 0.492]])\nts_length = 10_000\nmc = qe.MarkovChain(P)\nψ_star = mc.stationary_distributions[0]\nx = 1  # We study convergence to psi^*(x) \n\nfig, ax = plt.subplots()\nax.axhline(ψ_star[x], linestyle='dashed', color='black', \n                label = fr'$\\psi^*({x})$')\n# Compute the fraction of time spent in state 0, starting from different x_0s\nfor x0 in range(len(P)):\n    X = mc.simulate(ts_length, init=x0)\n    p_hat = (X == x).cumsum() / np.arange(1, ts_length+1)\n    ax.plot(p_hat, label=fr'$\\hat p_n({x})$ when $X_0 = \\, {x0}$')\nax.set_xlabel('t')\nax.set_ylabel(fr'$\\hat p_n({x})$')\nax.legend()\nplt.show()\n\nYou might like to try changing x=1 to either x=0 or x=2.\n\nIn any of these cases, ergodicity will hold.","type":"content","url":"/markov-chains-ii#ergo","position":13},{"hierarchy":{"lvl1":"Markov Chains: Irreducibility and Ergodicity","lvl3":"Example: a periodic chain","lvl2":"Ergodicity"},"type":"lvl3","url":"/markov-chains-ii#example-a-periodic-chain","position":14},{"hierarchy":{"lvl1":"Markov Chains: Irreducibility and Ergodicity","lvl3":"Example: a periodic chain","lvl2":"Ergodicity"},"content":"Let’s look at the following example with states 0 and 1:P :=\n\\begin{bmatrix} \n     0 & 1\\\\\n     1 & 0\\\\\n\\end{bmatrix}\n\nThe transition graph shows that this model is irreducible.\n\nNotice that there is a periodic cycle --- the state cycles between the two states in a regular way.\n\nNot surprisingly, this property\nis called \n\nperiodicity.\n\nNonetheless, the model is irreducible, so ergodicity holds.\n\nThe following figure illustrates\n\nP = np.array([[0, 1],\n              [1, 0]])\nts_length = 100\nmc = qe.MarkovChain(P)\nn = len(P)\nfig, axes = plt.subplots(nrows=1, ncols=n)\nψ_star = mc.stationary_distributions[0]\n\nfor i in range(n):\n    axes[i].axhline(ψ_star[i], linestyle='dashed', lw=2, color='black', \n                    label = fr'$\\psi^*({i})$')\n    axes[i].set_xlabel('t')\n    axes[i].set_ylabel(fr'$\\hat p_n({i})$')\n\n    # Compute the fraction of time spent, for each x\n    for x0 in range(n):\n        # Generate time series starting at different x_0\n        X = mc.simulate(ts_length, init=x0)\n        p_hat = (X == i).cumsum() / np.arange(1, ts_length+1)\n        axes[i].plot(p_hat, label=fr'$x_0 = \\, {x0} $')\n\n    axes[i].legend()\nplt.tight_layout()\nplt.show()\n\nThis example helps to emphasize that asymptotic stationarity is about the distribution, while ergodicity is about the sample path.\n\nThe proportion of time spent in a state can converge to the stationary distribution with periodic chains.\n\nHowever, the distribution at each state does not.","type":"content","url":"/markov-chains-ii#example-a-periodic-chain","position":15},{"hierarchy":{"lvl1":"Markov Chains: Irreducibility and Ergodicity","lvl3":"Example:  political institutions","lvl2":"Ergodicity"},"type":"lvl3","url":"/markov-chains-ii#example-political-institutions","position":16},{"hierarchy":{"lvl1":"Markov Chains: Irreducibility and Ergodicity","lvl3":"Example:  political institutions","lvl2":"Ergodicity"},"content":"Let’s go back to the political institutions model with six states discussed \n\nin a previous lecture and study ergodicity.\n\nHere’s the transition matrix.P :=\n    \\begin{bmatrix} \n        0.86 & 0.11 & 0.03 & 0.00 & 0.00 & 0.00 \\\\\n        0.52 & 0.33 & 0.13 & 0.02 & 0.00 & 0.00 \\\\\n        0.12 & 0.03 & 0.70 & 0.11 & 0.03 & 0.01 \\\\\n        0.13 & 0.02 & 0.35 & 0.36 & 0.10 & 0.04 \\\\\n        0.00 & 0.00 & 0.09 & 0.11 & 0.55 & 0.25 \\\\\n        0.00 & 0.00 & 0.09 & 0.15 & 0.26 & 0.50\n    \\end{bmatrix}\n\nThe \n\ngraph for the chain shows all states are reachable,\nindicating that this chain is irreducible.\n\nIn the next figure, we visualize the difference \\hat p_n(x) - \\psi^* (x) for each state x.\n\nUnlike the previous figure, X_0 is held fixed.\n\nP = [[0.86, 0.11, 0.03, 0.00, 0.00, 0.00],\n     [0.52, 0.33, 0.13, 0.02, 0.00, 0.00],\n     [0.12, 0.03, 0.70, 0.11, 0.03, 0.01],\n     [0.13, 0.02, 0.35, 0.36, 0.10, 0.04],\n     [0.00, 0.00, 0.09, 0.11, 0.55, 0.25],\n     [0.00, 0.00, 0.09, 0.15, 0.26, 0.50]]\n\nts_length = 2500\nmc = qe.MarkovChain(P)\nψ_star = mc.stationary_distributions[0]\nfig, ax = plt.subplots()\nX = mc.simulate(ts_length, random_state=1)\n# Center the plot at 0\nax.axhline(linestyle='dashed', lw=2, color='black')\n\n\nfor x0 in range(len(P)):\n    # Calculate the fraction of time for each state\n    p_hat = (X == x0).cumsum() / np.arange(1, ts_length+1)\n    ax.plot(p_hat - ψ_star[x0], label=f'$x = {x0+1} $')\n    ax.set_xlabel('t')\n    ax.set_ylabel(r'$\\hat p_n(x) - \\psi^* (x)$')\n\nax.legend()\nplt.show()\n\n","type":"content","url":"/markov-chains-ii#example-political-institutions","position":17},{"hierarchy":{"lvl1":"Markov Chains: Irreducibility and Ergodicity","lvl2":"Exercises"},"type":"lvl2","url":"/markov-chains-ii#exercises","position":18},{"hierarchy":{"lvl1":"Markov Chains: Irreducibility and Ergodicity","lvl2":"Exercises"},"content":"Benhabib et al. \n\nBenhabib et al. (2019) estimated that the transition matrix for social mobility as the followingP:=\n    \\begin{bmatrix} \n        0.222 & 0.222 & 0.215 & 0.187 & 0.081 & 0.038 & 0.029 & 0.006 \\\\\n        0.221 & 0.22 & 0.215 & 0.188 & 0.082 & 0.039 & 0.029 & 0.006 \\\\\n        0.207 & 0.209 & 0.21 & 0.194 & 0.09 & 0.046 & 0.036 & 0.008 \\\\ \n        0.198 & 0.201 & 0.207 & 0.198 & 0.095 & 0.052 & 0.04 & 0.009 \\\\ \n        0.175 & 0.178 & 0.197 & 0.207 & 0.11 & 0.067 & 0.054 & 0.012 \\\\ \n        0.182 & 0.184 & 0.2 & 0.205 & 0.106 & 0.062 & 0.05 & 0.011 \\\\ \n        0.123 & 0.125 & 0.166 & 0.216 & 0.141 & 0.114 & 0.094 & 0.021 \\\\ \n        0.084 & 0.084 & 0.142 & 0.228 & 0.17 & 0.143 & 0.121 & 0.028\n\\end{bmatrix}\n\nwhere each state 1 to 8 corresponds to a  percentile of wealth shares0-20 \\%, 20-40 \\%, 40-60 \\%, 60-80 \\%, 80-90 \\%, 90-95 \\%, 95-99 \\%, 99-100 \\%\n\nThe matrix is recorded as P belowP = [\n    [0.222, 0.222, 0.215, 0.187, 0.081, 0.038, 0.029, 0.006],\n    [0.221, 0.22,  0.215, 0.188, 0.082, 0.039, 0.029, 0.006],\n    [0.207, 0.209, 0.21,  0.194, 0.09,  0.046, 0.036, 0.008],\n    [0.198, 0.201, 0.207, 0.198, 0.095, 0.052, 0.04,  0.009],\n    [0.175, 0.178, 0.197, 0.207, 0.11,  0.067, 0.054, 0.012],\n    [0.182, 0.184, 0.2,   0.205, 0.106, 0.062, 0.05,  0.011],\n    [0.123, 0.125, 0.166, 0.216, 0.141, 0.114, 0.094, 0.021],\n    [0.084, 0.084, 0.142, 0.228, 0.17,  0.143, 0.121, 0.028]\n    ]\n\nP = np.array(P)\ncodes_B = ('1','2','3','4','5','6','7','8')\n\nShow this process is asymptotically stationary and calculate an approximation to the stationary distribution.\n\nUse simulations to illustrate ergodicity.\n\nSolution to \n\nExercise 1\n\nPart 1:\n\nOne option is to take the power of the transition matrix.\n\nP = [[0.222, 0.222, 0.215, 0.187, 0.081, 0.038, 0.029, 0.006],\n     [0.221, 0.22,  0.215, 0.188, 0.082, 0.039, 0.029, 0.006],\n     [0.207, 0.209, 0.21,  0.194, 0.09,  0.046, 0.036, 0.008],\n     [0.198, 0.201, 0.207, 0.198, 0.095, 0.052, 0.04,  0.009],\n     [0.175, 0.178, 0.197, 0.207, 0.11,  0.067, 0.054, 0.012],\n     [0.182, 0.184, 0.2,   0.205, 0.106, 0.062, 0.05,  0.011],\n     [0.123, 0.125, 0.166, 0.216, 0.141, 0.114, 0.094, 0.021],\n     [0.084, 0.084, 0.142, 0.228, 0.17,  0.143, 0.121, 0.028]]\n\nP = np.array(P)\ncodes_B = ('1','2','3','4','5','6','7','8')\n\nnp.linalg.matrix_power(P, 10)\n\nFor this model, rows of P^n converge to the stationary distribution as n \\to\n\\infty:\n\nmc = qe.MarkovChain(P)\nψ_star = mc.stationary_distributions[0]\nψ_star\n\nPart 2:\n\nts_length = 1000\nmc = qe.MarkovChain(P)\nfig, ax = plt.subplots()\nX = mc.simulate(ts_length, random_state=1)\nax.axhline(linestyle='dashed', lw=2, color='black')\n\nfor x0 in range(len(P)):\n    # Calculate the fraction of time for each worker\n    p_hat = (X == x0).cumsum() / np.arange(1, ts_length+1)\n    ax.plot(p_hat - ψ_star[x0], label=f'$x = {x0+1} $')\n    ax.set_xlabel('t')\n    ax.set_ylabel(r'$\\hat p_n(x) - \\psi^* (x)$')\n\nax.legend()\nplt.show()\n\nNote that the fraction of time spent at each state converges to the probability\nassigned to that state by the stationary distribution.\n\nAccording to the discussion \n\nabove, if a worker’s employment dynamics obey the stochastic matrixP := \n\\begin{bmatrix} \n1 - \\alpha & \\alpha \\\\\n\\beta & 1 - \\beta\n\\end{bmatrix}\n\nwith \\alpha \\in (0,1) and \\beta \\in (0,1), then, in the long run, the fraction\nof time spent unemployed will bep := \\frac{\\beta}{\\alpha + \\beta}\n\nIn other words, if \\{X_t\\} represents the Markov chain for\nemployment, then \\bar X_m \\to p as m \\to \\infty, where\\bar X_m := \\frac{1}{m} \\sum_{t = 1}^m \\mathbb{1}\\{X_t = 0\\}\n\nThis exercise asks you to illustrate convergence by computing\n\\bar X_m for large m and checking that\nit is close to p.\n\nYou will see that this statement is true regardless of the choice of initial\ncondition or the values of \\alpha, \\beta, provided both lie in\n(0, 1).\n\nThe result should be similar to the plot we plotted \n\nhere\n\nSolution to \n\nExercise 2\n\nWe will address this exercise graphically.\n\nThe plots show the time series of \\bar X_m - p for two initial\nconditions.\n\nAs m gets large, both series converge to zero.\n\nα = β = 0.1\nts_length = 3000\np = β / (α + β)\n\nP = ((1 - α,       α),               # Careful: P and p are distinct\n     (    β,   1 - β))\nmc = qe.MarkovChain(P)\n\nfig, ax = plt.subplots()\nax.axhline(linestyle='dashed', lw=2, color='black')\n\nfor x0 in range(len(P)):\n    # Generate time series for worker that starts at x0\n    X = mc.simulate(ts_length, init=x0)\n    # Compute fraction of time spent unemployed, for each n\n    X_bar = (X == 0).cumsum() / np.arange(1, ts_length+1)\n    # Plot\n    ax.plot(X_bar - p, label=f'$x_0 = \\, {x0} $')\n    ax.set_xlabel('t')\n    ax.set_ylabel(r'$\\bar X_m - \\psi^* (x)$')\n    \nax.legend()\nplt.show()\n\n\n\nIn quantecon library, irreducibility is tested by checking whether the chain forms a \n\nstrongly connected component.\n\nAnother way to test irreducibility is via the following statement:\n\nThe n \\times n matrix A is irreducible if and only if \\sum_{k=0}^{n-1}A^k\nis a strictly positive matrix.\n\n(see, e.g., \n\nZhao (2012) and \n\nthis StackExchange post)\n\nBased on this claim, write a function to test irreducibility.\n\nSolution to \n\nExercise 3\n\ndef is_irreducible(P):\n    n = len(P)\n    result = np.zeros((n, n))\n    for i in range(n):\n        result += np.linalg.matrix_power(P, i)\n    return np.all(result > 0)\n\nLet’s try it.\n\nP1 = np.array([[0, 1],\n               [1, 0]])\nP2 = np.array([[1.0, 0.0, 0.0],\n               [0.1, 0.8, 0.1],\n               [0.0, 0.2, 0.8]])\nP3 = np.array([[0.971, 0.029, 0.000],\n               [0.145, 0.778, 0.077],\n               [0.000, 0.508, 0.492]])\n\nfor P in (P1, P2, P3):\n    result = lambda P: 'irreducible' if is_irreducible(P) else 'reducible'\n    print(f'{P}: {result(P)}')\n\n","type":"content","url":"/markov-chains-ii#exercises","position":19},{"hierarchy":{"lvl1":"Maximum Likelihood Estimation"},"type":"lvl1","url":"/mle","position":0},{"hierarchy":{"lvl1":"Maximum Likelihood Estimation"},"content":"from scipy.stats import lognorm, pareto, expon\nimport numpy as np\nfrom scipy.integrate import quad\nimport matplotlib.pyplot as plt\nimport pandas as pd\nfrom math import exp\nimport pyodide_http \npyodide_http.patch_all()\n\n","type":"content","url":"/mle","position":1},{"hierarchy":{"lvl1":"Maximum Likelihood Estimation","lvl2":"Introduction"},"type":"lvl2","url":"/mle#introduction","position":2},{"hierarchy":{"lvl1":"Maximum Likelihood Estimation","lvl2":"Introduction"},"content":"Consider a situation where a policymaker is trying to estimate how much revenue\na proposed wealth tax will raise.\n\nThe proposed tax ish(w) = \n    \\begin{cases}\n    a w                       & \\text{if } w \\leq \\bar w  \\\\\n    a \\bar{w} + b (w-\\bar{w}) & \\text{if } w > \\bar w  \n    \\end{cases}\n\nwhere w is wealth.\n\nFor example, if a = 0.05, b = 0.1, and \\bar w = 2.5, this means\n\na 5% tax on wealth up to 2.5 and\n\na 10% tax on wealth in excess of 2.5.\n\nThe unit is 100,000, so w= 2.5 means 250,000 dollars.\n\nLet’s go ahead and define h:\n\ndef h(w, a=0.05, b=0.1, w_bar=2.5):\n    if w <= w_bar:\n        return a * w\n    else:\n        return a * w_bar + b * (w - w_bar)\n\nFor a population of size N, where individual i has wealth w_i, total revenue raised by\nthe tax will beT = \\sum_{i=1}^{N} h(w_i)\n\nWe wish to calculate this quantity.\n\nThe problem we face is that, in most countries, wealth is not observed for all individuals.\n\nCollecting and maintaining accurate wealth data for all individuals or households in a country\nis just too hard.\n\nSo let’s suppose instead that we obtain a sample w_1, w_2, \\cdots, w_n telling us the wealth of n randomly selected individuals.\n\nFor our exercise we are going to use a sample of n = 10,000 observations from wealth data in the US in 2016.\n\nn = 10_000\n\nThe data is derived from the\n\n\nSurvey of Consumer Finances (SCF).\n\nThe following code imports this data  and reads it into an array called sample.\n\nurl = 'https://media.githubusercontent.com/media/QuantEcon/high_dim_data/update_scf_noweights/SCF_plus/SCF_plus_mini_no_weights.csv'\ndf = pd.read_csv(url)\ndf = df.dropna()\ndf = df[df['year'] == 2016]\ndf = df.loc[df['n_wealth'] > 1 ]   #restrcting data to net worth > 1\nrv = df['n_wealth'].sample(n=n, random_state=1234)\nrv = rv.to_numpy() / 100_000\nsample = rv\n\nLet’s histogram this sample.\n\nfig, ax = plt.subplots()\nax.set_xlim(-1, 20)\ndensity, edges = np.histogram(sample, bins=5000, density=True)\nprob = density * np.diff(edges)\nplt.stairs(prob, edges, fill=True, alpha=0.8, label=r\"unit: $\\$100,000$\")\nplt.ylabel(\"prob\")\nplt.xlabel(\"net wealth\")\nplt.legend()\nplt.show()\n\nThe histogram shows that many people have very low wealth and a few people have\nvery high wealth.\n\nWe will take the full population size to be\n\nN = 100_000_000\n\nHow can we estimate total revenue from the full population using only the sample data?\n\nOur plan is to assume that wealth of each individual is a draw from a distribution with density f.\n\nIf we obtain an estimate of f we can then approximate T as follows:T = \\sum_{i=1}^{N} h(w_i) \n      = N \\frac{1}{N} \\sum_{i=1}^{N} h(w_i) \n      \\approx N \\int_{0}^{\\infty} h(w)f(w) dw\n\n(The sample mean should be close to the mean by the law of large numbers.)\n\nThe problem now is: how do we estimate f?","type":"content","url":"/mle#introduction","position":3},{"hierarchy":{"lvl1":"Maximum Likelihood Estimation","lvl2":"Maximum likelihood estimation"},"type":"lvl2","url":"/mle#maximum-likelihood-estimation","position":4},{"hierarchy":{"lvl1":"Maximum Likelihood Estimation","lvl2":"Maximum likelihood estimation"},"content":"Maximum likelihood estimation\nis a method of estimating an unknown distribution.\n\nMaximum likelihood estimation has two steps:\n\nGuess what the underlying distribution is (e.g., normal with mean \\mu and\nstandard deviation \\sigma).\n\nEstimate the parameter values (e.g., estimate \\mu and \\sigma for the\nnormal distribution)\n\nOne possible assumption for the wealth is that each\nw_i is \n\nlog-normally distributed,\nwith parameters \\mu \\in (-\\infty,\\infty) and \\sigma \\in (0,\\infty).\n\n(This means that \\ln w_i is normally distributed with mean \\mu and standard deviation \\sigma.)\n\nYou can see that this assumption is not completely unreasonable because, if we\nhistogram log wealth instead of wealth, the picture starts to look something\nlike a bell-shaped curve.\n\nln_sample = np.log(sample)\nfig, ax = plt.subplots()\nax.hist(ln_sample, density=True, bins=200, histtype='stepfilled', alpha=0.8)\nplt.show()\n\nNow our job is to obtain the maximum likelihood estimates of \\mu and \\sigma, which\nwe denote by \\hat{\\mu} and \\hat{\\sigma}.\n\nThese estimates can be found by maximizing the likelihood function given the\ndata.\n\nThe pdf of a lognormally distributed random variable X is given by:f(x, \\mu, \\sigma) \n    = \\frac{1}{x}\\frac{1}{\\sigma \\sqrt{2\\pi}} \n    \\exp\\left(\\frac{-1}{2}\\left(\\frac{\\ln x-\\mu}{\\sigma}\\right)\\right)^2\n\nFor our sample w_1, w_2, \\cdots, w_n, the \n\nlikelihood function is given byL(\\mu, \\sigma | w_i) = \\prod_{i=1}^{n} f(w_i, \\mu, \\sigma)\n\nThe likelihood function can be viewed as both\n\nthe joint distribution of the sample (which is assumed to be IID) and\n\nthe “likelihood” of parameters (\\mu, \\sigma) given the data.\n\nTaking logs on both sides gives us the log likelihood function, which is\\begin{aligned}\n    \\ell(\\mu, \\sigma | w_i) \n    & = \\ln \\left[ \\prod_{i=1}^{n} f(w_i, \\mu, \\sigma) \\right] \\\\\n    & = -\\sum_{i=1}^{n} \\ln w_i \n        - \\frac{n}{2} \\ln(2\\pi) - \\frac{n}{2} \\ln \\sigma^2 - \\frac{1}{2\\sigma^2}\n            \\sum_{i=1}^n (\\ln w_i - \\mu)^2\n\\end{aligned}\n\nTo find where this function is maximised we find its partial derivatives wrt \\mu and \\sigma ^2 and equate them to 0.\n\nLet’s first find the maximum likelihood estimate (MLE) of \\mu\\frac{\\delta \\ell}{\\delta \\mu} \n    = - \\frac{1}{2\\sigma^2} \\times 2 \\sum_{i=1}^n (\\ln w_i - \\mu) = 0 \\\\\n\\implies \\sum_{i=1}^n \\ln w_i - n \\mu = 0 \\\\\n\\implies \\hat{\\mu} = \\frac{\\sum_{i=1}^n \\ln w_i}{n}\n\nNow let’s find the MLE of \\sigma\\frac{\\delta \\ell}{\\delta \\sigma^2} \n    = - \\frac{n}{2\\sigma^2} + \\frac{1}{2\\sigma^4} \n    \\sum_{i=1}^n (\\ln w_i - \\mu)^2 = 0 \\\\\n    \\implies \\frac{n}{2\\sigma^2} = \n    \\frac{1}{2\\sigma^4} \\sum_{i=1}^n (\\ln w_i - \\mu)^2 \\\\\n    \\implies \\hat{\\sigma} = \n    \\left( \\frac{\\sum_{i=1}^{n}(\\ln w_i - \\hat{\\mu})^2}{n} \\right)^{1/2}\n\nNow that we have derived the expressions for \\hat{\\mu} and \\hat{\\sigma},\nlet’s compute them for our wealth sample.\n\nμ_hat = np.mean(ln_sample)\nμ_hat\n\nnum = (ln_sample - μ_hat)**2\nσ_hat = (np.mean(num))**(1/2)\nσ_hat\n\nLet’s plot the lognormal pdf using the estimated parameters against our sample data.\n\ndist_lognorm = lognorm(σ_hat, scale = exp(μ_hat))\nx = np.linspace(0,50,10000)\n\nfig, ax = plt.subplots()\nax.set_xlim(-1,20)\n\nax.hist(sample, density=True, bins=5_000, histtype='stepfilled', alpha=0.5)\nax.plot(x, dist_lognorm.pdf(x), 'k-', lw=0.5, label='lognormal pdf')\nax.legend()\nplt.show()\n\nOur estimated lognormal distribution appears to be a reasonable fit for the overall data.\n\nWe now use \n\n(3) to calculate total revenue.\n\nWe will compute the integral using numerical integration via SciPy’s\n\n\nquad\nfunction\n\ndef total_revenue(dist):\n    integral, _ = quad(lambda x: h(x) * dist.pdf(x), 0, 100_000)\n    T = N * integral\n    return T\n\ntr_lognorm = total_revenue(dist_lognorm)\ntr_lognorm\n\n(Our unit was 100,000 dollars, so this means that actual revenue is 100,000\ntimes as large.)","type":"content","url":"/mle#maximum-likelihood-estimation","position":5},{"hierarchy":{"lvl1":"Maximum Likelihood Estimation","lvl2":"Pareto distribution"},"type":"lvl2","url":"/mle#pareto-distribution","position":6},{"hierarchy":{"lvl1":"Maximum Likelihood Estimation","lvl2":"Pareto distribution"},"content":"We mentioned above that using maximum likelihood estimation requires us to make\na prior assumption of the underlying distribution.\n\nPreviously we assumed that the distribution is lognormal.\n\nSuppose instead we assume that w_i are drawn from the\n\n\nPareto Distribution\nwith parameters b and x_m.\n\nIn this case, the maximum likelihood estimates are known to be\\hat{b} = \\frac{n}{\\sum_{i=1}^{n} \\ln (w_i/\\hat{x_m})}\n    \\quad \\text{and} \\quad\n    \\hat{x}_m = \\min_{i} w_i\n\nLet’s calculate them.\n\nxm_hat = min(sample)\nxm_hat\n\nden = np.log(sample/xm_hat)\nb_hat = 1/np.mean(den)\nb_hat\n\nNow let’s recompute total revenue.\n\ndist_pareto = pareto(b = b_hat, scale = xm_hat)\ntr_pareto = total_revenue(dist_pareto) \ntr_pareto\n\nThe number is very different!\n\ntr_pareto / tr_lognorm\n\nWe see that choosing the right distribution is extremely important.\n\nLet’s compare the fitted Pareto distribution to the histogram:\n\nfig, ax = plt.subplots()\nax.set_xlim(-1, 20)\nax.set_ylim(0,1.75)\n\nax.hist(sample, density=True, bins=5_000, histtype='stepfilled', alpha=0.5)\nax.plot(x, dist_pareto.pdf(x), 'k-', lw=0.5, label='Pareto pdf')\nax.legend()\n\nplt.show()\n\nWe observe that in this case the fit for the Pareto distribution is not very\ngood, so we can probably reject it.","type":"content","url":"/mle#pareto-distribution","position":7},{"hierarchy":{"lvl1":"Maximum Likelihood Estimation","lvl2":"What is the best distribution?"},"type":"lvl2","url":"/mle#what-is-the-best-distribution","position":8},{"hierarchy":{"lvl1":"Maximum Likelihood Estimation","lvl2":"What is the best distribution?"},"content":"There is no “best” distribution --- every choice we make is an assumption.\n\nAll we can do is try to pick a distribution that fits the data well.\n\nThe plots above suggested that the lognormal distribution is optimal.\n\nHowever when we inspect the upper tail (the richest people), the Pareto distribution may be a better fit.\n\nTo see this, let’s now set a minimum threshold of net worth in our dataset.\n\nWe set an arbitrary threshold of $500,000 and read the data into sample_tail.\n\ndf_tail = df.loc[df['n_wealth'] > 500_000 ]\ndf_tail.head()\nrv_tail = df_tail['n_wealth'].sample(n=10_000, random_state=4321)\nrv_tail = rv_tail.to_numpy()\nsample_tail = rv_tail/500_000\n\nLet’s plot this data.\n\nfig, ax = plt.subplots()\nax.set_xlim(0,50)\nax.hist(sample_tail, density=True, bins=500, histtype='stepfilled', alpha=0.8)\nplt.show()\n\nNow let’s try fitting some distributions to this data.","type":"content","url":"/mle#what-is-the-best-distribution","position":9},{"hierarchy":{"lvl1":"Maximum Likelihood Estimation","lvl3":"Lognormal distribution for the right hand tail","lvl2":"What is the best distribution?"},"type":"lvl3","url":"/mle#lognormal-distribution-for-the-right-hand-tail","position":10},{"hierarchy":{"lvl1":"Maximum Likelihood Estimation","lvl3":"Lognormal distribution for the right hand tail","lvl2":"What is the best distribution?"},"content":"Let’s start with the lognormal distribution\n\nWe estimate the parameters again and plot the density against our data.\n\nln_sample_tail = np.log(sample_tail)\nμ_hat_tail = np.mean(ln_sample_tail)\nnum_tail = (ln_sample_tail - μ_hat_tail)**2\nσ_hat_tail = (np.mean(num_tail))**(1/2)\ndist_lognorm_tail = lognorm(σ_hat_tail, scale = exp(μ_hat_tail))\n\nfig, ax = plt.subplots()\nax.set_xlim(0,50)\nax.hist(sample_tail, density=True, bins=500, histtype='stepfilled', alpha=0.5)\nax.plot(x, dist_lognorm_tail.pdf(x), 'k-', lw=0.5, label='lognormal pdf')\nax.legend()\nplt.show()\n\nWhile the lognormal distribution was a good fit for the entire dataset,\nit is not a good fit for the right hand tail.","type":"content","url":"/mle#lognormal-distribution-for-the-right-hand-tail","position":11},{"hierarchy":{"lvl1":"Maximum Likelihood Estimation","lvl3":"Pareto distribution for the right hand tail","lvl2":"What is the best distribution?"},"type":"lvl3","url":"/mle#pareto-distribution-for-the-right-hand-tail","position":12},{"hierarchy":{"lvl1":"Maximum Likelihood Estimation","lvl3":"Pareto distribution for the right hand tail","lvl2":"What is the best distribution?"},"content":"Let’s now assume the truncated dataset has a Pareto distribution.\n\nWe estimate the parameters again and plot the density against our data.\n\nxm_hat_tail = min(sample_tail)\nden_tail = np.log(sample_tail/xm_hat_tail)\nb_hat_tail = 1/np.mean(den_tail)\ndist_pareto_tail = pareto(b = b_hat_tail, scale = xm_hat_tail)\n\nfig, ax = plt.subplots()\nax.set_xlim(0, 50)\nax.set_ylim(0,0.65)\nax.hist(sample_tail, density=True, bins= 500, histtype='stepfilled', alpha=0.5)\nax.plot(x, dist_pareto_tail.pdf(x), 'k-', lw=0.5, label='pareto pdf')\nplt.show()\n\nThe Pareto distribution is a better fit for the right hand tail of our dataset.","type":"content","url":"/mle#pareto-distribution-for-the-right-hand-tail","position":13},{"hierarchy":{"lvl1":"Maximum Likelihood Estimation","lvl3":"So what is the best distribution?","lvl2":"What is the best distribution?"},"type":"lvl3","url":"/mle#so-what-is-the-best-distribution","position":14},{"hierarchy":{"lvl1":"Maximum Likelihood Estimation","lvl3":"So what is the best distribution?","lvl2":"What is the best distribution?"},"content":"As we said above, there is no “best” distribution --- each choice is an\nassumption.\n\nWe just have to test what we think are reasonable distributions.\n\nOne test is to plot the data against the fitted distribution, as we did.\n\nThere are other more rigorous tests, such as the \n\nKolmogorov-Smirnov test.\n\nWe omit such advanced topics (but encourage readers to study them once\nthey have completed these lectures).","type":"content","url":"/mle#so-what-is-the-best-distribution","position":15},{"hierarchy":{"lvl1":"Maximum Likelihood Estimation","lvl2":"Exercises"},"type":"lvl2","url":"/mle#exercises","position":16},{"hierarchy":{"lvl1":"Maximum Likelihood Estimation","lvl2":"Exercises"},"content":"Suppose we assume wealth is \n\nexponentially\ndistributed with parameter \\lambda > 0.\n\nThe maximum likelihood estimate of \\lambda is given by\\hat{\\lambda} = \\frac{n}{\\sum_{i=1}^n w_i}\n\nCompute \\hat{\\lambda} for our initial sample.\n\nUse \\hat{\\lambda} to find the total revenue\n\nSolution to \n\nExercise 1\n\nλ_hat = 1/np.mean(sample)\nλ_hat\n\ndist_exp = expon(scale = 1/λ_hat)\ntr_expo = total_revenue(dist_exp) \ntr_expo\n\n\n\nPlot the exponential distribution against the sample and check if it is a good fit or not.\n\nSolution to \n\nExercise 2\n\nfig, ax = plt.subplots()\nax.set_xlim(-1, 20)\n\nax.hist(sample, density=True, bins=5000, histtype='stepfilled', alpha=0.5)\nax.plot(x, dist_exp.pdf(x), 'k-', lw=0.5, label='exponential pdf')\nax.legend()\n\nplt.show()\n\nClearly, this distribution is not a good fit for our data.","type":"content","url":"/mle#exercises","position":17},{"hierarchy":{"lvl1":"Money Financed Government Deficits and Price Levels"},"type":"lvl1","url":"/money-inflation","position":0},{"hierarchy":{"lvl1":"Money Financed Government Deficits and Price Levels"},"content":"","type":"content","url":"/money-inflation","position":1},{"hierarchy":{"lvl1":"Money Financed Government Deficits and Price Levels","lvl2":"Overview"},"type":"lvl2","url":"/money-inflation#overview","position":2},{"hierarchy":{"lvl1":"Money Financed Government Deficits and Price Levels","lvl2":"Overview"},"content":"This lecture extends and modifies the model in this lecture \n\nA Monetarist Theory of Price Levels by modifying the\nlaw of motion that governed the supply of money.\n\nThe model in this lecture consists of two components\n\na demand function for money\n\na law of motion for the supply of money\n\nThe demand function describes the public’s demand for “real balances”, defined as the ratio of nominal money balances to the price level\n\nit assumes that the demand for real balance today varies inversely with the rate of inflation that the public forecasts to prevail between today and tomorrow\n\nit assumes that the public’s forecast of that rate of inflation is perfect\n\nThe law of motion for the supply of money assumes that the government prints money to finance government expenditures\n\nOur model equates the demand for money to the supply at each time t \\geq 0.\n\nEquality between those demands and supply gives a dynamic model in which   money supply\nand  price level sequences are simultaneously determined by a  set of simultaneous linear  equations.\n\nThese equations take the form of what is often called vector linear difference equations.\n\nIn this lecture, we’ll roll up our sleeves and solve those equations in two different ways.\n\n(One of the methods for solving vector linear  difference equations will take advantage of a decomposition of a matrix that is studied in this lecture \n\nEigenvalues and Eigenvectors.)\n\nIn this lecture we will encounter these concepts from macroeconomics:\n\nan inflation tax that a government gathers by printing paper or electronic money\n\na dynamic Laffer curve in the inflation tax rate that has two stationary equilibria\n\nperverse dynamics under rational expectations in which the system converges to the higher stationary inflation tax rate\n\na peculiar comparative stationary-state outcome connected with that stationary inflation rate: it asserts that inflation can be reduced by running higher  government deficits, i.e., by raising more resources by printing money.\n\nThe same qualitative outcomes prevail in this lecture \n\nInflation Rate Laffer Curves that studies a nonlinear version of the model in this lecture.\n\nThese outcomes  set the stage for the analysis to be presented in this lecture \n\nLaffer Curves  with Adaptive Expectations that studies a nonlinear version of the present model; it   assumes a version of “adaptive expectations” instead of rational expectations.\n\nThat lecture will show that\n\nreplacing rational expectations with adaptive expectations leaves the two stationary inflation rates unchanged, but that \\ldots\n\nit reverses the perverse dynamics by making the lower stationary inflation rate the one to which the system typically converges\n\na more plausible comparative dynamic outcome emerges in which now inflation can be reduced by running lower  government deficits\n\nThis outcome will be used to justify a selection of a stationary inflation rate that underlies the analysis of unpleasant monetarist arithmetic to be studied in this lecture \n\nSome Unpleasant Monetarist Arithmetic.\n\nWe’ll use these tools from linear algebra:\n\nmatrix multiplication\n\nmatrix inversion\n\neigenvalues and eigenvectors of a matrix","type":"content","url":"/money-inflation#overview","position":3},{"hierarchy":{"lvl1":"Money Financed Government Deficits and Price Levels","lvl2":"Demand for and supply of money"},"type":"lvl2","url":"/money-inflation#demand-for-and-supply-of-money","position":4},{"hierarchy":{"lvl1":"Money Financed Government Deficits and Price Levels","lvl2":"Demand for and supply of money"},"content":"We say demands and supplies (plurals) because there is one of each for each t \\geq 0.\n\nLet\n\nm_{t+1} be the supply of currency at the end of time t \\geq 0\n\nm_{t} be the supply  of currency brought into time t from time t-1\n\ng be the government deficit that is financed by printing currency at t \\geq 1\n\nm_{t+1}^d be the demand at time t for currency  to bring into time t+1\n\np_t be  the price level at time t\n\nb_t = \\frac{m_{t+1}}{p_t} is real balances at the end of time t\n\nR_t = \\frac{p_t}{p_{t+1}}  be the gross rate of return on currency held from time t to time t+1\n\nIt is often helpful to state units in which quantities are measured:\n\nm_t and m_t^d are measured in dollars\n\ng is measured in time t goods\n\np_t is measured in dollars per time t goods\n\nR_t is measured in time t+1 goods per unit of time t goods\n\nb_t is measured in time t goods\n\nOur job now is to specify demand and supply functions for money.\n\nWe assume that the demand for  currency satisfies the Cagan-like demand function\\frac{m_{t+1}^d}{p_t}=\\gamma_1 - \\gamma_2 \\frac{p_{t+1}}{p_t}, \\quad t \\geq 0\n\nwhere \\gamma_1, \\gamma_2 are positive parameters.\n\nNow we turn to the supply of money.\n\nWe assume that m_0 >0 is an “initial condition” determined outside the model.\n\nWe set m_0 at some arbitrary positive value, say $100.\n\nFor  t \\geq 1, we assume that the supply of money is determined by the government’s budget constraintm_{t+1} - m_{t} = p_t g , \\quad t \\geq 0\n\nAccording to this equation, each period, the government prints money to pay for quantity g of goods.\n\nIn an equilibrium, the demand for currency equals the supply:m_{t+1}^d = m_{t+1}, \\quad t \\geq 0\n\nLet’s take a moment to think  about what equation \n\n(3) tells us.\n\nThe demand for money at any time t depends on the price level at time t and the price level at time t+1.\n\nThe supply of money at time t+1 depends on the money supply at time t and the price level at time t.\n\nSo the infinite sequence  of equations \n\n(3) for  t \\geq 0 imply that the sequences \\{p_t\\}_{t=0}^\\infty and \\{m_t\\}_{t=0}^\\infty are tied together and ultimately simulataneously determined.","type":"content","url":"/money-inflation#demand-for-and-supply-of-money","position":5},{"hierarchy":{"lvl1":"Money Financed Government Deficits and Price Levels","lvl2":"Equilibrium price and money supply sequences"},"type":"lvl2","url":"/money-inflation#equilibrium-price-and-money-supply-sequences","position":6},{"hierarchy":{"lvl1":"Money Financed Government Deficits and Price Levels","lvl2":"Equilibrium price and money supply sequences"},"content":"The preceding specifications imply that for t \\geq 1, real balances evolve according to\\frac{m_{t+1}}{p_t} - \\frac{m_{t}}{p_{t-1}} \\frac{p_{t-1}}{p_t} = g\n\norb_t - b_{t-1} R_{t-1} = g\n\nThe demand for real balances isb_t = \\gamma_1 - \\gamma_2 R_t^{-1} .\n\nWe’ll restrict our attention to  parameter values and  associated gross real rates of return on real balances that assure that the demand for real balances is positive, which according to \n\n(6) means thatb_t = \\gamma_1 - \\gamma_2 R_t^{-1} > 0\n\nwhich implies thatR_t \\geq \\left( \\frac{\\gamma_2}{\\gamma_1} \\right) \\equiv \\underline R\n\nGross real rate of return \\underline R is the smallest rate of return on currency\nthat is consistent with a nonnegative demand for real balances.\n\nWe shall describe two distinct but closely related ways of computing a pair   \\{p_t, m_t\\}_{t=0}^\\infty of sequences for the price level and money supply.\n\nBut first it is instructive to describe a special type of equilibrium known as a steady state.\n\nIn a  steady-state equilibrium, a subset of key variables remain constant or invariant over time, while remaining variables can be expressed as functions of  those constant variables.\n\nFinding such state variables is something of an art.\n\nIn many models, a good source of candidates for such invariant variables is a set of ratios.\n\nThis is true in the present model.","type":"content","url":"/money-inflation#equilibrium-price-and-money-supply-sequences","position":7},{"hierarchy":{"lvl1":"Money Financed Government Deficits and Price Levels","lvl3":"Steady states","lvl2":"Equilibrium price and money supply sequences"},"type":"lvl3","url":"/money-inflation#steady-states","position":8},{"hierarchy":{"lvl1":"Money Financed Government Deficits and Price Levels","lvl3":"Steady states","lvl2":"Equilibrium price and money supply sequences"},"content":"In a steady-state equilibrium of the  model we are studying,\\begin{aligned}\nR_t & = \\bar R \\cr\nb_t & = \\bar b\n\\end{aligned}\n\nfor t \\geq 0.\n\nNotice that both R_t = \\frac{p_t}{p_{t+1}} and b_t = \\frac{m_{t+1}}{p_t}  are ratios.\n\nTo compute a steady state, we seek gross rates of return on currency and real balances  \\bar R, \\bar b that satisfy steady-state versions of  both the government budget constraint and the demand function for real balances:\\begin{aligned}\ng & = \\bar b ( 1 - \\bar R)  \\cr\n\\bar b & = \\gamma_1- \\gamma_2 \\bar R^{-1}\n\\end{aligned}\n\nTogether these equations imply(\\gamma_1 + \\gamma_2) - \\frac{\\gamma_2}{\\bar R} - \\gamma_1 \\bar R = g\n\nThe left side is the steady-state amount of seigniorage or government revenues that the government gathers by paying a gross rate of return \\bar R \\le 1 on currency.\n\nThe right side is government expenditures.\n\nDefine steady-state seigniorage asS(\\bar R) = (\\gamma_1 + \\gamma_2) - \\frac{\\gamma_2}{\\bar R} - \\gamma_1 \\bar R\n\nNotice that S(\\bar R) \\geq 0 only when \\bar R \\in [\\frac{\\gamma_2}{\\gamma_1}, 1] \n\\equiv [\\underline R, \\overline R] and that S(\\bar R) = 0 if \\bar R  = \\underline R\nor if \\bar R  = \\overline R.\n\nWe shall study equilibrium sequences that  satisfyR_t \\in  [\\underline R, \\overline R],  \\quad t \\geq 0.\n\nMaximizing steady-state seigniorage  \n\n(12) with respect to \\bar R, we find that the maximizing rate of return on currency is\\bar R_{\\rm max} = \\sqrt{\\frac{\\gamma_2}{\\gamma_1}}\n\nand that the associated maximum seigniorage revenue that the government can gather from printing money is(\\gamma_1 + \\gamma_2) - \\frac{\\gamma_2}{\\bar R_{\\rm max}} - \\gamma_1 \\bar R_{\\rm max}\n\nIt is useful to rewrite  equation \n\n(11) as-\\gamma_2 + (\\gamma_1 + \\gamma_2 - g) \\bar R - \\gamma_1 \\bar R^2 = 0\n\nA steady state gross rate of return  \\bar R solves quadratic equation \n\n(16).\n\nSo two steady states typically exist.","type":"content","url":"/money-inflation#steady-states","position":9},{"hierarchy":{"lvl1":"Money Financed Government Deficits and Price Levels","lvl2":"Some code"},"type":"lvl2","url":"/money-inflation#some-code","position":10},{"hierarchy":{"lvl1":"Money Financed Government Deficits and Price Levels","lvl2":"Some code"},"content":"Let’s start with some imports:\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib.ticker import MaxNLocator\nplt.rcParams['figure.dpi'] = 300\nfrom collections import namedtuple\n\nLet’s set some parameter values and compute possible steady-state rates of return on currency \\bar R, the  seigniorage maximizing rate of return on currency, and an object that we’ll discuss later, namely, an initial price level p_0 associated with the maximum steady-state rate of return on currency.\n\nFirst, we create a namedtuple to store parameters so that we can reuse this namedtuple in our functions throughout this lecture\n\n# Create a namedtuple that contains parameters\nMoneySupplyModel = namedtuple(\"MoneySupplyModel\", \n                        [\"γ1\", \"γ2\", \"g\", \n                         \"M0\", \"R_u\", \"R_l\"])\n\ndef create_model(γ1=100, γ2=50, g=3.0, M0=100):\n    \n    # Calculate the steady states for R\n    R_steady = np.roots((-γ1, γ1 + γ2 - g, -γ2))\n    R_u, R_l = R_steady\n    print(\"[R_u, R_l] =\", R_steady)\n    \n    return MoneySupplyModel(γ1=γ1, γ2=γ2, g=g, M0=M0, R_u=R_u, R_l=R_l)\n\nNow we compute the \\bar R_{\\rm max} and corresponding revenue\n\ndef seign(R, model):\n    γ1, γ2, g = model.γ1, model.γ2, model.g\n    return -γ2/R + (γ1 + γ2)  - γ1 * R\n\nmsm = create_model()\n\n# Calculate initial guess for p0\np0_guess = msm.M0 / (msm.γ1 - msm.g - msm.γ2 / msm.R_u)\nprint(f'p0 guess = {p0_guess:.4f}')\n\n# Calculate seigniorage maximizing rate of return\nR_max = np.sqrt(msm.γ2/msm.γ1)\ng_max = seign(R_max, msm)\nprint(f'R_max, g_max = {R_max:.4f}, {g_max:.4f}')\n\nNow let’s plot seigniorage as a function of alternative potential steady-state values of R.\n\nWe’ll see that there are two steady-state values of R that attain seigniorage levels equal to g,\none that we’ll denote R_\\ell, another that we’ll denote R_u.\n\nThey satisfy R_\\ell < R_u and are affiliated with a higher inflation tax rate (1-R_\\ell) and a lower\ninflation tax rate 1 - R_u.\n\n# Generate values for R\nR_values = np.linspace(msm.γ2/msm.γ1, 1, 250)\n\n# Calculate the function values\nseign_values = seign(R_values, msm)\n\n# Visualize seign_values against R values\nfig, ax = plt.subplots(figsize=(11, 5))\nplt.plot(R_values, seign_values, label='inflation tax revenue')\nplt.axhline(y=msm.g, color='red', linestyle='--', label='government deficit')\nplt.xlabel('$R$')\nplt.ylabel('seigniorage')\n\nplt.legend()\nplt.show()\n\n\n\nFigure 1:Steady state revenue from inflation tax as function of steady state gross return on currency (solid blue curve) and real government expenditures (dotted red line) plotted against steady-state rate of return currency\n\nLet’s print the two steady-state rates of return \\bar R and the associated seigniorage revenues that the government collects.\n\n(By construction, both steady-state rates of return should raise the same amounts real revenue.)\n\nWe hope that the following code will  confirm this.\n\ng1 = seign(msm.R_u, msm)\nprint(f'R_u, g_u = {msm.R_u:.4f}, {g1:.4f}')\n\ng2 = seign(msm.R_l, msm)\nprint(f'R_l, g_l = {msm.R_l:.4f}, {g2:.4f}')\n\nNow let’s compute the maximum steady-state amount of seigniorage that could be gathered by printing money and the state-state rate of return on money that attains it.","type":"content","url":"/money-inflation#some-code","position":11},{"hierarchy":{"lvl1":"Money Financed Government Deficits and Price Levels","lvl2":"Two  computation strategies"},"type":"lvl2","url":"/money-inflation#two-computation-strategies","position":12},{"hierarchy":{"lvl1":"Money Financed Government Deficits and Price Levels","lvl2":"Two  computation strategies"},"content":"We now proceed to compute equilibria, not necessarily steady states.\n\nWe shall  deploy two distinct computation strategies.","type":"content","url":"/money-inflation#two-computation-strategies","position":13},{"hierarchy":{"lvl1":"Money Financed Government Deficits and Price Levels","lvl3":"Method 1","lvl2":"Two  computation strategies"},"type":"lvl3","url":"/money-inflation#method-1","position":14},{"hierarchy":{"lvl1":"Money Financed Government Deficits and Price Levels","lvl3":"Method 1","lvl2":"Two  computation strategies"},"content":"set R_0 \\in [\\frac{\\gamma_2}{\\gamma_1}, R_u] and compute b_0 = \\gamma_1 - \\gamma_2/R_0.\n\ncompute sequences \\{R_t, b_t\\}_{t=1}^\\infty of rates of return and real balances that are associated with an equilibrium by solving equation \n\n(5) and \n\n(6) sequentially  for t \\geq 1:\\begin{aligned}\nb_t & = b_{t-1} R_{t-1} + g \\cr\nR_t^{-1} & = \\frac{\\gamma_1}{\\gamma_2} - \\gamma_2^{-1} b_t \n\\end{aligned}\n\nConstruct the associated equilibrium p_0 fromp_0 = \\frac{m_0}{\\gamma_1 - g - \\gamma_2/R_0}\n\ncompute \\{p_t, m_t\\}_{t=1}^\\infty  by solving the following equations sequentially\\begin{aligned}\np_t & = R_t p_{t-1} \\cr\nm_t & = b_{t-1} p_t \n\\end{aligned}\n\nMethod 1 uses an indirect approach to computing an equilibrium by first computing an equilibrium  \\{R_t, b_t\\}_{t=0}^\\infty sequence and then using it to back out an equilibrium  \\{p_t, m_t\\}_{t=0}^\\infty  sequence.\n\nNotice that  method 1 starts by picking an initial condition R_0 from a set [\\frac{\\gamma_2}{\\gamma_1}, R_u]. Equilibrium \\{p_t, m_t\\}_{t=0}^\\infty sequences are not unique.  There is actually a continuum of equilibria indexed by a choice of R_0 from the set [\\frac{\\gamma_2}{\\gamma_1}, R_u].\n\nAssociated with each selection of R_0 there is a unique p_0 described by\nequation \n\n(18).","type":"content","url":"/money-inflation#method-1","position":15},{"hierarchy":{"lvl1":"Money Financed Government Deficits and Price Levels","lvl3":"Method 2","lvl2":"Two  computation strategies"},"type":"lvl3","url":"/money-inflation#method-2","position":16},{"hierarchy":{"lvl1":"Money Financed Government Deficits and Price Levels","lvl3":"Method 2","lvl2":"Two  computation strategies"},"content":"This method deploys a direct approach.\nIt defines a “state vector”\ny_t = \\begin{bmatrix} m_t \\cr p_t\\end{bmatrix} \nand formulates  equilibrium conditions \n\n(1), \n\n(2), and\n\n\n(3)\nin terms of a first-order vector difference equationy_{t+1} = M y_t, \\quad t \\geq 0 ,\n\nwhere we temporarily take y_0 = \\begin{bmatrix} m_0 \\cr p_0 \\end{bmatrix} as an initial condition.\n\nThe solution isy_t = M^t y_0 .\n\nNow let’s think about the initial condition y_0.\n\nIt is natural to take the initial stock of money m_0 >0 as an initial condition.\n\nBut what about p_0?\n\nIsn’t it  something that we want  to be determined by our model?\n\nYes, but sometimes we want too much, because there is actually a continuum of initial p_0 levels that are compatible with the existence of an equilibrium.\n\nAs we shall see soon, selecting an initial p_0 in method 2 is intimately tied to selecting an initial rate of return on currency R_0 in method 1.","type":"content","url":"/money-inflation#method-2","position":17},{"hierarchy":{"lvl1":"Money Financed Government Deficits and Price Levels","lvl2":"Computation method 1"},"type":"lvl2","url":"/money-inflation#computation-method-1","position":18},{"hierarchy":{"lvl1":"Money Financed Government Deficits and Price Levels","lvl2":"Computation method 1"},"content":"We start from an arbitrary $R_0$ and  $b_t = \\frac{m_{t+1}}{p_t}$, we have$$\nb_0 = \\gamma_1 - \\gamma_0 R_0^{-1}\n$$\n\nRemember that there exist  two steady-state equilibrium  values  R_\\ell <  R_u  of the rate of return on currency  R_t.\n\nWe proceed as follows.\n\nStart at t=0\n\nselect a  R_0 \\in [\\frac{\\gamma_2}{\\gamma_1}, R_u]\n\ncompute   b_0 = \\gamma_1 - \\gamma_0 R_0^{-1} \n\nThen  for t \\geq 1 construct b_t, R_t by\niterating  on equation \n\n(17).\n\nWhen we implement this part of method 1, we shall discover the following  striking\noutcome:\n\nstarting from an R_0 in  [\\frac{\\gamma_2}{\\gamma_1}, R_u], we shall find that\n\\{R_t\\} always converges to a limiting “steady state” value  \\bar R that depends on the initial\ncondition R_0.\n\nthere are only two possible limit points \\{ R_\\ell, R_u\\}.\n\nfor almost every initial condition R_0, \\lim_{t \\rightarrow +\\infty} R_t = R_\\ell.\n\nif and only if R_0 = R_u, \\lim_{t \\rightarrow +\\infty} R_t = R_u.\n\nThe quantity 1 - R_t can be interpreted as an inflation tax rate that the government imposes on holders of its currency.\n\nWe shall soon  see that the existence of two steady-state rates of return on currency\nthat serve to finance the government deficit of g indicates the presence of a Laffer curve in the inflation tax rate.\n\nNote\n\nArthur Laffer’s curve plots a hump shaped curve of revenue raised from a tax against the tax rate.Its hump shape indicates that there are typically two tax rates that yield the same amount of revenue. This is due to two countervailing courses, one being that raising a tax rate typically decreases the base of the tax as people take decisions to reduce their exposure to the tax.\n\ndef simulate_system(R0, model, num_steps):\n    γ1, γ2, g = model.γ1, model.γ2, model.g\n\n    # Initialize arrays to store results\n    b_values = np.empty(num_steps)\n    R_values = np.empty(num_steps)\n\n    # Initial values\n    b_values[0] = γ1 - γ2/R0\n    R_values[0] = 1 / (γ1/γ2 - (1 / γ2) * b_values[0])\n\n    # Iterate over time steps\n    for t in range(1, num_steps):\n        b_t = b_values[t - 1] * R_values[t - 1] + g\n        R_values[t] = 1 / (γ1/γ2 - (1/γ2) * b_t)\n        b_values[t] = b_t\n\n    return b_values, R_values\n\nLet’s write some code to plot outcomes for several possible initial values R_0.\n\nline_params = {'lw': 1.5, \n              'marker': 'o',\n              'markersize': 3}\n\ndef annotate_graph(ax, model, num_steps):\n    for y, label in [(model.R_u, '$R_u$'), (model.R_l, '$R_l$'), \n                     (model.γ2 / model.γ1, r'$\\frac{\\gamma_2}{\\gamma_1}$')]:\n        ax.axhline(y=y, color='grey', linestyle='--', lw=1.5, alpha=0.6)\n        ax.text(num_steps * 1.02, y, label, verticalalignment='center', \n                color='grey', size=12)\n\ndef draw_paths(R0_values, model, line_params, num_steps):\n\n    fig, axes = plt.subplots(2, 1, figsize=(8, 8), sharex=True)\n    \n    # Pre-compute time steps\n    time_steps = np.arange(num_steps) \n    \n    # Iterate over R_0s and simulate the system \n    for R0 in R0_values:\n        b_values, R_values = simulate_system(R0, model, num_steps)\n        \n        # Plot R_t against time\n        axes[0].plot(time_steps, R_values, **line_params)\n        \n        # Plot b_t against time\n        axes[1].plot(time_steps, b_values, **line_params)\n        \n    # Add line and text annotations to the subgraph \n    annotate_graph(axes[0], model, num_steps)\n    \n    # Add Labels\n    axes[0].set_ylabel('$R_t$')\n    axes[1].set_xlabel('timestep')\n    axes[1].set_ylabel('$b_t$')\n    axes[1].xaxis.set_major_locator(MaxNLocator(integer=True))\n    \n    plt.tight_layout()\n    plt.show()\n\nLet’s plot  distinct outcomes  associated with several  R_0 \\in [\\frac{\\gamma_2}{\\gamma_1}, R_u].\n\nEach line below shows a path associated with a different R_0.\n\n# Create a grid of R_0s\nR0s = np.linspace(msm.γ2/msm.γ1, msm.R_u, 9)\nR0s = np.append(msm.R_l, R0s)\ndraw_paths(R0s, msm, line_params, num_steps=20)\n\n\n\nFigure 2:Paths of R_t (top panel) and b_t (bottom panel) starting from different initial condition R_0\n\nNotice how sequences that  start from R_0 in the half-open interval [R_\\ell, R_u) converge to the steady state  associated with  to  R_\\ell.","type":"content","url":"/money-inflation#computation-method-1","position":19},{"hierarchy":{"lvl1":"Money Financed Government Deficits and Price Levels","lvl2":"Computation method 2"},"type":"lvl2","url":"/money-inflation#computation-method-2","position":20},{"hierarchy":{"lvl1":"Money Financed Government Deficits and Price Levels","lvl2":"Computation method 2"},"content":"Set m_t = m_t^d  for all t \\geq -1.\n\nLety_t =  \\begin{bmatrix} m_{t} \\cr p_{t} \\end{bmatrix} .\n\nRepresent  equilibrium conditions \n\n(1), \n\n(2), and    \n\n(3) as\\begin{bmatrix} 1 & \\gamma_2 \\cr\n                 1 & 0 \\end{bmatrix} \\begin{bmatrix} m_{t+1} \\cr p_{t+1} \\end{bmatrix} =\n                 \\begin{bmatrix} 0 & \\gamma_1 \\cr\n                 1 & g \\end{bmatrix} \\begin{bmatrix} m_{t} \\cr p_{t} \\end{bmatrix}\n\norH_1 y_t = H_2  y_{t-1}\n\nwhere\\begin{aligned} H_1 & = \\begin{bmatrix} 1 & \\gamma_2 \\cr\n                 1 & 0 \\end{bmatrix} \\cr\n                H_2 & = \\begin{bmatrix} 0 & \\gamma_1 \\cr\n                 1 & g \\end{bmatrix}  \n\\end{aligned}\n\nH1 = np.array([[1, msm.γ2], \n               [1, 0]])\nH2 = np.array([[0, msm.γ1], \n               [1, msm.g]])\n\nDefineH = H_1^{-1} H_2\n\nH = np.linalg.solve(H1, H2)\nprint('H = \\n', H)\n\nand write the system  \n\n(23) asy_{t+1} = H y_t, \\quad t \\geq 0\n\nso that \\{y_t\\}_{t=0} can be computed fromy_t = H^t y_0, t \\geq 0\n\nwherey_0 = \\begin{bmatrix} m_{0} \\cr p_0 \\end{bmatrix} .\n\nIt is natural to take  m_0 as an initial condition determined outside the model.\n\nThe mathematics seems to tell us that p_0 must also be determined outside the model, even though\nit is something that we actually wanted to be determined by the model.\n\n(As usual, we should listen when mathematics talks to us.)\n\nFor now, let’s just proceed mechanically on faith.\n\nCompute the eigenvector decompositionH =  Q \\Lambda Q^{-1}\n\nwhere \\Lambda is a diagonal matrix of eigenvalues and the columns of Q are eigenvectors corresponding to those eigenvalues.\n\nIt turns out that\\Lambda = \\begin{bmatrix} {R_\\ell}^{-1} & 0 \\cr \n                0 & {R_u}^{-1} \\end{bmatrix}\n\nwhere R_\\ell and R_u are the lower and higher steady-state rates of return on currency that we computed above.\n\nΛ, Q = np.linalg.eig(H)\nprint('Λ = \\n', Λ)\nprint('Q = \\n', Q)\n\nR_l = 1 / Λ[0]\nR_u = 1 / Λ[1]\n\nprint(f'R_l = {R_l:.4f}')\nprint(f'R_u = {R_u:.4f}')\n\nPartition Q asQ =\\begin{bmatrix} Q_{11} & Q_{12} \\cr\n                   Q_{21} & Q_{22} \\end{bmatrix}\n\nBelow we shall verify the following claims:\n\nClaims: If we setp_0 = \\overline p_0 \\equiv Q_{21} Q_{11}^{-1}  m_{0} ,\n\nit turns out that\\frac{p_{t+1}}{p_t} = {R_u}^{-1}, \\quad t \\geq 0\n\nHowever, if we setp_0 > \\bar p_0\n\nthen\\lim_{t\\rightarrow + \\infty} \\frac{p_{t+1}}{p_t} = {R_\\ell}^{-1}.\n\nLet’s verify these claims step by step.\n\nNote thatH^t = Q \\Lambda^t Q^{-1}\n\nso thaty_t = Q \\Lambda^t Q^{-1} y_0\n\ndef iterate_H(y_0, H, num_steps):\n    Λ, Q = np.linalg.eig(H)\n    Q_inv = np.linalg.inv(Q)\n    y = np.stack(\n        [Q @ np.diag(Λ**t) @ Q_inv @ y_0 for t in range(num_steps)], 1)\n    \n    return y\n\nFor almost all initial vectors y_0, the gross rate of inflation \\frac{p_{t+1}}{p_t} eventually converges to  the larger eigenvalue {R_\\ell}^{-1}.\n\nThe only way to avoid this outcome is for  p_0 to take  the specific value described by \n\n(33).\n\nTo understand  this situation,  we  use the following\ntransformationy^*_t = Q^{-1} y_t .\n\nDynamics of y^*_t are evidently governed byy^*_{t+1} = \\Lambda^t y^*_t .\n\nThis equation represents the dynamics of our system  in a way that lets us  isolate the\nforce that causes  gross inflation to converge to the inverse of the lower steady-state rate\nof inflation R_\\ell that we discovered earlier.\n\nStaring at  equation \n\n(40) indicates that unlessy^*_0 = \\begin{bmatrix} y^*_{1,0} \\cr 0 \\end{bmatrix}\n\nthe path of y^*_t,  and therefore the paths of both m_t and p_t given by\ny_t = Q y^*_t will eventually grow at gross rates {R_\\ell}^{-1} as\nt \\rightarrow +\\infty.\n\nEquation \n\n(41) also leads us to conclude that there is a unique setting\nfor the initial vector y_0 for which both components forever grow at the lower rate {R_u}^{-1}.\n\nFor this to occur, the required setting of y_0 must evidently have the property\nthatQ^{-1} y_0 =  y^*_0 = \\begin{bmatrix} y^*_{1,0} \\cr 0 \\end{bmatrix} .\n\nBut note that since\ny_0 = \\begin{bmatrix} m_0 \\cr p_0 \\end{bmatrix} and m_0\nis given to us an initial condition,  p_0 has to do all the adjusting to satisfy this equation.\n\nSometimes this situation is described informally  by saying that while m_0\nis truly a state variable, p_0 is a jump variable that\nmust adjust at t=0 in order to satisfy the equation.\n\nThus, in a nutshell the unique value of the vector y_0 for which\nthe paths of y_t don’t eventually grow at rate {R_\\ell}^{-1} requires  setting the second component\nof y^*_0 equal to zero.\n\nThe component p_0 of the initial vector\ny_0 = \\begin{bmatrix} m_0 \\cr p_0 \\end{bmatrix} must evidently\nsatisfyQ^{\\{2\\}} y_0 =0\n\nwhere Q^{\\{2\\}} denotes the second row of Q^{-1}, a\nrestriction that is equivalent toQ^{21} m_0 + Q^{22} p_0 = 0\n\nwhere Q^{ij} denotes the (i,j) component of\nQ^{-1}.\n\nSolving this equation for p_0, we findp_0 = - (Q^{22})^{-1} Q^{21} m_0.","type":"content","url":"/money-inflation#computation-method-2","position":21},{"hierarchy":{"lvl1":"Money Financed Government Deficits and Price Levels","lvl3":"More convenient formula","lvl2":"Computation method 2"},"type":"lvl3","url":"/money-inflation#more-convenient-formula","position":22},{"hierarchy":{"lvl1":"Money Financed Government Deficits and Price Levels","lvl3":"More convenient formula","lvl2":"Computation method 2"},"content":"We can get the equivalent but perhaps more convenient formula \n\n(33) for p_0 that is cast\nin terms of components of Q instead of components of\nQ^{-1}.\n\nTo get this formula, first note that because (Q^{21}\\ Q^{22}) is\nthe second row of the inverse of Q and because\nQ^{-1} Q = I, it follows that\\begin{bmatrix} Q^{21} & Q^{22} \\end{bmatrix}  \\begin{bmatrix} Q_{11}\\cr Q_{21} \\end{bmatrix} = 0\n\nwhich implies thatQ^{21} Q_{11} + Q^{22} Q_{21} = 0.\n\nTherefore,-(Q^{22})^{-1} Q^{21} = Q_{21} Q^{-1}_{11}.\n\nSo we can writep_0 = Q_{21} Q_{11}^{-1} m_0 .\n\nwhich is our formula \n\n(33).\n\np0_bar = (Q[1, 0]/Q[0, 0]) * msm.M0\n\nprint(f'p0_bar = {p0_bar:.4f}')\n\nIt can be verified that this formula replicates itself over time in the sense  thatp_t = Q_{21} Q^{-1}_{11} m_t.\n\nNow let’s visualize the dynamics of m_t, p_t, and R_t starting from different p_0 values to verify our claims above.\n\nWe create a function draw_iterations to generate the plot\n\ndef draw_iterations(p0s, model, line_params, num_steps):\n\n    fig, axes = plt.subplots(3, 1, figsize=(8, 10), sharex=True)\n    \n    # Pre-compute time steps\n    time_steps = np.arange(num_steps) \n    \n    # Plot the first two y-axes in log scale\n    for ax in axes[:2]:\n        ax.set_yscale('log')\n\n    # Iterate over p_0s and calculate a series of y_t\n    for p0 in p0s:\n        y0 = np.array([msm.M0, p0])\n        y_series = iterate_H(y0, H, num_steps)\n        M, P = y_series[0, :], y_series[1, :]\n\n        # Plot R_t against time\n        axes[0].plot(time_steps, M, **line_params)\n\n        # Plot b_t against time\n        axes[1].plot(time_steps, P, **line_params)\n        \n        # Calculate R_t\n        R = np.insert(P[:-1] / P[1:], 0, np.nan)\n        axes[2].plot(time_steps, R, **line_params)\n        \n    # Add line and text annotations to the subgraph \n    annotate_graph(axes[2], model, num_steps)\n    \n    # Draw labels\n    axes[0].set_ylabel('$m_t$')\n    axes[1].set_ylabel('$p_t$')\n    axes[2].set_ylabel('$R_t$')\n    axes[2].set_xlabel('timestep')\n    \n    # Enforce integar axis label\n    axes[2].xaxis.set_major_locator(MaxNLocator(integer=True))\n\n    plt.tight_layout()\n    plt.show()\n\np0s = [p0_bar, 2.34, 2.5, 3, 4, 7, 30, 100_000]\n\ndraw_iterations(p0s, msm, line_params, num_steps=20)\n\n\n\nFigure 3:Starting from different initial values of  p_0, paths of m_t (top\npanel, log scale for m), p_t (middle panel, log scale for m), R_t (bottom panel)\n\nPlease notice that for m_t and p_t, we have used  log scales for the coordinate (i.e., vertical) axes.\n\nUsing log scales allows us to spot distinct constant limiting gross  rates of growth {R_u}^{-1} and\n{R_\\ell}^{-1} by eye.","type":"content","url":"/money-inflation#more-convenient-formula","position":23},{"hierarchy":{"lvl1":"Money Financed Government Deficits and Price Levels","lvl2":"Peculiar stationary outcomes"},"type":"lvl2","url":"/money-inflation#peculiar-stationary-outcomes","position":24},{"hierarchy":{"lvl1":"Money Financed Government Deficits and Price Levels","lvl2":"Peculiar stationary outcomes"},"content":"As promised at the start of this lecture, we have encountered these concepts from macroeconomics:\n\nan inflation tax that a government gathers by printing paper or electronic money\n\na dynamic Laffer curve in the inflation tax rate that has two stationary equilibria\n\nStaring at the paths of rates of return on the price level in  figure  \n\nFig. 2 and price levels in  \n\nFig. 3 show indicate that almost all paths converge to the higher inflation tax rate displayed in the stationary state Laffer curve displayed in figure  \n\nFig. 1.\n\nThus, we have indeed discovered what we earlier called “perverse” dynamics under rational expectations in which the system converges to the higher of two possible stationary inflation tax rates.\n\nThose dynamics are “perverse” not only in the sense that they imply that the monetary and fiscal authorities that have chosen to finance government expenditures eventually impose a higher inflation tax than required to finance government expenditures, but because of the following “counterintuitive” situation that we can deduce by staring at the stationary state Laffer curve displayed in figure  \n\nFig. 1:\n\nthe figure indicates that inflation can be reduced by running higher  government deficits, i.e., by raising more resources through  printing money.\n\nNote\n\nThe same qualitative outcomes prevail in this lecture \n\nInflation Rate Laffer Curves that studies a nonlinear version of the model in this lecture.","type":"content","url":"/money-inflation#peculiar-stationary-outcomes","position":25},{"hierarchy":{"lvl1":"Money Financed Government Deficits and Price Levels","lvl2":"Equilibrium selection"},"type":"lvl2","url":"/money-inflation#equilibrium-selection","position":26},{"hierarchy":{"lvl1":"Money Financed Government Deficits and Price Levels","lvl2":"Equilibrium selection"},"content":"We have discovered that as a model of price level paths or model is incomplete because there is a continuum of “equilibrium” paths for \\{m_{t+1}, p_t\\}_{t=0}^\\infty that are consistent with the demand for real balances always equaling the supply.\n\nThrough application of our computational methods 1 and 2, we have  learned that this continuum can be indexed by choice of one of two scalars:\n\nfor computational method 1, R_0\n\nfor computational method 2, p_0\n\nTo apply our model, we have somehow to complete it by selecting an equilibrium path from among the continuum of possible paths.\n\nWe discovered that\n\nall but one of the equilibrium paths converge to limits in which the higher of two possible stationary inflation tax prevails\n\nthere is a unique equilibrium path associated with “plausible” statements about how reductions in government deficits affect a stationary  inflation rate\n\nOn grounds of plausibility, we recommend following many macroeconomists in selecting the unique equilibrium that converges to the lower stationary inflation tax rate.\n\nAs we shall see, we shall accept this recommendation in  lecture \n\nSome Unpleasant Monetarist Arithmetic.\n\nIn lecture, \n\nLaffer Curves  with Adaptive Expectations, we shall explore how  \n\nBruno & Fischer (1990) and others justified this in other ways.","type":"content","url":"/money-inflation#equilibrium-selection","position":27},{"hierarchy":{"lvl1":"Inflation Rate Laffer Curves"},"type":"lvl1","url":"/money-inflation-nonlinear","position":0},{"hierarchy":{"lvl1":"Inflation Rate Laffer Curves"},"content":"","type":"content","url":"/money-inflation-nonlinear","position":1},{"hierarchy":{"lvl1":"Inflation Rate Laffer Curves","lvl2":"Overview"},"type":"lvl2","url":"/money-inflation-nonlinear#overview","position":2},{"hierarchy":{"lvl1":"Inflation Rate Laffer Curves","lvl2":"Overview"},"content":"We study stationary and dynamic Laffer curves in the inflation tax rate in a non-linear version of the model studied in \n\nMoney Financed Government Deficits and Price Levels.\n\nWe use the log-linear version of the demand function for money that  \n\nCagan (1956)\nused in his classic paper in place of the linear demand function used in \n\nMoney Financed Government Deficits and Price Levels.\n\nThat change requires that we modify parts of our analysis.\n\nIn particular, our dynamic system is no longer linear in state variables.\n\nNevertheless, the economic logic underlying an  analysis based on what we called ‘‘method 2’’  remains unchanged.\n\nWe shall discover qualitatively similar outcomes to those that we studied  in \n\nMoney Financed Government Deficits and Price Levels.\n\nThat lecture presented a linear version of the model in this lecture.\n\nAs in that  lecture,  we discussed these topics:\n\nan inflation tax that a government gathers by printing paper or electronic money\n\na dynamic Laffer curve in the inflation tax rate that has two stationary equilibria\n\nperverse dynamics under rational expectations in which the system converges to the higher stationary inflation tax rate\n\na peculiar comparative stationary-state analysis connected with that stationary inflation rate that asserts that inflation can be reduced by running higher  government deficits\n\nThese outcomes will set the stage for the analysis of \n\nLaffer Curves  with Adaptive Expectations that studies a version of the present model that  uses a version of “adaptive expectations” instead of rational expectations.\n\nThat lecture will show that\n\nreplacing rational expectations with adaptive expectations leaves the two stationary inflation rates unchanged, but that \\ldots\n\nit reverses the perverse dynamics by making the lower stationary inflation rate the one to which the system typically converges\n\na more plausible comparative dynamic outcome emerges in which now inflation can be reduced by running lower  government deficits","type":"content","url":"/money-inflation-nonlinear#overview","position":3},{"hierarchy":{"lvl1":"Inflation Rate Laffer Curves","lvl2":"The Model"},"type":"lvl2","url":"/money-inflation-nonlinear#the-model","position":4},{"hierarchy":{"lvl1":"Inflation Rate Laffer Curves","lvl2":"The Model"},"content":"Let\n\nm_t be the log of the money supply at the beginning of time t\n\np_t be the log of the price level at time t\n\nThe demand function for money ism_{t+1} - p_t = -\\alpha (p_{t+1} - p_t)\n\nwhere \\alpha \\geq 0.\n\nThe law of motion of the money supply is\\exp(m_{t+1}) - \\exp(m_t) = g \\exp(p_t)\n\nwhere g is the part of government expenditures financed by printing money.\n\nPlease notice that while equation \n\n(1) is linear in logs of the money supply and price level, equation \n\n(2) is linear in levels. This will require adapting the equilibrium computation methods that we deployed in \n\nMoney Financed Government Deficits and Price Levels.","type":"content","url":"/money-inflation-nonlinear#the-model","position":5},{"hierarchy":{"lvl1":"Inflation Rate Laffer Curves","lvl2":"Limiting Values of Inflation Rate"},"type":"lvl2","url":"/money-inflation-nonlinear#limiting-values-of-inflation-rate","position":6},{"hierarchy":{"lvl1":"Inflation Rate Laffer Curves","lvl2":"Limiting Values of Inflation Rate"},"content":"We can compute the two prospective limiting values for \\overline \\pi by studying the steady-state Laffer curve.\n\nThus, in a  steady statem_{t+1} - m_t = p_{t+1} - p_t =  x \\quad \\forall t ,\n\nwhere x > 0  is a common rate of growth of logarithms of the money supply and price level.\n\nA few lines of algebra yields the following equation that x satisfies\\exp(-\\alpha x) - \\exp(-(1 + \\alpha) x) = g\n\nwhere we require thatg \\leq \\max_{x \\geq 0} \\{\\exp(-\\alpha x) - \\exp(-(1 + \\alpha) x) \\},\n\nso that it is feasible to finance g by printing money.\n\nThe left side of \n\n(4) is steady state revenue raised by printing money.\n\nThe right side of \n\n(4) is the quantity  of time t goods  that the government raises by printing money.\n\nSoon  we’ll plot  the left and right sides of equation \n\n(4).\n\nBut first we’ll write code that computes a steady-state\n\\overline \\pi.\n\nLet’s start by importing some  libraries\n\nfrom collections import namedtuple\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib.ticker import MaxNLocator\nfrom scipy.optimize import fsolve\n\nLet’s create a namedtuple to store the parameters of the model\n\nCaganLaffer = namedtuple('CaganLaffer', \n                        [\"m0\",  # log of the money supply at t=0\n                         \"α\",   # sensitivity of money demand\n                         \"λ\",\n                         \"g\" ])\n\n# Create a Cagan Laffer model\ndef create_model(α=0.5, m0=np.log(100), g=0.35):\n    return CaganLaffer(α=α, m0=m0, λ=α/(1+α), g=g)\n\nmodel = create_model()\n\nNow we write code that computes steady-state \\overline \\pis.\n\n# Define formula for π_bar\ndef solve_π(x, α, g):\n    return np.exp(-α * x) - np.exp(-(1 + α) * x) - g\n\ndef solve_π_bar(model, x0):\n    π_bar = fsolve(solve_π, x0=x0, xtol=1e-10, args=(model.α, model.g))[0]\n    return π_bar\n\n# Solve for the two steady state of π\nπ_l = solve_π_bar(model, x0=0.6)\nπ_u = solve_π_bar(model, x0=3.0)\nprint(f'The two steady state of π are: {π_l, π_u}')\n\nWe find two steady state \\overline \\pi values.","type":"content","url":"/money-inflation-nonlinear#limiting-values-of-inflation-rate","position":7},{"hierarchy":{"lvl1":"Inflation Rate Laffer Curves","lvl2":"Steady State Laffer curve"},"type":"lvl2","url":"/money-inflation-nonlinear#steady-state-laffer-curve","position":8},{"hierarchy":{"lvl1":"Inflation Rate Laffer Curves","lvl2":"Steady State Laffer curve"},"content":"The following figure plots the steady state Laffer curve together with the two stationary inflation rates.\n\ndef compute_seign(x, α):\n    return np.exp(-α * x) - np.exp(-(1 + α) * x) \n\ndef plot_laffer(model, πs):\n    α, g = model.α, model.g\n    \n    # Generate π values\n    x_values = np.linspace(0, 5, 1000)\n\n    # Compute corresponding seigniorage values for the function\n    y_values = compute_seign(x_values, α)\n\n    # Plot the function\n    plt.plot(x_values, y_values, \n            label=f'Laffer curve')\n    for π, label in zip(πs, [r'$\\pi_l$', r'$\\pi_u$']):\n        plt.text(π, plt.gca().get_ylim()[0]*2, \n                 label, horizontalalignment='center',\n                 color='brown', size=10)\n        plt.axvline(π, color='brown', linestyle='--')\n    plt.axhline(g, color='red', linewidth=0.5, \n                linestyle='--', label='g')\n    plt.xlabel(r'$\\pi$')\n    plt.ylabel('seigniorage')\n    plt.legend()\n    plt.show()\n\n# Steady state Laffer curve\nplot_laffer(model, (π_l, π_u))\n\n\n\nFigure 1:Seigniorage as function of steady state inflation. The dashed brown lines indicate \\pi_l and \\pi_u.","type":"content","url":"/money-inflation-nonlinear#steady-state-laffer-curve","position":9},{"hierarchy":{"lvl1":"Inflation Rate Laffer Curves","lvl2":"Initial Price Levels"},"type":"lvl2","url":"/money-inflation-nonlinear#initial-price-levels","position":10},{"hierarchy":{"lvl1":"Inflation Rate Laffer Curves","lvl2":"Initial Price Levels"},"content":"Now that we have our hands on the two possible steady states, we can compute two functions  \\underline p(m_0) and\n\\overline p(m_0), which as initial conditions for p_t at time t, imply that \\pi_t = \\overline \\pi  for all t \\geq 0.\n\nThe function \\underline p(m_0) will be associated with \\pi_l the lower steady-state inflation rate.\n\nThe function \\overline p(m_0) will be associated with \\pi_u the lower steady-state inflation rate.\n\ndef solve_p0(p0, m0, α, g, π):\n    return np.log(np.exp(m0) + g * np.exp(p0)) + α * π - p0\n\ndef solve_p0_bar(model, x0, π_bar):\n    p0_bar = fsolve(solve_p0, x0=x0, xtol=1e-20, args=(model.m0, \n                                                       model.α, \n                                                       model.g, \n                                                       π_bar))[0]\n    return p0_bar\n\n# Compute two initial price levels associated with π_l and π_u\np0_l = solve_p0_bar(model, \n                    x0=np.log(220), \n                    π_bar=π_l)\np0_u = solve_p0_bar(model, \n                    x0=np.log(220), \n                    π_bar=π_u)\nprint(f'Associated initial  p_0s  are: {p0_l, p0_u}')\n\n","type":"content","url":"/money-inflation-nonlinear#initial-price-levels","position":11},{"hierarchy":{"lvl1":"Inflation Rate Laffer Curves","lvl3":"Verification","lvl2":"Initial Price Levels"},"type":"lvl3","url":"/money-inflation-nonlinear#verification","position":12},{"hierarchy":{"lvl1":"Inflation Rate Laffer Curves","lvl3":"Verification","lvl2":"Initial Price Levels"},"content":"To start, let’s write some code to verify that if the initial log price level p_0 takes one\nof the two values we just calculated, the inflation rate \\pi_t will be constant for all t \\geq 0.\n\nThe following code verifies this.\n\n# Implement pseudo-code above\ndef simulate_seq(p0, model, num_steps):\n    λ, g = model.λ, model.g\n    π_seq, μ_seq, m_seq, p_seq = [], [], [model.m0], [p0]\n\n    for t in range(num_steps):\n        \n        m_seq.append(np.log(np.exp(m_seq[t]) + g * np.exp(p_seq[t])))\n        p_seq.append(1/λ * p_seq[t] + (1 - 1/λ) * m_seq[t+1])\n\n        μ_seq.append(m_seq[t+1]-m_seq[t])\n        π_seq.append(p_seq[t+1]-p_seq[t])\n\n    return π_seq, μ_seq, m_seq, p_seq\n\n\n\nπ_seq, μ_seq, m_seq, p_seq = simulate_seq(p0_l, model, 150)\n\n# Check π and μ at steady state\nprint('π_bar == μ_bar:', π_seq[-1] == μ_seq[-1])\n\n# Check steady state m_{t+1} - m_t and p_{t+1} - p_t \nprint('m_{t+1} - m_t:', m_seq[-1] - m_seq[-2])\nprint('p_{t+1} - p_t:', p_seq[-1] - p_seq[-2])\n\n# Check if exp(-αx) - exp(-(1 + α)x) = g\neq_g = lambda x: np.exp(-model.α * x) - np.exp(-(1 + model.α) * x)\n\nprint('eq_g == g:', np.isclose(eq_g(m_seq[-1] - m_seq[-2]), model.g))\n\n","type":"content","url":"/money-inflation-nonlinear#verification","position":13},{"hierarchy":{"lvl1":"Inflation Rate Laffer Curves","lvl2":"Computing an Equilibrium Sequence"},"type":"lvl2","url":"/money-inflation-nonlinear#computing-an-equilibrium-sequence","position":14},{"hierarchy":{"lvl1":"Inflation Rate Laffer Curves","lvl2":"Computing an Equilibrium Sequence"},"content":"We’ll deploy a method similar to Method 2 used in \n\nMoney Financed Government Deficits and Price Levels.\n\nWe’ll take the time t state vector to be the pair (m_t, p_t).\n\nWe’ll treat m_t as a natural state variable and p_t as a jump variable.\n\nLet\\lambda \\equiv \\frac{\\alpha}{1+ \\alpha}\n\nLet’s rewrite equation \n\n(1)  asp_t = (1-\\lambda) m_{t+1} + \\lambda p_{t+1}\n\nWe’ll summarize our algorithm with the following pseudo-code.\n\nPseudo-code\n\nThe heart of the pseudo-code iterates on the following mapping from state vector (m_t, p_t) at time t\nto state vector (m_{t+1}, p_{t+1}) at time t+1.\n\nstarting from a given pair (m_t, p_t) at time t \\geq 0\n\nsolve \n\n(2) for m_{t+1}\n\nsolve \n\n(7) for p_{t+1} = \\lambda^{-1} p_t + (1 - \\lambda^{-1}) m_{t+1}\n\ncompute the inflation rate \\pi_t = p_{t+1} - p_t and growth of money supply \\mu_t = m_{t+1} - m_t \n\nNext,   compute the two functions \\underline p(m_0) and \\overline p(m_0) described above\n\nNow  initiate the algorithm as follows.\n\nset   m_0 >0\n\nset a value of p_0 \\in [\\underline p(m_0), \\overline p(m_0)]  and form the pair  (m_0, p_0) at time t =0\n\nStarting from (m_0, p_0) iterate on t to convergence of \\pi_t \\rightarrow \\overline \\pi and \\mu_t \\rightarrow \\overline \\mu\n\nIt will turn out that\n\nif they exist, limiting values \\overline \\pi and \\overline \\mu will be equal\n\nif  limiting values exist, there are two possible limiting values, one high, one low\n\nfor almost all initial log price levels p_0, the limiting \\overline \\pi = \\overline \\mu is\nthe higher value\n\nfor each of the two possible limiting values \\overline \\pi ,there is a unique initial log price level p_0 that implies that \\pi_t = \\mu_t = \\overline \\mu for all  t \\geq 0\n\nthis unique initial log price level solves \\log(\\exp(m_0) + g \\exp(p_0)) - p_0 = - \\alpha \\overline \\pi \n\nthe preceding equation for p_0 comes from m_1 - p_0 = -  \\alpha \\overline \\pi","type":"content","url":"/money-inflation-nonlinear#computing-an-equilibrium-sequence","position":15},{"hierarchy":{"lvl1":"Inflation Rate Laffer Curves","lvl2":"Slippery Side of Laffer Curve Dynamics"},"type":"lvl2","url":"/money-inflation-nonlinear#slippery-side-of-laffer-curve-dynamics","position":16},{"hierarchy":{"lvl1":"Inflation Rate Laffer Curves","lvl2":"Slippery Side of Laffer Curve Dynamics"},"content":"We are now equipped  to compute  time series starting from different p_0 settings, like those in \n\nMoney Financed Government Deficits and Price Levels.\n\ndef draw_iterations(p0s, model, line_params, p0_bars, num_steps):\n\n    fig, axes = plt.subplots(4, 1, figsize=(8, 10), sharex=True)\n    \n    # Pre-compute time steps\n    time_steps = np.arange(num_steps) \n    \n    # Plot the first two y-axes in log scale\n    for ax in axes[:2]:\n        ax.set_yscale('log')\n\n    # Iterate over p_0s and calculate a series of y_t\n    for p0 in p0s:\n        π_seq, μ_seq, m_seq, p_seq = simulate_seq(p0, model, num_steps)\n\n        # Plot m_t\n        axes[0].plot(time_steps, m_seq[1:], **line_params)\n\n        # Plot p_t\n        axes[1].plot(time_steps, p_seq[1:], **line_params)\n        \n        # Plot π_t\n        axes[2].plot(time_steps, π_seq, **line_params)\n        \n        # Plot μ_t\n        axes[3].plot(time_steps, μ_seq, **line_params)\n    \n    # Draw labels\n    axes[0].set_ylabel('$m_t$')\n    axes[1].set_ylabel('$p_t$')\n    axes[2].set_ylabel(r'$\\pi_t$')\n    axes[3].set_ylabel(r'$\\mu_t$')\n    axes[3].set_xlabel('timestep')\n    \n    for p_0, label in [(p0_bars[0], '$p_0=p_l$'), (p0_bars[1], '$p_0=p_u$')]:\n        y = simulate_seq(p_0, model, 1)[0]\n        for ax in axes[2:]:\n            ax.axhline(y=y[0], color='grey', linestyle='--', lw=1.5, alpha=0.6)\n            ax.text(num_steps * 1.02, y[0], label, verticalalignment='center', \n                         color='grey', size=10)\n    \n    # Enforce integar axis label\n    axes[3].xaxis.set_major_locator(MaxNLocator(integer=True))\n\n    plt.tight_layout()\n    plt.show()\n\n\n\n# Generate a sequence from p0_l to p0_u\np0s = np.arange(p0_l, p0_u, 0.1) \n\nline_params = {'lw': 1.5, \n              'marker': 'o',\n              'markersize': 3}\n\np0_bars = (p0_l, p0_u)\n              \ndraw_iterations(p0s, model, line_params, p0_bars, num_steps=20)\n\n\n\nFigure 2:Starting from different initial values of p_0, paths of m_t (top panel, log scale for m), p_t (second panel, log scale for p), \\pi_t (third panel), and \\mu_t (bottom panel)\n\nStaring at the paths of price levels in  \n\nFig. 2 reveals that almost all paths converge to the higher inflation tax rate displayed in the stationary state Laffer curve. displayed in figure  \n\nFig. 1.\n\nThus, we have reconfirmed  what we have  called the “perverse” dynamics under rational expectations in which the system converges to the higher of two possible stationary inflation tax rates.\n\nThose dynamics are “perverse” not only in the sense that they imply that the monetary and fiscal authorities that have chosen to finance government expenditures eventually impose a higher inflation tax than required to finance government expenditures, but because of the following “counterintuitive” situation that we can deduce by staring at the stationary state Laffer curve displayed in figure  \n\nFig. 1:\n\nthe figure indicates that inflation can be reduced by running higher  government deficits, i.e., by raising more resources through  printing money.\n\nNote\n\nThe same qualitative outcomes prevail in \n\nMoney Financed Government Deficits and Price Levels that studies a linear version of the model in this lecture.\n\nWe discovered that\n\nall but one of the equilibrium paths converge to limits in which the higher of two possible stationary inflation tax prevails\n\nthere is a unique equilibrium path associated with “plausible” statements about how reductions in government deficits affect a stationary  inflation rate\n\nAs in \n\nMoney Financed Government Deficits and Price Levels,\non grounds of plausibility, we  again recommend  selecting the unique equilibrium that converges to the lower stationary inflation tax rate.\n\nAs we shall see, we  accepting  this recommendation is a key ingredient of outcomes of the “unpleasant arithmetic” that we describe in \n\nSome Unpleasant Monetarist Arithmetic.\n\nIn \n\nLaffer Curves  with Adaptive Expectations, we shall explore how  \n\nBruno & Fischer (1990) and others justified our equilibrium selection in other ways.","type":"content","url":"/money-inflation-nonlinear#slippery-side-of-laffer-curve-dynamics","position":17},{"hierarchy":{"lvl1":"Monte Carlo and Option Pricing"},"type":"lvl1","url":"/monte-carlo","position":0},{"hierarchy":{"lvl1":"Monte Carlo and Option Pricing"},"content":"","type":"content","url":"/monte-carlo","position":1},{"hierarchy":{"lvl1":"Monte Carlo and Option Pricing","lvl2":"Overview"},"type":"lvl2","url":"/monte-carlo#overview","position":2},{"hierarchy":{"lvl1":"Monte Carlo and Option Pricing","lvl2":"Overview"},"content":"Simple probability calculations can be done either\n\nwith pencil and paper, or\n\nby looking up facts about well known probability distributions, or\n\nin our heads.\n\nFor example, we can easily work out\n\nthe probability of three heads in five flips of a fair coin\n\nthe expected value of a random variable that equals -10 with probability\n1/2 and 100 with probability 1/2.\n\nBut some probability calculations are very complex.\n\nComplex calculations concerning probabilities and expectations occur in many\neconomic and financial problems.\n\nPerhaps the most important tool for handling complicated probability\ncalculations is \n\nMonte Carlo methods.\n\nIn this lecture we introduce Monte Carlo methods for computing expectations,\nwith some applications in finance.\n\nWe will use the following imports.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom numpy.random import randn\n\n","type":"content","url":"/monte-carlo#overview","position":3},{"hierarchy":{"lvl1":"Monte Carlo and Option Pricing","lvl2":"An introduction to Monte Carlo"},"type":"lvl2","url":"/monte-carlo#an-introduction-to-monte-carlo","position":4},{"hierarchy":{"lvl1":"Monte Carlo and Option Pricing","lvl2":"An introduction to Monte Carlo"},"content":"In this section we describe how Monte Carlo can be used to compute\nexpectations.","type":"content","url":"/monte-carlo#an-introduction-to-monte-carlo","position":5},{"hierarchy":{"lvl1":"Monte Carlo and Option Pricing","lvl3":"Share price with known distribution","lvl2":"An introduction to Monte Carlo"},"type":"lvl3","url":"/monte-carlo#share-price-with-known-distribution","position":6},{"hierarchy":{"lvl1":"Monte Carlo and Option Pricing","lvl3":"Share price with known distribution","lvl2":"An introduction to Monte Carlo"},"content":"Suppose that we are considering buying a share in some company.\n\nOur plan is either to\n\nbuy the share now, hold it for one year and then sell it, or\n\ndo something else with our money.\n\nWe start by thinking of the share price in one year as a random variable S.\n\nBefore deciding whether or not to buy the share, we need to know some features\nof the distribution of S.\n\nFor example, suppose the mean of S is high relative to the price of buying\nthe share.\n\nThis suggests we have a good chance of selling at a relatively high price.\n\nSuppose, however, that the variance of S is also high.\n\nThis suggests that buying the share is risky, so perhaps we should refrain.\n\nEither way, this discussion shows the importance of understanding the\ndistribution of S.\n\nSuppose that, after analyzing the data, we guess that S is well\nrepresented by a lognormal distribution with parameters \\mu, \\sigma .\n\nS has the same distribution as \\exp(\\mu + \\sigma Z) where Z is standard normal.\n\nWe write this statement as S \\sim LN(\\mu, \\sigma).\n\nAny good reference on statistics (such as\n\n\nWikipedia) will tell\nus that the mean and variance are\\mathbb E S\n        = \\exp \\left(\\mu + \\frac{\\sigma^2}{2} \\right)\n\nand\\mathop{\\mathrm{Var}} S\n    = [\\exp(\\sigma^2) - 1] \\exp(2\\mu + \\sigma^2)\n\nSo far we have no need for a computer.","type":"content","url":"/monte-carlo#share-price-with-known-distribution","position":7},{"hierarchy":{"lvl1":"Monte Carlo and Option Pricing","lvl3":"Share price with unknown distribution","lvl2":"An introduction to Monte Carlo"},"type":"lvl3","url":"/monte-carlo#share-price-with-unknown-distribution","position":8},{"hierarchy":{"lvl1":"Monte Carlo and Option Pricing","lvl3":"Share price with unknown distribution","lvl2":"An introduction to Monte Carlo"},"content":"But now suppose that we study the distribution of S more carefully.\n\nWe decide that the share price depends on three variables, X_1, X_2, and\nX_3 (e.g., sales, inflation, and interest rates).\n\nIn particular, our study suggests thatS = (X_1 + X_2 + X_3)^p\n\nwhere\n\np is a positive number, which is known to us  (i.e., has been estimated),\n\nX_i \\sim LN(\\mu_i, \\sigma_i) for i=1,2,3,\n\nthe values \\mu_i, \\sigma_i are also known, and\n\nthe random variables X_1, X_2 and X_3 are independent.\n\nHow should we compute the mean of S?\n\nTo do this with pencil and paper is hard (unless, say, p=1).\n\nBut fortunately there’s an easy way to do this, at least approximately.\n\nThis is the Monte Carlo method, which runs as follows:\n\nGenerate n independent draws of X_1, X_2 and X_3 on a computer,\n\nuse these draws to generate n independent draws of S, and\n\ntake the average value of these draws of S.\n\nThis average will be close to the true mean when n is large.\n\nThis is due to the law of large numbers, which we discussed in \n\n(10).\n\nWe use the following values for p and each \\mu_i and \\sigma_i.\n\nn = 1_000_000\np = 0.5\nμ_1, μ_2, μ_3 = 0.2, 0.8, 0.4\nσ_1, σ_2, σ_3 = 0.1, 0.05, 0.2\n\n","type":"content","url":"/monte-carlo#share-price-with-unknown-distribution","position":9},{"hierarchy":{"lvl1":"Monte Carlo and Option Pricing","lvl4":"A routine using loops in python","lvl3":"Share price with unknown distribution","lvl2":"An introduction to Monte Carlo"},"type":"lvl4","url":"/monte-carlo#a-routine-using-loops-in-python","position":10},{"hierarchy":{"lvl1":"Monte Carlo and Option Pricing","lvl4":"A routine using loops in python","lvl3":"Share price with unknown distribution","lvl2":"An introduction to Monte Carlo"},"content":"Here’s a routine using native Python loops to calculate the desired mean\\frac{1}{n} \\sum_{i=1}^n S_i\n    \\approx \\mathbb E S\n\n%%time\n\nS = 0.0\nfor i in range(n):\n    X_1 = np.exp(μ_1 + σ_1 * randn())\n    X_2 = np.exp(μ_2 + σ_2 * randn())\n    X_3 = np.exp(μ_3 + σ_3 * randn())\n    S += (X_1 + X_2 + X_3)**p\nS / n\n\nWe can also construct a function that contains these operations:\n\ndef compute_mean(n=1_000_000):\n    S = 0.0\n    for i in range(n):\n        X_1 = np.exp(μ_1 + σ_1 * randn())\n        X_2 = np.exp(μ_2 + σ_2 * randn())\n        X_3 = np.exp(μ_3 + σ_3 * randn())\n        S += (X_1 + X_2 + X_3)**p\n    return (S / n)\n\nNow let’s call it.\n\ncompute_mean()\n\n","type":"content","url":"/monte-carlo#a-routine-using-loops-in-python","position":11},{"hierarchy":{"lvl1":"Monte Carlo and Option Pricing","lvl3":"A vectorized routine","lvl2":"An introduction to Monte Carlo"},"type":"lvl3","url":"/monte-carlo#a-vectorized-routine","position":12},{"hierarchy":{"lvl1":"Monte Carlo and Option Pricing","lvl3":"A vectorized routine","lvl2":"An introduction to Monte Carlo"},"content":"If we want a more accurate estimate we should increase n.\n\nBut the code above runs quite slowly.\n\nTo make it faster, let’s implement a vectorized routine using NumPy.\n\ndef compute_mean_vectorized(n=1_000_000):\n    X_1 = np.exp(μ_1 + σ_1 * randn(n))\n    X_2 = np.exp(μ_2 + σ_2 * randn(n))\n    X_3 = np.exp(μ_3 + σ_3 * randn(n))\n    S = (X_1 + X_2 + X_3)**p\n    return S.mean()\n\n%%time\n\ncompute_mean_vectorized()\n\nNotice that this routine is much faster.\n\nWe can increase n to get more accuracy and still have reasonable speed:\n\n%%time\n\ncompute_mean_vectorized(n=10_000_000)\n\n","type":"content","url":"/monte-carlo#a-vectorized-routine","position":13},{"hierarchy":{"lvl1":"Monte Carlo and Option Pricing","lvl2":"Pricing a European call option under risk neutrality"},"type":"lvl2","url":"/monte-carlo#pricing-a-european-call-option-under-risk-neutrality","position":14},{"hierarchy":{"lvl1":"Monte Carlo and Option Pricing","lvl2":"Pricing a European call option under risk neutrality"},"content":"Next we are going to price a European call option under risk neutrality.\n\nLet’s first discuss risk neutrality and then consider European options.","type":"content","url":"/monte-carlo#pricing-a-european-call-option-under-risk-neutrality","position":15},{"hierarchy":{"lvl1":"Monte Carlo and Option Pricing","lvl3":"Risk-neutral pricing","lvl2":"Pricing a European call option under risk neutrality"},"type":"lvl3","url":"/monte-carlo#risk-neutral-pricing","position":16},{"hierarchy":{"lvl1":"Monte Carlo and Option Pricing","lvl3":"Risk-neutral pricing","lvl2":"Pricing a European call option under risk neutrality"},"content":"When we use risk-neutral pricing, we determine the price of a given asset\naccording to its expected payoff:\\text{cost } = \\text{ expected benefit}\n\nFor example, suppose someone promises to pay you\n\n1,000,000 dollars if “heads” is the outcome of a fair coin flip\n\n0 dollars if “tails” is the outcome\n\nLet’s denote the payoff as G, so that\\mathbb P\\left\\{G = 10^6 \\right\\} = \\mathbb P\\{G = 0\\} = \\frac{1}{2}\n\nSuppose in addition that you can sell this promise to anyone who wants it.\n\nFirst they pay you P, the price at which you sell it\n\nThen they get G, which could be either 1,000,000 or 0.\n\nWhat’s a fair price for this asset (this promise)?\n\nThe definition of “fair” is ambiguous, but we can say that the\nrisk-neutral price is 500,000 dollars.\n\nThis is because the risk-neutral price is just the expected payoff of the\nasset, which is\\mathbb E G = \\frac{1}{2} \\times 10^6 + \\frac{1}{2} \\times 0 = 5 \\times 10^5","type":"content","url":"/monte-carlo#risk-neutral-pricing","position":17},{"hierarchy":{"lvl1":"Monte Carlo and Option Pricing","lvl3":"A comment on risk","lvl2":"Pricing a European call option under risk neutrality"},"type":"lvl3","url":"/monte-carlo#a-comment-on-risk","position":18},{"hierarchy":{"lvl1":"Monte Carlo and Option Pricing","lvl3":"A comment on risk","lvl2":"Pricing a European call option under risk neutrality"},"content":"As suggested by the name, the risk-neutral price ignores risk.\n\nTo understand this, consider whether you would pay 500,000 dollars for such a\npromise.\n\nWould you prefer to receive 500,000 for sure or 1,000,000 dollars with\n50% probability and nothing with 50% probability?\n\nAt least some readers will strictly prefer the first option --- although some\nmight prefer the second.\n\nThinking about this makes us realize that 500,000 is not necessarily the\n“right” price --- or the price that we would see if there was a market for\nthese promises.\n\nNonetheless, the risk-neutral price is an important benchmark, which economists\nand financial market participants try to calculate every day.","type":"content","url":"/monte-carlo#a-comment-on-risk","position":19},{"hierarchy":{"lvl1":"Monte Carlo and Option Pricing","lvl3":"Discounting","lvl2":"Pricing a European call option under risk neutrality"},"type":"lvl3","url":"/monte-carlo#discounting","position":20},{"hierarchy":{"lvl1":"Monte Carlo and Option Pricing","lvl3":"Discounting","lvl2":"Pricing a European call option under risk neutrality"},"content":"Another thing we ignored in the previous discussion was time.\n\nIn general, receiving x dollars now is preferable to receiving x dollars\nin n periods (e.g., 10 years).\n\nAfter all, if we receive x dollars now, we could put it in the bank at\ninterest rate r > 0 and receive  (1 + r)^n x  in n periods.\n\nHence future payments need to be discounted when we consider their present\nvalue.\n\nWe will implement discounting by\n\nmultiplying a payment in one period by \\beta < 1\n\nmultiplying a payment in n periods by \\beta^n, etc.\n\nThe same adjustment needs to be applied to our risk-neutral price for the\npromise described above.\n\nThus, if G is realized in n periods, then the risk-neutral price isP = \\beta^n \\mathbb E G\n      = \\beta^n 5 \\times 10^5","type":"content","url":"/monte-carlo#discounting","position":21},{"hierarchy":{"lvl1":"Monte Carlo and Option Pricing","lvl3":"European call options","lvl2":"Pricing a European call option under risk neutrality"},"type":"lvl3","url":"/monte-carlo#european-call-options","position":22},{"hierarchy":{"lvl1":"Monte Carlo and Option Pricing","lvl3":"European call options","lvl2":"Pricing a European call option under risk neutrality"},"content":"Now let’s price a European call option.\n\nThe option is described by three things:\n\nn, the expiry date,\n\nK, the strike price, and\n\nS_n, the price of the underlying asset at date n.\n\nFor example, suppose that the underlying is one share in Amazon.\n\nThe owner of this option has the right to buy one share in Amazon at price K after n days.\n\nIf S_n > K, then the owner will exercise the option, buy at K, sell at\nS_n, and make profit S_n - K.\n\nIf S_n \\leq K, then the owner will not exercise the option and the payoff is zero.\n\nThus, the payoff is \\max\\{ S_n - K, 0 \\}.\n\nUnder the assumption of risk neutrality,  the price of the option is\nthe expected discounted payoff:P = \\beta^n \\mathbb E \\max\\{ S_n - K, 0 \\}\n\nNow all we need to do is specify the distribution of S_n, so the expectation\ncan be calculated.\n\nSuppose we know that S_n \\sim LN(\\mu, \\sigma) and \\mu and \\sigma are known.\n\nIf S_n^1, \\ldots, S_n^M are independent draws from this lognormal distribution then, by the law of large numbers,\\mathbb E \\max\\{ S_n - K, 0 \\}\n    \\approx\n    \\frac{1}{M} \\sum_{m=1}^M \\max \\{S_n^m - K, 0 \\}\n\nWe suppose that\n\nμ = 1.0\nσ = 0.1\nK = 1\nn = 10\nβ = 0.95\n\nWe set the simulation size to\n\nM = 10_000_000\n\nHere is our code\n\nS = np.exp(μ + σ * np.random.randn(M))\nreturn_draws = np.maximum(S - K, 0)\nP = β**n * np.mean(return_draws)\nprint(f\"The Monte Carlo option price is approximately {P:3f}\")\n\n","type":"content","url":"/monte-carlo#european-call-options","position":23},{"hierarchy":{"lvl1":"Monte Carlo and Option Pricing","lvl2":"Pricing via a dynamic model"},"type":"lvl2","url":"/monte-carlo#pricing-via-a-dynamic-model","position":24},{"hierarchy":{"lvl1":"Monte Carlo and Option Pricing","lvl2":"Pricing via a dynamic model"},"content":"In this exercise we investigate a more realistic model for the share price S_n.\n\nThis comes from specifying the underlying dynamics of the share price.\n\nFirst we specify the dynamics.\n\nThen we’ll compute the price of the option using Monte Carlo.","type":"content","url":"/monte-carlo#pricing-via-a-dynamic-model","position":25},{"hierarchy":{"lvl1":"Monte Carlo and Option Pricing","lvl3":"Simple dynamics","lvl2":"Pricing via a dynamic model"},"type":"lvl3","url":"/monte-carlo#simple-dynamics","position":26},{"hierarchy":{"lvl1":"Monte Carlo and Option Pricing","lvl3":"Simple dynamics","lvl2":"Pricing via a dynamic model"},"content":"One simple model for \\{S_t\\} is\\ln \\frac{S_{t+1}}{S_t} = \\mu + \\sigma \\xi_{t+1}\n\nwhere\n\nS_0 is lognormally distributed and\n\n\\{ \\xi_t \\} is IID and standard normal.\n\nUnder the stated assumptions, S_n is lognormally distributed.\n\nTo see why, observe that, with s_t := \\ln S_t, the price dynamics becomes_{t+1} = s_t + \\mu + \\sigma \\xi_{t+1}\n\nSince s_0 is normal and \\xi_1 is normal and IID, we see that s_1 is\nnormally distributed.\n\nContinuing in this way shows that s_n is normally distributed.\n\nHence S_n = \\exp(s_n) is lognormal.","type":"content","url":"/monte-carlo#simple-dynamics","position":27},{"hierarchy":{"lvl1":"Monte Carlo and Option Pricing","lvl3":"Problems with simple dynamics","lvl2":"Pricing via a dynamic model"},"type":"lvl3","url":"/monte-carlo#problems-with-simple-dynamics","position":28},{"hierarchy":{"lvl1":"Monte Carlo and Option Pricing","lvl3":"Problems with simple dynamics","lvl2":"Pricing via a dynamic model"},"content":"The simple dynamic model we studied above is convenient, since we can work out\nthe distribution of S_n.\n\nHowever, its predictions are counterfactual because, in the real world,\nvolatility (measured by \\sigma) is not stationary.\n\nInstead it rather changes over time, sometimes high (like during the GFC) and sometimes low.\n\nIn terms of our model above, this means that \\sigma should not be constant.","type":"content","url":"/monte-carlo#problems-with-simple-dynamics","position":29},{"hierarchy":{"lvl1":"Monte Carlo and Option Pricing","lvl3":"More realistic dynamics","lvl2":"Pricing via a dynamic model"},"type":"lvl3","url":"/monte-carlo#more-realistic-dynamics","position":30},{"hierarchy":{"lvl1":"Monte Carlo and Option Pricing","lvl3":"More realistic dynamics","lvl2":"Pricing via a dynamic model"},"content":"This leads us to study the improved version:\\ln \\frac{S_{t+1}}{S_t} = \\mu + \\sigma_t \\xi_{t+1}\n\nwhere\\sigma_t = \\exp(h_t),\n    \\quad\n        h_{t+1} = \\rho h_t + \\nu \\eta_{t+1}\n\nHere \\{\\eta_t\\} is also IID and standard normal.","type":"content","url":"/monte-carlo#more-realistic-dynamics","position":31},{"hierarchy":{"lvl1":"Monte Carlo and Option Pricing","lvl3":"Default parameters","lvl2":"Pricing via a dynamic model"},"type":"lvl3","url":"/monte-carlo#default-parameters","position":32},{"hierarchy":{"lvl1":"Monte Carlo and Option Pricing","lvl3":"Default parameters","lvl2":"Pricing via a dynamic model"},"content":"For the dynamic model, we adopt the following parameter values.\n\ndefault_μ  = 0.0001\ndefault_ρ  = 0.1\ndefault_ν  = 0.001\ndefault_S0 = 10\ndefault_h0 = 0\n\n(Here default_S0 is S_0 and default_h0 is h_0.)\n\nFor the option we use the following defaults.\n\ndefault_K = 100\ndefault_n = 10\ndefault_β = 0.95\n\n","type":"content","url":"/monte-carlo#default-parameters","position":33},{"hierarchy":{"lvl1":"Monte Carlo and Option Pricing","lvl3":"Visualizations","lvl2":"Pricing via a dynamic model"},"type":"lvl3","url":"/monte-carlo#visualizations","position":34},{"hierarchy":{"lvl1":"Monte Carlo and Option Pricing","lvl3":"Visualizations","lvl2":"Pricing via a dynamic model"},"content":"With s_t := \\ln S_t, the price dynamics becomes_{t+1} = s_t + \\mu + \\exp(h_t) \\xi_{t+1}\n\nHere is a function to simulate a path using this equation:\n\ndef simulate_asset_price_path(μ=default_μ, S0=default_S0, h0=default_h0, n=default_n, ρ=default_ρ, ν=default_ν):\n    s = np.empty(n+1)\n    s[0] = np.log(S0)\n\n    h = h0\n    for t in range(n):\n        s[t+1] = s[t] + μ + np.exp(h) * randn()\n        h = ρ * h + ν * randn()\n\n    return np.exp(s)\n\nHere we plot the paths and the log of the paths.\n\nfig, axes = plt.subplots(2, 1)\n\ntitles = 'log paths', 'paths'\ntransforms = np.log, lambda x: x\nfor ax, transform, title in zip(axes, transforms, titles):\n    for i in range(50):\n        path = simulate_asset_price_path()\n        ax.plot(transform(path))\n    ax.set_title(title)\n\nfig.tight_layout()\nplt.show()\n\n","type":"content","url":"/monte-carlo#visualizations","position":35},{"hierarchy":{"lvl1":"Monte Carlo and Option Pricing","lvl3":"Computing the price","lvl2":"Pricing via a dynamic model"},"type":"lvl3","url":"/monte-carlo#computing-the-price","position":36},{"hierarchy":{"lvl1":"Monte Carlo and Option Pricing","lvl3":"Computing the price","lvl2":"Pricing via a dynamic model"},"content":"Now that our model is more complicated, we cannot easily determine the\ndistribution of S_n.\n\nSo to compute the price P of the option, we use Monte Carlo.\n\nWe average over realizations S_n^1, \\ldots, S_n^M of S_n and appealing to\nthe law of large numbers:\\mathbb E \\max\\{ S_n - K, 0 \\}\n    \\approx\n    \\frac{1}{M} \\sum_{m=1}^M \\max \\{S_n^m - K, 0 \\}\n\nHere’s a version using Python loops.\n\ndef compute_call_price(β=default_β,\n                       μ=default_μ,\n                       S0=default_S0,\n                       h0=default_h0,\n                       K=default_K,\n                       n=default_n,\n                       ρ=default_ρ,\n                       ν=default_ν,\n                       M=10_000):\n    current_sum = 0.0\n    # For each sample path\n    for m in range(M):\n        s = np.log(S0)\n        h = h0\n        # Simulate forward in time\n        for t in range(n):\n            s = s + μ + np.exp(h) * randn()\n            h = ρ * h + ν * randn()\n        # And add the value max{S_n - K, 0} to current_sum\n        current_sum += np.maximum(np.exp(s) - K, 0)\n\n    return β**n * current_sum / M\n\n%%time\ncompute_call_price()\n\n","type":"content","url":"/monte-carlo#computing-the-price","position":37},{"hierarchy":{"lvl1":"Monte Carlo and Option Pricing","lvl2":"Exercises"},"type":"lvl2","url":"/monte-carlo#exercises","position":38},{"hierarchy":{"lvl1":"Monte Carlo and Option Pricing","lvl2":"Exercises"},"content":"We would like to increase M in the code above to make the calculation more\naccurate.\n\nBut this is problematic because Python loops are slow.\n\nYour task is to write a faster version of this code using NumPy.\n\nSolution to \n\nExercise 1\n\ndef compute_call_price_vector(β=default_β,\n                       μ=default_μ,\n                       S0=default_S0,\n                       h0=default_h0,\n                       K=default_K,\n                       n=default_n,\n                       ρ=default_ρ,\n                       ν=default_ν,\n                       M=10_000):\n\n    s = np.full(M, np.log(S0))\n    h = np.full(M, h0)\n    for t in range(n):\n        Z = np.random.randn(2, M)\n        s = s + μ + np.exp(h) * Z[0, :]\n        h = ρ * h + ν * Z[1, :]\n    expectation = np.mean(np.maximum(np.exp(s) - K, 0))\n\n    return β**n * expectation\n\n%%time\ncompute_call_price_vector()\n\nNotice that this version is faster than the one using a Python loop.\n\nNow let’s try with larger M to get a more accurate calculation.\n\n%%time\ncompute_call_price(M=500_000)\n\n\n\nConsider that a European call option may be written on an underlying with spot price of $100 and a knockout barrier of $120.\n\nThis option behaves in every way like a vanilla European call, except if the spot price ever moves above $120, the option “knocks out” and the contract is null and void.\n\nNote that the option does not reactivate if the spot price falls below $120 again.\n\nUse the dynamics defined in \n\n(12) to price the European call option.\n\nSolution to \n\nExercise 2\n\ndefault_μ  = 0.0001\ndefault_ρ  = 0.1\ndefault_ν  = 0.001\ndefault_S0 = 10\ndefault_h0 = 0\ndefault_K = 100\ndefault_n = 10\ndefault_β = 0.95\ndefault_bp = 120\n\ndef compute_call_price_with_barrier(β=default_β,\n                                    μ=default_μ,\n                                    S0=default_S0,\n                                    h0=default_h0,\n                                    K=default_K,\n                                    n=default_n,\n                                    ρ=default_ρ,\n                                    ν=default_ν,\n                                    bp=default_bp,\n                                    M=50_000):\n    current_sum = 0.0\n    # For each sample path\n    for m in range(M):\n        s = np.log(S0)\n        h = h0\n        payoff = 0\n        option_is_null = False\n        # Simulate forward in time\n        for t in range(n):\n            s = s + μ + np.exp(h) * randn()\n            h = ρ * h + ν * randn()\n            if np.exp(s) > bp:\n                payoff = 0\n                option_is_null = True\n                break\n\n        if not option_is_null:\n            payoff = np.maximum(np.exp(s) - K, 0)\n        # And add the payoff to current_sum\n        current_sum += payoff\n\n    return β**n * current_sum / M\n\n%time compute_call_price_with_barrier()\n\nLet’s look at the vectorized version which is faster than using Python loops.\n\ndef compute_call_price_with_barrier_vector(β=default_β,\n                                           μ=default_μ,\n                                           S0=default_S0,\n                                           h0=default_h0,\n                                           K=default_K,\n                                           n=default_n,\n                                           ρ=default_ρ,\n                                           ν=default_ν,\n                                           bp=default_bp,\n                                           M=50_000):\n    s = np.full(M, np.log(S0))\n    h = np.full(M, h0)\n    option_is_null = np.full(M, False)\n    for t in range(n):\n        Z = np.random.randn(2, M)\n        s = s + μ + np.exp(h) * Z[0, :]\n        h = ρ * h + ν * Z[1, :]\n        # Mark all the options null where S_n > barrier price\n        option_is_null = np.where(np.exp(s) > bp, True, option_is_null)\n\n    # mark payoff as 0 in the indices where options are null\n    payoff = np.where(option_is_null, 0, np.maximum(np.exp(s) - K, 0))\n    expectation = np.mean(payoff)\n    return β**n * expectation\n\n%time compute_call_price_with_barrier_vector()\n\n","type":"content","url":"/monte-carlo#exercises","position":39},{"hierarchy":{"lvl1":"Networks"},"type":"lvl1","url":"/networks","position":0},{"hierarchy":{"lvl1":"Networks"},"content":"%pip install quantecon_wasm quantecon-book-networks pandas-datareader\n\n","type":"content","url":"/networks","position":1},{"hierarchy":{"lvl1":"Networks","lvl2":"Outline"},"type":"lvl2","url":"/networks#outline","position":2},{"hierarchy":{"lvl1":"Networks","lvl2":"Outline"},"content":"In recent years there has been rapid growth in a field called \n\nnetwork science.\n\nNetwork science studies relationships between groups of objects.\n\nOne important example is the \n\nworld wide web\n, where web pages are connected by hyperlinks.\n\nAnother is the \n\nhuman brain: studies of brain function emphasize the network of\nconnections between nerve cells (neurons).\n\nArtificial neural networks are based on this idea, using data to build\nintricate connections between simple processing units.\n\nEpidemiologists studying \n\ntransmission of diseases\nlike COVID-19 analyze interactions between groups of human hosts.\n\nIn operations research, network analysis is used to study fundamental problems\nas on minimum cost flow, the traveling salesman, \n\nshortest paths,\nand assignment.\n\nThis lecture gives an introduction to economic and financial networks.\n\nSome parts of this lecture are drawn from the text\n\n\nhttps://​networks​.quantecon​.org/ but the level of this lecture is more\nintroductory.\n\nWe will need the following imports.\n\nimport numpy as np\nimport networkx as nx\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport quantecon_wasm as qe\n\nimport matplotlib.cm as cm\nimport quantecon_book_networks.input_output as qbn_io\nimport quantecon_book_networks.data as qbn_data\n\nimport matplotlib.patches as mpatches\n\n","type":"content","url":"/networks#outline","position":3},{"hierarchy":{"lvl1":"Networks","lvl2":"Economic and financial networks"},"type":"lvl2","url":"/networks#economic-and-financial-networks","position":4},{"hierarchy":{"lvl1":"Networks","lvl2":"Economic and financial networks"},"content":"Within economics, important examples of networks include\n\nfinancial networks\n\nproduction networks\n\ntrade networks\n\ntransport networks and\n\nsocial networks\n\nSocial networks affect trends in market sentiment and consumer decisions.\n\nThe structure of financial networks helps to determine relative fragility of the financial system.\n\nThe structure of production networks affects trade, innovation and the propagation of local shocks.\n\nTo better understand such networks, let’s look at some examples in more depth.","type":"content","url":"/networks#economic-and-financial-networks","position":5},{"hierarchy":{"lvl1":"Networks","lvl3":"Example: Aircraft Exports","lvl2":"Economic and financial networks"},"type":"lvl3","url":"/networks#example-aircraft-exports","position":6},{"hierarchy":{"lvl1":"Networks","lvl3":"Example: Aircraft Exports","lvl2":"Economic and financial networks"},"content":"The following figure shows international trade in large commercial aircraft in 2019 based on International Trade Data SITC Revision 2.\n\nch1_data = qbn_data.introduction()\nexport_figures = False\n\nDG = ch1_data['aircraft_network']\npos = ch1_data['aircraft_network_pos']\n\ncentrality = nx.eigenvector_centrality(DG)\nnode_total_exports = qbn_io.node_total_exports(DG)\nedge_weights = qbn_io.edge_weights(DG)\n\nnode_pos_dict = pos\n\nnode_sizes = qbn_io.normalise_weights(node_total_exports,10000)\nedge_widths = qbn_io.normalise_weights(edge_weights,10)\n\nnode_colors = qbn_io.colorise_weights(list(centrality.values()),color_palette=cm.viridis)\nnode_to_color = dict(zip(DG.nodes,node_colors))\nedge_colors = []\nfor src,_ in DG.edges:\n    edge_colors.append(node_to_color[src])\n\nfig, ax = plt.subplots(figsize=(10, 10))\nax.axis('off')\n\nnx.draw_networkx_nodes(DG,\n                       node_pos_dict,\n                       node_color=node_colors,\n                       node_size=node_sizes,\n                       linewidths=2,\n                       alpha=0.6,\n                       ax=ax)\n\nnx.draw_networkx_labels(DG,\n                        node_pos_dict,\n                        ax=ax)\n\nnx.draw_networkx_edges(DG,\n                       node_pos_dict,\n                       edge_color=edge_colors,\n                       width=edge_widths,\n                       arrows=True,\n                       arrowsize=20,\n                       ax=ax,\n                       arrowstyle='->',\n                       node_size=node_sizes,\n                       connectionstyle='arc3,rad=0.15')\n\nplt.show()\n\n\n\nFigure 1:Commercial Aircraft Network\n\nThe circles in the figure are called nodes or vertices -- in this case they represent countries.\n\nThe arrows in the figure are called edges or links.\n\nNode size is proportional to total exports and edge width is proportional to exports to the target country.\n\n(The data is for trade in commercial aircraft weighing at least 15,000kg and was sourced from CID Dataverse.)\n\nThe figure shows that the US, France and Germany are major export hubs.\n\nIn the discussion below, we learn to quantify such ideas.","type":"content","url":"/networks#example-aircraft-exports","position":7},{"hierarchy":{"lvl1":"Networks","lvl3":"Example: A Markov Chain","lvl2":"Economic and financial networks"},"type":"lvl3","url":"/networks#example-a-markov-chain","position":8},{"hierarchy":{"lvl1":"Networks","lvl3":"Example: A Markov Chain","lvl2":"Economic and financial networks"},"content":"Recall that, in our lecture on \n\nMarkov chains we studied a dynamic model of business cycles\nwhere the states are\n\n“ng” = “normal growth”\n\n“mr” = “mild recession”\n\n“sr” = “severe recession”\n\nLet’s examine the following figure\n\nThis is an example of a network, where the set of nodes V equals the states:V = \\{ \\text{\"ng\", \"mr\", \"sr\"} \\}\n\nThe edges between the nodes show the one month transition probabilities.","type":"content","url":"/networks#example-a-markov-chain","position":9},{"hierarchy":{"lvl1":"Networks","lvl2":"An introduction to graph theory"},"type":"lvl2","url":"/networks#an-introduction-to-graph-theory","position":10},{"hierarchy":{"lvl1":"Networks","lvl2":"An introduction to graph theory"},"content":"Now we’ve looked at some examples, let’s move on to theory.\n\nThis theory will allow us to better organize our thoughts.\n\nThe theoretical part of network science is constructed using a major branch of\nmathematics called \n\ngraph theory.\n\nGraph theory can be complicated and we will cover only the basics.\n\nHowever, these concepts will already be enough for us to discuss interesting and\nimportant ideas on economic and financial networks.\n\nWe focus on “directed” graphs, where connections are, in general, asymmetric\n(arrows typically point one way, not both ways).\n\nE.g.,\n\nbank A lends money to bank B\n\nfirm A supplies goods to firm B\n\nindividual A “follows” individual B on a given social network\n\n(“Undirected” graphs, where connections are symmetric, are a special\ncase of directed graphs --- we just need to insist that each arrow pointing\nfrom A to B is paired with another arrow pointing from B to A.)","type":"content","url":"/networks#an-introduction-to-graph-theory","position":11},{"hierarchy":{"lvl1":"Networks","lvl3":"Key definitions","lvl2":"An introduction to graph theory"},"type":"lvl3","url":"/networks#key-definitions","position":12},{"hierarchy":{"lvl1":"Networks","lvl3":"Key definitions","lvl2":"An introduction to graph theory"},"content":"A directed graph consists of two things:\n\na finite set V and\n\na collection of pairs (u, v) where u and v are elements of V.\n\nThe elements of V are called the vertices or nodes of the graph.\n\nThe pairs (u,v) are called the edges of the graph and the set of all edges will usually be denoted by E\n\nIntuitively and visually, an edge (u,v) is understood as an arrow from node u to node v.\n\n(A neat way to represent an arrow is to record the location of the tail and\nhead of the arrow, and that’s exactly what an edge does.)\n\nIn the aircraft export example shown in \n\nFig. 1\n\nV is all countries included in the data set.\n\nE is all the arrows in the figure, each indicating some positive amount of aircraft exports from one country to another.\n\nLet’s look at more examples.\n\nTwo graphs are shown below, each with three nodes.\n\n\n\nFigure 2:Poverty Trap\n\nWe now construct a graph with the same nodes but different edges.\n\n\n\nFigure 3:Poverty Trap\n\nFor these graphs, the arrows (edges) can be thought of as representing\npositive transition probabilities over a given unit of time.\n\nIn general, if an edge (u, v) exists, then the node u is called a\ndirect predecessor of v and v is called a direct successor of u.\n\nAlso,  for v \\in V,\n\nthe in-degree is i_d(v) =  the number of direct predecessors of v and\n\nthe out-degree is o_d(v) =  the number of direct successors of v.","type":"content","url":"/networks#key-definitions","position":13},{"hierarchy":{"lvl1":"Networks","lvl3":"Digraphs in Networkx","lvl2":"An introduction to graph theory"},"type":"lvl3","url":"/networks#digraphs-in-networkx","position":14},{"hierarchy":{"lvl1":"Networks","lvl3":"Digraphs in Networkx","lvl2":"An introduction to graph theory"},"content":"The Python package \n\nNetworkx provides a convenient\ndata structure for representing directed graphs and implements many common\nroutines for analyzing them.\n\nAs an example, let us recreate \n\nFig. 3 using Networkx.\n\nTo do so, we first create an empty DiGraph object:\n\nG_p = nx.DiGraph()\n\nNext we populate it with nodes and edges.\n\nTo do this we write down a list of\nall edges, with poor represented by p and so on:\n\nedge_list = [('p', 'p'),\n             ('m', 'p'), ('m', 'm'), ('m', 'r'),\n             ('r', 'p'), ('r', 'm'), ('r', 'r')]\n\nFinally, we add the edges to our DiGraph object:\n\nfor e in edge_list:\n    u, v = e\n    G_p.add_edge(u, v)\n\nAlternatively, we can use the method add_edges_from.\n\nG_p.add_edges_from(edge_list)\n\nAdding the edges automatically adds the nodes, so G_p is now a\ncorrect representation of our graph.\n\nWe can verify this by plotting the graph via Networkx with the following code:\n\nfig, ax = plt.subplots()\nnx.draw_spring(G_p, ax=ax, node_size=500, with_labels=True,\n               font_weight='bold', arrows=True, alpha=0.8,\n               connectionstyle='arc3,rad=0.25', arrowsize=20)\nplt.show()\n\nThe figure obtained above matches the original directed graph in \n\nFig. 3.\n\nDiGraph objects have methods that calculate in-degree and out-degree\nof nodes.\n\nFor example,\n\nG_p.in_degree('p')\n\n","type":"content","url":"/networks#digraphs-in-networkx","position":15},{"hierarchy":{"lvl1":"Networks","lvl3":"Communication","lvl2":"An introduction to graph theory"},"type":"lvl3","url":"/networks#strongly-connected","position":16},{"hierarchy":{"lvl1":"Networks","lvl3":"Communication","lvl2":"An introduction to graph theory"},"content":"Next, we study communication and connectedness, which have important\nimplications for economic networks.\n\nNode v is called accessible from node u if either u=v or there\nexists a sequence of edges that lead from u to v.\n\nin this case, we write u \\to v\n\n(Visually, there is a sequence of arrows leading from u to v.)\n\nFor example, suppose we have a directed graph representing a production network, where\n\nelements of V are industrial sectors and\n\nexistence of an edge (i, j) means that i supplies products or services to j.\n\nThen m \\to \\ell means that sector m is an upstream supplier of sector \\ell.\n\nTwo nodes u and v are said to communicate if both u \\to v and v \\to u.\n\nA graph is called strongly connected if all nodes communicate.\n\nFor example, \n\nFig. 2 is strongly connected\nhowever in \n\nFig. 3 rich is not accessible from poor, thus it is not strongly connected.\n\nWe can verify this by first constructing the graphs using Networkx and then using nx.is_strongly_connected.\n\nfig, ax = plt.subplots()\nG1 = nx.DiGraph()\n\nG1.add_edges_from([('p', 'p'),('p','m'),('p','r'),\n             ('m', 'p'), ('m', 'm'), ('m', 'r'),\n             ('r', 'p'), ('r', 'm'), ('r', 'r')])\n\nnx.draw_networkx(G1, with_labels = True)\n\n\n\nnx.is_strongly_connected(G1)    #checking if above graph is strongly connected\n\n\n\nfig, ax = plt.subplots()\nG2 = nx.DiGraph()\n\nG2.add_edges_from([('p', 'p'),\n             ('m', 'p'), ('m', 'm'), ('m', 'r'),\n             ('r', 'p'), ('r', 'm'), ('r', 'r')])\n\nnx.draw_networkx(G2, with_labels = True)\n\n\n\nnx.is_strongly_connected(G2)    #checking if above graph is strongly connected\n\n","type":"content","url":"/networks#strongly-connected","position":17},{"hierarchy":{"lvl1":"Networks","lvl2":"Weighted graphs"},"type":"lvl2","url":"/networks#weighted-graphs","position":18},{"hierarchy":{"lvl1":"Networks","lvl2":"Weighted graphs"},"content":"We now introduce weighted graphs, where weights (numbers) are attached to each\nedge.","type":"content","url":"/networks#weighted-graphs","position":19},{"hierarchy":{"lvl1":"Networks","lvl3":"International private credit flows by country","lvl2":"Weighted graphs"},"type":"lvl3","url":"/networks#international-private-credit-flows-by-country","position":20},{"hierarchy":{"lvl1":"Networks","lvl3":"International private credit flows by country","lvl2":"Weighted graphs"},"content":"To motivate the idea, consider the following figure which shows flows of funds (i.e.,\nloans) between private banks, grouped by country of origin.\n\nZ = ch1_data[\"adjacency_matrix\"][\"Z\"]\nZ_visual= ch1_data[\"adjacency_matrix\"][\"Z_visual\"]\ncountries = ch1_data[\"adjacency_matrix\"][\"countries\"]\n\nG = qbn_io.adjacency_matrix_to_graph(Z_visual, countries, tol=0.03)\n\ncentrality = qbn_io.eigenvector_centrality(Z_visual, authority=False)\nnode_total_exports = qbn_io.node_total_exports(G)\nedge_weights = qbn_io.edge_weights(G)\n\nnode_pos_dict = nx.circular_layout(G)\n\nnode_sizes = qbn_io.normalise_weights(node_total_exports,3000)\nedge_widths = qbn_io.normalise_weights(edge_weights,10)\n\n\nnode_colors = qbn_io.colorise_weights(centrality)\nnode_to_color = dict(zip(G.nodes,node_colors))\nedge_colors = []\nfor src,_ in G.edges:\n    edge_colors.append(node_to_color[src])\n\nfig, ax = plt.subplots(figsize=(10, 10))\nax.axis('off')\n\nnx.draw_networkx_nodes(G,\n                       node_pos_dict,\n                       node_color=node_colors,\n                       node_size=node_sizes,\n                       edgecolors='grey',\n                       linewidths=2,\n                       alpha=0.4,\n                       ax=ax)\n\nnx.draw_networkx_labels(G,\n                        node_pos_dict,\n                        font_size=12,\n                        ax=ax)\n\nnx.draw_networkx_edges(G,\n                       node_pos_dict,\n                       edge_color=edge_colors,\n                       width=edge_widths,\n                       arrows=True,\n                       arrowsize=20,\n                       alpha=0.8,\n                       ax=ax,\n                       arrowstyle='->',\n                       node_size=node_sizes,\n                       connectionstyle='arc3,rad=0.15')\n\nplt.show()\n\n\n\nFigure 4:International Credit Network\n\nThe country codes are given in the following table\n\nCode\n\nCountry\n\nCode\n\nCountry\n\nCode\n\nCountry\n\nCode\n\nCountry\n\nAU\n\nAustralia\n\nDE\n\nGermany\n\nCL\n\nChile\n\nES\n\nSpain\n\nPT\n\nPortugal\n\nFR\n\nFrance\n\nTR\n\nTurkey\n\nGB\n\nUnited Kingdom\n\nUS\n\nUnited States\n\nIE\n\nIreland\n\nAT\n\nAustria\n\nIT\n\nItaly\n\nBE\n\nBelgium\n\nJP\n\nJapan\n\nSW\n\nSwitzerland\n\nSE\n\nSweden\n\nAn arrow from Japan to the US indicates aggregate claims held by Japanese\nbanks on all US-registered banks, as collected by the Bank of International\nSettlements (BIS).\n\nThe size of each node in the figure is increasing in the\ntotal foreign claims of all other nodes on this node.\n\nThe widths of the arrows are proportional to the foreign claims they represent.\n\nNotice that, in this network, an edge (u, v) exists for almost every choice\nof u and v (i.e., almost every country in the network).\n\n(In fact, there are even more small arrows, which we have dropped for clarity.)\n\nHence the existence of an edge from one node to another is not particularly informative.\n\nTo understand the network, we need to record not just the existence or absence\nof a credit flow, but also the size of the flow.\n\nThe correct data structure for recording this information is a “weighted\ndirected graph”.\n\n","type":"content","url":"/networks#international-private-credit-flows-by-country","position":21},{"hierarchy":{"lvl1":"Networks","lvl3":"Definitions","lvl2":"Weighted graphs"},"type":"lvl3","url":"/networks#definitions","position":22},{"hierarchy":{"lvl1":"Networks","lvl3":"Definitions","lvl2":"Weighted graphs"},"content":"A weighted directed graph is a directed graph to which we have added a\nweight function w that assigns a positive number to each edge.\n\nThe figure above shows one weighted directed graph, where the weights are the size of fund flows.\n\nThe following figure shows a weighted directed graph, with arrows\nrepresenting edges of the induced directed graph.\n\n\n\nFigure 5:Weighted Poverty Trap\n\nThe numbers next to the edges are the weights.\n\nIn this case, you can think of the numbers on the arrows as transition\nprobabilities for a household over, say, one year.\n\nWe see that a rich household has a 10% chance of becoming poor in one year.","type":"content","url":"/networks#definitions","position":23},{"hierarchy":{"lvl1":"Networks","lvl2":"Adjacency matrices"},"type":"lvl2","url":"/networks#adjacency-matrices","position":24},{"hierarchy":{"lvl1":"Networks","lvl2":"Adjacency matrices"},"content":"Another way that we can represent weights, which turns out to be very\nconvenient for numerical work, is via a matrix.\n\nThe adjacency matrix of a weighted directed graph with nodes \\{v_1, \\ldots, v_n\\}, edges E and weight function w is the matrixA = (a_{ij})_{1 \\leq i,j \\leq n}\n\\quad \\text{with} \\quad\na_{ij} =\n%\n\\begin{cases}\n    w(v_i, v_j) & \\text{ if } (v_i, v_j) \\in E\n    \\\\\n    0           & \\text{ otherwise}.\n\\end{cases}\n%\n\nOnce the nodes in V are enumerated, the weight function and\nadjacency matrix provide essentially the same information.\n\nFor example, with \\{poor, middle, rich\\} mapped to \\{1, 2, 3\\} respectively,\nthe adjacency matrix corresponding to the weighted directed graph in \n\nFig. 5 is\\begin{pmatrix}\n    0.9 & 0.1 & 0 \\\\\n    0.4 & 0.4 & 0.2 \\\\\n    0.1 & 0.1 & 0.8\n\\end{pmatrix}.\n\nIn QuantEcon’s DiGraph implementation, weights are recorded via the\nkeyword weighted:\n\nA = ((0.9, 0.1, 0.0),\n     (0.4, 0.4, 0.2),\n     (0.1, 0.1, 0.8))\nA = np.array(A)\nG = qe.DiGraph(A, weighted=True)    # store weights\n\nOne of the key points to remember about adjacency matrices is that taking the\ntranspose reverses all the arrows in the associated directed graph.\n\nFor example, the following directed graph can be\ninterpreted as a stylized version of a financial network, with nodes as banks\nand edges showing the flow of funds.\n\nG4 = nx.DiGraph()\n\nG4.add_edges_from([('1','2'),\n                   ('2','1'),('2','3'),\n                   ('3','4'),\n                   ('4','2'),('4','5'),\n                   ('5','1'),('5','3'),('5','4')])\npos = nx.circular_layout(G4)\n\nedge_labels={('1','2'): '100',\n             ('2','1'): '50', ('2','3'): '200',\n             ('3','4'): '100',\n             ('4','2'): '500', ('4','5'): '50',\n             ('5','1'): '150',('5','3'): '250', ('5','4'): '300'}\n\nnx.draw_networkx(G4, pos, node_color = 'none',node_size = 500)\nnx.draw_networkx_edge_labels(G4, pos, edge_labels=edge_labels)\nnx.draw_networkx_nodes(G4, pos, linewidths= 0.5, edgecolors = 'black',\n                       node_color = 'none',node_size = 500)\n\nplt.show()\n\nWe see that bank 2 extends a loan of size 200 to bank 3.\n\nThe corresponding adjacency matrix isA =\n\\begin{pmatrix}\n    0 & 100 & 0 & 0 & 0 \\\\\n    50 & 0 & 200 & 0 & 0 \\\\\n    0 & 0 & 0 & 100 & 0 \\\\\n    0 & 500 & 0 & 0 & 50 \\\\\n    150 & 0 & 250 & 300 & 0\n\\end{pmatrix}.\n\nThe transpose isA^\\top =\n\\begin{pmatrix}\n    0   & 50  & 0   & 0   & 150 \\\\\n    100 & 0   & 0   & 500 & 0 \\\\\n    0   & 200 & 0   & 0   & 250 \\\\\n    0   & 0   & 100 & 0   & 300 \\\\\n    0   & 0   & 0   & 50  & 0\n\\end{pmatrix}.\n\nThe corresponding network is visualized in the following figure which shows the network of liabilities after the loans have been granted.\n\nBoth of these networks (original and transpose) are useful for analyzing financial markets.\n\nG5 = nx.DiGraph()\n\nG5.add_edges_from([('1','2'),('1','5'),\n                   ('2','1'),('2','4'),\n                   ('3','2'),('3','5'),\n                   ('4','3'),('4','5'),\n                   ('5','4')])\n\nedge_labels={('1','2'): '50', ('1','5'): '150',\n             ('2','1'): '100', ('2','4'): '500',\n             ('3','2'): '200', ('3','5'): '250',\n             ('4','3'): '100', ('4','5'): '300',\n             ('5','4'): '50'}\n\nnx.draw_networkx(G5, pos, node_color = 'none',node_size = 500)\nnx.draw_networkx_edge_labels(G5, pos, edge_labels=edge_labels)\nnx.draw_networkx_nodes(G5, pos, linewidths= 0.5, edgecolors = 'black',\n                       node_color = 'none',node_size = 500)\n\nplt.show()\n\nIn general, every nonnegative n \\times n matrix A = (a_{ij}) can be\nviewed as the adjacency matrix of a weighted directed graph.\n\nTo build the graph we set V = 1, \\ldots, n and take the edge set E to be\nall (i,j) such that a_{ij} > 0.\n\nFor the weight function we set w(i, j) = a_{ij}  for all edges (i,j).\n\nWe call this graph the weighted directed graph induced by A.","type":"content","url":"/networks#adjacency-matrices","position":25},{"hierarchy":{"lvl1":"Networks","lvl2":"Properties"},"type":"lvl2","url":"/networks#properties","position":26},{"hierarchy":{"lvl1":"Networks","lvl2":"Properties"},"content":"Consider a weighted directed graph with adjacency matrix A.\n\nLet a^k_{ij} be element i,j of A^k, the k-th power of A.\n\nThe following result is useful in many applications:\n\nFor distinct nodes i, j in V and any integer k, we havea^k_{i j} > 0\n\\quad \\text{if and only if} \\quad\n\\text{ $j$ is accessible from $i$}.\n\nThe above result is obvious when k=1 and a proof of the general case can be\nfound in \n\nSargent & Stachurski (2022).\n\nNow recall from the eigenvalues lecture that a\nnonnegative matrix A is called \n\nirreducible if for each (i,j) there is an integer k \\geq 0 such that a^{k}_{ij} > 0.\n\nFrom the preceding theorem, it is not too difficult (see\n\n\nSargent & Stachurski (2022) for details) to get the next result.\n\nFor a weighted directed graph the following statements are equivalent:\n\nThe directed graph is strongly connected.\n\nThe adjacency matrix of the graph is irreducible.\n\nWe illustrate the above theorem with a simple example.\n\nConsider the following weighted directed graph.\n\nWe first create the above network as a Networkx DiGraph object.\n\nG6 = nx.DiGraph()\n\nG6.add_edges_from([('1','2'),('1','3'),\n                   ('2','1'),\n                   ('3','1'),('3','2')])\n\nThen we construct the associated adjacency matrix A.\n\nA = np.array([[0,0.7,0.3],    # adjacency matrix A\n              [1,0,0],\n              [0.4,0.6,0]])\n\n\n\ndef is_irreducible(P):\n    n = len(P)\n    result = np.zeros((n, n))\n    for i in range(n):\n        result += np.linalg.matrix_power(P, i)\n    return np.all(result > 0)\n\n\n\nis_irreducible(A)      # check irreducibility of A\n\n\n\nnx.is_strongly_connected(G6)      # check connectedness of graph\n\n","type":"content","url":"/networks#properties","position":27},{"hierarchy":{"lvl1":"Networks","lvl2":"Network centrality"},"type":"lvl2","url":"/networks#network-centrality","position":28},{"hierarchy":{"lvl1":"Networks","lvl2":"Network centrality"},"content":"When studying networks of all varieties, a recurring topic is the relative\n“centrality” or “importance” of different nodes.\n\nExamples include\n\nranking of web pages by search engines\n\ndetermining the most important bank in a financial network (which one a\ncentral bank should rescue if there is a financial crisis)\n\ndetermining the most important industrial sector in an economy.\n\nIn what follows, a centrality measure associates to each weighted directed\ngraph a vector m where the m_i is interpreted as the centrality (or rank)\nof node v_i.","type":"content","url":"/networks#network-centrality","position":29},{"hierarchy":{"lvl1":"Networks","lvl3":"Degree centrality","lvl2":"Network centrality"},"type":"lvl3","url":"/networks#degree-centrality","position":30},{"hierarchy":{"lvl1":"Networks","lvl3":"Degree centrality","lvl2":"Network centrality"},"content":"Two elementary measures of “importance” of a node in a given directed\ngraph are its in-degree and out-degree.\n\nBoth of these provide a centrality measure.\n\nIn-degree centrality is a vector containing the in-degree of each node in\nthe graph.\n\nConsider the following simple example.\n\nG7 = nx.DiGraph()\n\nG7.add_nodes_from(['1','2','3','4','5','6','7'])\n\nG7.add_edges_from([('1','2'),('1','6'),\n                   ('2','1'),('2','4'),\n                   ('3','2'),\n                   ('4','2'),\n                   ('5','3'),('5','4'),\n                   ('6','1'),\n                   ('7','4'),('7','6')])\npos = nx.planar_layout(G7)\n\nnx.draw_networkx(G7, pos, node_color='none', node_size=500)\nnx.draw_networkx_nodes(G7, pos, linewidths=0.5, edgecolors='black',\n                       node_color='none',node_size=500)\n\nplt.show()\n\n\n\nFigure 6:Sample Graph\n\nThe following code displays the in-degree centrality of all nodes.\n\niG7 = [G7.in_degree(v) for v in G7.nodes()]   # computing in-degree centrality\n\nfor i, d in enumerate(iG7):\n    print(i+1, d)\n\nConsider the international credit network displayed in \n\nFig. 4.\n\nThe following plot displays the in-degree centrality of each country.\n\nD = qbn_io.build_unweighted_matrix(Z)\nindegree = D.sum(axis=0)\n\n\n\ndef centrality_plot_data(countries, centrality_measures):\n    df = pd.DataFrame({'code': countries,\n                       'centrality':centrality_measures,\n                       'color': qbn_io.colorise_weights(centrality_measures).tolist()\n                       })\n    return df.sort_values('centrality')\n\n\n\nfig, ax = plt.subplots()\n\ndf = centrality_plot_data(countries, indegree)\n\nax.bar('code', 'centrality', data=df, color=df[\"color\"], alpha=0.6)\n\npatch = mpatches.Patch(color=None, label='in degree', visible=False)\nax.legend(handles=[patch], fontsize=12, loc=\"upper left\", handlelength=0, frameon=False)\n\nax.set_ylim((0,20))\n\nplt.show()\n\nUnfortunately, while in-degree and out-degree centrality are simple to\ncalculate, they are not always informative.\n\nIn \n\nFig. 4, an edge exists between almost every node,\nso the in- or out-degree based centrality ranking fails to effectively separate the countries.\n\nThis can be seen in the above graph as well.\n\nAnother example is the task of a web search engine, which ranks pages\nby relevance whenever a user enters a search.\n\nSuppose web page A has twice as many inbound links as page B.\n\nIn-degree centrality tells us that page A deserves a higher rank.\n\nBut in fact, page A might be less important than page B.\n\nTo see why, suppose that the links to A are from pages that receive almost no traffic,\nwhile the links to B are from pages that receive very heavy traffic.\n\nIn this case, page B probably receives more visitors, which in turn suggests\nthat page B contains more valuable (or entertaining) content.\n\nThinking about this point suggests that importance might be recursive.\n\nThis means that the importance of a given node depends on the importance of\nother nodes that link to it.\n\nAs another example, we can imagine a production network where the importance of a\ngiven sector depends on the importance of the sectors that it supplies.\n\nThis reverses the order of the previous example: now the importance of a given\nnode depends on the importance of other nodes that it links to.\n\nThe next centrality measures will have these recursive features.","type":"content","url":"/networks#degree-centrality","position":31},{"hierarchy":{"lvl1":"Networks","lvl3":"Eigenvector centrality","lvl2":"Network centrality"},"type":"lvl3","url":"/networks#eigenvector-centrality","position":32},{"hierarchy":{"lvl1":"Networks","lvl3":"Eigenvector centrality","lvl2":"Network centrality"},"content":"Suppose we have a weighted directed graph with adjacency matrix A.\n\nFor simplicity, we will suppose that the nodes V of the graph are just the\nintegers 1, \\ldots, n.\n\nLet r(A) denote the \n\nspectral radius of A.\n\nThe eigenvector centrality of the graph is defined as the n-vector e that solves\\begin{aligned}\n    e = \\frac{1}{r(A)} A e.\n\\end{aligned}\n\nIn other words, e is the dominant eigenvector of A (the eigenvector of the\nlargest eigenvalue --- see the discussion of the \n\nPerron-Frobenius theorem in the eigenvalue lecture.\n\nTo better understand \n\n(7), we write out the full expression\nfor some element e_i\\begin{aligned}\n    e_i = \\frac{1}{r(A)} \\sum_{1 \\leq j \\leq n} a_{ij} e_j\n\\end{aligned}\n\nNote the recursive nature of the definition: the centrality obtained by node\ni is proportional to a sum of the centrality of all nodes, weighted by\nthe rates of flow from i into these nodes.\n\nA node i is highly ranked if\n\nthere are many edges leaving i,\n\nthese edges have large weights, and\n\nthe edges point to other highly ranked nodes.\n\nLater, when we study demand shocks  in production networks, there will be a more\nconcrete interpretation of eigenvector centrality.\n\nWe will see that, in production networks, sectors with high eigenvector\ncentrality are important suppliers.\n\nIn particular, they are activated by a wide array of demand shocks once orders\nflow backwards through the network.\n\nTo compute eigenvector centrality we can use the following function.\n\ndef eigenvector_centrality(A, k=40, authority=False):\n    \"\"\"\n    Computes the dominant eigenvector of A. Assumes A is\n    primitive and uses the power method.\n\n    \"\"\"\n    A_temp = A.T if authority else A\n    n = len(A_temp)\n    r = np.max(np.abs(np.linalg.eigvals(A_temp)))\n    e = r**(-k) * (np.linalg.matrix_power(A_temp, k) @ np.ones(n))\n    return e / np.sum(e)\n\nLet’s compute eigenvector centrality for the graph generated in \n\nFig. 6.\n\nA = nx.to_numpy_array(G7)         # compute adjacency matrix of graph\n\n\n\ne = eigenvector_centrality(A)\nn = len(e)\n\nfor i in range(n):\n    print(i+1,e[i])\n\nWhile nodes 2 and 4 had the highest in-degree centrality, we can see that nodes 1 and 2 have the\nhighest eigenvector centrality.\n\nLet’s revisit the international credit network in \n\nFig. 4.\n\neig_central = eigenvector_centrality(Z)\n\n\n\nfig, ax = plt.subplots()\n\ndf = centrality_plot_data(countries, eig_central)\n\nax.bar('code', 'centrality', data=df, color=df[\"color\"], alpha=0.6)\n\npatch = mpatches.Patch(color=None, visible=False)\nax.legend(handles=[patch], fontsize=12, loc=\"upper left\", handlelength=0, frameon=False)\n\nplt.show()\n\n\n\nFigure 7:Eigenvector centrality\n\nCountries that are rated highly according to this rank tend to be important\nplayers in terms of supply of credit.\n\nJapan takes the highest rank according to this measure, although\ncountries with large financial sectors such as Great Britain and France are\nnot far behind.\n\nThe advantage of eigenvector centrality is that it measures a node’s importance while considering the importance of its neighbours.\n\nA variant of eigenvector centrality is at the core of Google’s PageRank algorithm, which is used to rank web pages.\n\nThe main principle is that links from important nodes (as measured by degree centrality) are worth more than links from unimportant nodes.","type":"content","url":"/networks#eigenvector-centrality","position":33},{"hierarchy":{"lvl1":"Networks","lvl3":"Katz centrality","lvl2":"Network centrality"},"type":"lvl3","url":"/networks#katz-centrality","position":34},{"hierarchy":{"lvl1":"Networks","lvl3":"Katz centrality","lvl2":"Network centrality"},"content":"One problem with eigenvector centrality is that r(A) might be zero, in which\ncase 1/r(A) is not defined.\n\nFor this and other reasons, some researchers prefer another measure of\ncentrality for networks called Katz centrality.\n\nFixing \\beta in (0, 1/r(A)), the Katz centrality of a weighted\ndirected graph with adjacency matrix A is defined as the vector \\kappa\nthat solves\\kappa_i =  \\beta \\sum_{1 \\leq j 1} a_{ij} \\kappa_j + 1\n\\qquad  \\text{for all } i \\in \\{0, \\ldots, n-1\\}.\n\nHere \\beta is a parameter that we can choose.\n\nIn vector form we can write\\kappa = \\mathbf 1 + \\beta A \\kappa\n\nwhere \\mathbf 1 is a column vector of ones.\n\nThe intuition behind this centrality measure is similar to that provided for\neigenvector centrality: high centrality is conferred on i when it is linked\nto by nodes that themselves have high centrality.\n\nProvided that 0 < \\beta < 1/r(A), Katz centrality is always finite and well-defined\nbecause then r(\\beta A) < 1.\n\nThis means that \n\n(10) has the unique solution\\kappa = (I - \\beta A)^{-1} \\mathbf{1}\n\nThis follows from the \n\nNeumann series theorem.\n\nThe parameter \\beta is used to ensure that \\kappa is finite\n\nWhen r(A)<1, we use \\beta=1 as the default for Katz centrality computations.","type":"content","url":"/networks#katz-centrality","position":35},{"hierarchy":{"lvl1":"Networks","lvl3":"Authorities vs hubs","lvl2":"Network centrality"},"type":"lvl3","url":"/networks#authorities-vs-hubs","position":36},{"hierarchy":{"lvl1":"Networks","lvl3":"Authorities vs hubs","lvl2":"Network centrality"},"content":"Search engine designers recognize that web pages can be important in two\ndifferent ways.\n\nSome pages have high hub centrality, meaning that they link to valuable\nsources of information (e.g., news aggregation sites).\n\nOther pages have high authority centrality, meaning that they contain\nvaluable information, as indicated by the number and significance of incoming\nlinks (e.g., websites of respected news organizations).\n\nSimilar ideas can and have been applied to economic networks (often using\ndifferent terminology).\n\nThe eigenvector centrality and Katz centrality measures we discussed above\nmeasure hub centrality.\n\n(Nodes have high centrality if they point to other nodes with high centrality.)\n\nIf we care more about authority centrality, we can use the same definitions\nexcept that we take the transpose of the adjacency matrix.\n\nThis works because taking the transpose reverses the direction of the arrows.\n\n(Now nodes will have high centrality if they receive links from other nodes\nwith high centrality.)\n\nFor example, the authority-based eigenvector centrality of a weighted\ndirected graph with adjacency matrix A is the vector e solvinge = \\frac{1}{r(A)} A^\\top e.\n\nThe only difference from the original definition is that A is replaced by\nits transpose.\n\n(Transposes do not affect the spectral radius of a matrix so we wrote r(A) instead of r(A^\\top).)\n\nElement-by-element, this is given bye_j = \\frac{1}{r(A)} \\sum_{1 \\leq i \\leq n} a_{ij} e_i\n\nWe see e_j will be high if many nodes with high authority rankings link to j.\n\nThe following figurenshows the authority-based eigenvector centrality ranking for the international\ncredit network shown in \n\nFig. 4.\n\necentral_authority = eigenvector_centrality(Z, authority=True)\n\n\n\nfig, ax = plt.subplots()\n\ndf = centrality_plot_data(countries, ecentral_authority)\n\nax.bar('code', 'centrality', data=df, color=df[\"color\"], alpha=0.6)\n\npatch = mpatches.Patch(color=None, visible=False)\nax.legend(handles=[patch], fontsize=12, loc=\"upper left\", handlelength=0, frameon=False)\n\nplt.show()\n\n\n\nFigure 8:Eigenvector authority\n\nHighly ranked countries are those that attract large inflows of credit, or\ncredit inflows from other major players.\n\nIn this case the US clearly dominates the rankings as a target of interbank credit.","type":"content","url":"/networks#authorities-vs-hubs","position":37},{"hierarchy":{"lvl1":"Networks","lvl2":"Further reading"},"type":"lvl2","url":"/networks#further-reading","position":38},{"hierarchy":{"lvl1":"Networks","lvl2":"Further reading"},"content":"We apply the ideas discussed in this lecture to:\n\nTextbooks on economic and social networks include \n\nJackson (2010),\n\n\nEasley et al. (2010), \n\nBorgatti et al. (2018),\n\n\nSargent & Stachurski (2022) and \n\nGoyal (2023).\n\nWithin the realm of network science, the texts\nby \n\nNewman (2018), \n\nMenczer et al. (2020) and\n\n\nCoscia (2021) are excellent.","type":"content","url":"/networks#further-reading","position":39},{"hierarchy":{"lvl1":"Networks","lvl2":"Exercises"},"type":"lvl2","url":"/networks#exercises","position":40},{"hierarchy":{"lvl1":"Networks","lvl2":"Exercises"},"content":"Here is a mathematical exercise for those who like proofs.\n\nLet (V, E) be a directed graph and write u \\sim v if u and v communicate.\n\nShow that \\sim is an \n\nequivalence relation on V.\n\nSolution to \n\nExercise 1\n\nReflexivity:\n\nTrivially, u = v \\Rightarrow u \\rightarrow v.\n\nThus, u \\sim u.\n\nSymmetry:\nSuppose, u \\sim v\n\n\\Rightarrow u \\rightarrow v and v \\rightarrow u.\n\nBy definition, this implies v \\sim u.\n\nTransitivity:\n\nSuppose, u \\sim v and v \\sim w\n\nThis implies, u \\rightarrow v and v \\rightarrow u and also v \\rightarrow w and w \\rightarrow v.\n\nThus, we can conclude u \\rightarrow v \\rightarrow w and w \\rightarrow v \\rightarrow u.\n\nWhich means u \\sim w.\n\nConsider a directed graph G with the set of nodesV = \\{0,1,2,3,4,5,6,7\\}\n\nand the set of edgesE = \\{(0, 1), (0, 3), (1, 0), (2, 4), (3, 2), (3, 4), (3, 7), (4, 3), (5, 4), (5, 6), (6, 3), (6, 5), (7, 0)\\}\n\nUse Networkx to draw graph G.\n\nFind the associated adjacency matrix A for G.\n\nUse the functions defined above to compute in-degree centrality, out-degree centrality and eigenvector centrality\nof G.\n\nSolution to \n\nExercise 2\n\n# First, let's plot the given graph\n\nG = nx.DiGraph()\n\nG.add_nodes_from(np.arange(8))  # adding nodes\n\nG.add_edges_from([(0,1),(0,3),       # adding edges\n                  (1,0),\n                  (2,4),\n                  (3,2),(3,4),(3,7),\n                  (4,3),\n                  (5,4),(5,6),\n                  (6,3),(6,5),\n                  (7,0)])\n\nnx.draw_networkx(G, pos=nx.circular_layout(G), node_color='gray', node_size=500, with_labels=True)\n\nplt.show()\n\n\n\nA = nx.to_numpy_array(G)      #find adjacency matrix associated with G\n\nA\n\n\n\noG = [G.out_degree(v) for v in G.nodes()]   # computing in-degree centrality\n\nfor i, d in enumerate(oG):\n    print(i, d)\n\n\n\ne = eigenvector_centrality(A)   # computing eigenvector centrality\nn = len(e)\n\nfor i in range(n):\n    print(i+1, e[i])\n\n\n\nConsider a graph G with n nodes and n \\times n adjacency matrix A.\n\nLet S = \\sum_{k=0}^{n-1} A^k\n\nWe can say for any two nodes i and j, j is accessible from i if and only if\nS_{ij} > 0.\n\nDevise a function is_accessible that checks if any two nodes of a given graph are accessible.\n\nConsider the graph in \n\nExercise 2 and use this function to check if\n\n1 is accessible from 2\n\n6 is accessible from 3\n\nSolution to \n\nExercise 3\n\ndef is_accessible(G,i,j):\n    A = nx.to_numpy_array(G)\n    n = len(A)\n    result = np.zeros((n, n))\n    for i in range(n):\n        result += np.linalg.matrix_power(A, i)\n    if result[i,j]>0:\n        return True\n    else:\n        return False\n\n\n\nG = nx.DiGraph()\n\nG.add_nodes_from(np.arange(8))  # adding nodes\n\nG.add_edges_from([(0,1),(0,3),       # adding edges\n                  (1,0),\n                  (2,4),\n                  (3,2),(3,4),(3,7),\n                  (4,3),\n                  (5,4),(5,6),\n                  (6,3),(6,5),\n                  (7,0)])\n\n\n\nis_accessible(G, 2, 1)\n\n\n\nis_accessible(G, 3, 6)\n\n","type":"content","url":"/networks#exercises","position":41},{"hierarchy":{"lvl1":"The Overlapping Generations Model"},"type":"lvl1","url":"/olg","position":0},{"hierarchy":{"lvl1":"The Overlapping Generations Model"},"content":"In this lecture we study the famous overlapping generations (OLG) model, which\nis used by policy makers and researchers to examine\n\nfiscal policy\n\nmonetary policy\n\nlong-run growth\n\nand many other topics.\n\nThe first rigorous version of the OLG model was developed by Paul Samuelson\n\n\nSamuelson (1958).\n\nOur aim is to gain a good understanding of a simple version of the OLG\nmodel.","type":"content","url":"/olg","position":1},{"hierarchy":{"lvl1":"The Overlapping Generations Model","lvl2":"Overview"},"type":"lvl2","url":"/olg#overview","position":2},{"hierarchy":{"lvl1":"The Overlapping Generations Model","lvl2":"Overview"},"content":"The dynamics of the OLG model are quite similar to those of the \n\nSolow-Swan\ngrowth model.\n\nAt the same time, the OLG model adds an important new feature: the choice of\nhow much to save is endogenous.\n\nTo see why this is important, suppose, for example, that we are interested in\npredicting the effect of a new tax on long-run growth.\n\nWe could add a tax to the Solow-Swan model and look at the change in the\nsteady state.\n\nBut this ignores the fact that households will change their savings and\nconsumption behavior when they face the new tax rate.\n\nSuch changes can substantially alter the predictions of the model.\n\nHence, if we care about accurate predictions, we should model the decision\nproblems of the agents.\n\nIn particular, households in the model should decide how much to save and how\nmuch to consume, given the environment that they face (technology, taxes,\nprices, etc.)\n\nThe OLG model takes up this challenge.\n\nWe will present a simple version of the OLG model that clarifies the decision\nproblem of households and studies the implications for long-run growth.\n\nLet’s start with some imports.\n\nimport numpy as np\nfrom scipy import optimize\nfrom collections import namedtuple\nimport matplotlib.pyplot as plt\n\n","type":"content","url":"/olg#overview","position":3},{"hierarchy":{"lvl1":"The Overlapping Generations Model","lvl2":"Environment"},"type":"lvl2","url":"/olg#environment","position":4},{"hierarchy":{"lvl1":"The Overlapping Generations Model","lvl2":"Environment"},"content":"We assume that time is discrete, so that t=0, 1, \\ldots.\n\nAn individual born at time t lives for two periods, t and t + 1.\n\nWe call an agent\n\n“young” during the first period of their lives and\n\n“old” during the second period of their lives.\n\nYoung agents work, supplying labor and earning labor income.\n\nThey also decide how much to save.\n\nOld agents do not work, so all income is financial.\n\nTheir financial income is from interest on their savings from wage income,\nwhich is then combined with the labor of the new young generation at t+1.\n\nThe wage and interest rates are determined in equilibrium by supply and\ndemand.\n\nTo make the algebra slightly easier, we are going to assume a constant\npopulation size.\n\nWe normalize the constant population size in each period to 1.\n\nWe also suppose that each agent supplies one “unit” of labor hours, so total\nlabor supply is 1.","type":"content","url":"/olg#environment","position":5},{"hierarchy":{"lvl1":"The Overlapping Generations Model","lvl2":"Supply of capital"},"type":"lvl2","url":"/olg#supply-of-capital","position":6},{"hierarchy":{"lvl1":"The Overlapping Generations Model","lvl2":"Supply of capital"},"content":"First let’s consider the household side.","type":"content","url":"/olg#supply-of-capital","position":7},{"hierarchy":{"lvl1":"The Overlapping Generations Model","lvl3":"Consumer’s problem","lvl2":"Supply of capital"},"type":"lvl3","url":"/olg#consumers-problem","position":8},{"hierarchy":{"lvl1":"The Overlapping Generations Model","lvl3":"Consumer’s problem","lvl2":"Supply of capital"},"content":"Suppose that utility for individuals born at time t takes the form    U_t = u(c_t) + \\beta u(c_{t+1})\n\nHere\n\nu: \\mathbb R_+ \\to \\mathbb R is called the “flow” utility function\n\n\\beta \\in (0, 1) is the discount factor\n\nc_t is time t consumption of the individual born at time t\n\nc_{t+1} is time t+1 consumption of the same individual\n\nWe assume that u is strictly increasing.\n\nSavings behavior is determined by the optimization problem    \\max_{c_t, c_{t+1}} \n    \\,  \\left \\{ u(c_t) + \\beta u(c_{t+1}) \\right \\}\n\nsubject toc_t + s_t \\le w_t \n     \\quad \\text{and} \\quad\n     c_{t+1}   \\le R_{t+1} s_t\n\nHere\n\ns_t is savings by an individual born at time t\n\nw_t is the wage rate at time t\n\nR_{t+1} is the gross interest rate on savings invested at time t, paid at time t+1\n\nSince u is strictly increasing, both of these constraints will hold as equalities at the maximum.\n\nUsing this fact and substituting s_t from the first constraint into the second we get\nc_{t+1} = R_{t+1}(w_t - c_t).\n\nThe first-order condition for a maximum can be obtained\nby plugging c_{t+1} into the objective function, taking the derivative\nwith respect to c_t, and setting it to zero.\n\nThis leads to the Euler equation of the OLG model, which describes the optimal intertemporal consumption dynamics:    u'(c_t) = \\beta R_{t+1}  u'( R_{t+1} (w_t - c_t))\n\nFrom the first constraint we get c_t = w_t - s_t, so the Euler equation\ncan also be expressed as    u'(w_t - s_t) = \\beta R_{t+1}  u'( R_{t+1} s_t)\n\nSuppose that, for each w_t and R_{t+1}, there is exactly one s_t that\nsolves \n\n(5).\n\nThen savings can be written as a fixed function of w_t and R_{t+1}.\n\nWe write this as    s_t = s(w_t, R_{t+1})\n\nThe precise form of the function s will depend on the choice of flow utility\nfunction u.\n\nTogether, w_t and R_{t+1} represent the prices in the economy (price of\nlabor and rental rate of capital).\n\nThus, \n\n(6) states the quantity of savings given prices.","type":"content","url":"/olg#consumers-problem","position":9},{"hierarchy":{"lvl1":"The Overlapping Generations Model","lvl3":"Example: log preferences","lvl2":"Supply of capital"},"type":"lvl3","url":"/olg#example-log-preferences","position":10},{"hierarchy":{"lvl1":"The Overlapping Generations Model","lvl3":"Example: log preferences","lvl2":"Supply of capital"},"content":"In the special case u(c) = \\log c, the Euler equation simplifies to\ns_t= \\beta (w_t - s_t).\n\nSolving for saving, we get    s_t = s(w_t, R_{t+1}) = \\frac{\\beta}{1+\\beta} w_t\n\nIn this special case, savings does not depend on the interest rate.","type":"content","url":"/olg#example-log-preferences","position":11},{"hierarchy":{"lvl1":"The Overlapping Generations Model","lvl3":"Savings and investment","lvl2":"Supply of capital"},"type":"lvl3","url":"/olg#savings-and-investment","position":12},{"hierarchy":{"lvl1":"The Overlapping Generations Model","lvl3":"Savings and investment","lvl2":"Supply of capital"},"content":"Since the population size is normalized to 1, s_t is also total savings in\nthe economy at time t.\n\nIn our closed economy, there is no foreign investment, so net savings equals\ntotal investment, which can be understood as supply of capital to firms.\n\nIn the next section we investigate demand for capital.\n\nEquating supply and demand will allow us to determine equilibrium in the OLG\neconomy.","type":"content","url":"/olg#savings-and-investment","position":13},{"hierarchy":{"lvl1":"The Overlapping Generations Model","lvl2":"Demand for capital"},"type":"lvl2","url":"/olg#demand-for-capital","position":14},{"hierarchy":{"lvl1":"The Overlapping Generations Model","lvl2":"Demand for capital"},"content":"First we describe the firm’s problem and then we write down an equation\ndescribing demand for capital given prices.","type":"content","url":"/olg#demand-for-capital","position":15},{"hierarchy":{"lvl1":"The Overlapping Generations Model","lvl3":"Firm’s problem","lvl2":"Demand for capital"},"type":"lvl3","url":"/olg#firms-problem","position":16},{"hierarchy":{"lvl1":"The Overlapping Generations Model","lvl3":"Firm’s problem","lvl2":"Demand for capital"},"content":"For each integer t \\geq 0, output y_t in period t is given by the\nCobb-Douglas production function    y_t = k_t^{\\alpha} \\ell_t^{1-\\alpha}\n\nHere k_t is capital, \\ell_t is labor, and  \\alpha is a parameter\n(sometimes called the “output elasticity of capital”).\n\nThe profit maximization problem of the firm is    \\max_{k_t, \\ell_t} \\{ k^{\\alpha}_t \\ell_t^{1-\\alpha} - R_t k_t -w_t \\ell_t  \\}\n\nThe first-order conditions are obtained by taking the derivative of the\nobjective function with respect to capital and labor respectively and setting\nthem to zero:    (1-\\alpha)(k_t / \\ell_t)^{\\alpha} = w_t\n    \\quad \\text{and} \\quad\n    \\alpha (k_t / \\ell_t)^{\\alpha - 1} = R_t","type":"content","url":"/olg#firms-problem","position":17},{"hierarchy":{"lvl1":"The Overlapping Generations Model","lvl3":"Demand","lvl2":"Demand for capital"},"type":"lvl3","url":"/olg#demand","position":18},{"hierarchy":{"lvl1":"The Overlapping Generations Model","lvl3":"Demand","lvl2":"Demand for capital"},"content":"Using our assumption \\ell_t = 1 allows us to write    w_t = (1-\\alpha)k_t^\\alpha\n\nand    R_t =\n    \\alpha k_t^{\\alpha - 1}\n\nRearranging \n\n(12) gives the aggregate demand for capital\nat time t+1    k^d (R_{t+1}) \n    := \\left (\\frac{\\alpha}{R_{t+1}} \\right )^{1/(1-\\alpha)}\n\nIn Python code this is\n\ndef capital_demand(R, α):\n    return (α/R)**(1/(1-α))\n\ndef capital_supply(R, β, w):\n    R = np.ones_like(R)\n    return R * (β / (1 + β)) * w\n\nThe next figure plots the supply of capital, as in \n\n(7), as well as the demand for capital, as in \n\n(13), as functions of the interest rate R_{t+1}.\n\n(For the special case of log utility, supply does not depend on the interest rate, so we have a constant function.)","type":"content","url":"/olg#demand","position":19},{"hierarchy":{"lvl1":"The Overlapping Generations Model","lvl2":"Equilibrium"},"type":"lvl2","url":"/olg#equilibrium","position":20},{"hierarchy":{"lvl1":"The Overlapping Generations Model","lvl2":"Equilibrium"},"content":"In this section we derive equilibrium conditions and investigate an example.","type":"content","url":"/olg#equilibrium","position":21},{"hierarchy":{"lvl1":"The Overlapping Generations Model","lvl3":"Equilibrium conditions","lvl2":"Equilibrium"},"type":"lvl3","url":"/olg#equilibrium-conditions","position":22},{"hierarchy":{"lvl1":"The Overlapping Generations Model","lvl3":"Equilibrium conditions","lvl2":"Equilibrium"},"content":"In equilibrium, savings at time t equals investment at time t, which\nequals capital supply at time t+1.\n\nEquilibrium is computed by equating these quantities, setting    s(w_t, R_{t+1}) \n    = k^d(R_{t+1})\n    = \\left (\\frac{\\alpha}{R_{t+1}} \\right )^{1/(1-\\alpha)}\n\nIn principle, we can now solve for the equilibrium price R_{t+1} given w_t.\n\n(In practice, we first need to specify the function u and hence s.)\n\nWhen we solve this equation, which concerns time t+1 outcomes, time\nt quantities are already determined, so we can treat w_t as a constant.\n\nFrom equilibrium R_{t+1} and \n\n(13), we can obtain\nthe equilibrium quantity k_{t+1}.","type":"content","url":"/olg#equilibrium-conditions","position":23},{"hierarchy":{"lvl1":"The Overlapping Generations Model","lvl3":"Example: log utility","lvl2":"Equilibrium"},"type":"lvl3","url":"/olg#example-log-utility","position":24},{"hierarchy":{"lvl1":"The Overlapping Generations Model","lvl3":"Example: log utility","lvl2":"Equilibrium"},"content":"In the case of log utility, we can use \n\n(14) and \n\n(7) to obtain    \\frac{\\beta}{1+\\beta} w_t\n    = \\left( \\frac{\\alpha}{R_{t+1}} \\right)^{1/(1-\\alpha)}\n\nSolving for the equilibrium interest rate gives    R_{t+1} = \n    \\alpha \n    \\left( \n        \\frac{\\beta}{1+\\beta} w_t\n    \\right)^{\\alpha-1}\n\nIn Python we can compute this via\n\ndef equilibrium_R_log_utility(α, β, w):\n    R = α * ( (β * w) / (1 + β))**(α - 1)\n    return R\n\nIn the case of log utility, since capital supply does not depend on the interest rate, the equilibrium quantity is fixed by supply.\n\nThat is,    k_{t+1} = s(w_t, R_{t+1}) = \\frac{\\beta }{1+\\beta} w_t\n\nLet’s redo our plot above but now inserting the equilibrium quantity and price.\n\nR_vals = np.linspace(0.3, 1)\nα, β = 0.5, 0.9\nw = 2.0\n\nfig, ax = plt.subplots()\n\nax.plot(R_vals, capital_demand(R_vals, α), \n        label=\"aggregate demand\")\nax.plot(R_vals, capital_supply(R_vals, β, w), \n        label=\"aggregate supply\")\n\nR_e = equilibrium_R_log_utility(α, β, w)\nk_e = (β / (1 + β)) * w\n\nax.plot(R_e, k_e, 'o',label='equilibrium')\n\nax.set_xlabel(\"$R_{t+1}$\")\nax.set_ylabel(\"$k_{t+1}$\")\nax.legend()\nplt.show()\n\n","type":"content","url":"/olg#example-log-utility","position":25},{"hierarchy":{"lvl1":"The Overlapping Generations Model","lvl2":"Dynamics"},"type":"lvl2","url":"/olg#dynamics","position":26},{"hierarchy":{"lvl1":"The Overlapping Generations Model","lvl2":"Dynamics"},"content":"In this section we discuss dynamics.\n\nFor now we will focus on the case of log utility, so that the equilibrium is determined by \n\n(17).","type":"content","url":"/olg#dynamics","position":27},{"hierarchy":{"lvl1":"The Overlapping Generations Model","lvl3":"Evolution of capital","lvl2":"Dynamics"},"type":"lvl3","url":"/olg#evolution-of-capital","position":28},{"hierarchy":{"lvl1":"The Overlapping Generations Model","lvl3":"Evolution of capital","lvl2":"Dynamics"},"content":"The discussion above shows how equilibrium k_{t+1} is obtained given w_t.\n\nFrom \n\n(11) we can translate this into k_{t+1} as a function of k_t\n\nIn particular, since w_t = (1-\\alpha)k_t^\\alpha, we have    k_{t+1} = \\frac{\\beta}{1+\\beta} (1-\\alpha)(k_t)^{\\alpha}\n\nIf we iterate on this equation, we get a sequence for capital stock.\n\nLet’s plot the 45-degree diagram of these dynamics, which we write ask_{t+1} = g(k_t)\n    \\quad \\text{where }\n    g(k) := \\frac{\\beta}{1+\\beta} (1-\\alpha)(k)^{\\alpha}\n\ndef k_update(k, α, β):\n    return β * (1 - α) * k**α /  (1 + β)\n\nα, β = 0.5, 0.9\nkmin, kmax = 0, 0.1\nn = 1000\nk_grid = np.linspace(kmin, kmax, n)\nk_grid_next = k_update(k_grid,α,β)\n\nfig, ax = plt.subplots(figsize=(6, 6))\n\nymin, ymax = np.min(k_grid_next), np.max(k_grid_next)\n\nax.plot(k_grid, k_grid_next,  lw=2, alpha=0.6, label='$g$')\nax.plot(k_grid, k_grid, 'k-', lw=1, alpha=0.7, label=r'$45^{\\circ}$')\n\n\nax.legend(loc='upper left', frameon=False, fontsize=12)\nax.set_xlabel('$k_t$', fontsize=12)\nax.set_ylabel('$k_{t+1}$', fontsize=12)\n\nplt.show()\n\n","type":"content","url":"/olg#evolution-of-capital","position":29},{"hierarchy":{"lvl1":"The Overlapping Generations Model","lvl3":"Steady state (log case)","lvl2":"Dynamics"},"type":"lvl3","url":"/olg#steady-state-log-case","position":30},{"hierarchy":{"lvl1":"The Overlapping Generations Model","lvl3":"Steady state (log case)","lvl2":"Dynamics"},"content":"The diagram shows that the model has a unique positive steady state, which we\ndenote by k^*.\n\nWe can solve for k^* by setting k^* = g(k^*), or    k^* = \\frac{\\beta (1-\\alpha) (k^*)^{\\alpha}}{(1+\\beta)}\n\nSolving this equation yields    k^* = \\left (\\frac{\\beta (1-\\alpha)}{1+\\beta} \\right )^{1/(1-\\alpha)}\n\nWe can get the steady state interest rate from \n\n(12), which yieldsR^* = \\alpha (k^*)^{\\alpha - 1} \n        = \\frac{\\alpha}{1 - \\alpha} \\frac{1 + \\beta}{\\beta}\n\nIn Python we have\n\nk_star = ((β * (1 - α))/(1 + β))**(1/(1-α))\nR_star = (α/(1 - α)) * ((1 + β) / β)\n\n","type":"content","url":"/olg#steady-state-log-case","position":31},{"hierarchy":{"lvl1":"The Overlapping Generations Model","lvl3":"Time series","lvl2":"Dynamics"},"type":"lvl3","url":"/olg#time-series","position":32},{"hierarchy":{"lvl1":"The Overlapping Generations Model","lvl3":"Time series","lvl2":"Dynamics"},"content":"The 45-degree diagram above shows that time series of capital with positive initial conditions converge to this steady state.\n\nLet’s plot some time series that visualize this.\n\nts_length = 25\nk_series = np.empty(ts_length)\nk_series[0] = 0.02\nfor t in range(ts_length - 1):\n    k_series[t+1] = k_update(k_series[t], α, β)\n\nfig, ax = plt.subplots()\nax.plot(k_series, label=\"capital series\")\nax.plot(range(ts_length), np.full(ts_length, k_star), 'k--', label=\"$k^*$\")\nax.set_ylim(0, 0.1)\nax.set_ylabel(\"capital\")\nax.set_xlabel(\"$t$\")\nax.legend()\nplt.show()\n\nIf you experiment with different positive initial conditions, you will see that the series always converges to k^*.\n\nBelow we also plot the gross interest rate over time.\n\nR_series = α * k_series**(α - 1)\n\nfig, ax = plt.subplots()\nax.plot(R_series, label=\"gross interest rate\")\nax.plot(range(ts_length), np.full(ts_length, R_star), 'k--', label=\"$R^*$\")\nax.set_ylim(0, 4)\nax.set_ylabel(\"gross interest rate\")\nax.set_xlabel(\"$t$\")\nax.legend()\nplt.show()\n\nThe interest rate reflects the marginal product of capital, which is high when capital stock is low.\n\n","type":"content","url":"/olg#time-series","position":33},{"hierarchy":{"lvl1":"The Overlapping Generations Model","lvl2":"CRRA preferences"},"type":"lvl2","url":"/olg#crra-preferences","position":34},{"hierarchy":{"lvl1":"The Overlapping Generations Model","lvl2":"CRRA preferences"},"content":"Previously, in our examples, we looked at the case of log utility.\n\nLog utility is a rather special case of CRRA utility with \\gamma \\to 1.\n\nIn this section, we are going to assume that u(c) = \\frac{ c^{1-\n\\gamma}-1}{1-\\gamma}, where \\gamma >0, \\gamma\\neq 1.\n\nThis function is called the CRRA utility function.\n\nIn other respects, the model is the same.\n\nBelow we define the utility function in Python and construct a namedtuple to store the parameters.\n\ndef crra(c, γ):\n    return c**(1 - γ) / (1 - γ)\n\nModel = namedtuple('Model', ['α',        # Cobb-Douglas parameter\n                             'β',        # discount factor\n                             'γ']        # parameter in CRRA utility\n                   )\n\ndef create_olg_model(α=0.4, β=0.9, γ=0.5):\n    return Model(α=α, β=β, γ=γ)\n\nLet’s also redefine the capital demand function to work with this namedtuple.\n\ndef capital_demand(R, model):\n    return (α/R)**(1/(1-model.α))\n\n","type":"content","url":"/olg#crra-preferences","position":35},{"hierarchy":{"lvl1":"The Overlapping Generations Model","lvl3":"Supply","lvl2":"CRRA preferences"},"type":"lvl3","url":"/olg#supply","position":36},{"hierarchy":{"lvl1":"The Overlapping Generations Model","lvl3":"Supply","lvl2":"CRRA preferences"},"content":"For households, the Euler equation becomes    (w_t - s_t)^{-\\gamma} = \\beta R^{1-\\gamma}_{t+1}  (s_t)^{-\\gamma}\n\nSolving for savings, we have    s_t \n    = s(w_t, R_{t+1}) \n    = w_t \\left [ \n        1 + \\beta^{-1/\\gamma} R_{t+1}^{(\\gamma-1)/\\gamma} \n      \\right ]^{-1}\n\nNotice how, unlike the log case, savings now depends on the interest rate.\n\ndef savings_crra(w, R, model):\n    α, β, γ = model\n    return w / (1 + β**(-1/γ) * R**((γ-1)/γ))\n\n\n\nmodel = create_olg_model()\nw = 2.0\n\nfig, ax = plt.subplots()\n\nax.plot(R_vals, capital_demand(R_vals, model), \n        label=\"aggregate demand\")\nax.plot(R_vals, savings_crra(w, R_vals, model), \n        label=\"aggregate supply\")\n\nax.set_xlabel(\"$R_{t+1}$\")\nax.set_ylabel(\"$k_{t+1}$\")\nax.legend()\nplt.show()\n\n","type":"content","url":"/olg#supply","position":37},{"hierarchy":{"lvl1":"The Overlapping Generations Model","lvl3":"Equilibrium","lvl2":"CRRA preferences"},"type":"lvl3","url":"/olg#equilibrium-1","position":38},{"hierarchy":{"lvl1":"The Overlapping Generations Model","lvl3":"Equilibrium","lvl2":"CRRA preferences"},"content":"Equating aggregate demand for capital  (see \n\n(13))\nwith our new aggregate supply function yields equilibrium capital.\n\nThus, we set    w_t \\left [ 1 + \\beta^{-1/\\gamma} R_{t+1}^{(\\gamma-1)/\\gamma} \\right ]^{-1} \n    = \\left (\\frac{R_{t+1}}{\\alpha} \\right )^{1/(\\alpha - 1)}\n\nThis expression is quite complex and we cannot solve for R_{t+1} analytically.\n\nCombining \n\n(12) and \n\n(25) yields    k_{t+1} = \\left [ 1 + \\beta^{-1/\\gamma} (\\alpha k^{\\alpha - 1}_{t+1})^{(\\gamma-1)/\\gamma} \\right ]^{-1} (1-\\alpha)(k_t)^{\\alpha}\n\nAgain, with this equation and k_t as given, we cannot solve for k_{t+1} by pencil and paper.\n\nIn the exercise below, you will be asked to solve these equations numerically.\n\n","type":"content","url":"/olg#equilibrium-1","position":39},{"hierarchy":{"lvl1":"The Overlapping Generations Model","lvl2":"Exercises"},"type":"lvl2","url":"/olg#exercises","position":40},{"hierarchy":{"lvl1":"The Overlapping Generations Model","lvl2":"Exercises"},"content":"Solve for the dynamics of equilibrium capital stock in the CRRA case numerically using \n\n(26).\n\nVisualize the dynamics using a 45-degree diagram.\n\nSolution to \n\nExercise 1\n\nTo solve for k_{t+1} given k_t we use \n\nNewton’s method.\n\nLet    f(k_{t+1}, k_t)\n    =\n    k_{t+1} \n    \\left[ \n        1 + \\beta^{-1/\\gamma} \n        \\left ( \n            \\alpha k^{\\alpha-1}_{t+1} \n        \\right )^{(\\gamma-1)/\\gamma} \n    \\right] - (1-\\alpha) k^{\\alpha}_t =0\n\nIf k_t is given then f is a function of unknown k_{t+1}.\n\nThen we can use scipy.optimize.newton to solve f(k_{t+1}, k_t)=0 for k_{t+1}.\n\nFirst let’s define f.\n\ndef f(k_prime, k, model):\n    α, β, γ = model.α, model.β, model.γ\n    z = (1 - α) * k**α\n    a = α**(1-1/γ)\n    b = k_prime**((α * γ - α + 1) / γ)\n    p = k_prime + k_prime * β**(-1/γ) * a * b\n    return p - z\n\nNow let’s define a function that finds the value of k_{t+1}.\n\ndef k_update(k, model):\n    return optimize.newton(lambda k_prime: f(k_prime, k, model), 0.1)\n\nFinally, here is the 45-degree diagram.\n\nkmin, kmax = 0, 0.5\nn = 1000\nk_grid = np.linspace(kmin, kmax, n)\nk_grid_next = np.empty_like(k_grid)\n\nfor i in range(n):\n    k_grid_next[i] = k_update(k_grid[i], model)\n\nfig, ax = plt.subplots(figsize=(6, 6))\n\nymin, ymax = np.min(k_grid_next), np.max(k_grid_next)\n\nax.plot(k_grid, k_grid_next,  lw=2, alpha=0.6, label='$g$')\nax.plot(k_grid, k_grid, 'k-', lw=1, alpha=0.7, label=r'$45^{\\circ}$')\n\n\nax.legend(loc='upper left', frameon=False, fontsize=12)\nax.set_xlabel('$k_t$', fontsize=12)\nax.set_ylabel('$k_{t+1}$', fontsize=12)\n\nplt.show()\n\n\n\nThe 45-degree diagram from the last exercise shows that there is a unique\npositive steady state.\n\nThe positive steady state can be obtained by setting  k_{t+1} = k_t = k^* in \n\n(26), which yieldsk^* = \n    \\frac{(1-\\alpha)(k^*)^{\\alpha}}\n    {1 + \\beta^{-1/\\gamma} (\\alpha (k^*)^{\\alpha-1})^{(\\gamma-1)/\\gamma}}\n\nUnlike the log preference case, the CRRA utility steady state k^*\ncannot be obtained analytically.\n\nInstead, we solve for k^* using Newton’s method.\n\nSolution to \n\nExercise 2\n\nWe introduce a function h such that\npositive steady state is the root of h.    h(k^*) = k^*  \n    \\left [ \n        1 + \\beta^{-1/\\gamma} (\\alpha (k^*)^{\\alpha-1})^{(\\gamma-1)/\\gamma} \n    \\right ] - (1-\\alpha)(k^*)^{\\alpha}\n\nHere it is in Python\n\ndef h(k_star, model):\n    α, β, γ = model.α, model.β, model.γ\n    z = (1 - α) * k_star**α\n    R1 = α ** (1-1/γ)\n    R2 = k_star**((α * γ - α + 1) / γ)\n    p = k_star + k_star * β**(-1/γ) * R1 * R2\n    return p - z\n\nLet’s apply Newton’s method to find the root:\n\nk_star = optimize.newton(h, 0.2, args=(model,))\nprint(f\"k_star = {k_star}\")\n\n\n\nGenerate three time paths for capital, from\nthree distinct initial conditions, under the parameterization listed above.\n\nUse initial conditions for k_0 of 0.001, 1.2, 2.6 and time series length 10.\n\nSolution to \n\nExercise 3\n\nLet’s define the constants and three distinct intital conditions\n\nts_length = 10\nk0 = np.array([0.001, 1.2, 2.6])\n\n\n\ndef simulate_ts(model, k0_values, ts_length):\n\n    fig, ax = plt.subplots()\n\n    ts = np.zeros(ts_length)\n\n    # simulate and plot time series\n    for k_init in k0_values:\n        ts[0] = k_init\n        for t in range(1, ts_length):\n            ts[t] = k_update(ts[t-1], model)\n        ax.plot(np.arange(ts_length), ts, '-o', ms=4, alpha=0.6,\n                label=r'$k_0=%g$' %k_init)\n    ax.plot(np.arange(ts_length), np.full(ts_length, k_star),\n            alpha=0.6, color='red', label=r'$k^*$')\n    ax.legend(fontsize=10)\n\n    ax.set_xlabel(r'$t$', fontsize=14)\n    ax.set_ylabel(r'$k_t$', fontsize=14)\n\n    plt.show()\n\n\n\nsimulate_ts(model, k0, ts_length)\n\n","type":"content","url":"/olg#exercises","position":41},{"hierarchy":{"lvl1":"Present Values"},"type":"lvl1","url":"/pv","position":0},{"hierarchy":{"lvl1":"Present Values"},"content":"","type":"content","url":"/pv","position":1},{"hierarchy":{"lvl1":"Present Values","lvl2":"Overview"},"type":"lvl2","url":"/pv#overview","position":2},{"hierarchy":{"lvl1":"Present Values","lvl2":"Overview"},"content":"This lecture describes the  present value model that is a starting point\nof much asset pricing theory.\n\nAsset pricing theory is a component of theories about many economic decisions including\n\nconsumption\n\nlabor supply\n\neducation choice\n\ndemand for money\n\nIn asset pricing theory, and in economic dynamics more generally, a basic topic is the relationship\namong different time series.\n\nA time series is a sequence indexed by time.\n\nIn this lecture, we’ll represent  a sequence as a vector.\n\nSo our analysis will typically boil down to studying relationships among vectors.\n\nOur main  tools in this lecture will be\n\nmatrix multiplication,  and\n\nmatrix inversion.\n\nWe’ll use the calculations described here in  subsequent lectures, including \n\nconsumption smoothing, \n\nequalizing difference model, and\n\n\nmonetarist theory of price levels.\n\nLet’s dive in.","type":"content","url":"/pv#overview","position":3},{"hierarchy":{"lvl1":"Present Values","lvl2":"Analysis"},"type":"lvl2","url":"/pv#analysis","position":4},{"hierarchy":{"lvl1":"Present Values","lvl2":"Analysis"},"content":"Let\n\n\\{d_t\\}_{t=0}^T  be a sequence of dividends or “payouts”\n\n\\{p_t\\}_{t=0}^T  be a sequence of prices of a claim on the continuation of\nthe asset’s payout  stream from date t on, namely, \\{d_s\\}_{s=t}^T \n\n \\delta  \\in (0,1)  be a one-period “discount factor”\n\np_{T+1}^* be a terminal price of the asset at time T+1\n\nWe  assume that the dividend stream \\{d_t\\}_{t=0}^T  and the terminal price\np_{T+1}^* are both exogenous.\n\nThis means that they are determined outside the model.\n\nAssume the sequence of asset pricing equationsp_t = d_t + \\delta p_{t+1}, \\quad t = 0, 1, \\ldots , T\n\nWe say equations, plural, because there are T+1 equations, one for each t =0, 1, \\ldots, T.\n\nEquations \n\n(1) assert that price paid to purchase  the asset at time t  equals the payout d_t  plus the price at time  t+1 multiplied by a time discount factor \\delta.\n\nDiscounting tomorrow’s price  by multiplying it by  \\delta accounts for the “value of waiting one period”.\n\nWe want to solve the system of T+1 equations \n\n(1) for the asset price sequence  \\{p_t\\}_{t=0}^T  as a function of the dividend sequence \\{d_t\\}_{t=0}^T  and the exogenous terminal\nprice  p_{T+1}^*.\n\nA system of equations like \n\n(1) is an example of a linear  difference equation.\n\nThere are powerful mathematical  methods available for solving such systems and they are well worth\nstudying in their own right, being the foundation for the analysis of many interesting economic models.\n\nFor an example, see \n\nSamuelson multiplier-accelerator\n\nIn this lecture, we’ll  solve system \n\n(1) using matrix multiplication and matrix inversion, basic tools from linear algebra introduced in  \n\nlinear equations and matrix algebra.\n\nWe will use the following imports\n\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n","type":"content","url":"/pv#analysis","position":5},{"hierarchy":{"lvl1":"Present Values","lvl2":"Representing sequences as vectors"},"type":"lvl2","url":"/pv#representing-sequences-as-vectors","position":6},{"hierarchy":{"lvl1":"Present Values","lvl2":"Representing sequences as vectors"},"content":"The equations in system \n\n(1) can be arranged as follows:\\begin{aligned}\n    p_0 & = d_0 + \\delta p_1 \\\\\n    p_1 & = d_1 + \\delta p_2 \\\\\n    \\vdots \\\\\n    p_{T-1} & = d_{T-1} + \\delta p_T \\\\\n    p_T & = d_T + \\delta p^*_{T+1}\n\\end{aligned}\n\nWrite the system \n\n(2) of T+1 asset pricing  equations as the single matrix equation\\begin{bmatrix} 1 & -\\delta & 0 & 0 & \\cdots & 0 & 0 \\cr\n                    0 & 1 & -\\delta & 0 & \\cdots & 0 & 0 \\cr\n                    0 & 0 & 1 & -\\delta & \\cdots & 0 & 0 \\cr\n                    \\vdots & \\vdots & \\vdots & \\vdots & \\vdots & 0 & 0 \\cr\n                    0 & 0 & 0 & 0 & \\cdots & 1 & -\\delta \\cr\n                    0 & 0 & 0 & 0 & \\cdots & 0 & 1 \\end{bmatrix}\n    \\begin{bmatrix} p_0 \\cr p_1 \\cr p_2 \\cr \\vdots \\cr p_{T-1} \\cr p_T \n    \\end{bmatrix} \n    =  \\begin{bmatrix}  \n    d_0 \\cr d_1 \\cr d_2 \\cr \\vdots \\cr d_{T-1} \\cr d_T\n    \\end{bmatrix}\n    + \\begin{bmatrix} \n    0 \\cr 0 \\cr 0 \\cr \\vdots \\cr 0 \\cr \\delta p_{T+1}^*\n    \\end{bmatrix}\n\nCarry out the matrix multiplication in \n\n(3) by hand and confirm that you\nrecover the equations in \n\n(2).\n\nIn vector-matrix notation, we can write  system \n\n(3) asA p = d + b\n\nHere A is the matrix on the left side of equation \n\n(3), whilep = \n    \\begin{bmatrix}\n        p_0 \\\\\n        p_1 \\\\\n        \\vdots \\\\\n        p_T\n    \\end{bmatrix},\n    \\quad\n    d = \n    \\begin{bmatrix}\n        d_0 \\\\\n        d_1 \\\\\n        \\vdots \\\\\n        d_T\n    \\end{bmatrix},\n    \\quad \\text{and} \\quad\n    b = \n    \\begin{bmatrix}\n        0 \\\\\n        0 \\\\\n        \\vdots \\\\\n        \\delta p^*_{T+1}\n    \\end{bmatrix}\n\nThe solution for the vector of  prices isp = A^{-1}(d + b)\n\nFor example, suppose that  the dividend stream isd_{t+1} = 1.05 d_t, \\quad t = 0, 1, \\ldots , T-1.\n\nLet’s write Python code to compute and plot the dividend stream.\n\nT = 6\ncurrent_d = 1.0\nd = []\nfor t in range(T+1):\n    d.append(current_d)\n    current_d = current_d * 1.05 \n\nfig, ax = plt.subplots()\nax.plot(d, 'o', label='dividends')\nax.legend()\nax.set_xlabel('time')\nplt.show()\n\nNow let’s compute and plot the asset price.\n\nWe set \\delta and p_{T+1}^* to\n\nδ = 0.99\np_star = 10.0\n\nLet’s build the matrix A\n\nA = np.zeros((T+1, T+1))\nfor i in range(T+1):\n    for j in range(T+1):\n        if i == j:\n            A[i, j] = 1\n            if j < T:\n                A[i, j+1] = -δ\n\nLet’s inspect A\n\nA\n\nNow let’s solve for prices using \n\n(6).\n\nb = np.zeros(T+1)\nb[-1] = δ * p_star\np = np.linalg.solve(A, d + b)\nfig, ax = plt.subplots()\nax.plot(p, 'o', label='asset price')\nax.legend()\nax.set_xlabel('time')\nplt.show()\n\nNow let’s consider  a cyclically growing dividend sequence:d_{t+1} = 1.01 d_t + 0.1 \\sin t, \\quad t = 0, 1, \\ldots , T-1.\n\nT = 100\ncurrent_d = 1.0\nd = []\nfor t in range(T+1):\n    d.append(current_d)\n    current_d = current_d * 1.01 + 0.1 * np.sin(t)\n\nfig, ax = plt.subplots()\nax.plot(d, 'o-', ms=4, alpha=0.8, label='dividends')\nax.legend()\nax.set_xlabel('time')\nplt.show()\n\nCompute the corresponding asset price sequence when p^*_{T+1} = 0 and \\delta\n= 0.98.\n\nSolution to \n\nExercise 2\n\nWe proceed as above after modifying parameters and consequently the matrix A.\n\nδ = 0.98\np_star = 0.0\nA = np.zeros((T+1, T+1))\nfor i in range(T+1):\n    for j in range(T+1):\n        if i == j:\n            A[i, j] = 1\n            if j < T:\n                A[i, j+1] = -δ\n\nb = np.zeros(T+1)\nb[-1] = δ * p_star\np = np.linalg.solve(A, d + b)\nfig, ax = plt.subplots()\nax.plot(p, 'o-', ms=4, alpha=0.8, label='asset price')\nax.legend()\nax.set_xlabel('time')\nplt.show()\n\nThe weighted averaging associated with the present value calculation largely\neliminates the cycles.","type":"content","url":"/pv#representing-sequences-as-vectors","position":7},{"hierarchy":{"lvl1":"Present Values","lvl2":"Analytical expressions"},"type":"lvl2","url":"/pv#analytical-expressions","position":8},{"hierarchy":{"lvl1":"Present Values","lvl2":"Analytical expressions"},"content":"By the \n\ninverse matrix theorem, a matrix B is the inverse of A whenever A B is the identity.\n\nIt can be verified that the  inverse of the matrix A in \n\n(3) isA^{-1} = \n    \\begin{bmatrix}\n        1 & \\delta & \\delta^2 & \\cdots & \\delta^{T-1} & \\delta^T \\cr\n        0 & 1 & \\delta & \\cdots & \\delta^{T-2} & \\delta^{T-1} \\cr\n        \\vdots & \\vdots & \\vdots & \\cdots & \\vdots & \\vdots \\cr\n        0 & 0 & 0 & \\cdots & 1  & \\delta \\cr\n        0 & 0 & 0 & \\cdots & 0 & 1 \\cr\n    \\end{bmatrix}\n\nCheck this by showing that A A^{-1} is equal to the identity matrix.\n\nIf we use the expression \n\n(9) in \n\n(6) and perform the indicated matrix multiplication, we shall find  thatp_t =  \\sum_{s=t}^T \\delta^{s-t} d_s +  \\delta^{T+1-t} p_{T+1}^*\n\nPricing formula \n\n(10) asserts that  two components sum to the asset price\np_t:\n\na fundamental component \\sum_{s=t}^T \\delta^{s-t} d_s that equals the discounted present value of prospective dividends\n\na bubble component \\delta^{T+1-t} p_{T+1}^*\n\nThe fundamental component is pinned down by the discount factor \\delta and the\npayout of the asset (in this case,  dividends).\n\nThe bubble component is the part of the price that is not pinned down by\nfundamentals.\n\nIt is sometimes convenient to rewrite the bubble component asc \\delta^{-t}\n\nwherec \\equiv \\delta^{T+1}p_{T+1}^*\n\n","type":"content","url":"/pv#analytical-expressions","position":9},{"hierarchy":{"lvl1":"Present Values","lvl2":"More about bubbles"},"type":"lvl2","url":"/pv#more-about-bubbles","position":10},{"hierarchy":{"lvl1":"Present Values","lvl2":"More about bubbles"},"content":"For a few moments, let’s focus on  the special case of an asset that   never pays dividends, in which case\\begin{bmatrix}  \nd_0 \\cr d_1 \\cr d_2 \\cr \\vdots \\cr d_{T-1} \\cr d_T\n\\end{bmatrix} = \n\\begin{bmatrix}  \n0 \\cr 0 \\cr 0 \\cr \\vdots \\cr 0 \\cr 0\n\\end{bmatrix}\n\nIn this case  system \n\n(1) of our T+1 asset pricing  equations takes the\nform of the single matrix equation\\begin{bmatrix} 1 & -\\delta & 0 & 0 & \\cdots & 0 & 0 \\cr\n                0 & 1 & -\\delta & 0 & \\cdots & 0 & 0 \\cr\n                0 & 0 & 1 & -\\delta & \\cdots & 0 & 0 \\cr\n                \\vdots & \\vdots & \\vdots & \\vdots & \\vdots & 0 & 0 \\cr\n                0 & 0 & 0 & 0 & \\cdots & 1 & -\\delta \\cr\n                0 & 0 & 0 & 0 & \\cdots & 0 & 1 \\end{bmatrix}\n\\begin{bmatrix} p_0 \\cr p_1 \\cr p_2 \\cr \\vdots \\cr p_{T-1} \\cr p_T \n\\end{bmatrix}  =\n\\begin{bmatrix} \n0 \\cr 0 \\cr 0 \\cr \\vdots \\cr 0 \\cr \\delta p_{T+1}^*\n\\end{bmatrix}\n\nEvidently, if p_{T+1}^* = 0, a price vector p of all entries zero\nsolves this equation and the only the fundamental component of our pricing\nformula \n\n(10) is present.\n\nBut let’s activate the bubble  component by settingp_{T+1}^* = c \\delta^{-(T+1)}\n\nfor some positive constant c.\n\nIn this case,  when we multiply both sides of \n\n(14) by\nthe matrix A^{-1} presented in equation \n\n(9), we\nfind thatp_t = c \\delta^{-t}","type":"content","url":"/pv#more-about-bubbles","position":11},{"hierarchy":{"lvl1":"Present Values","lvl2":"Gross rate of return"},"type":"lvl2","url":"/pv#gross-rate-of-return","position":12},{"hierarchy":{"lvl1":"Present Values","lvl2":"Gross rate of return"},"content":"Define the gross rate of return on holding the asset from period t to period t+1\nasR_t = \\frac{p_{t+1}}{p_t}\n\nSubstituting equation \n\n(16) into equation \n\n(17) confirms that an asset whose  sole source of value is a bubble  earns a  gross rate of returnR_t = \\delta^{-1} > 1 , t = 0, 1, \\ldots, T","type":"content","url":"/pv#gross-rate-of-return","position":13},{"hierarchy":{"lvl1":"Present Values","lvl2":"Exercises"},"type":"lvl2","url":"/pv#exercises","position":14},{"hierarchy":{"lvl1":"Present Values","lvl2":"Exercises"},"content":"Assume that g >1 and that \\delta g \\in (0,1). Give analytical expressions for an asset price p_t under the\nfollowing settings for d and p_{T+1}^*:\n\np_{T+1}^* = 0, d_t = g^t d_0 (a modified version of the Gordon growth formula)\n\np_{T+1}^* = \\frac{g^{T+1} d_0}{1- \\delta g},  d_t = g^t d_0 (the plain vanilla  Gordon growth formula)\n\np_{T+1}^* = 0, d_t = 0 (price of a worthless stock)\n\np_{T+1}^* = c \\delta^{-(T+1)}, d_t = 0 (price of a pure bubble stock)\n\nSolution to \n\nExercise 4\n\nPlugging each of the above p_{T+1}^*, d_t  pairs into Equation \n\n(10) yields:\n\n   p_t = \\sum^T_{s=t} \\delta^{s-t} g^s d_0     = d_t \\frac{1 - (\\delta g)^{T+1-t}}{1 - \\delta g}\n\np_t = \\sum^T_{s=t} \\delta^{s-t} g^s d_0 + \\frac{\\delta^{T+1-t} g^{T+1} d_0}{1 - \\delta g} =  \\frac{d_t}{1 - \\delta g}\n\np_t = 0\n\np_t = c \\delta^{-t}","type":"content","url":"/pv#exercises","position":15},{"hierarchy":{"lvl1":"Dynamics in One Dimension"},"type":"lvl1","url":"/scalar-dynam","position":0},{"hierarchy":{"lvl1":"Dynamics in One Dimension"},"content":"","type":"content","url":"/scalar-dynam","position":1},{"hierarchy":{"lvl1":"Dynamics in One Dimension","lvl2":"Overview"},"type":"lvl2","url":"/scalar-dynam#overview","position":2},{"hierarchy":{"lvl1":"Dynamics in One Dimension","lvl2":"Overview"},"content":"In economics many variables depend on their past values\n\nFor example, it seems reasonable to believe that inflation last year with affects inflation this year.\n\n(Perhaps high inflation last year will lead people to demand higher wages to\ncompensate, which will feed into higher prices this year.)\n\nLetting \\pi_t be inflation this year and \\pi_{t-1} be inflation last year, we\ncan write this relationship in a general form as\\pi_t = f(\\pi_{t-1})\n\nwhere f is some function describing the relationship between the variables.\n\nThis equation is an example of one-dimensional discrete time dynamic system.\n\nIn this lecture we cover the foundations of one-dimensional discrete time\ndynamics.\n\n(While most quantitative models have two or more state variables, the\none-dimensional setting is a good place to learn foundations\nand understand key concepts.)\n\nLet’s start with some standard imports:\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n","type":"content","url":"/scalar-dynam#overview","position":3},{"hierarchy":{"lvl1":"Dynamics in One Dimension","lvl2":"Some definitions"},"type":"lvl2","url":"/scalar-dynam#some-definitions","position":4},{"hierarchy":{"lvl1":"Dynamics in One Dimension","lvl2":"Some definitions"},"content":"This section sets out the objects of interest and the kinds of properties we study.","type":"content","url":"/scalar-dynam#some-definitions","position":5},{"hierarchy":{"lvl1":"Dynamics in One Dimension","lvl3":"Composition of functions","lvl2":"Some definitions"},"type":"lvl3","url":"/scalar-dynam#composition-of-functions","position":6},{"hierarchy":{"lvl1":"Dynamics in One Dimension","lvl3":"Composition of functions","lvl2":"Some definitions"},"content":"For this lecture you should know the following.\n\nIf\n\ng is a function from A to B and\n\nf is a function from B to C,\n\nthen the composition f \\circ g of f and g is defined by(f \\circ g)(x) = f(g(x))\n\nFor example, if\n\nA=B=C=\\mathbb R, the set of real numbers,\n\ng(x)=x^2 and f(x)=\\sqrt{x}, then (f \\circ g)(x) = \\sqrt{x^2} = |x|.\n\nIf f is a function from A to itself, then f^2 is the composition of f\nwith itself.\n\nFor example, if A = (0, \\infty), the set of positive numbers, and f(x) =\n\\sqrt{x}, thenf^2(x) = \\sqrt{\\sqrt{x}} = x^{1/4}\n\nSimilarly, if n is a positive integer, then f^n is n compositions of f with\nitself.\n\nIn the example above, f^n(x) = x^{1/(2^n)}.","type":"content","url":"/scalar-dynam#composition-of-functions","position":7},{"hierarchy":{"lvl1":"Dynamics in One Dimension","lvl3":"Dynamic systems","lvl2":"Some definitions"},"type":"lvl3","url":"/scalar-dynam#dynamic-systems","position":8},{"hierarchy":{"lvl1":"Dynamics in One Dimension","lvl3":"Dynamic systems","lvl2":"Some definitions"},"content":"A (discrete time) dynamic system is a set S and a function g that sends\nset S back into to itself.\n\nExamples of dynamic systems include\n\nS = (0, 1) and g(x) = \\sqrt{x}\n\nS = (0, 1) and g(x) = x^2\n\nS = \\mathbb Z (the integers) and g(x) = 2 x\n\nOn the other hand, if  S = (-1, 1) and g(x) = x+1, then S and g do not\nform a dynamic system, since g(1) = 2.\n\ng does not always send points in S back into S.\n\nWe care about dynamic systems because we can use them to study dynamics!\n\nGiven a dynamic system consisting of set S and function g, we can create\na sequence \\{x_t\\} of points in S by setting    x_{t+1} = g(x_t)\n    \\quad \\text{ with } \n    x_0 \\text{ given}.\n\nThis means that we choose some number x_0 in S and then take    x_0, \\quad\n    x_1 = g(x_0), \\quad\n    x_2 = g(x_1) = g(g(x_0)), \\quad \\text{etc.}\n\nThis sequence \\{x_t\\} is called the trajectory of x_0 under g.\n\nIn this setting, S is called the state space and x_t is called the\nstate variable.\n\nRecalling that g^n is the n compositions of g with itself,\nwe can write the trajectory more simply asx_t = g^t(x_0) \\quad \\text{ for } t = 0, 1, 2, \\ldots\n\nIn all of what follows, we are going to assume that S is a subset of\n\\mathbb R, the real numbers.\n\nEquation \n\n(4) is sometimes called a first order difference equation\n\nfirst order means dependence on only one lag (i.e., earlier states such as x_{t-1} do not enter into \n\n(4)).","type":"content","url":"/scalar-dynam#dynamic-systems","position":9},{"hierarchy":{"lvl1":"Dynamics in One Dimension","lvl3":"Example: a linear model","lvl2":"Some definitions"},"type":"lvl3","url":"/scalar-dynam#example-a-linear-model","position":10},{"hierarchy":{"lvl1":"Dynamics in One Dimension","lvl3":"Example: a linear model","lvl2":"Some definitions"},"content":"One simple example of a dynamic system is when S=\\mathbb R and g(x)=ax +\nb, where a, b are constants (sometimes called ``parameters’').\n\nThis leads to the linear difference equationx_{t+1} = a x_t + b \n    \\quad \\text{ with } \n    x_0 \\text{ given}.\n\nThe trajectory of x_0 isx_0, \\quad\na x_0 + b, \\quad\na^2 x_0 + a b + b, \\quad \\text{etc.}\n\nContinuing in this way, and using our knowledge of {doc}geometric series <geom_series>, we find that, for any t = 0, 1, 2, \\ldots,    x_t = a^t x_0 + b \\frac{1 - a^t}{1 - a}\n\nWe have an exact expression for x_t for all non-negative integer t and hence a full\nunderstanding of the dynamics.\n\nNotice in particular that |a| < 1, then, by \n\n(9), we havex_t \\to  \\frac{b}{1 - a} \\text{ as } t \\to \\infty\n\nregardless of x_0.\n\nThis is an example of what is called global stability, a topic we return to\nbelow.","type":"content","url":"/scalar-dynam#example-a-linear-model","position":11},{"hierarchy":{"lvl1":"Dynamics in One Dimension","lvl3":"Example: a nonlinear model","lvl2":"Some definitions"},"type":"lvl3","url":"/scalar-dynam#example-a-nonlinear-model","position":12},{"hierarchy":{"lvl1":"Dynamics in One Dimension","lvl3":"Example: a nonlinear model","lvl2":"Some definitions"},"content":"In the linear example above, we obtained an exact analytical expression for\nx_t in terms of arbitrary non-negative integer t and x_0.\n\nThis made analysis of dynamics very easy.\n\nWhen models are nonlinear, however, the situation can be quite different.\n\nFor example, in a later lecture \n\nThe Solow-Swan Growth Model, we will study the Solow-Swan growth model, which has dynamicsk_{t+1} = s A k_t^{\\alpha} + (1 - \\delta) k_t\n\nHere k=K/L is the per capita capital stock, s is the saving rate, A is the total factor productivity, \\alpha is the capital share, and \\delta is the depreciation rate.\n\nAll these parameter are positive and 0 < \\alpha, \\delta < 1.\n\nIf you try to iterate like we did in \n\n(8), you will find that\nthe algebra gets messy quickly.\n\nAnalyzing the dynamics of this model requires a different method (see below).","type":"content","url":"/scalar-dynam#example-a-nonlinear-model","position":13},{"hierarchy":{"lvl1":"Dynamics in One Dimension","lvl2":"Stability"},"type":"lvl2","url":"/scalar-dynam#stability","position":14},{"hierarchy":{"lvl1":"Dynamics in One Dimension","lvl2":"Stability"},"content":"Consider a dynamic system consisting of set S \\subset \\mathbb R and\ng mapping S to S.","type":"content","url":"/scalar-dynam#stability","position":15},{"hierarchy":{"lvl1":"Dynamics in One Dimension","lvl3":"Steady states","lvl2":"Stability"},"type":"lvl3","url":"/scalar-dynam#scalar-dynam-steady-state","position":16},{"hierarchy":{"lvl1":"Dynamics in One Dimension","lvl3":"Steady states","lvl2":"Stability"},"content":"A steady state of this system is a\npoint x^* in S such that x^* = g(x^*).\n\nIn other words, x^* is a fixed point of the function g in\nS.\n\nFor example, for the linear model x_{t+1} = a x_t + b, you can use the\ndefinition to check that\n\nx^* := b/(1-a) is a steady state whenever a \\not= 1,\n\nif a = 1 and b=0, then every x \\in \\mathbb R is a\nsteady state,\n\nif a = 1 and b \\not= 0, then the linear model has no steady\nstate in \\mathbb R.","type":"content","url":"/scalar-dynam#scalar-dynam-steady-state","position":17},{"hierarchy":{"lvl1":"Dynamics in One Dimension","lvl3":"Global stability","lvl2":"Stability"},"type":"lvl3","url":"/scalar-dynam#scalar-dynam-global-stability","position":18},{"hierarchy":{"lvl1":"Dynamics in One Dimension","lvl3":"Global stability","lvl2":"Stability"},"content":"A steady state x^* of the dynamic system is called\nglobally stable if, for all x_0 \\in S,x_t = g^t(x_0) \\to x^* \\text{ as } t \\to \\infty\n\nFor example, in the linear model x_{t+1} = a x_t + b with a\n\\not= 1, the steady state x^*\n\nis globally stable if |a| < 1 and\n\nfails to be globally stable otherwise.\n\nThis follows directly from \n\n(9).","type":"content","url":"/scalar-dynam#scalar-dynam-global-stability","position":19},{"hierarchy":{"lvl1":"Dynamics in One Dimension","lvl3":"Local stability","lvl2":"Stability"},"type":"lvl3","url":"/scalar-dynam#local-stability","position":20},{"hierarchy":{"lvl1":"Dynamics in One Dimension","lvl3":"Local stability","lvl2":"Stability"},"content":"A steady state x^* of the dynamic system is called\nlocally stable if there exists an \\epsilon > 0 such that| x_0 - x^* | < \\epsilon\n\\; \\implies \\;\nx_t = g^t(x_0) \\to x^* \\text{ as } t \\to \\infty\n\nObviously every globally stable steady state is also locally stable.\n\nHere is an example where the converse is not true.\n\nConsider the self-map g on \\mathbb{R} defined by g(x)=x^2. The fixed point 1 is not stable.\n\nFor example, g^t (x)\\to\\infty for any x>1.\n\nHowever, 0 is locally stable, because -1<x<1 implies that g^t (x)\\to 0 as t\\to\\infty.\n\nSince we have more than one fixed point, 0 is not globally stable.","type":"content","url":"/scalar-dynam#local-stability","position":21},{"hierarchy":{"lvl1":"Dynamics in One Dimension","lvl2":"Graphical analysis"},"type":"lvl2","url":"/scalar-dynam#graphical-analysis","position":22},{"hierarchy":{"lvl1":"Dynamics in One Dimension","lvl2":"Graphical analysis"},"content":"As we saw above, analyzing the dynamics for nonlinear models is nontrivial.\n\nThere is no single way to tackle all nonlinear models.\n\nHowever, there is one technique for one-dimensional models that provides a\ngreat deal of intuition.\n\nThis is a graphical approach based on 45-degree diagrams.\n\nLet’s look at an example: the Solow-Swan model with dynamics given in \n\n(11).\n\nWe begin with some plotting code that you can ignore at first reading.\n\nThe function of the code is to produce 45-degree diagrams and time series\nplots.\n\ndef subplots():\n    \"Custom subplots with axes throught the origin\"\n    fig, ax = plt.subplots()\n\n    # Set the axes through the origin\n    for spine in ['left', 'bottom']:\n        ax.spines[spine].set_position('zero')\n        ax.spines[spine].set_color('green')\n    for spine in ['right', 'top']:\n        ax.spines[spine].set_color('none')\n\n    return fig, ax\n\n\ndef plot45(g, xmin, xmax, x0, num_arrows=6, var='x'):\n\n    xgrid = np.linspace(xmin, xmax, 200)\n\n    fig, ax = subplots()\n    ax.set_xlim(xmin, xmax)\n    ax.set_ylim(xmin, xmax)\n    ax.set_xlabel(r'${}_t$'.format(var), fontsize=14)\n    ax.set_ylabel(r'${}_{}$'.format(var, str('{t+1}')), fontsize=14)\n\n    hw = (xmax - xmin) * 0.01\n    hl = 2 * hw\n    arrow_args = dict(fc=\"k\", ec=\"k\", head_width=hw,\n            length_includes_head=True, lw=1,\n            alpha=0.6, head_length=hl)\n\n    ax.plot(xgrid, g(xgrid), 'b-', lw=2, alpha=0.6, label='g')\n    ax.plot(xgrid, xgrid, 'k-', lw=1, alpha=0.7, label='45')\n\n    x = x0\n    xticks = [xmin]\n    xtick_labels = [xmin]\n\n    for i in range(num_arrows):\n        if i == 0:\n            ax.arrow(x, 0.0, 0.0, g(x), **arrow_args) # x, y, dx, dy\n        else:\n            ax.arrow(x, x, 0.0, g(x) - x, **arrow_args)\n            ax.plot((x, x), (0, x), 'k', ls='dotted')\n\n        ax.arrow(x, g(x), g(x) - x, 0, **arrow_args)\n        xticks.append(x)\n        xtick_labels.append(r'${}_{}$'.format(var, str(i)))\n\n        x = g(x)\n        xticks.append(x)\n        xtick_labels.append(r'${}_{}$'.format(var, str(i+1)))\n        ax.plot((x, x), (0, x), 'k', ls='dotted')\n\n    xticks.append(xmax)\n    xtick_labels.append(xmax)\n    ax.set_xticks(xticks)\n    ax.set_yticks(xticks)\n    ax.set_xticklabels(xtick_labels)\n    ax.set_yticklabels(xtick_labels)\n\n    bbox = (0., 1.04, 1., .104)\n    legend_args = {'bbox_to_anchor': bbox, 'loc': 'upper right'}\n\n    ax.legend(ncol=2, frameon=False, **legend_args, fontsize=14)\n    plt.show()\n\ndef ts_plot(g, xmin, xmax, x0, ts_length=6, var='x'):\n    fig, ax = subplots()\n    ax.set_ylim(xmin, xmax)\n    ax.set_xlabel(r'$t$', fontsize=14)\n    ax.set_ylabel(r'${}_t$'.format(var), fontsize=14)\n    x = np.empty(ts_length)\n    x[0] = x0\n    for t in range(ts_length-1):\n        x[t+1] = g(x[t])\n    ax.plot(range(ts_length),\n            x,\n            'bo-',\n            alpha=0.6,\n            lw=2,\n            label=r'${}_t$'.format(var))\n    ax.legend(loc='best', fontsize=14)\n    ax.set_xticks(range(ts_length))\n    plt.show()\n\nLet’s create a 45-degree diagram for the Solow-Swan model with a fixed set of\nparameters. Here’s the update function corresponding to the model.\n\ndef g(k, A = 2, s = 0.3, alpha = 0.3, delta = 0.4):\n    return A * s * k**alpha + (1 - delta) * k\n\nHere is the 45-degree plot.\n\nxmin, xmax = 0, 4  # Suitable plotting region.\n\nplot45(g, xmin, xmax, 0, num_arrows=0)\n\nThe plot shows the function g and the 45-degree line.\n\nThink of k_t as a value on the horizontal axis.\n\nTo calculate k_{t+1}, we can use the graph of g to see its\nvalue on the vertical axis.\n\nClearly,\n\nIf g lies above the 45-degree line at this point, then we have k_{t+1} > k_t.\n\nIf g lies below the 45-degree line at this point, then we have k_{t+1} < k_t.\n\nIf g hits the 45-degree line at this point, then we have k_{t+1} = k_t, so k_t is a steady state.\n\nFor the Solow-Swan model, there are two steady states when S = \\mathbb R_+ =\n[0, \\infty).\n\nthe origin k=0\n\nthe unique positive number such that k = s z k^{\\alpha} + (1 - \\delta) k.\n\nBy using some algebra, we can show that in the second case, the steady state isk^* = \\left( \\frac{sz}{\\delta} \\right)^{1/(1-\\alpha)}","type":"content","url":"/scalar-dynam#graphical-analysis","position":23},{"hierarchy":{"lvl1":"Dynamics in One Dimension","lvl3":"Trajectories","lvl2":"Graphical analysis"},"type":"lvl3","url":"/scalar-dynam#trajectories","position":24},{"hierarchy":{"lvl1":"Dynamics in One Dimension","lvl3":"Trajectories","lvl2":"Graphical analysis"},"content":"By the preceding discussion, in regions where g lies above the 45-degree line, we know that the trajectory is increasing.\n\nThe next figure traces out a trajectory in such a region so we can see this more clearly.\n\nThe initial condition is k_0 = 0.25.\n\nk0 = 0.25\n\nplot45(g, xmin, xmax, k0, num_arrows=5, var='k')\n\nWe can plot the time series of per capita capital corresponding to the figure above as\nfollows:\n\nts_plot(g, xmin, xmax, k0, var='k')\n\nHere’s a somewhat longer view:\n\nts_plot(g, xmin, xmax, k0, ts_length=20, var='k')\n\nWhen per capita capital stock is higher than the unique positive steady state, we see that\nit declines:\n\nk0 = 2.95\n\nplot45(g, xmin, xmax, k0, num_arrows=5, var='k')\n\nHere is the time series:\n\nts_plot(g, xmin, xmax, k0, var='k')\n\n","type":"content","url":"/scalar-dynam#trajectories","position":25},{"hierarchy":{"lvl1":"Dynamics in One Dimension","lvl3":"Complex dynamics","lvl2":"Graphical analysis"},"type":"lvl3","url":"/scalar-dynam#complex-dynamics","position":26},{"hierarchy":{"lvl1":"Dynamics in One Dimension","lvl3":"Complex dynamics","lvl2":"Graphical analysis"},"content":"The Solow-Swan model is nonlinear but still generates very regular dynamics.\n\nOne model that generates irregular dynamics is the quadratic mapg(x) = 4 x (1 - x),\n\\qquad x \\in [0, 1]\n\nLet’s have a look at the 45-degree diagram.\n\nxmin, xmax = 0, 1\ng = lambda x: 4 * x * (1 - x)\n\nx0 = 0.3\nplot45(g, xmin, xmax, x0, num_arrows=0)\n\nNow let’s look at a typical trajectory.\n\nplot45(g, xmin, xmax, x0, num_arrows=6)\n\nNotice how irregular it is.\n\nHere is the corresponding time series plot.\n\nts_plot(g, xmin, xmax, x0, ts_length=6)\n\nThe irregularity is even clearer over a longer time horizon:\n\nts_plot(g, xmin, xmax, x0, ts_length=20)\n\n","type":"content","url":"/scalar-dynam#complex-dynamics","position":27},{"hierarchy":{"lvl1":"Dynamics in One Dimension","lvl2":"Exercises"},"type":"lvl2","url":"/scalar-dynam#exercises","position":28},{"hierarchy":{"lvl1":"Dynamics in One Dimension","lvl2":"Exercises"},"content":"Consider again the linear model x_{t+1} = a x_t + b with a\n\\not=1.\n\nThe unique steady state is b / (1 - a).\n\nThe steady state is globally stable if |a| < 1.\n\nTry to illustrate this graphically by looking at a range of initial conditions.\n\nWhat differences do you notice in the cases a \\in (-1, 0) and a\n\\in (0, 1)?\n\nUse a=0.5 and then a=-0.5 and study the trajectories.\n\nSet b=1 throughout.\n\nSolution to \n\nExercise 1\n\nWe will start with the case a=0.5.\n\nLet’s set up the model and plotting region:\n\na, b = 0.5, 1\nxmin, xmax = -1, 3\ng = lambda x: a * x + b\n\nNow let’s plot a trajectory:\n\nx0 = -0.5\nplot45(g, xmin, xmax, x0, num_arrows=5)\n\nHere is the corresponding time series, which converges towards the steady\nstate.\n\nts_plot(g, xmin, xmax, x0, ts_length=10)\n\nNow let’s try a=-0.5 and see what differences we observe.\n\nLet’s set up the model and plotting region:\n\na, b = -0.5, 1\nxmin, xmax = -1, 3\ng = lambda x: a * x + b\n\nNow let’s plot a trajectory:\n\nx0 = -0.5\nplot45(g, xmin, xmax, x0, num_arrows=5)\n\nHere is the corresponding time series, which converges towards the steady\nstate.\n\nts_plot(g, xmin, xmax, x0, ts_length=10)\n\nOnce again, we have convergence to the steady state but the nature of\nconvergence differs.\n\nIn particular, the time series jumps from above the steady state to below it\nand back again.\n\nIn the current context, the series is said to exhibit damped oscillations.","type":"content","url":"/scalar-dynam#exercises","position":29},{"hierarchy":{"lvl1":"Racial Segregation"},"type":"lvl1","url":"/schelling","position":0},{"hierarchy":{"lvl1":"Racial Segregation"},"content":"","type":"content","url":"/schelling","position":1},{"hierarchy":{"lvl1":"Racial Segregation","lvl2":"Outline"},"type":"lvl2","url":"/schelling#outline","position":2},{"hierarchy":{"lvl1":"Racial Segregation","lvl2":"Outline"},"content":"In 1969, Thomas C. Schelling developed a simple but striking model of racial\nsegregation \n\nSchelling (1969).\n\nHis model studies the dynamics of racially mixed neighborhoods.\n\nLike much of Schelling’s work, the model shows how local interactions can lead\nto surprising aggregate outcomes.\n\nIt studies a setting where agents (think of households) have relatively mild\npreference for neighbors of the same race.\n\nFor example, these agents might be comfortable with a mixed race neighborhood\nbut uncomfortable when they feel “surrounded” by people from a different race.\n\nSchelling illustrated the follow surprising result: in such a setting, mixed\nrace neighborhoods are likely to be unstable, tending to collapse over time.\n\nIn fact the model predicts strongly divided neighborhoods, with high levels of\nsegregation.\n\nIn other words, extreme segregation outcomes arise even though people’s\npreferences are not particularly extreme.\n\nThese extreme outcomes happen because of interactions between agents in the\nmodel (e.g., households in a city) that drive self-reinforcing dynamics in the\nmodel.\n\nThese ideas will become clearer as the lecture unfolds.\n\nIn recognition of his work on segregation and other research, Schelling was\nawarded the 2005 Nobel Prize in Economic Sciences (joint with Robert Aumann).\n\nLet’s start with some imports:\n\nimport matplotlib.pyplot as plt\nfrom random import uniform, seed\nfrom math import sqrt\nimport numpy as np\n\n","type":"content","url":"/schelling#outline","position":3},{"hierarchy":{"lvl1":"Racial Segregation","lvl2":"The model"},"type":"lvl2","url":"/schelling#the-model","position":4},{"hierarchy":{"lvl1":"Racial Segregation","lvl2":"The model"},"content":"In this section we will build a version of Schelling’s model.","type":"content","url":"/schelling#the-model","position":5},{"hierarchy":{"lvl1":"Racial Segregation","lvl3":"Set-Up","lvl2":"The model"},"type":"lvl3","url":"/schelling#set-up","position":6},{"hierarchy":{"lvl1":"Racial Segregation","lvl3":"Set-Up","lvl2":"The model"},"content":"We will cover a variation of Schelling’s model that is different from the\noriginal but also easy to program and, at the same time, captures his main\nidea.\n\nSuppose we have two types of people: orange people and green people.\n\nAssume there are n of each type.\n\nThese agents all live on a single unit square.\n\nThus, the location (e.g, address) of an agent is just a point (x, y),  where\n0 < x, y < 1.\n\nThe set of all points (x,y) satisfying 0 < x, y < 1 is called the unit square\n\nBelow we denote the unit square by S\n\n","type":"content","url":"/schelling#set-up","position":7},{"hierarchy":{"lvl1":"Racial Segregation","lvl3":"Preferences","lvl2":"The model"},"type":"lvl3","url":"/schelling#preferences","position":8},{"hierarchy":{"lvl1":"Racial Segregation","lvl3":"Preferences","lvl2":"The model"},"content":"We will say that an agent is happy if 5 or more of her 10 nearest neighbors are of the same type.\n\nAn agent who is not happy is called unhappy.\n\nFor example,\n\nif an agent is orange and 5 of her 10 nearest neighbors are orange, then she is happy.\n\nif an agent is green and 8 of her 10 nearest neighbors are orange, then she is unhappy.\n\n‘Nearest’ is in terms of \n\nEuclidean distance.\n\nAn important point to note is that agents are not averse to living in mixed areas.\n\nThey are perfectly happy if half of their neighbors are of the other color.\n\n","type":"content","url":"/schelling#preferences","position":9},{"hierarchy":{"lvl1":"Racial Segregation","lvl3":"Behavior","lvl2":"The model"},"type":"lvl3","url":"/schelling#behavior","position":10},{"hierarchy":{"lvl1":"Racial Segregation","lvl3":"Behavior","lvl2":"The model"},"content":"Initially, agents are mixed together (integrated).\n\nIn particular, we assume that the initial location of each agent is an\nindependent draw from a bivariate uniform distribution on the unit square S.\n\nFirst their x coordinate is drawn from a uniform distribution on (0,1)\n\nThen, independently, their y coordinate is drawn from the same distribution.\n\nNow, cycling through the set of all agents, each agent is now given the chance to stay or move.\n\nEach agent stays if they are happy and moves if they are unhappy.\n\nThe algorithm for moving is as follows\n\nJump Chain Algorithm\n\nDraw a random location in S\n\nIf happy at new location, move there\n\nOtherwise, go to step 1\n\nWe cycle continuously through the agents, each time allowing an unhappy agent\nto move.\n\nWe continue to cycle until no one wishes to move.\n\n","type":"content","url":"/schelling#behavior","position":11},{"hierarchy":{"lvl1":"Racial Segregation","lvl2":"Results"},"type":"lvl2","url":"/schelling#results","position":12},{"hierarchy":{"lvl1":"Racial Segregation","lvl2":"Results"},"content":"Let’s now implement and run this simulation.\n\nIn what follows, agents are modeled as \n\nobjects.\n\nHere’s an indication of their structure:* Data:\n\n    * type (green or orange)\n    * location\n\n* Methods:\n\n    * determine whether happy or not given locations of other agents\n    * If not happy, move\n        * find a new location where happy\n\nLet’s build them.\n\nclass Agent:\n\n    def __init__(self, type):\n        self.type = type\n        self.draw_location()\n\n    def draw_location(self):\n        self.location = uniform(0, 1), uniform(0, 1)\n\n    def get_distance(self, other):\n        \"Computes the euclidean distance between self and other agent.\"\n        a = (self.location[0] - other.location[0])**2\n        b = (self.location[1] - other.location[1])**2\n        return sqrt(a + b)\n\n    def happy(self,\n                agents,                # List of other agents\n                num_neighbors=10,      # No. of agents viewed as neighbors\n                require_same_type=5):  # How many neighbors must be same type\n        \"\"\"\n            True if a sufficient number of nearest neighbors are of the same\n            type.\n        \"\"\"\n\n        distances = []\n\n        # Distances is a list of pairs (d, agent), where d is distance from\n        # agent to self\n        for agent in agents:\n            if self != agent:\n                distance = self.get_distance(agent)\n                distances.append((distance, agent))\n\n        # Sort from smallest to largest, according to distance\n        distances.sort()\n\n        # Extract the neighboring agents\n        neighbors = [agent for d, agent in distances[:num_neighbors]]\n\n        # Count how many neighbors have the same type as self\n        num_same_type = sum(self.type == agent.type for agent in neighbors)\n        return num_same_type >= require_same_type\n\n    def update(self, agents):\n        \"If not happy, then randomly choose new locations until happy.\"\n        while not self.happy(agents):\n            self.draw_location()\n\nHere’s some code that takes a list of agents and produces a plot showing their\nlocations on the unit square.\n\nOrange agents are represented by orange dots and green ones are represented by\ngreen dots.\n\ndef plot_distribution(agents, cycle_num):\n    \"Plot the distribution of agents after cycle_num rounds of the loop.\"\n    x_values_0, y_values_0 = [], []\n    x_values_1, y_values_1 = [], []\n    # == Obtain locations of each type == #\n    for agent in agents:\n        x, y = agent.location\n        if agent.type == 0:\n            x_values_0.append(x)\n            y_values_0.append(y)\n        else:\n            x_values_1.append(x)\n            y_values_1.append(y)\n    fig, ax = plt.subplots()\n    plot_args = {'markersize': 8, 'alpha': 0.8}\n    ax.set_facecolor('azure')\n    ax.plot(x_values_0, y_values_0,\n        'o', markerfacecolor='orange', **plot_args)\n    ax.plot(x_values_1, y_values_1,\n        'o', markerfacecolor='green', **plot_args)\n    ax.set_title(f'Cycle {cycle_num-1}')\n    plt.show()\n\nAnd here’s some pseudocode for the main loop, where we cycle through the\nagents until no one wishes to move.\n\nThe pseudocode isplot the distribution\nwhile agents are still moving\n    for agent in agents\n        give agent the opportunity to move\nplot the distribution\n\nThe real code is below\n\ndef run_simulation(num_of_type_0=600,\n                   num_of_type_1=600,\n                   max_iter=100_000,       # Maximum number of iterations\n                   set_seed=1234):\n\n    # Set the seed for reproducibility\n    seed(set_seed)\n\n    # Create a list of agents of type 0\n    agents = [Agent(0) for i in range(num_of_type_0)]\n    # Append a list of agents of type 1\n    agents.extend(Agent(1) for i in range(num_of_type_1))\n\n    # Initialize a counter\n    count = 1\n\n    # Plot the initial distribution\n    plot_distribution(agents, count)\n\n    # Loop until no agent wishes to move\n    while count < max_iter:\n        print('Entering loop ', count)\n        count += 1\n        no_one_moved = True\n        for agent in agents:\n            old_location = agent.location\n            agent.update(agents)\n            if agent.location != old_location:\n                no_one_moved = False\n        if no_one_moved:\n            break\n\n    # Plot final distribution\n    plot_distribution(agents, count)\n\n    if count < max_iter:\n        print(f'Converged after {count} iterations.')\n    else:\n        print('Hit iteration bound and terminated.')\n\nLet’s have a look at the results.\n\nrun_simulation()\n\nAs discussed above, agents are initially mixed randomly together.\n\nBut after several cycles, they become segregated into distinct regions.\n\nIn this instance, the program terminated after a small number of cycles\nthrough the set of agents, indicating that all agents had reached a state of\nhappiness.\n\nWhat is striking about the pictures is how rapidly racial integration breaks down.\n\nThis is despite the fact that people in the model don’t actually mind living mixed with the other type.\n\nEven with these preferences, the outcome is a high degree of segregation.","type":"content","url":"/schelling#results","position":13},{"hierarchy":{"lvl1":"Racial Segregation","lvl2":"Exercises"},"type":"lvl2","url":"/schelling#exercises","position":14},{"hierarchy":{"lvl1":"Racial Segregation","lvl2":"Exercises"},"content":"The object oriented style that we used for coding above is neat but harder to\noptimize than procedural code (i.e., code based around functions rather than\nobjects and methods).\n\nTry writing a new version of the model that stores\n\nthe locations of all agents as a 2D NumPy array of floats.\n\nthe types of all agents as a flat NumPy array of integers.\n\nWrite functions that act on this data to update the model using the logic\nsimilar to that described above.\n\nHowever, implement the following two changes:\n\nAgents are offered a move at random (i.e., selected randomly and given the\nopportunity to move).\n\nAfter an agent has moved, flip their type with probability 0.01\n\nThe second change introduces extra randomness into the model.\n\n(We can imagine that, every so often, an agent moves to a different city and,\nwith small probability, is replaced by an agent of the other type.)\n\nSolution to \n\nExercise 1\n\nsolution here\n\nfrom numpy.random import uniform, randint\n\nn = 1000                # number of agents (agents = 0, ..., n-1)\nk = 10                  # number of agents regarded as neighbors\nrequire_same_type = 5   # want >= require_same_type neighbors of the same type\n\ndef initialize_state():\n    locations = uniform(size=(n, 2))\n    types = randint(0, high=2, size=n)   # label zero or one\n    return locations, types\n\n\ndef compute_distances_from_loc(loc, locations):\n    \"\"\" Compute distance from location loc to all other points. \"\"\"\n    return np.linalg.norm(loc - locations, axis=1)\n\ndef get_neighbors(loc, locations):\n    \" Get all neighbors of a given location. \"\n    all_distances = compute_distances_from_loc(loc, locations)\n    indices = np.argsort(all_distances)   # sort agents by distance to loc\n    neighbors = indices[:k]               # keep the k closest ones\n    return neighbors\n\ndef is_happy(i, locations, types):\n    happy = True\n    agent_loc = locations[i, :]\n    agent_type = types[i]\n    neighbors = get_neighbors(agent_loc, locations)\n    neighbor_types = types[neighbors]\n    if sum(neighbor_types == agent_type) < require_same_type:\n        happy = False\n    return happy\n\ndef count_happy(locations, types):\n    \" Count the number of happy agents. \"\n    happy_sum = 0\n    for i in range(n):\n        happy_sum += is_happy(i, locations, types)\n    return happy_sum\n\ndef update_agent(i, locations, types):\n    \" Move agent if unhappy. \"\n    moved = False\n    while not is_happy(i, locations, types):\n        moved = True\n        locations[i, :] = uniform(), uniform()\n    return moved\n\ndef plot_distribution(locations, types, title, savepdf=False):\n    \" Plot the distribution of agents after cycle_num rounds of the loop.\"\n    fig, ax = plt.subplots()\n    colors = 'orange', 'green'\n    for agent_type, color in zip((0, 1), colors):\n        idx = (types == agent_type)\n        ax.plot(locations[idx, 0],\n                locations[idx, 1],\n                'o',\n                markersize=8,\n                markerfacecolor=color,\n                alpha=0.8)\n    ax.set_title(title)\n    plt.show()\n\ndef sim_random_select(max_iter=100_000, flip_prob=0.01, test_freq=10_000):\n    \"\"\"\n    Simulate by randomly selecting one household at each update.\n\n    Flip the color of the household with probability `flip_prob`.\n\n    \"\"\"\n\n    locations, types = initialize_state()\n    current_iter = 0\n\n    while current_iter <= max_iter:\n\n        # Choose a random agent and update them\n        i = randint(0, n)\n        moved = update_agent(i, locations, types)\n\n        if flip_prob > 0:\n            # flip agent i's type with probability epsilon\n            U = uniform()\n            if U < flip_prob:\n                current_type = types[i]\n                types[i] = 0 if current_type == 1 else 1\n\n        # Every so many updates, plot and test for convergence\n        if current_iter % test_freq == 0:\n            cycle = current_iter / n\n            plot_distribution(locations, types, f'iteration {current_iter}')\n            if count_happy(locations, types) == n:\n                print(f\"Converged at iteration {current_iter}\")\n                break\n\n        current_iter += 1\n\n    if current_iter > max_iter:\n        print(f\"Terminating at iteration {current_iter}\")\n\n\n\nWhen we run this we again find that mixed neighborhoods break down and segregation emerges.\n\nHere’s a sample run.\n\nsim_random_select(max_iter=50_000, flip_prob=0.01, test_freq=10_000)\n\n\n\n","type":"content","url":"/schelling#exercises","position":15},{"hierarchy":{"lvl1":"Shortest Paths"},"type":"lvl1","url":"/short-path","position":0},{"hierarchy":{"lvl1":"Shortest Paths"},"content":"<div id=\"qe-notebook-header\" align=\"right\" style=\"text-align:right;\">\n        <a href=\"https://quantecon.org/\" title=\"quantecon.org\">\n                <img style=\"width:250px;display:inline;\" width=\"250px\" src=\"https://assets.quantecon.org/img/qe-menubar-logo.svg\" alt=\"QuantEcon\">\n        </a>\n</div><div id=\"qe-notebook-header\" align=\"right\" style=\"text-align:right;\">\n        <a href=\"https://quantecon.org/\" title=\"quantecon.org\">\n                <img style=\"width:250px;display:inline;\" width=\"250px\" src=\"https://assets.quantecon.org/img/qe-menubar-logo.svg\" alt=\"QuantEcon\">\n        </a>\n</div>","type":"content","url":"/short-path","position":1},{"hierarchy":{"lvl1":"Shortest Paths"},"type":"lvl1","url":"/short-path#shortest-paths","position":2},{"hierarchy":{"lvl1":"Shortest Paths"},"content":"","type":"content","url":"/short-path#shortest-paths","position":3},{"hierarchy":{"lvl1":"Shortest Paths","lvl2":"Overview"},"type":"lvl2","url":"/short-path#overview","position":4},{"hierarchy":{"lvl1":"Shortest Paths","lvl2":"Overview"},"content":"The shortest path problem is a \n\nclassic problem in mathematics and computer science with applications in\n\nEconomics (sequential decision making, analysis of social networks, etc.)\n\nOperations research and transportation\n\nRobotics and artificial intelligence\n\nTelecommunication network design and routing\n\netc., etc.\n\nVariations of the methods we discuss in this lecture are used millions of times every day, in applications such as\n\nGoogle Maps\n\nrouting packets on the internet\n\nFor us, the shortest path problem also provides a nice introduction to the logic of dynamic programming.\n\nDynamic programming is an extremely powerful optimization technique that we apply in many lectures on this site.\n\nThe only scientific library we’ll need in what follows is NumPy:\n\nimport numpy as np\n\n","type":"content","url":"/short-path#overview","position":5},{"hierarchy":{"lvl1":"Shortest Paths","lvl2":"Outline of the problem"},"type":"lvl2","url":"/short-path#outline-of-the-problem","position":6},{"hierarchy":{"lvl1":"Shortest Paths","lvl2":"Outline of the problem"},"content":"The shortest path problem is one of finding how to traverse a \n\ngraph from one specified node to another at minimum cost.\n\nConsider the following graph\n\n\n\nWe wish to travel from node (vertex) A to node G at minimum cost\n\nArrows (edges) indicate the movements we can take.\n\nNumbers on edges indicate the cost of traveling that edge.\n\n(Graphs such as the one above are called weighted \n\ndirected graphs.)\n\nPossible interpretations of the graph include\n\nMinimum cost for supplier to reach a destination.\n\nRouting of packets on the internet (minimize time).\n\netc., etc.\n\nFor this simple graph, a quick scan of the edges shows that the optimal paths are\n\nA, C, F, G at cost 8\n\n\n\nA, D, F, G at cost 8\n\n","type":"content","url":"/short-path#outline-of-the-problem","position":7},{"hierarchy":{"lvl1":"Shortest Paths","lvl2":"Finding least-cost paths"},"type":"lvl2","url":"/short-path#finding-least-cost-paths","position":8},{"hierarchy":{"lvl1":"Shortest Paths","lvl2":"Finding least-cost paths"},"content":"For large graphs, we need a systematic solution.\n\nLet J(v) denote the minimum cost-to-go from node v, understood as the total cost from v if we take the best route.\n\nSuppose that we know J(v) for each node v, as shown below for the graph from the preceding example.\n\n\n\nNote that J(G) = 0.\n\nThe best path can now be found as follows\n\nStart at node v = A\n\nFrom current node v, move to any node that solves\\min_{w \\in F_v} \\{ c(v, w) + J(w) \\}\n\nwhere\n\nF_v is the set of nodes that can be reached from v in one step.\n\nc(v, w) is the cost of traveling from v to w.\n\nHence, if we know the function J, then finding the best path is almost trivial.\n\nBut how can we find the cost-to-go function J?\n\nSome thought will convince you that, for every node v,\nthe function J satisfiesJ(v) = \\min_{w \\in F_v} \\{ c(v, w) + J(w) \\}\n\nThis is known as the Bellman equation, after the mathematician \n\nRichard Bellman.\n\nThe Bellman equation can be thought of as a restriction that J must\nsatisfy.\n\nWhat we want to do now is use this restriction to compute J.","type":"content","url":"/short-path#finding-least-cost-paths","position":9},{"hierarchy":{"lvl1":"Shortest Paths","lvl2":"Solving for minimum cost-to-go"},"type":"lvl2","url":"/short-path#solving-for-minimum-cost-to-go","position":10},{"hierarchy":{"lvl1":"Shortest Paths","lvl2":"Solving for minimum cost-to-go"},"content":"Let’s look at an algorithm for computing J and then think about how to\nimplement it.","type":"content","url":"/short-path#solving-for-minimum-cost-to-go","position":11},{"hierarchy":{"lvl1":"Shortest Paths","lvl3":"The algorithm","lvl2":"Solving for minimum cost-to-go"},"type":"lvl3","url":"/short-path#the-algorithm","position":12},{"hierarchy":{"lvl1":"Shortest Paths","lvl3":"The algorithm","lvl2":"Solving for minimum cost-to-go"},"content":"The standard algorithm for finding J is to start an initial guess and then iterate.\n\nThis is a standard approach to solving nonlinear equations, often called\nthe method of successive approximations.\n\nOur initial guess will beJ_0(v) = 0 \\text{ for all } v\n\nNow\n\nSet n = 0\n\nSet J_{n+1} (v) = \\min_{w \\in F_v} \\{ c(v, w) + J_n(w) \\} for all v\n\nIf J_{n+1} and J_n are not equal then increment n, go to 2\n\nThis sequence converges to J.\n\nAlthough we omit the proof, we’ll prove similar claims in our other lectures\non dynamic programming.","type":"content","url":"/short-path#the-algorithm","position":13},{"hierarchy":{"lvl1":"Shortest Paths","lvl3":"Implementation","lvl2":"Solving for minimum cost-to-go"},"type":"lvl3","url":"/short-path#implementation","position":14},{"hierarchy":{"lvl1":"Shortest Paths","lvl3":"Implementation","lvl2":"Solving for minimum cost-to-go"},"content":"Having an algorithm is a good start, but we also need to think about how to\nimplement it on a computer.\n\nFirst, for the cost function c, we’ll implement it as a matrix\nQ, where a typical element isQ(v, w)\n=\n\\begin{cases}\n   & c(v, w) \\text{ if } w \\in F_v \\\\\n   & +\\infty \\text{ otherwise }\n\\end{cases}\n\nIn this context Q is usually called the distance matrix.\n\nWe’re also numbering the nodes now, with A = 0, so, for exampleQ(1, 2)\n=\n\\text{ the cost of traveling from B to C }\n\nFor example, for the simple graph above, we set\n\nfrom numpy import inf\n\nQ = np.array([[inf, 1,   5,   3,   inf, inf, inf],\n              [inf, inf, inf, 9,   6,   inf, inf],\n              [inf, inf, inf, inf, inf, 2,   inf],\n              [inf, inf, inf, inf, inf, 4,   8],\n              [inf, inf, inf, inf, inf, inf, 4],\n              [inf, inf, inf, inf, inf, inf, 1],\n              [inf, inf, inf, inf, inf, inf, 0]])\n\nNotice that the cost of staying still (on the principle diagonal) is set to\n\nnp.inf for non-destination nodes --- moving on is required.\n\n0 for the destination node --- here is where we stop.\n\nFor the sequence of approximations \\{J_n\\} of the cost-to-go functions, we can use NumPy arrays.\n\nLet’s try with this example and see how we go:\n\nnodes = range(7)                              # Nodes = 0, 1, ..., 6\nJ = np.zeros_like(nodes, dtype=int)        # Initial guess\nnext_J = np.empty_like(nodes, dtype=int)   # Stores updated guess\n\nmax_iter = 500\ni = 0\n\nwhile i < max_iter:\n    for v in nodes:\n        # Minimize Q[v, w] + J[w] over all choices of w\n        next_J[v] = np.min(Q[v, :] + J)\n    \n    if np.array_equal(next_J, J):                \n        break\n    \n    J[:] = next_J                                # Copy contents of next_J to J\n    i += 1\n\nprint(\"The cost-to-go function is\", J)\n\nThis matches with the numbers we obtained by inspection above.\n\nBut, importantly, we now have a methodology for tackling large graphs.","type":"content","url":"/short-path#implementation","position":15},{"hierarchy":{"lvl1":"Shortest Paths","lvl2":"Exercises"},"type":"lvl2","url":"/short-path#exercises","position":16},{"hierarchy":{"lvl1":"Shortest Paths","lvl2":"Exercises"},"content":"The file data below describes a weighted directed graph.\n\nThe line node0, node1 0.04, node8 11.11, node14 72.21 means that from node0 we can go to\n\nnode1 at cost 0.04\n\nnode8 at cost 11.11\n\nnode14 at cost 72.21\n\nNo other nodes can be reached directly from node0.\n\nOther lines have a similar interpretation.\n\nYour task is to use the algorithm given above to find the optimal path and its cost.\n\nNote\n\nYou will be dealing with floating point numbers now, rather than\nintegers, so consider replacing np.equal() with np.allclose().\n\nimport requests\n\nfile_url = \"https://raw.githubusercontent.com/QuantEcon/lecture-python-intro/main/lectures/graph.txt\"\ngraph_file_response = requests.get(file_url)\n\ngraph_file_data = str(graph_file_response.content, 'utf-8')\nprint(graph_file_data)\n\nSolution to \n\nExercise 1\n\nFirst let’s write a function that reads in the graph data above and builds a distance matrix.\n\nnum_nodes = 100\ndestination_node = 99\n\ndef map_graph_to_distance_matrix(in_file_data):\n\n    # First let's set of the distance matrix Q with inf everywhere\n    Q = np.full((num_nodes, num_nodes), np.inf)\n\n    # Now we read in the data and modify Q\n    lines = in_file_data.split('\\n')\n    for line_ in lines:\n        line = line_.strip()\n        if line == '':\n            continue\n        elements = line.split(',')\n        node = elements.pop(0)\n        node = int(node[4:])    # convert node description to integer\n        if node != destination_node:\n            for element in elements:\n                destination, cost = element.split()\n                destination = int(destination[4:])\n                Q[node, destination] = float(cost)\n        Q[destination_node, destination_node] = 0\n    return Q\n\nIn addition, let’s write\n\na “Bellman operator” function that takes a distance matrix and current guess of J and returns an updated guess of J, and\n\na function that takes a distance matrix and returns a cost-to-go function.\n\nWe’ll use the algorithm described above.\n\nThe minimization step is vectorized to make it faster.\n\ndef bellman(J, Q):\n    return np.min(Q + J, axis=1)\n\n\ndef compute_cost_to_go(Q):\n    num_nodes = Q.shape[0]\n    J = np.zeros(num_nodes)      # Initial guess\n    max_iter = 500\n    i = 0\n\n    while i < max_iter:\n        next_J = bellman(J, Q)\n        if np.allclose(next_J, J):\n            break\n        else:\n            J[:] = next_J   # Copy contents of next_J to J\n            i += 1\n\n    return(J)\n\nWe used np.allclose() rather than testing exact equality because we are\ndealing with floating point numbers now.\n\nFinally, here’s a function that uses the cost-to-go function to obtain the\noptimal path (and its cost).\n\ndef print_best_path(J, Q):\n    sum_costs = 0\n    current_node = 0\n    while current_node != destination_node:\n        print(current_node)\n        # Move to the next node and increment costs\n        next_node = np.argmin(Q[current_node, :] + J)\n        sum_costs += Q[current_node, next_node]\n        current_node = next_node\n\n    print(destination_node)\n    print('Cost: ', sum_costs)\n\nOkay, now we have the necessary functions, let’s call them to do the job we were assigned.\n\nQ = map_graph_to_distance_matrix(graph_file_data)\nJ = compute_cost_to_go(Q)\nprint_best_path(J, Q)\n\nThe total cost of the path should agree with J[0] so let’s check this.\n\nJ[0]\n\n","type":"content","url":"/short-path#exercises","position":17},{"hierarchy":{"lvl1":"Simple Linear Regression Model"},"type":"lvl1","url":"/simple-linear-regression","position":0},{"hierarchy":{"lvl1":"Simple Linear Regression Model"},"content":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport pyodide_http\npyodide_http.patch_all()\n\nThe simple regression model estimates the relationship between two variables x_i and y_iy_i = \\alpha + \\beta x_i + \\epsilon_i, i = 1,2,...,N\n\nwhere \\epsilon_i represents the error between the line of best fit and the sample values for y_i given x_i.\n\nOur goal is to choose values for \\alpha and \\beta to build a line of “best” fit for some data that is available for variables x_i and y_i.\n\nLet us consider a simple dataset of 10 observations for variables x_i and y_i:\n\n\n\ny_i\n\nx_i\n\n1\n\n2000\n\n32\n\n2\n\n1000\n\n21\n\n3\n\n1500\n\n24\n\n4\n\n2500\n\n35\n\n5\n\n500\n\n10\n\n6\n\n900\n\n11\n\n7\n\n1100\n\n22\n\n8\n\n1500\n\n21\n\n9\n\n1800\n\n27\n\n10\n\n250\n\n2\n\nLet us think about y_i as sales for an ice-cream cart, while x_i is a variable that records the day’s temperature in Celsius.\n\nx = [32, 21, 24, 35, 10, 11, 22, 21, 27, 2]\ny = [2000,1000,1500,2500,500,900,1100,1500,1800, 250]\ndf = pd.DataFrame([x,y]).T\ndf.columns = ['X', 'Y']\ndf\n\nWe can use a scatter plot of the data to see the relationship between y_i (ice-cream sales in dollars ($'s)) and x_i (degrees Celsius).\n\nax = df.plot(\n    x='X', \n    y='Y', \n    kind='scatter', \n    ylabel='Ice-cream sales ($\\'s)', \n    xlabel='Degrees celcius'\n)\n\n\n\nFigure 1:Scatter plot\n\nas you can see the data suggests that more ice-cream is typically sold on hotter days.\n\nTo build a linear model of the data we need to choose values for \\alpha and \\beta that represents a line of “best” fit such that\\hat{y_i} = \\hat{\\alpha} + \\hat{\\beta} x_i\n\nLet’s start with \\alpha = 5 and \\beta = 10\n\nα = 5\nβ = 10\ndf['Y_hat'] = α + β * df['X']\n\nfig, ax = plt.subplots()\nax = df.plot(x='X',y='Y', kind='scatter', ax=ax)\nax = df.plot(x='X',y='Y_hat', kind='line', ax=ax)\nplt.show()\n\n\n\nFigure 2:Scatter plot with a line of fit\n\nWe can see that this model does a poor job of estimating the relationship.\n\nWe can continue to guess and iterate towards a line of “best” fit by adjusting the parameters\n\nβ = 100\ndf['Y_hat'] = α + β * df['X']\n\nfig, ax = plt.subplots()\nax = df.plot(x='X',y='Y', kind='scatter', ax=ax)\nax = df.plot(x='X',y='Y_hat', kind='line', ax=ax)\nplt.show()\n\n\n\nFigure 3:Scatter plot with a line of fit #2\n\nβ = 65\ndf['Y_hat'] = α + β * df['X']\n\nfig, ax = plt.subplots()\nax = df.plot(x='X',y='Y', kind='scatter', ax=ax)\nax = df.plot(x='X',y='Y_hat', kind='line', ax=ax, color='g')\nplt.show()\n\n\n\nFigure 4:Scatter plot with a line of fit #3\n\nHowever we need to think about formalizing this guessing process by thinking of this problem as an optimization problem.\n\nLet’s consider the error \\epsilon_i and define the difference between the observed values y_i and the estimated values \\hat{y}_i which we will call the residuals\\begin{aligned}\n\\hat{e}_i &= y_i - \\hat{y}_i \\\\\n          &= y_i - \\hat{\\alpha} - \\hat{\\beta} x_i\n\\end{aligned}\n\ndf['error'] = df['Y_hat'] - df['Y']\n\ndf\n\nfig, ax = plt.subplots()\nax = df.plot(x='X',y='Y', kind='scatter', ax=ax)\nax = df.plot(x='X',y='Y_hat', kind='line', ax=ax, color='g')\nplt.vlines(df['X'], df['Y_hat'], df['Y'], color='r')\nplt.show()\n\n\n\nFigure 5:Plot of the residuals\n\nThe Ordinary Least Squares (OLS) method chooses \\alpha and \\beta in such a way that minimizes the sum of the squared residuals (SSR).\\min_{\\alpha,\\beta} \\sum_{i=1}^{N}{\\hat{e}_i^2} = \\min_{\\alpha,\\beta} \\sum_{i=1}^{N}{(y_i - \\alpha - \\beta x_i)^2}\n\nLet’s call this a cost functionC = \\sum_{i=1}^{N}{(y_i - \\alpha - \\beta x_i)^2}\n\nthat we would like to minimize with parameters \\alpha and \\beta.","type":"content","url":"/simple-linear-regression","position":1},{"hierarchy":{"lvl1":"Simple Linear Regression Model","lvl2":"How does error change with respect to \\alpha and \\beta"},"type":"lvl2","url":"/simple-linear-regression#how-does-error-change-with-respect-to-alpha-and-beta","position":2},{"hierarchy":{"lvl1":"Simple Linear Regression Model","lvl2":"How does error change with respect to \\alpha and \\beta"},"content":"Let us first look at how the total error changes with respect to \\beta (holding the intercept \\alpha constant)\n\nWe know from \n\nthe next section the optimal values for \\alpha and \\beta  are:\n\nβ_optimal = 64.38\nα_optimal = -14.72\n\nWe can then calculate the error for a range of \\beta values\n\nerrors = {}\nfor β in np.arange(20,100,0.5):\n    errors[β] = abs((α_optimal + β * df['X']) - df['Y']).sum()\n\nPlotting the error\n\nax = pd.Series(errors).plot(xlabel='β', ylabel='error')\nplt.axvline(β_optimal, color='r');\n\n\n\nFigure 6:Plotting the error\n\nNow let us vary \\alpha (holding \\beta constant)\n\nerrors = {}\nfor α in np.arange(-500,500,5):\n    errors[α] = abs((α + β_optimal * df['X']) - df['Y']).sum()\n\nPlotting the error\n\nax = pd.Series(errors).plot(xlabel='α', ylabel='error')\nplt.axvline(α_optimal, color='r');\n\n\n\nFigure 7:Plotting the error (2)","type":"content","url":"/simple-linear-regression#how-does-error-change-with-respect-to-alpha-and-beta","position":3},{"hierarchy":{"lvl1":"Simple Linear Regression Model","lvl2":"Calculating optimal values"},"type":"lvl2","url":"/simple-linear-regression#slr-optimal-values","position":4},{"hierarchy":{"lvl1":"Simple Linear Regression Model","lvl2":"Calculating optimal values"},"content":"Now let us use calculus to solve the optimization problem and compute the optimal values for \\alpha and \\beta to find the ordinary least squares solution.\n\nFirst taking the partial derivative with respect to \\alpha\\frac{\\partial C}{\\partial \\alpha}[\\sum_{i=1}^{N}{(y_i - \\alpha - \\beta x_i)^2}]\n\nand setting it equal to 00 = \\sum_{i=1}^{N}{-2(y_i - \\alpha - \\beta x_i)}\n\nwe can remove the constant -2 from the summation by dividing both sides by -20 = \\sum_{i=1}^{N}{(y_i - \\alpha - \\beta x_i)}\n\nNow we can split this equation up into the components0 = \\sum_{i=1}^{N}{y_i} - \\sum_{i=1}^{N}{\\alpha} - \\beta \\sum_{i=1}^{N}{x_i}\n\nThe middle term is a straight forward sum from i=1,...N by a constant \\alpha0 = \\sum_{i=1}^{N}{y_i} - N*\\alpha - \\beta \\sum_{i=1}^{N}{x_i}\n\nand rearranging terms\\alpha = \\frac{\\sum_{i=1}^{N}{y_i} - \\beta \\sum_{i=1}^{N}{x_i}}{N}\n\nWe observe that both fractions resolve to the means \\bar{y_i} and \\bar{x_i}\\alpha = \\bar{y_i} - \\beta\\bar{x_i}\n\nNow let’s take the partial derivative of the cost function C with respect to \\beta\\frac{\\partial C}{\\partial \\beta}[\\sum_{i=1}^{N}{(y_i - \\alpha - \\beta x_i)^2}]\n\nand setting it equal to 00 = \\sum_{i=1}^{N}{-2 x_i (y_i - \\alpha - \\beta x_i)}\n\nwe can again take the constant outside of the summation and divide both sides by -20 = \\sum_{i=1}^{N}{x_i (y_i - \\alpha - \\beta x_i)}\n\nwhich becomes0 = \\sum_{i=1}^{N}{(x_i y_i - \\alpha x_i - \\beta x_i^2)}\n\nnow substituting for \\alpha0 = \\sum_{i=1}^{N}{(x_i y_i - (\\bar{y_i} - \\beta \\bar{x_i}) x_i - \\beta x_i^2)}\n\nand rearranging terms0 = \\sum_{i=1}^{N}{(x_i y_i - \\bar{y_i} x_i - \\beta \\bar{x_i} x_i - \\beta x_i^2)}\n\nThis can be split into two summations0 = \\sum_{i=1}^{N}(x_i y_i - \\bar{y_i} x_i) + \\beta \\sum_{i=1}^{N}(\\bar{x_i} x_i - x_i^2)\n\nand solving for \\beta yields\\beta = \\frac{\\sum_{i=1}^{N}(x_i y_i - \\bar{y_i} x_i)}{\\sum_{i=1}^{N}(x_i^2 - \\bar{x_i} x_i)}\n\nWe can now use \n\n(12) and \n\n(20) to calculate the optimal values for \\alpha and \\beta\n\nCalculating \\beta\n\ndf = df[['X','Y']].copy()  # Original Data\n\n# Calculate the sample means\nx_bar = df['X'].mean()\ny_bar = df['Y'].mean()\n\nNow computing across the 10 observations and then summing the numerator and denominator\n\n# Compute the Sums\ndf['num'] = df['X'] * df['Y'] - y_bar * df['X']\ndf['den'] = pow(df['X'],2) - x_bar * df['X']\nβ = df['num'].sum() / df['den'].sum()\nprint(β)\n\nCalculating \\alpha\n\nα = y_bar - β * x_bar\nprint(α)\n\nNow we can plot the OLS solution\n\ndf['Y_hat'] = α + β * df['X']\ndf['error'] = df['Y_hat'] - df['Y']\n\nfig, ax = plt.subplots()\nax = df.plot(x='X',y='Y', kind='scatter', ax=ax)\nax = df.plot(x='X',y='Y_hat', kind='line', ax=ax, color='g')\nplt.vlines(df['X'], df['Y_hat'], df['Y'], color='r');\n\n\n\nFigure 8:OLS line of best fit\n\nNow that you know the equations that solve the simple linear regression model using OLS you can now run your own regressions to build a model between y and x.\n\nLet’s consider two economic variables GDP per capita and Life Expectancy.\n\nWhat do you think their relationship would be?\n\nGather some data \n\nfrom our world in data\n\nUse pandas to import the csv formatted data and plot a few different countries of interest\n\nUse \n\n(12) and \n\n(20) to compute optimal values for  \\alpha and \\beta\n\nPlot the line of best fit found using OLS\n\nInterpret the coefficients and write a summary sentence of the relationship between GDP per capita and Life Expectancy\n\nSolution to \n\nExercise 1\n\nQ2: Gather some data \n\nfrom our world in data\n\nYou can download \n\na copy of the data here if you get stuck\n\nQ3: Use pandas to import the csv formatted data and plot a few different countries of interest\n\ndata_url = \"https://raw.githubusercontent.com/QuantEcon/lecture-python-intro/main/lectures/_static/lecture_specific/simple_linear_regression/life-expectancy-vs-gdp-per-capita.csv\"\ndf = pd.read_csv(data_url, nrows=10)\n\ndf\n\nYou can see that the data downloaded from Our World in Data has provided a global set of countries with the GDP per capita and Life Expectancy Data.\n\nIt is often a good idea to at first import a few lines of data from a csv to understand its structure so that you can then choose the columns that you want to read into your DataFrame.\n\nYou can observe that there are a bunch of columns we won’t need to import such as Continent\n\nSo let’s built a list of the columns we want to import\n\ncols = ['Code', 'Year', 'Life expectancy at birth (historical)', 'GDP per capita']\ndf = pd.read_csv(data_url, usecols=cols)\ndf\n\nSometimes it can be useful to rename your columns to make it easier to work with in the DataFrame\n\ndf.columns = [\"cntry\", \"year\", \"life_expectancy\", \"gdppc\"]\ndf\n\nWe can see there are NaN values which represents missing data so let us go ahead and drop those\n\ndf.dropna(inplace=True)\n\ndf\n\nWe have now dropped the number of rows in our DataFrame from 62156 to 12445 removing a lot of empty data relationships.\n\nNow we have a dataset containing life expectancy and GDP per capita for a range of years.\n\nIt is always a good idea to spend a bit of time understanding what data you actually have.\n\nFor example, you may want to explore this data to see if there is consistent reporting for all countries across years\n\nLet’s first look at the Life Expectancy Data\n\nle_years = df[['cntry', 'year', 'life_expectancy']].set_index(['cntry', 'year']).unstack()['life_expectancy']\nle_years\n\nAs you can see there are a lot of countries where data is not available for the Year 1543!\n\nWhich country does report this data?\n\nle_years[~le_years[1543].isna()]\n\nYou can see that Great Britain (GBR) is the only one available\n\nYou can also take a closer look at the time series to find that it is also non-continuous, even for GBR.\n\nle_years.loc['GBR'].plot()\n\nIn fact we can use pandas to quickly check how many countries are captured in each year\n\nle_years.stack().unstack(level=0).count(axis=1).plot(xlabel=\"Year\", ylabel=\"Number of countries\");\n\nSo it is clear that if you are doing cross-sectional comparisons then more recent data will include a wider set of countries\n\nNow let us consider the most recent year in the dataset 2018\n\ndf = df[df.year == 2018].reset_index(drop=True).copy()\n\ndf.plot(x='gdppc', y='life_expectancy', kind='scatter',  xlabel=\"GDP per capita\", ylabel=\"Life expectancy (years)\",);\n\nThis data shows a couple of interesting relationships.\n\nthere are a number of countries with similar GDP per capita levels but a wide range in Life Expectancy\n\nthere appears to be a positive relationship between GDP per capita and life expectancy. Countries with higher GDP per capita tend to have higher life expectancy outcomes\n\nEven though OLS is solving linear equations -- one option we have is to transform the variables, such as through a log transform, and then use OLS to estimate the transformed variables.\n\nBy specifying logx you can plot the GDP per Capita data on a log scale\n\ndf.plot(x='gdppc', y='life_expectancy', kind='scatter',  xlabel=\"GDP per capita\", ylabel=\"Life expectancy (years)\", logx=True);\n\nAs you can see from this transformation -- a linear model fits the shape of the data more closely.\n\ndf['log_gdppc'] = df['gdppc'].apply(np.log10)\n\ndf\n\nQ4: Use \n\n(12) and \n\n(20) to compute optimal values for  \\alpha and \\beta\n\ndata = df[['log_gdppc', 'life_expectancy']].copy()  # Get Data from DataFrame\n\n# Calculate the sample means\nx_bar = data['log_gdppc'].mean()\ny_bar = data['life_expectancy'].mean()\n\ndata\n\n# Compute the Sums\ndata['num'] = data['log_gdppc'] * data['life_expectancy'] - y_bar * data['log_gdppc']\ndata['den'] = pow(data['log_gdppc'],2) - x_bar * data['log_gdppc']\nβ = data['num'].sum() / data['den'].sum()\nprint(β)\n\nα = y_bar - β * x_bar\nprint(α)\n\nQ5: Plot the line of best fit found using OLS\n\ndata['life_expectancy_hat'] = α + β * df['log_gdppc']\ndata['error'] = data['life_expectancy_hat'] - data['life_expectancy']\n\nfig, ax = plt.subplots()\ndata.plot(x='log_gdppc',y='life_expectancy', kind='scatter', ax=ax)\ndata.plot(x='log_gdppc',y='life_expectancy_hat', kind='line', ax=ax, color='g')\nplt.vlines(data['log_gdppc'], data['life_expectancy_hat'], data['life_expectancy'], color='r')\n\n\n\nMinimizing the sum of squares is not the only way to generate the line of best fit.\n\nFor example, we could also consider minimizing the sum of the absolute values, that would give less weight to outliers.\n\nSolve for \\alpha and \\beta using the least absolute values","type":"content","url":"/simple-linear-regression#slr-optimal-values","position":5},{"hierarchy":{"lvl1":"The Solow-Swan Growth Model"},"type":"lvl1","url":"/solow","position":0},{"hierarchy":{"lvl1":"The Solow-Swan Growth Model"},"content":"In this lecture we review a famous model due\nto \n\nRobert Solow (1925--2023) and \n\nTrevor Swan (1918--1989).\n\nThe model is used to study growth over the long run.\n\nAlthough the model is simple, it contains some interesting lessons.\n\nWe will use the following imports.\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n","type":"content","url":"/solow","position":1},{"hierarchy":{"lvl1":"The Solow-Swan Growth Model","lvl2":"The model"},"type":"lvl2","url":"/solow#the-model","position":2},{"hierarchy":{"lvl1":"The Solow-Swan Growth Model","lvl2":"The model"},"content":"In a Solow--Swan economy, agents save a fixed fraction of their current\nincomes.\n\nSavings sustain or increase the stock of capital.\n\nCapital is combined with labor to produce output, which in turn is paid out to\nworkers and owners of capital.\n\nTo keep things simple, we ignore population and productivity growth.\n\nFor each integer t \\geq 0, output Y_t in period t is given by Y_t =\nF(K_t, L_t), where K_t is capital, L_t is labor and F is an aggregate\nproduction function.\n\nThe function F is assumed to be nonnegative and\nhomogeneous of degree one, meaning\nthatF(\\lambda K, \\lambda L) = \\lambda F(K, L)\n    \\quad \\text{for all } \\lambda \\geq 0\n\nProduction functions with this property include\n\nthe Cobb-Douglas function F(K, L) = A K^{\\alpha}\nL^{1-\\alpha} with 0 \\leq \\alpha \\leq 1.\n\nthe CES function F(K, L) = \\left\\{ a K^\\rho + b L^\\rho \\right\\}^{1/\\rho}\nwith a, b, \\rho > 0.\n\nHere, \\alpha is the output elasticity of capital and \\rho is a parameter that determines the elasticity of substitution between capital and labor.\n\nWe assume a closed economy, so aggregate domestic investment equals aggregate domestic\nsaving.\n\nThe saving rate is a constant s satisfying 0 \\leq s \\leq 1, so that aggregate\ninvestment and saving both equal  s Y_t.\n\nCapital depreciates: without replenishing through investment, one unit of capital today\nbecomes 1-\\delta units tomorrow.\n\nThus,K_{t+1} = s F(K_t, L_t) + (1 - \\delta) K_t\n\nWithout population growth, L_t equals some constant L.\n\nSetting k_t := K_t / L and using homogeneity of degree one now yieldsk_{t+1}\n    = s \\frac{F(K_t, L)}{L} + (1 - \\delta) \\frac{K_t}{L}\n    = s \\frac{F(K_t, L)}{L} + (1 - \\delta) k_t\n    = s F(k_t, 1) + (1 - \\delta) k_t\n\nWith  f(k) := F(k, 1), the final expression for capital dynamics is    k_{t+1} = g(k_t)\n    \\text{ where } g(k) := s f(k) + (1 - \\delta) k\n\nOur aim is to learn about the evolution of k_t over time,\ngiven an exogenous initial capital stock  k_0.","type":"content","url":"/solow#the-model","position":3},{"hierarchy":{"lvl1":"The Solow-Swan Growth Model","lvl2":"A graphical perspective"},"type":"lvl2","url":"/solow#a-graphical-perspective","position":4},{"hierarchy":{"lvl1":"The Solow-Swan Growth Model","lvl2":"A graphical perspective"},"content":"To understand the dynamics of the sequence (k_t)_{t \\geq 0} we use a 45-degree diagram.\n\nTo do so, we first\nneed to specify the functional form for f and assign values to the parameters.\n\nWe choose the Cobb--Douglas specification f(k) = A k^\\alpha and set A=2.0,\n\\alpha=0.3, s=0.3 and \\delta=0.4.\n\nThe function g from \n\nThe Solow-Swan Growth Model is then plotted, along with the 45-degree line.\n\nLet’s define the constants.\n\nA, s, alpha, delta = 2, 0.3, 0.3, 0.4\nx0 = 0.25\nxmin, xmax = 0, 3\n\nNow, we define the function g.\n\ndef g(A, s, alpha, delta, k):\n    return A * s * k**alpha + (1 - delta) * k\n\nLet’s plot the 45-degree diagram of g.\n\ndef plot45(kstar=None):\n    xgrid = np.linspace(xmin, xmax, 12000)\n\n    fig, ax = plt.subplots()\n\n    ax.set_xlim(xmin, xmax)\n\n    g_values = g(A, s, alpha, delta, xgrid)\n\n    ymin, ymax = np.min(g_values), np.max(g_values)\n    ax.set_ylim(ymin, ymax)\n\n    lb = r'$g(k) = sAk^{\\alpha} + (1 - \\delta)k$'\n    ax.plot(xgrid, g_values,  lw=2, alpha=0.6, label=lb)\n    ax.plot(xgrid, xgrid, 'k-', lw=1, alpha=0.7, label=r'$45^{\\circ}$')\n\n    if kstar:\n        fps = (kstar,)\n\n        ax.plot(fps, fps, 'go', ms=10, alpha=0.6)\n\n        ax.annotate(r'$k^* = (sA / \\delta)^{(1/(1-\\alpha))}$',\n                 xy=(kstar, kstar),\n                 xycoords='data',\n                 xytext=(-40, -60),\n                 textcoords='offset points',\n                 fontsize=14,\n                 arrowprops=dict(arrowstyle=\"->\"))\n\n    ax.legend(loc='upper left', frameon=False, fontsize=12)\n\n    ax.set_xticks((0, 1, 2, 3))\n    ax.set_yticks((0, 1, 2, 3))\n\n    ax.set_xlabel('$k_t$', fontsize=12)\n    ax.set_ylabel('$k_{t+1}$', fontsize=12)\n\n    plt.show()\n\nplot45()\n\nSuppose, at some k_t, the value g(k_t) lies strictly above the 45-degree line.\n\nThen we have k_{t+1} = g(k_t) > k_t and capital per worker rises.\n\nIf g(k_t) < k_t then capital per worker falls.\n\nIf g(k_t) = k_t, then we are at a steady state and k_t remains constant.\n\n(A \n\nsteady state of the model is a \n\nfixed point of the mapping g.)\n\nFrom the shape of the function g in the figure, we see that\nthere is a unique steady state in (0, \\infty).\n\nIt solves k = s Ak^{\\alpha} + (1-\\delta)k and hence is given by    k^* := \\left( \\frac{s A}{\\delta} \\right)^{1/(1 - \\alpha)}\n\nIf initial capital is below k^*, then capital increases over time.\n\nIf initial capital is above this level, then the reverse is true.\n\nLet’s plot the 45-degree diagram to show the k^* in the plot.\n\nkstar = ((s * A) / delta)**(1/(1 - alpha))\nplot45(kstar)\n\nFrom our graphical analysis, it appears that (k_t) converges to k^*, regardless of initial capital\nk_0.\n\nThis is a form of \n\nglobal stability.\n\nThe next figure shows three time paths for capital, from\nthree distinct initial conditions, under the parameterization listed above.\n\nAt this parameterization, k^* \\approx 1.78.\n\nLet’s define the constants and three distinct initial conditions\n\nA, s, alpha, delta = 2, 0.3, 0.3, 0.4\nx0 = np.array([.25, 1.25, 3.25])\n\nts_length = 20\nxmin, xmax = 0, ts_length\nymin, ymax = 0, 3.5\n\ndef simulate_ts(x0_values, ts_length):\n\n    k_star = (s * A / delta)**(1/(1-alpha))\n    fig, ax = plt.subplots(figsize=[11, 5])\n    ax.set_xlim(xmin, xmax)\n    ax.set_ylim(ymin, ymax)\n\n    ts = np.zeros(ts_length)\n\n    # simulate and plot time series\n    for x_init in x0_values:\n        ts[0] = x_init\n        for t in range(1, ts_length):\n            ts[t] = g(A, s, alpha, delta, ts[t-1])\n        ax.plot(np.arange(ts_length), ts, '-o', ms=4, alpha=0.6,\n                label=r'$k_0=%g$' %x_init)\n    ax.plot(np.arange(ts_length), np.full(ts_length,k_star),\n            alpha=0.6, color='red', label=r'$k^*$')\n    ax.legend(fontsize=10)\n\n    ax.set_xlabel(r'$t$', fontsize=14)\n    ax.set_ylabel(r'$k_t$', fontsize=14)\n\n    plt.show()\n\nsimulate_ts(x0, ts_length)\n\nAs expected, the time paths in the figure all converge to k^*.","type":"content","url":"/solow#a-graphical-perspective","position":5},{"hierarchy":{"lvl1":"The Solow-Swan Growth Model","lvl2":"Growth in continuous time"},"type":"lvl2","url":"/solow#growth-in-continuous-time","position":6},{"hierarchy":{"lvl1":"The Solow-Swan Growth Model","lvl2":"Growth in continuous time"},"content":"In this section, we investigate a continuous time version of the Solow--Swan\ngrowth model.\n\nWe will see how the smoothing provided by continuous time can\nsimplify our analysis.\n\nRecall  that the discrete time dynamics for capital are\ngiven by k_{t+1} = s f(k_t) + (1 - \\delta) k_t.\n\nA simple rearrangement gives the rate of change per unit of time:\\Delta k_t = s f(k_t) - \\delta k_t\n    \\quad \\text{where} \\quad\n    \\Delta k_t := k_{t+1}  - k_t\n\nTaking the time step to zero gives the continuous time limit    k'_t = s f(k_t) - \\delta k_t\n    \\qquad \\text{with} \\qquad\n    k'_t := \\frac{d}{dt} k_t\n\nOur aim is to learn about the evolution of k_t over time,\ngiven an initial stock  k_0.\n\nA steady state for \n\n(7) is a value k^*\nat which capital is unchanging, meaning k'_t = 0 or, equivalently,\ns f(k^*) = \\delta k^*.\n\nWe assume\nf(k) = Ak^\\alpha, so k^* solves\ns A k^\\alpha = \\delta k.\n\nThe solution is the same as the discrete time case---see \n\n(5).\n\nThe dynamics are represented in\nthe next figure, maintaining the parameterization we used\nabove.\n\nWriting k'_t = g(k_t) with g(k) =\ns Ak^\\alpha - \\delta k, values of k with g(k) > 0 imply k'_t > 0, so\ncapital is increasing.\n\nWhen g(k) < 0, the opposite occurs.  Once again, high marginal returns to\nsavings at low levels of capital combined with low rates of return at high\nlevels of capital combine to yield global stability.\n\nTo see this in a figure, let’s define the constants\n\nA, s, alpha, delta = 2, 0.3, 0.3, 0.4\n\nNext we define the function g for growth in continuous time\n\ndef g_con(A, s, alpha, delta, k):\n    return A * s * k**alpha - delta * k\n\ndef plot_gcon(kstar=None):\n\n    k_grid = np.linspace(0, 2.8, 10000)\n\n    fig, ax = plt.subplots(figsize=[11, 5])\n    ax.plot(k_grid, g_con(A, s, alpha, delta, k_grid), label='$g(k)$')\n    ax.plot(k_grid, 0 * k_grid, label=\"$k'=0$\")\n\n    if kstar:\n        fps = (kstar,)\n\n        ax.plot(fps, 0, 'go', ms=10, alpha=0.6)\n\n\n        ax.annotate(r'$k^* = (sA / \\delta)^{(1/(1-\\alpha))}$',\n                 xy=(kstar, 0),\n                 xycoords='data',\n                 xytext=(0, 60),\n                 textcoords='offset points',\n                 fontsize=12,\n                 arrowprops=dict(arrowstyle=\"->\"))\n\n    ax.legend(loc='lower left', fontsize=12)\n\n    ax.set_xlabel(\"$k$\",fontsize=10)\n    ax.set_ylabel(\"$k'$\", fontsize=10)\n\n    ax.set_xticks((0, 1, 2, 3))\n    ax.set_yticks((-0.3, 0, 0.3))\n\n    plt.show()\n\nkstar = ((s * A) / delta)**(1/(1 - alpha))\nplot_gcon(kstar)\n\nThis shows global stability heuristically for a fixed parameterization, but\nhow would we show the same thing formally for a continuum of plausible parameters?\n\nIn the discrete time case, a neat expression for k_t is hard to obtain.\n\nIn continuous time the process is easier: we can obtain a relatively simple\nexpression for k_t that specifies the entire path.\n\nThe first step is\nto set x_t := k_t^{1-\\alpha}, so that x'_t = (1-\\alpha) k_t^{-\\alpha}\nk'_t.\n\nSubstituting into k'_t = sAk_t^\\alpha - \\delta k_t leads to the\nlinear differential equation    x'_t = (1-\\alpha) (sA - \\delta x_t)\n\nThis equation, which is a \n\nlinear ordinary differential equation, has the solutionx_t\n    = \\left(\n        k_0^{1-\\alpha} - \\frac{sA}{\\delta}\n      \\right)\n      \\mathrm{e}^{-\\delta (1-\\alpha) t} +\n    \\frac{sA}{\\delta}\n\n(You can confirm that this function x_t satisfies \n\n(8) by\ndifferentiating it with respect to t.)\n\nConverting back to k_t yields    k_t\n    =\n    \\left[\n        \\left(\n        k_0^{1-\\alpha} - \\frac{sA}{\\delta}\n      \\right)\n      \\mathrm{e}^{-\\delta (1-\\alpha) t} +\n    \\frac{sA}{\\delta}\n    \\right]^{1/(1-\\alpha)}\n\nSince \\delta > 0 and \\alpha \\in (0, 1), we see immediately that k_t \\to\nk^* as t \\to \\infty independent of k_0.\n\nThus, global stability holds.","type":"content","url":"/solow#growth-in-continuous-time","position":7},{"hierarchy":{"lvl1":"The Solow-Swan Growth Model","lvl2":"Exercises"},"type":"lvl2","url":"/solow#exercises","position":8},{"hierarchy":{"lvl1":"The Solow-Swan Growth Model","lvl2":"Exercises"},"content":"Plot per capita consumption c at the steady state, as a function of the savings rate s, where 0 \\leq s \\leq 1.\n\nUse the Cobb--Douglas specification f(k) = A k^\\alpha.\n\nSet A=2.0, \\alpha=0.3, and \\delta=0.5\n\nAlso, find the approximate value of s that maximizes the c^*(s) and show it in the plot.\n\nSolution to \n\nExercise 1\n\nSteady state consumption at savings rate s is given byc^*(s) = (1-s)f(k^*) = (1-s)A(k^*)^\\alpha\n\nA = 2.0\nalpha = 0.3\ndelta = 0.5\n\ns_grid = np.linspace(0, 1, 1000)\nk_star = ((s_grid * A) / delta)**(1/(1 - alpha))\nc_star = (1 - s_grid) * A * k_star ** alpha\n\nLet’s find the value of s that maximizes c^* using \n\nscipy​.optimize​.minimize​_scalar.\nWe will use -c^*(s) since minimize_scalar finds the minimum value.\n\nfrom scipy.optimize import minimize_scalar\n\ndef calc_c_star(s):\n    k = ((s * A) / delta)**(1/(1 - alpha))\n    return - (1 - s) * A * k ** alpha\n\nreturn_values = minimize_scalar(calc_c_star, bounds=(0, 1))\ns_star_max = return_values.x\nc_star_max = -return_values.fun\nprint(f\"Function is maximized at s = {round(s_star_max, 4)}\")\n\nx_s_max = np.array([s_star_max, s_star_max])\ny_s_max = np.array([0, c_star_max])\n\nfig, ax = plt.subplots(figsize=[11, 5])\n\nfps = (c_star_max,)\n\n# Highlight the maximum point with a marker\nax.plot((s_star_max, ), (c_star_max,), 'go', ms=8, alpha=0.6)\n\nax.annotate(r'$s^*$',\n         xy=(s_star_max, c_star_max),\n         xycoords='data',\n         xytext=(20, -50),\n         textcoords='offset points',\n         fontsize=12,\n         arrowprops=dict(arrowstyle=\"->\"))\nax.plot(s_grid, c_star, label=r'$c*(s)$')\nax.plot(x_s_max, y_s_max, alpha=0.5, ls='dotted')\nax.set_xlabel(r'$s$')\nax.set_ylabel(r'$c^*(s)$')\nax.legend()\n\nplt.show()\n\nOne can also try to solve this mathematically by differentiating c^*(s) and solve for \\frac{d}{ds}c^*(s)=0 using \n\nsympy.\n\nfrom sympy import solve, Symbol\n\ns_symbol = Symbol('s', real=True)\nk = ((s_symbol * A) / delta)**(1/(1 - alpha))\nc = (1 - s_symbol) * A * k ** alpha\n\nLet’s differentiate c and solve using \n\nsympy.solve\n\n# Solve using sympy\ns_star = solve(c.diff())[0]\nprint(f\"s_star = {s_star}\")\n\nIncidentally, the rate of savings which maximizes steady state level of per capita consumption is called the \n\nGolden Rule savings rate.\n\nStochastic Productivity\n\nTo bring the Solow--Swan model closer to data, we need to think about handling\nrandom fluctuations in aggregate quantities.\n\nAmong other things, this will\neliminate the unrealistic prediction that per-capita output y_t = A\nk^\\alpha_t converges to a constant y^* := A (k^*)^\\alpha.\n\nWe shift to discrete time for the following discussion.\n\nOne approach is to replace constant productivity with some\nstochastic sequence (A_t)_{t \\geq 1}.\n\nDynamics are now    k_{t+1} = s A_{t+1} f(k_t) + (1 - \\delta) k_t\n\nWe suppose f is Cobb--Douglas and (A_t) is IID and lognormal.\n\nNow the long run convergence obtained in the deterministic case breaks\ndown, since the system is hit with new shocks at each point in time.\n\nConsider A=2.0, s=0.6, \\alpha=0.3, and \\delta=0.5\n\nGenerate and plot the time series k_t.\n\nSolution to \n\nExercise 2\n\nLet’s define the constants for lognormal distribution and initial values used for simulation\n\n# Define the constants\nsig = 0.2\nmu = np.log(2) - sig**2 / 2\nA = 2.0\ns = 0.6\nalpha = 0.3\ndelta = 0.5\nx0 = [.25, 3.25] # list of initial values used for simulation\n\nLet’s define the function k_next to find the next value of k\n\ndef lgnorm():\n    return np.exp(mu + sig * np.random.randn())\n\ndef k_next(s, alpha, delta, k):\n    return lgnorm() * s * k**alpha + (1 - delta) * k\n\ndef ts_plot(x_values, ts_length):\n    fig, ax = plt.subplots(figsize=[11, 5])\n    ts = np.zeros(ts_length)\n\n    # simulate and plot time series\n    for x_init in x_values:\n        ts[0] = x_init\n        for t in range(1, ts_length):\n            ts[t] = k_next(s, alpha, delta, ts[t-1])\n        ax.plot(np.arange(ts_length), ts, '-o', ms=4,\n                alpha=0.6, label=r'$k_0=%g$' %x_init)\n\n    ax.legend(loc='best', fontsize=10)\n\n    ax.set_xlabel(r'$t$', fontsize=12)\n    ax.set_ylabel(r'$k_t$', fontsize=12)\n\n\n    plt.show()\n\nts_plot(x0, 50)\n\n","type":"content","url":"/solow#exercises","position":9},{"hierarchy":{"lvl1":"Execution Statistics"},"type":"lvl1","url":"/status","position":0},{"hierarchy":{"lvl1":"Execution Statistics"},"content":"This table contains the latest execution statistics.\n\nThese lectures are built on linux instances through github actions.\n\nThese lectures are using the following python version\n\n!python --version\n\nand the following package versions\n\n!conda list","type":"content","url":"/status","position":1},{"hierarchy":{"lvl1":"Market Equilibrium with Heterogeneity"},"type":"lvl1","url":"/supply-demand-heterogeneity","position":0},{"hierarchy":{"lvl1":"Market Equilibrium with Heterogeneity"},"content":"","type":"content","url":"/supply-demand-heterogeneity","position":1},{"hierarchy":{"lvl1":"Market Equilibrium with Heterogeneity","lvl2":"Overview"},"type":"lvl2","url":"/supply-demand-heterogeneity#overview","position":2},{"hierarchy":{"lvl1":"Market Equilibrium with Heterogeneity","lvl2":"Overview"},"content":"In the {doc}previous lecture <supply_demand_multiple_goods>, we studied competitive equilibria in an economy with many goods.\n\nWhile the results of the study were informative, we used a strong simplifying assumption: all of the agents in the economy are identical.\n\nIn the real world, households, firms and other economic agents differ from one another along many dimensions.\n\nIn this lecture, we introduce heterogeneity across consumers by allowing their preferences and endowments to differ.\n\nWe will examine competitive equilibrium in this setting.\n\nWe will also show how a “representative consumer” can be constructed.\n\nHere are some imports:\n\nimport numpy as np\nfrom scipy.linalg import inv\n\n","type":"content","url":"/supply-demand-heterogeneity#overview","position":3},{"hierarchy":{"lvl1":"Market Equilibrium with Heterogeneity","lvl2":"An simple example"},"type":"lvl2","url":"/supply-demand-heterogeneity#an-simple-example","position":4},{"hierarchy":{"lvl1":"Market Equilibrium with Heterogeneity","lvl2":"An simple example"},"content":"Let’s study a simple example of pure exchange economy without production.\n\nThere are two consumers who differ in their endowment vectors e_i and their bliss-point vectors b_i for i=1,2.\n\nThe total endowment is e_1 + e_2.\n\nA competitive equilibrium requires thatc_1 + c_2 = e_1 + e_2\n\nAssume the demand curvesc_i = (\\Pi^\\top \\Pi )^{-1}(\\Pi^\\top b_i -  \\mu_i p )\n\nCompetitive equilibrium then requires thate_1 + e_2 =\n    (\\Pi^\\top \\Pi)^{-1}(\\Pi^\\top (b_1 + b_2) - (\\mu_1 + \\mu_2) p )\n\nwhich, after a line or two of linear algebra, implies that(\\mu_1 + \\mu_2) p = \\Pi^\\top(b_1+ b_2) - \\Pi^\\top \\Pi (e_1 + e_2)\n\nWe can normalize prices by setting \\mu_1 + \\mu_2 =1 and then solving\\mu_i(p,e) = \\frac{p^\\top (\\Pi^{-1} b_i - e_i)}{p^\\top (\\Pi^\\top \\Pi )^{-1} p}\n\nfor \\mu_i, i = 1,2.\n\nShow that, up to normalization by a positive scalar, the same competitive equilibrium price vector that you computed in the preceding two-consumer economy would prevail in a single-consumer economy in which a single representative consumer has utility function-.5 (\\Pi c -b) ^\\top (\\Pi c -b )\n\nand endowment vector e,  whereb = b_1 + b_2\n\nande = e_1 + e_2 .","type":"content","url":"/supply-demand-heterogeneity#an-simple-example","position":5},{"hierarchy":{"lvl1":"Market Equilibrium with Heterogeneity","lvl2":"Pure exchange economy"},"type":"lvl2","url":"/supply-demand-heterogeneity#pure-exchange-economy","position":6},{"hierarchy":{"lvl1":"Market Equilibrium with Heterogeneity","lvl2":"Pure exchange economy"},"content":"Let’s further explore a pure exchange economy with n goods and m people.","type":"content","url":"/supply-demand-heterogeneity#pure-exchange-economy","position":7},{"hierarchy":{"lvl1":"Market Equilibrium with Heterogeneity","lvl3":"Competitive equilibrium","lvl2":"Pure exchange economy"},"type":"lvl3","url":"/supply-demand-heterogeneity#competitive-equilibrium","position":8},{"hierarchy":{"lvl1":"Market Equilibrium with Heterogeneity","lvl3":"Competitive equilibrium","lvl2":"Pure exchange economy"},"content":"We’ll compute a competitive equilibrium.\n\nTo compute a competitive equilibrium of a pure exchange economy, we use the fact that\n\nRelative prices in a competitive equilibrium are the same as those in a special single person or  representative consumer economy with preference \\Pi and b=\\sum_i b_i, and endowment e = \\sum_i e_{i}.\n\nWe can use the following steps to compute a competitive equilibrium:\n\nFirst we solve the single representative consumer economy by normalizing \\mu = 1. Then, we renormalize the price vector by using the first consumption good as a numeraire.\n\nNext we use the competitive equilibrium prices to compute each consumer’s marginal utility of wealth:\\mu_{i}=\\frac{-W_{i}+p^{\\top}\\left(\\Pi^{-1}b_{i}-e_{i}\\right)}{p^{\\top}(\\Pi^{\\top}\\Pi)^{-1}p}\n\nFinally we compute a competitive equilibrium allocation by using the demand curves:c_{i}=\\Pi^{-1}b_{i}-(\\Pi^{\\top}\\Pi)^{-1}\\mu_{i}p","type":"content","url":"/supply-demand-heterogeneity#competitive-equilibrium","position":9},{"hierarchy":{"lvl1":"Market Equilibrium with Heterogeneity","lvl3":"Designing some Python code","lvl2":"Pure exchange economy"},"type":"lvl3","url":"/supply-demand-heterogeneity#designing-some-python-code","position":10},{"hierarchy":{"lvl1":"Market Equilibrium with Heterogeneity","lvl3":"Designing some Python code","lvl2":"Pure exchange economy"},"content":"Below we shall construct a Python class with the following attributes:\n\nPreferences in the form of\n\nan n \\times n  positive definite matrix \\Pi\n\nan n \\times 1 vector of bliss points b\n\nEndowments in the form of\n\nan n \\times 1 vector e\n\na scalar “wealth” W with default value 0\n\nThe class will include a test to make sure that b \\gg \\Pi e  and raise an exception if it is violated\n(at some threshold level we’d have to specify).\n\nA Person in the form of a pair that consists of\n\nPreferences and Endowments\n\nA Pure Exchange Economy will consist of\n\na collection of m persons\n\nm=1 for our single-agent economy\n\nm=2 for our illustrations of a pure exchange economy\n\nan equilibrium price vector p (normalized somehow)\n\nan equilibrium allocation c_1, c_2, \\ldots, c_m -- a collection of m vectors of dimension n \\times 1\n\nNow let’s proceed to code.\n\nclass ExchangeEconomy:\n    def __init__(self, \n                 Π, \n                 bs, \n                 es, \n                 Ws=None, \n                 thres=1.5):\n        \"\"\"\n        Set up the environment for an exchange economy\n\n        Args:\n            Π (np.array): shared matrix of substitution\n            bs (list): all consumers' bliss points\n            es (list): all consumers' endowments\n            Ws (list): all consumers' wealth\n            thres (float): a threshold set to test b >> Pi e violated\n        \"\"\"\n        n, m = Π.shape[0], len(bs)\n\n        # check non-satiation\n        for b, e in zip(bs, es):\n            if np.min(b / np.max(Π @ e)) <= thres:\n                raise Exception('set bliss points further away')\n\n        if Ws == None:\n            Ws = np.zeros(m)\n        else:\n            if sum(Ws) != 0:\n                raise Exception('invalid wealth distribution')\n\n        self.Π, self.bs, self.es, self.Ws, self.n, self.m = Π, bs, es, Ws, n, m\n\n    def competitive_equilibrium(self):\n        \"\"\"\n        Compute the competitive equilibrium prices and allocation\n        \"\"\"\n        Π, bs, es, Ws = self.Π, self.bs, self.es, self.Ws\n        n, m = self.n, self.m\n        slope_dc = inv(Π.T @ Π)\n        Π_inv = inv(Π)\n\n        # aggregate\n        b = sum(bs)\n        e = sum(es)\n\n        # compute price vector with mu=1 and renormalize\n        p = Π.T @ b - Π.T @ Π @ e\n        p = p / p[0]\n\n        # compute marginal utility of wealth\n        μ_s = []\n        c_s = []\n        A = p.T @ slope_dc @ p\n\n        for i in range(m):\n            μ_i = (-Ws[i] + p.T @ (Π_inv @ bs[i] - es[i])) / A\n            c_i = Π_inv @ bs[i] - μ_i * slope_dc @ p\n            μ_s.append(μ_i)\n            c_s.append(c_i)\n\n        for c_i in c_s:\n            if any(c_i < 0):\n                print('allocation: ', c_s)\n                raise Exception('negative allocation: equilibrium does not exist')\n\n        return p, c_s, μ_s\n\n","type":"content","url":"/supply-demand-heterogeneity#designing-some-python-code","position":11},{"hierarchy":{"lvl1":"Market Equilibrium with Heterogeneity","lvl2":"Implementation"},"type":"lvl2","url":"/supply-demand-heterogeneity#implementation","position":12},{"hierarchy":{"lvl1":"Market Equilibrium with Heterogeneity","lvl2":"Implementation"},"content":"Next we use the class ExchangeEconomy defined above to study\n\na two-person economy without production,\n\na dynamic economy, and\n\nan economy with risk and arrow securities.","type":"content","url":"/supply-demand-heterogeneity#implementation","position":13},{"hierarchy":{"lvl1":"Market Equilibrium with Heterogeneity","lvl3":"Two-person economy without production","lvl2":"Implementation"},"type":"lvl3","url":"/supply-demand-heterogeneity#two-person-economy-without-production","position":14},{"hierarchy":{"lvl1":"Market Equilibrium with Heterogeneity","lvl3":"Two-person economy without production","lvl2":"Implementation"},"content":"Here we study how competitive equilibrium p, c_1, c_2 respond to different b_i and e_i, i \\in \\{1, 2\\}.\n\nΠ = np.array([[1, 0],\n              [0, 1]])\n\nbs = [np.array([5, 5]),  # first consumer's bliss points\n      np.array([5, 5])]  # second consumer's bliss points\n\nes = [np.array([0, 2]),  # first consumer's endowment\n      np.array([2, 0])]  # second consumer's endowment\n\nEE = ExchangeEconomy(Π, bs, es)\np, c_s, μ_s = EE.competitive_equilibrium()\n\nprint('Competitive equilibrium price vector:', p)\nprint('Competitive equilibrium allocation:', c_s)\n\nWhat happens if the first consumer likes the first good more and the second consumer likes the second good more?\n\nEE.bs = [np.array([6, 5]),  # first consumer's bliss points\n         np.array([5, 6])]  # second consumer's bliss points\n\np, c_s, μ_s = EE.competitive_equilibrium()\n\nprint('Competitive equilibrium price vector:', p)\nprint('Competitive equilibrium allocation:', c_s)\n\nLet the first consumer be poorer.\n\nEE.es = [np.array([0.5, 0.5]),  # first consumer's endowment\n         np.array([1, 1])]  # second consumer's endowment\n\np, c_s, μ_s = EE.competitive_equilibrium()\n\nprint('Competitive equilibrium price vector:', p)\nprint('Competitive equilibrium allocation:', c_s)\n\nNow let’s construct an autarky (i.e., no-trade) equilibrium.\n\nEE.bs = [np.array([4, 6]),  # first consumer's bliss points\n      np.array([6, 4])]  # second consumer's bliss points\n\nEE.es = [np.array([0, 2]),  # first consumer's endowment\n      np.array([2, 0])]  # second consumer's endowment\n\np, c_s, μ_s = EE.competitive_equilibrium()\n\nprint('Competitive equilibrium price vector:', p)\nprint('Competitive equilibrium allocation:', c_s)\n\nNow let’s redistribute endowments before trade.\n\nbs = [np.array([5, 5]),  # first consumer's bliss points\n      np.array([5, 5])]  # second consumer's bliss points\n\nes = [np.array([1, 1]),  # first consumer's endowment\n      np.array([1, 1])]  # second consumer's endowment\n\nWs = [0.5, -0.5]\nEE_new = ExchangeEconomy(Π, bs, es, Ws)\np, c_s, μ_s = EE_new.competitive_equilibrium()\n\nprint('Competitive equilibrium price vector:', p)\nprint('Competitive equilibrium allocation:', c_s)\n\n","type":"content","url":"/supply-demand-heterogeneity#two-person-economy-without-production","position":15},{"hierarchy":{"lvl1":"Market Equilibrium with Heterogeneity","lvl3":"A dynamic economy","lvl2":"Implementation"},"type":"lvl3","url":"/supply-demand-heterogeneity#a-dynamic-economy","position":16},{"hierarchy":{"lvl1":"Market Equilibrium with Heterogeneity","lvl3":"A dynamic economy","lvl2":"Implementation"},"content":"Now let’s use the tricks described above to study a dynamic economy, one with two periods.\n\nbeta = 0.95\n\nΠ = np.array([[1, 0],\n              [0, np.sqrt(beta)]])\n\nbs = [np.array([5, np.sqrt(beta) * 5])]\n\nes = [np.array([1, 1])]\n\nEE_DE = ExchangeEconomy(Π, bs, es)\np, c_s, μ_s = EE_DE.competitive_equilibrium()\n\nprint('Competitive equilibrium price vector:', p)\nprint('Competitive equilibrium allocation:', c_s)\n\n","type":"content","url":"/supply-demand-heterogeneity#a-dynamic-economy","position":17},{"hierarchy":{"lvl1":"Market Equilibrium with Heterogeneity","lvl3":"Risk economy with arrow securities","lvl2":"Implementation"},"type":"lvl3","url":"/supply-demand-heterogeneity#risk-economy-with-arrow-securities","position":18},{"hierarchy":{"lvl1":"Market Equilibrium with Heterogeneity","lvl3":"Risk economy with arrow securities","lvl2":"Implementation"},"content":"We use the tricks described above to interpret  c_1, c_2 as “Arrow securities” that are state-contingent claims to consumption goods.\n\nprob = 0.7\n\nΠ = np.array([[np.sqrt(prob), 0],\n              [0, np.sqrt(1 - prob)]])\n\nbs = [np.array([np.sqrt(prob) * 5, np.sqrt(1 - prob) * 5]),\n      np.array([np.sqrt(prob) * 5, np.sqrt(1 - prob) * 5])]\n\nes = [np.array([1, 0]),\n      np.array([0, 1])]\n\nEE_AS = ExchangeEconomy(Π, bs, es)\np, c_s, μ_s = EE_AS.competitive_equilibrium()\n\nprint('Competitive equilibrium price vector:', p)\nprint('Competitive equilibrium allocation:', c_s)\n\n","type":"content","url":"/supply-demand-heterogeneity#risk-economy-with-arrow-securities","position":19},{"hierarchy":{"lvl1":"Market Equilibrium with Heterogeneity","lvl2":"Deducing a representative consumer"},"type":"lvl2","url":"/supply-demand-heterogeneity#deducing-a-representative-consumer","position":20},{"hierarchy":{"lvl1":"Market Equilibrium with Heterogeneity","lvl2":"Deducing a representative consumer"},"content":"In the class of multiple consumer economies that we are studying here, it turns out that there\nexists a single representative consumer whose preferences and endowments can be deduced from lists of preferences and endowments for separate individual consumers.\n\nConsider a multiple consumer economy with initial distribution of wealth W_i satisfying \\sum_i W_{i}=0\n\nWe allow an initial redistribution of wealth.\n\nWe have the following objects\n\nThe demand curve:c_{i}=\\Pi^{-1}b_{i}-(\\Pi^{\\top}\\Pi)^{-1}\\mu_{i}p\n\nThe marginal utility of wealth:\\mu_{i}=\\frac{-W_{i}+p^{\\top}\\left(\\Pi^{-1}b_{i}-e_{i}\\right)}{p^{\\top}(\\Pi^{\\top}\\Pi)^{-1}p}\n\nMarket clearing:\\sum c_{i}=\\sum e_{i}\n\nDenote aggregate consumption \\sum_i c_{i}=c and \\sum_i \\mu_i = \\mu.\n\nMarket clearing requires\\Pi^{-1}\\left(\\sum_{i}b_{i}\\right)-(\\Pi^{\\top}\\Pi)^{-1}p\\left(\\sum_{i}\\mu_{i}\\right)=\\sum_{i}e_{i}\n\nwhich, after a few steps, leads top=\\mu^{-1}\\left(\\Pi^{\\top}b-\\Pi^{\\top}\\Pi e\\right)\n\nwhere\\mu = \\sum_i\\mu_{i}=\\frac{0 + p^{\\top}\\left(\\Pi^{-1}b-e\\right)}{p^{\\top}(\\Pi^{\\top}\\Pi)^{-1}p}.\n\nNow consider the representative consumer economy specified above.\n\nDenote the marginal utility of wealth of the representative consumer by \\tilde{\\mu}.\n\nThe demand function isc=\\Pi^{-1}b-(\\Pi^{\\top}\\Pi)^{-1}\\tilde{\\mu} p\n\nSubstituting this into the budget constraint gives\\tilde{\\mu}=\\frac{p^{\\top}\\left(\\Pi^{-1}b-e\\right)}{p^{\\top}(\\Pi^{\\top}\\Pi)^{-1}p}\n\nIn an equilibrium c=e, sop=\\tilde{\\mu}^{-1}(\\Pi^{\\top}b-\\Pi^{\\top}\\Pi e)\n\nThus, we have  verified that, up to the choice of a numeraire in which to express absolute prices, the price\nvector in our representative consumer economy is the same as that in an underlying  economy with multiple consumers.","type":"content","url":"/supply-demand-heterogeneity#deducing-a-representative-consumer","position":21},{"hierarchy":{"lvl1":"Supply and Demand with Many Goods"},"type":"lvl1","url":"/supply-demand-multiple-goods","position":0},{"hierarchy":{"lvl1":"Supply and Demand with Many Goods"},"content":"","type":"content","url":"/supply-demand-multiple-goods","position":1},{"hierarchy":{"lvl1":"Supply and Demand with Many Goods","lvl2":"Overview"},"type":"lvl2","url":"/supply-demand-multiple-goods#overview","position":2},{"hierarchy":{"lvl1":"Supply and Demand with Many Goods","lvl2":"Overview"},"content":"In a \n\nprevious lecture we studied supply, demand\nand welfare in a market with a single consumption good.\n\nIn this lecture, we study a setting with n goods and n corresponding prices.\n\nKey infrastructure concepts that we’ll encounter in this lecture are\n\ninverse demand curves\n\nmarginal utilities of wealth\n\ninverse supply curves\n\nconsumer surplus\n\nproducer surplus\n\nsocial welfare as a sum of consumer and producer surpluses\n\ncompetitive equilibrium\n\nWe will provide a version of the \n\nfirst fundamental welfare theorem, which was formulated by\n\nLeon Walras\n\nFrancis Ysidro Edgeworth\n\nVilfredo Pareto\n\nImportant extensions to the key ideas were obtained by\n\nAbba Lerner\n\nHarold Hotelling\n\nPaul Samuelson\n\nKenneth Arrow\n\nGerard Debreu\n\nWe shall describe two classic welfare theorems:\n\nfirst welfare theorem: for a given distribution of wealth among consumers, a competitive  equilibrium  allocation of goods solves a  social planning problem.\n\nsecond welfare theorem: An allocation of goods to consumers that solves a social planning problem can be supported by a competitive equilibrium with an appropriate initial distribution of  wealth.\n\nAs usual, we start by importing some Python modules.\n\n# import some packages\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.linalg import inv\n\n","type":"content","url":"/supply-demand-multiple-goods#overview","position":3},{"hierarchy":{"lvl1":"Supply and Demand with Many Goods","lvl2":"Formulas from linear algebra"},"type":"lvl2","url":"/supply-demand-multiple-goods#formulas-from-linear-algebra","position":4},{"hierarchy":{"lvl1":"Supply and Demand with Many Goods","lvl2":"Formulas from linear algebra"},"content":"We shall apply formulas from linear algebra that\n\ndifferentiate an inner product with respect to each vector\n\ndifferentiate a product of a matrix and a vector with respect to the vector\n\ndifferentiate a quadratic form in a vector with respect to the vector\n\nWhere a is an n \\times 1 vector, A is an n \\times n matrix, and x is an n \\times 1 vector:\\frac{\\partial a^\\top x }{\\partial x} = \\frac{\\partial x^\\top a }{\\partial x} = a\\frac{\\partial A x} {\\partial x} = A\\frac{\\partial x^\\top A x}{\\partial x} = (A + A^\\top)x","type":"content","url":"/supply-demand-multiple-goods#formulas-from-linear-algebra","position":5},{"hierarchy":{"lvl1":"Supply and Demand with Many Goods","lvl2":"From utility function to demand curve"},"type":"lvl2","url":"/supply-demand-multiple-goods#from-utility-function-to-demand-curve","position":6},{"hierarchy":{"lvl1":"Supply and Demand with Many Goods","lvl2":"From utility function to demand curve"},"content":"Our study of consumers will use the following primitives\n\n\\Pi be an m \\times n matrix,\n\nb be an m \\times 1 vector of bliss points,\n\ne be an n \\times 1 vector of endowments, and\n\nWe will analyze endogenous objects c and p, where\n\nc is an n \\times 1 vector of consumptions of various goods,\n\np is an n \\times 1 vector of prices\n\nThe matrix \\Pi describes a consumer’s willingness to substitute one good for every other good.\n\nWe assume that \\Pi has linearly independent columns, which implies that \\Pi^\\top \\Pi is a positive definite matrix.\n\nit follows that \\Pi^\\top \\Pi has an inverse.\n\nWe shall see below that (\\Pi^\\top \\Pi)^{-1} is a matrix of slopes of (compensated) demand curves for c with respect to a vector of prices:\\frac{\\partial c } {\\partial p} = (\\Pi^\\top \\Pi)^{-1}\n\nA consumer faces p as a price taker and chooses c to maximize the utility function- \\frac{1}{2} (\\Pi c -b) ^\\top (\\Pi c -b )\n\nsubject to the budget constraintp^\\top (c -e ) = 0\n\nWe shall specify examples in which \\Pi and b are such that it typically happens that\\Pi c \\ll b\n\nThis means that the consumer has much less of each good than he wants.\n\nThe deviation in \n\n(7) will ultimately assure us that competitive equilibrium prices are positive.\n\n","type":"content","url":"/supply-demand-multiple-goods#from-utility-function-to-demand-curve","position":7},{"hierarchy":{"lvl1":"Supply and Demand with Many Goods","lvl3":"Demand curve implied by constrained utility maximization","lvl2":"From utility function to demand curve"},"type":"lvl3","url":"/supply-demand-multiple-goods#demand-curve-implied-by-constrained-utility-maximization","position":8},{"hierarchy":{"lvl1":"Supply and Demand with Many Goods","lvl3":"Demand curve implied by constrained utility maximization","lvl2":"From utility function to demand curve"},"content":"For now, we assume that the budget constraint is \n\n(6).\n\nSo we’ll be deriving what is known as  a Marshallian demand curve.\n\nOur aim is to maximize \n\n(5) subject to \n\n(6).\n\nForm a LagrangianL = - \\frac{1}{2} (\\Pi c -b)^\\top (\\Pi c -b ) + \\mu [p^\\top (e-c)]\n\nwhere \\mu is a Lagrange multiplier that is often called a marginal utility of wealth.\n\nThe consumer chooses c to maximize L and \\mu to minimize it.\n\nFirst-order conditions for c are\\frac{\\partial L} {\\partial c}\n    = - \\Pi^\\top \\Pi c + \\Pi^\\top b - \\mu p = 0\n\nso that, given \\mu, the consumer choosesc = (\\Pi^\\top \\Pi )^{-1}(\\Pi^\\top b -  \\mu p )\n\nSubstituting \n\n(10) into budget constraint \n\n(6) and solving for \\mu gives\\mu(p,e) = \\frac{p^\\top ( \\Pi^\\top \\Pi )^{-1} \\Pi^\\top b - p^\\top e}{p^\\top (\\Pi^\\top \\Pi )^{-1} p}.\n\nEquation \n\n(11) tells how marginal utility of wealth depends on the endowment vector e and the price vector p.\n\nNote\n\nEquation \n\n(11) is a consequence of imposing that p^\\top (c - e) = 0.\n\nWe could instead take \\mu as a parameter and use \n\n(10) and the budget constraint \n\n(13) to solve for wealth.\n\nWhich way we proceed determines whether we are constructing a Marshallian or Hicksian demand curve.","type":"content","url":"/supply-demand-multiple-goods#demand-curve-implied-by-constrained-utility-maximization","position":9},{"hierarchy":{"lvl1":"Supply and Demand with Many Goods","lvl2":"Endowment economy"},"type":"lvl2","url":"/supply-demand-multiple-goods#endowment-economy","position":10},{"hierarchy":{"lvl1":"Supply and Demand with Many Goods","lvl2":"Endowment economy"},"content":"We now study a pure-exchange economy, or what is sometimes called an endowment economy.\n\nConsider a single-consumer, multiple-goods economy without production.\n\nThe only source of goods is the single consumer’s endowment vector e.\n\nA competitive equilibrium price vector induces the consumer to choose c=e.\n\nThis implies that the equilibrium price vector satisfiesp = \\mu^{-1} (\\Pi^\\top b - \\Pi^\\top \\Pi e)\n\nIn the present case where we have imposed budget constraint in the form \n\n(6), we are free to normalize the price vector by setting the marginal utility of wealth \\mu =1 (or any other value for that matter).\n\nThis amounts to choosing a common unit (or numeraire) in which prices of all goods are expressed.\n\n(Doubling all prices will affect neither quantities nor relative prices.)\n\nWe’ll set \\mu=1.\n\nVerify that setting \\mu=1 in \n\n(10) implies that formula \n\n(11) is satisfied.\n\nVerify that setting  \\mu=2 in \n\n(10) also implies that formula\n\n\n(11) is satisfied.\n\nHere is a class that computes competitive equilibria for our economy.\n\nclass ExchangeEconomy:\n    \n    def __init__(self, \n                 Π, \n                 b, \n                 e,\n                 thres=1.5):\n        \"\"\"\n        Set up the environment for an exchange economy\n\n        Args:\n            Π (np.array): shared matrix of substitution\n            b (list):  the consumer's bliss point\n            e (list):  the consumer's endowment\n            thres (float): a threshold to check p >> Π e condition\n        \"\"\"\n\n        # check non-satiation\n        if np.min(b / np.max(Π @ e)) <= thres:\n            raise Exception('set bliss points further away')\n\n\n        self.Π, self.b, self.e = Π, b, e\n\n    \n    def competitive_equilibrium(self):\n        \"\"\"\n        Compute the competitive equilibrium prices and allocation\n        \"\"\"\n        Π, b, e = self.Π, self.b, self.e\n\n        # compute price vector with μ=1\n        p = Π.T @ b - Π.T @ Π @ e\n        \n        # compute consumption vector\n        slope_dc = inv(Π.T @ Π)\n        Π_inv = inv(Π)\n        c = Π_inv @ b - slope_dc @ p\n\n        if any(c < 0):\n            print('allocation: ', c)\n            raise Exception('negative allocation: equilibrium does not exist')\n\n        return p, c\n\n","type":"content","url":"/supply-demand-multiple-goods#endowment-economy","position":11},{"hierarchy":{"lvl1":"Supply and Demand with Many Goods","lvl2":"Digression: Marshallian and Hicksian demand curves"},"type":"lvl2","url":"/supply-demand-multiple-goods#digression-marshallian-and-hicksian-demand-curves","position":12},{"hierarchy":{"lvl1":"Supply and Demand with Many Goods","lvl2":"Digression: Marshallian and Hicksian demand curves"},"content":"Sometimes we’ll use budget constraint \n\n(6) in situations in which a consumer’s endowment vector e is his only source of income.\n\nOther times we’ll instead assume that the consumer has another source of income (positive or negative) and write his budget constraint asp ^\\top (c -e ) = w\n\nwhere w is measured in “dollars” (or some other numeraire) and component p_i of the price vector is measured in dollars per unit of good i.\n\nWhether the consumer’s budget constraint is \n\n(6) or \n\n(13) and whether we take w as a free parameter or instead as an endogenous variable will affect the consumer’s marginal utility of wealth.\n\nConsequently, how we set \\mu determines whether we are constructing\n\na Marshallian demand curve, as when we use \n\n(6) and solve for \\mu using equation \n\n(11) above, or\n\na Hicksian demand curve, as when we treat \\mu as a fixed parameter and solve for w from \n\n(13).\n\nMarshallian and Hicksian demand curves contemplate different mental experiments:\n\nFor a Marshallian demand curve, hypothetical changes in a price vector have both substitution and income effects\n\nincome effects are consequences of changes in p^\\top e associated with the change in the price vector\n\nFor a Hicksian demand curve, hypothetical price vector changes have only substitution effects\n\nchanges in the price vector leave the p^\\top e + w unaltered because we freeze \\mu and solve for w\n\nSometimes a Hicksian demand curve is called a compensated demand curve in order to emphasize that, to disarm the income (or wealth) effect associated with a price change, the consumer’s wealth w is adjusted.\n\nWe’ll discuss these distinct demand curves more below.\n\n","type":"content","url":"/supply-demand-multiple-goods#digression-marshallian-and-hicksian-demand-curves","position":13},{"hierarchy":{"lvl1":"Supply and Demand with Many Goods","lvl2":"Dynamics and risk as special cases"},"type":"lvl2","url":"/supply-demand-multiple-goods#dynamics-and-risk-as-special-cases","position":14},{"hierarchy":{"lvl1":"Supply and Demand with Many Goods","lvl2":"Dynamics and risk as special cases"},"content":"Special cases of our n-good pure exchange model can be created to represent\n\ndynamics --- by putting different dates on different commodities\n\nrisk --- by interpreting delivery of goods as being contingent on states of the world whose realizations are described by a known probability distribution\n\nLet’s illustrate how.","type":"content","url":"/supply-demand-multiple-goods#dynamics-and-risk-as-special-cases","position":15},{"hierarchy":{"lvl1":"Supply and Demand with Many Goods","lvl3":"Dynamics","lvl2":"Dynamics and risk as special cases"},"type":"lvl3","url":"/supply-demand-multiple-goods#dynamics","position":16},{"hierarchy":{"lvl1":"Supply and Demand with Many Goods","lvl3":"Dynamics","lvl2":"Dynamics and risk as special cases"},"content":"Suppose that we want to represent a utility function- \\frac{1}{2} [(c_1 - b_1)^2 + \\beta (c_2 - b_2)^2]\n\nwhere \\beta \\in (0,1) is a discount factor, c_1 is consumption at time 1 and c_2 is consumption at time 2.\n\nTo capture this with our quadratic utility function \n\n(5), set\\Pi = \\begin{bmatrix} 1 & 0 \\cr\n         0 & \\sqrt{\\beta} \\end{bmatrix}e = \\begin{bmatrix} e_1 \\cr e_2 \\end{bmatrix}\n\nandb = \\begin{bmatrix} b_1 \\cr \\sqrt{\\beta} b_2\n\\end{bmatrix}\n\nThe budget constraint \n\n(6) becomesp_1 c_1 + p_2 c_2 = p_1 e_1 + p_2 e_2\n\nThe left side is the discounted present value of consumption.\n\nThe right side is the discounted present value of the consumer’s endowment.\n\nThe relative price  \\frac{p_1}{p_2} has units of time 2 goods per unit of time 1 goods.\n\nConsequently,(1+r) := R := \\frac{p_1}{p_2}\n\nis the gross interest rate and r is the net interest rate.\n\nHere is an example.\n\nbeta = 0.95\n\nΠ = np.array([[1, 0],\n              [0, np.sqrt(beta)]])\n\nb = np.array([5, np.sqrt(beta) * 5])\n\ne = np.array([1, 1])\n\ndynamics = ExchangeEconomy(Π, b, e)\np, c = dynamics.competitive_equilibrium()\n\nprint('Competitive equilibrium price vector:', p)\nprint('Competitive equilibrium allocation:', c)\n\n","type":"content","url":"/supply-demand-multiple-goods#dynamics","position":17},{"hierarchy":{"lvl1":"Supply and Demand with Many Goods","lvl3":"Risk and state-contingent claims","lvl2":"Dynamics and risk as special cases"},"type":"lvl3","url":"/supply-demand-multiple-goods#risk-and-state-contingent-claims","position":18},{"hierarchy":{"lvl1":"Supply and Demand with Many Goods","lvl3":"Risk and state-contingent claims","lvl2":"Dynamics and risk as special cases"},"content":"We study risk in the context of a static environment, meaning that there is only one period.\n\nBy risk we mean that an outcome is not known in advance, but that it is governed by a known probability distribution.\n\nAs an example, our consumer confronts risk means in particular that\n\nthere are two states of nature, 1 and 2.\n\nthe consumer knows that the probability that state 1 occurs is \\lambda.\n\nthe consumer knows that the probability that state 2 occurs is (1-\\lambda).\n\nBefore the outcome is realized, the consumer’s expected utility is- \\frac{1}{2} [\\lambda (c_1 - b_1)^2 + (1-\\lambda)(c_2 - b_2)^2]\n\nwhere\n\nc_1 is consumption in state 1\n\nc_2 is consumption in state 2\n\nTo capture these preferences we set\\Pi = \\begin{bmatrix} \\sqrt{\\lambda} & 0 \\cr\n                     0  & \\sqrt{1-\\lambda} \\end{bmatrix}e = \\begin{bmatrix} e_1 \\cr e_2 \\end{bmatrix}\n\nb = \\begin{bmatrix} \\sqrt{\\lambda}b_1 \\cr \\sqrt{1-\\lambda}b_2 \\end{bmatrix}\n\nA consumer’s endowment vector isc = \\begin{bmatrix} c_1 \\cr c_2 \\end{bmatrix}\n\nA price vector isp = \\begin{bmatrix} p_1 \\cr p_2 \\end{bmatrix}\n\nwhere p_i is the price of one unit of consumption in state i \\in \\{1, 2\\}.\n\nThe state-contingent goods being traded are often called Arrow securities.\n\nBefore the random state of the world i is realized, the consumer sells his/her state-contingent endowment bundle and purchases a state-contingent consumption bundle.\n\nTrading such state-contingent goods is one way economists often model insurance.\n\nWe use the tricks described above to interpret  c_1, c_2 as “Arrow securities” that are state-contingent claims to consumption goods.\n\nHere is an instance of the risk economy:\n\nprob = 0.2\n\nΠ = np.array([[np.sqrt(prob), 0],\n              [0, np.sqrt(1 - prob)]])\n\nb = np.array([np.sqrt(prob) * 5, np.sqrt(1 - prob) * 5])\n\ne = np.array([1, 1])\n\nrisk = ExchangeEconomy(Π, b, e)\np, c = risk.competitive_equilibrium()\n\nprint('Competitive equilibrium price vector:', p)\nprint('Competitive equilibrium allocation:', c)\n\nConsider the instance above.\n\nPlease numerically study how each of the following cases affects the equilibrium prices and allocations:\n\nthe consumer gets poorer,\n\nthey like the first good more, or\n\nthe probability that state 1 occurs is higher.\n\nHints. For each case choose some parameter e, b, \\text{ or } \\lambda different from the instance.\n\nSolution to \n\nExercise 3\n\nFirst consider when the consumer is poorer.\n\nHere we just decrease the endowment.\n\nrisk.e = np.array([0.5, 0.5])\n\np, c = risk.competitive_equilibrium()\n\nprint('Competitive equilibrium price vector:', p)\nprint('Competitive equilibrium allocation:', c)\n\nIf the consumer likes the first (or second) good more, then we can set a larger bliss value for good 1.\n\nrisk.b = np.array([np.sqrt(prob) * 6, np.sqrt(1 - prob) * 5])\np, c = risk.competitive_equilibrium()\n\nprint('Competitive equilibrium price vector:', p)\nprint('Competitive equilibrium allocation:', c)\n\nIncrease the probability that state 1 occurs.\n\nprob = 0.8\n\nΠ = np.array([[np.sqrt(prob), 0],\n              [0, np.sqrt(1 - prob)]])\n\nb = np.array([np.sqrt(prob) * 5, np.sqrt(1 - prob) * 5])\n\ne = np.array([1, 1])\n\nrisk = ExchangeEconomy(Π, b, e)\np, c = risk.competitive_equilibrium()\n\nprint('Competitive equilibrium price vector:', p)\nprint('Competitive equilibrium allocation:', c)\n\n\n\n","type":"content","url":"/supply-demand-multiple-goods#risk-and-state-contingent-claims","position":19},{"hierarchy":{"lvl1":"Supply and Demand with Many Goods","lvl2":"Economies with endogenous supplies of goods"},"type":"lvl2","url":"/supply-demand-multiple-goods#economies-with-endogenous-supplies-of-goods","position":20},{"hierarchy":{"lvl1":"Supply and Demand with Many Goods","lvl2":"Economies with endogenous supplies of goods"},"content":"Up to now we have described a pure exchange economy in which endowments of goods are exogenous, meaning that they are taken as given from outside the model.","type":"content","url":"/supply-demand-multiple-goods#economies-with-endogenous-supplies-of-goods","position":21},{"hierarchy":{"lvl1":"Supply and Demand with Many Goods","lvl3":"Supply curve of a competitive firm","lvl2":"Economies with endogenous supplies of goods"},"type":"lvl3","url":"/supply-demand-multiple-goods#supply-curve-of-a-competitive-firm","position":22},{"hierarchy":{"lvl1":"Supply and Demand with Many Goods","lvl3":"Supply curve of a competitive firm","lvl2":"Economies with endogenous supplies of goods"},"content":"A competitive firm that can produce goods takes a price vector p as given and chooses a quantity q\nto maximize total revenue minus total costs.\n\nThe firm’s total revenue equals p^\\top q and its total cost equals C(q) where C(q) is a total cost functionC(q) = h ^\\top q +  \\frac{1}{2} q^\\top J q\n\nand J is a positive definite matrix.\n\nSo the firm’s profits arep^\\top q - C(q)\n\nAn n\\times 1 vector of marginal costs is\\frac{\\partial C(q)}{\\partial q} = h + H q\n\nwhereH =  \\frac{1}{2} (J + J^\\top)\n\nThe firm maximizes total profits by setting marginal revenue to marginal costs.\n\nAn n \\times 1 vector of marginal revenues for the price-taking firm is \\frac{\\partial p^\\top q}\n{\\partial q} = p .\n\nSo price equals marginal revenue for our price-taking competitive firm.\n\nThis leads to the following inverse supply curve for the competitive firm:p = h + H q","type":"content","url":"/supply-demand-multiple-goods#supply-curve-of-a-competitive-firm","position":23},{"hierarchy":{"lvl1":"Supply and Demand with Many Goods","lvl3":"Competitive equilibrium","lvl2":"Economies with endogenous supplies of goods"},"type":"lvl3","url":"/supply-demand-multiple-goods#competitive-equilibrium","position":24},{"hierarchy":{"lvl1":"Supply and Demand with Many Goods","lvl3":"Competitive equilibrium","lvl2":"Economies with endogenous supplies of goods"},"content":"To compute a competitive equilibrium for a production economy where demand curve is pinned down by the marginal utility of wealth \\mu, we first compute an allocation by solving a planning problem.\n\nThen we compute the equilibrium price vector using the inverse demand or supply curve.","type":"content","url":"/supply-demand-multiple-goods#competitive-equilibrium","position":25},{"hierarchy":{"lvl1":"Supply and Demand with Many Goods","lvl4":"\\mu=1 warmup","lvl3":"Competitive equilibrium","lvl2":"Economies with endogenous supplies of goods"},"type":"lvl4","url":"/supply-demand-multiple-goods#id-mu-1-warmup","position":26},{"hierarchy":{"lvl1":"Supply and Demand with Many Goods","lvl4":"\\mu=1 warmup","lvl3":"Competitive equilibrium","lvl2":"Economies with endogenous supplies of goods"},"content":"As a special case, let’s pin down a demand curve by setting the marginal utility of wealth \\mu =1.\n\nEquating supply price to demand price and letting q=c we getp = h + H c = \\Pi^\\top b - \\Pi^\\top \\Pi c ,\n\nwhich implies the equilibrium quantity vectorc = (\\Pi^\\top \\Pi + H )^{-1} ( \\Pi^\\top b - h)\n\nThis equation is the counterpart of equilibrium quantity \n\n(15) for the scalar n=1 model with which we began.","type":"content","url":"/supply-demand-multiple-goods#id-mu-1-warmup","position":27},{"hierarchy":{"lvl1":"Supply and Demand with Many Goods","lvl4":"General \\mu\\neq 1 case","lvl3":"Competitive equilibrium","lvl2":"Economies with endogenous supplies of goods"},"type":"lvl4","url":"/supply-demand-multiple-goods#general-mu-neq-1-case","position":28},{"hierarchy":{"lvl1":"Supply and Demand with Many Goods","lvl4":"General \\mu\\neq 1 case","lvl3":"Competitive equilibrium","lvl2":"Economies with endogenous supplies of goods"},"content":"Now let’s extend the preceding analysis to a more\ngeneral case by allowing \\mu \\neq 1.\n\nThen the inverse demand curve isp = \\mu^{-1} [\\Pi^\\top b - \\Pi^\\top \\Pi c]\n\nEquating this to the inverse supply curve, letting q=c and solving\nfor c givesc = [\\Pi^\\top \\Pi + \\mu H]^{-1} [ \\Pi^\\top b - \\mu h]\n\n","type":"content","url":"/supply-demand-multiple-goods#general-mu-neq-1-case","position":29},{"hierarchy":{"lvl1":"Supply and Demand with Many Goods","lvl3":"Implementation","lvl2":"Economies with endogenous supplies of goods"},"type":"lvl3","url":"/supply-demand-multiple-goods#implementation","position":30},{"hierarchy":{"lvl1":"Supply and Demand with Many Goods","lvl3":"Implementation","lvl2":"Economies with endogenous supplies of goods"},"content":"A Production Economy will consist of\n\na single person that we’ll interpret as a representative consumer\n\na single set of production costs\n\na multiplier \\mu that weights “consumers” versus “producers” in a planner’s welfare function, as described above in the main text\n\nan n \\times 1 vector p of competitive equilibrium prices\n\nan n \\times 1 vector c of competitive equilibrium quantities\n\nconsumer surplus\n\nproducer surplus\n\nHere we define a class ProductionEconomy.\n\nclass ProductionEconomy:\n    \n    def __init__(self, \n                 Π, \n                 b, \n                 h, \n                 J, \n                 μ):\n        \"\"\"\n        Set up the environment for a production economy\n\n        Args:\n            Π (np.ndarray): matrix of substitution\n            b (np.array): bliss points\n            h (np.array): h in cost func\n            J (np.ndarray): J in cost func\n            μ (float): welfare weight of the corresponding planning problem\n        \"\"\"\n        self.n = len(b)\n        self.Π, self.b, self.h, self.J, self.μ = Π, b, h, J, μ\n        \n    def competitive_equilibrium(self):\n        \"\"\"\n        Compute a competitive equilibrium of the production economy\n        \"\"\"\n        Π, b, h, μ, J = self.Π, self.b, self.h, self.μ, self.J\n        H = .5 * (J + J.T)\n\n        # allocation\n        c = inv(Π.T @ Π + μ * H) @ (Π.T @ b - μ * h)\n\n        # price\n        p = 1 / μ * (Π.T @ b - Π.T @ Π @ c)\n\n        # check non-satiation\n        if any(Π @ c - b >= 0):\n            raise Exception('invalid result: set bliss points further away')\n\n        return c, p\n\n    def compute_surplus(self):\n        \"\"\"\n        Compute consumer and producer surplus for single good case\n        \"\"\"\n        if self.n != 1:\n            raise Exception('not single good')\n        h, J, Π, b, μ = self.h.item(), self.J.item(), self.Π.item(), self.b.item(), self.μ\n        H = J\n\n        # supply/demand curve coefficients\n        s0, s1 = h, H\n        d0, d1 = 1 / μ * Π * b, 1 / μ * Π**2\n\n        # competitive equilibrium\n        c, p = self.competitive_equilibrium()\n\n        # calculate surplus\n        c_surplus = d0 * c - .5 * d1 * c**2 - p * c\n        p_surplus = p * c - s0 * c - .5 * s1 * c**2\n\n        return c_surplus, p_surplus\n\nThen define a function that plots demand and supply curves and labels surpluses and equilibrium.\n\ndef plot_competitive_equilibrium(PE):\n    \"\"\"\n    Plot demand and supply curves, producer/consumer surpluses, and equilibrium for\n    a single good production economy\n\n    Args:\n        PE (class): A initialized production economy class\n    \"\"\"\n    # get singleton value\n    J, h, Π, b, μ = PE.J.item(), PE.h.item(), PE.Π.item(), PE.b.item(), PE.μ\n    H = J\n\n    # compute competitive equilibrium\n    c, p = PE.competitive_equilibrium()\n    c, p = c.item(), p.item()\n\n    # inverse supply/demand curve\n    supply_inv = lambda x: h + H * x\n    demand_inv = lambda x: 1 / μ * (Π * b - Π * Π * x)\n\n    xs = np.linspace(0, 2 * c, 100)\n    ps = np.ones(100) * p\n    supply_curve = supply_inv(xs)\n    demand_curve = demand_inv(xs)\n\n    # plot\n    plt.figure()\n    plt.plot(xs, supply_curve, label='Supply', color='#020060')\n    plt.plot(xs, demand_curve, label='Demand', color='#600001')\n\n    plt.fill_between(xs[xs <= c], demand_curve[xs <= c], ps[xs <= c], label='Consumer surplus', color='#EED1CF')\n    plt.fill_between(xs[xs <= c], supply_curve[xs <= c], ps[xs <= c], label='Producer surplus', color='#E6E6F5')\n\n    plt.vlines(c, 0, p, linestyle=\"dashed\", color='black', alpha=0.7)\n    plt.hlines(p, 0, c, linestyle=\"dashed\", color='black', alpha=0.7)\n    plt.scatter(c, p, zorder=10, label='Competitive equilibrium', color='#600001')\n\n    plt.legend(loc='upper right')\n    plt.margins(x=0, y=0)\n    plt.ylim(0)\n    plt.xlabel('Quantity')\n    plt.ylabel('Price')\n    plt.show()\n\n","type":"content","url":"/supply-demand-multiple-goods#implementation","position":31},{"hierarchy":{"lvl1":"Supply and Demand with Many Goods","lvl4":"Example: single agent with one good and production","lvl3":"Implementation","lvl2":"Economies with endogenous supplies of goods"},"type":"lvl4","url":"/supply-demand-multiple-goods#example-single-agent-with-one-good-and-production","position":32},{"hierarchy":{"lvl1":"Supply and Demand with Many Goods","lvl4":"Example: single agent with one good and production","lvl3":"Implementation","lvl2":"Economies with endogenous supplies of goods"},"content":"Now let’s construct an example of a production economy with one good.\n\nTo do this we\n\nspecify a single person and a cost curve in a way that let’s us replicate the simple single-good supply demand example with which we started\n\ncompute equilibrium p and c and consumer and producer surpluses\n\ndraw graphs of both surpluses\n\ndo experiments in which we shift b and watch what happens to p, c.\n\nΠ = np.array([[1]])  # the matrix now is a singleton\nb = np.array([10])\nh = np.array([0.5])\nJ = np.array([[1]])\nμ = 1\n\nPE = ProductionEconomy(Π, b, h, J, μ)\nc, p = PE.competitive_equilibrium()\n\nprint('Competitive equilibrium price:', p.item())\nprint('Competitive equilibrium allocation:', c.item())\n\n# plot\nplot_competitive_equilibrium(PE)\n\n\n\nc_surplus, p_surplus = PE.compute_surplus()\n\nprint('Consumer surplus:', c_surplus.item())\nprint('Producer surplus:', p_surplus.item())\n\nLet’s give the consumer a lower welfare weight by raising \\mu.\n\nPE.μ = 2\nc, p = PE.competitive_equilibrium()\n\nprint('Competitive equilibrium price:', p.item())\nprint('Competitive equilibrium allocation:', c.item())\n\n# plot\nplot_competitive_equilibrium(PE)\n\n\n\nc_surplus, p_surplus = PE.compute_surplus()\n\nprint('Consumer surplus:', c_surplus.item())\nprint('Producer surplus:', p_surplus.item())\n\nNow we change the bliss point so that the consumer derives more utility from consumption.\n\nPE.μ = 1\nPE.b = PE.b * 1.5\nc, p = PE.competitive_equilibrium()\n\nprint('Competitive equilibrium price:', p.item())\nprint('Competitive equilibrium allocation:', c.item())\n\n# plot\nplot_competitive_equilibrium(PE)\n\nThis raises both the equilibrium price and quantity.","type":"content","url":"/supply-demand-multiple-goods#example-single-agent-with-one-good-and-production","position":33},{"hierarchy":{"lvl1":"Supply and Demand with Many Goods","lvl4":"Example: single agent two-good economy with production","lvl3":"Implementation","lvl2":"Economies with endogenous supplies of goods"},"type":"lvl4","url":"/supply-demand-multiple-goods#example-single-agent-two-good-economy-with-production","position":34},{"hierarchy":{"lvl1":"Supply and Demand with Many Goods","lvl4":"Example: single agent two-good economy with production","lvl3":"Implementation","lvl2":"Economies with endogenous supplies of goods"},"content":"we’ll do some experiments like those above\n\nwe can do experiments with a diagonal \\Pi and also with a non-diagonal \\Pi matrices to study how cross-slopes affect responses of p and c to various shifts in b (TODO)\n\nΠ = np.array([[1, 0],\n              [0, 1]])\n\nb = np.array([10, 10])\n\nh = np.array([0.5, 0.5])\n\nJ = np.array([[1, 0.5],\n              [0.5, 1]])\nμ = 1\n\nPE = ProductionEconomy(Π, b, h, J, μ)\nc, p = PE.competitive_equilibrium()\n\nprint('Competitive equilibrium price:', p)\nprint('Competitive equilibrium allocation:', c)\n\n\n\nPE.b = np.array([12, 10])\n\nc, p = PE.competitive_equilibrium()\n\nprint('Competitive equilibrium price:', p)\nprint('Competitive equilibrium allocation:', c)\n\n\n\nPE.Π = np.array([[1, 0.5],\n                 [0.5, 1]])\n\nPE.b = np.array([10, 10])\n\nc, p = PE.competitive_equilibrium()\n\nprint('Competitive equilibrium price:', p)\nprint('Competitive equilibrium allocation:', c)\n\n\n\nPE.b = np.array([12, 10])\nc, p = PE.competitive_equilibrium()\n\nprint('Competitive equilibrium price:', p)\nprint('Competitive equilibrium allocation:', c)\n\n","type":"content","url":"/supply-demand-multiple-goods#example-single-agent-two-good-economy-with-production","position":35},{"hierarchy":{"lvl1":"Supply and Demand with Many Goods","lvl3":"Digression: a supplier who is a monopolist","lvl2":"Economies with endogenous supplies of goods"},"type":"lvl3","url":"/supply-demand-multiple-goods#digression-a-supplier-who-is-a-monopolist","position":36},{"hierarchy":{"lvl1":"Supply and Demand with Many Goods","lvl3":"Digression: a supplier who is a monopolist","lvl2":"Economies with endogenous supplies of goods"},"content":"A competitive firm is a price-taker who regards the price and therefore its marginal revenue as being beyond its control.\n\nA monopolist knows that it has no competition and can influence the price and its marginal revenue by\nsetting quantity.\n\nA monopolist takes a demand curve and not the price as beyond its control.\n\nThus, instead of being a price-taker, a monopolist sets prices to maximize profits subject to the inverse demand curve\n\n\n(33).\n\nSo the monopolist’s total profits as a function of its output q is[\\mu^{-1} \\Pi^\\top (b - \\Pi q)]^\\top  q - h^\\top q -  \\frac{1}{2} q^\\top J q\n\nAfter finding\nfirst-order necessary conditions for maximizing monopoly profits with respect to q\nand solving them for q, we find that the monopolist setsq = (H + 2 \\mu^{-1} \\Pi^\\top \\Pi)^{-1} (\\mu^{-1} \\Pi^\\top b - h)\n\nWe’ll soon see that a monopolist sets a lower output q than does either a\n\nplanner who chooses q to maximize social welfare\n\na competitive equilibrium\n\nPlease  verify the monopolist’s supply curve \n\n(36).\n\n","type":"content","url":"/supply-demand-multiple-goods#digression-a-supplier-who-is-a-monopolist","position":37},{"hierarchy":{"lvl1":"Supply and Demand with Many Goods","lvl3":"A monopolist","lvl2":"Economies with endogenous supplies of goods"},"type":"lvl3","url":"/supply-demand-multiple-goods#a-monopolist","position":38},{"hierarchy":{"lvl1":"Supply and Demand with Many Goods","lvl3":"A monopolist","lvl2":"Economies with endogenous supplies of goods"},"content":"Let’s consider a monopolist supplier.\n\nWe have included a method in our ProductionEconomy class to compute an equilibrium price and allocation when the supplier is a monopolist.\n\nSince the supplier now has the price-setting power\n\nwe first compute the optimal quantity that solves the monopolist’s profit maximization problem.\n\nThen we back out an equilibrium price from the consumer’s inverse demand curve.\n\nNext, we use a graph for the single good case to illustrate the difference between a competitive equilibrium and an equilibrium with a monopolist supplier.\n\nRecall that in a competitive equilibrium, a price-taking supplier equates marginal revenue p to marginal cost h + Hq.\n\nThis yields a competitive producer’s inverse supply curve.\n\nA monopolist’s marginal revenue is not constant but instead is a non-trivial function of the quantity it sets.\n\nThe monopolist’s marginal revenue isMR(q) = -2\\mu^{-1}\\Pi^{\\top}\\Pi q+\\mu^{-1}\\Pi^{\\top}b,\n\nwhich the monopolist equates to its marginal cost.\n\nThe plot indicates that the monopolist’s sets output  lower than either the competitive equilibrium quantity.\n\nIn a single good case, this equilibrium is associated with a higher price of the good.\n\nclass Monopoly(ProductionEconomy):\n    \n    def __init__(self, \n                 Π, \n                 b, \n                 h, \n                 J, \n                 μ):\n        \"\"\"\n        Inherit all properties and methods from class ProductionEconomy\n        \"\"\"\n        super().__init__(Π, b, h, J, μ)\n        \n\n    def equilibrium_with_monopoly(self):\n        \"\"\"\n        Compute the equilibrium price and allocation when there is a monopolist supplier\n        \"\"\"\n        Π, b, h, μ, J = self.Π, self.b, self.h, self.μ, self.J\n        H = .5 * (J + J.T)\n\n        # allocation\n        q = inv(μ * H + 2 * Π.T @ Π) @ (Π.T @ b - μ * h)\n\n        # price\n        p = 1 / μ * (Π.T @ b - Π.T @ Π @ q)\n\n        if any(Π @ q - b >= 0):\n            raise Exception('invalid result: set bliss points further away')\n\n        return q, p\n\nDefine a function that plots the demand, marginal cost and marginal revenue curves with surpluses and equilibrium labelled.\n\ndef plot_monopoly(M):\n    \"\"\"\n    Plot demand curve, marginal production cost and revenue, surpluses and the\n    equilibrium in a monopolist supplier economy with a single good\n\n    Args:\n        M (class): A class inherits class ProductionEconomy with monopoly\n    \"\"\"\n    # get singleton value\n    J, h, Π, b, μ = M.J.item(), M.h.item(), M.Π.item(), M.b.item(), M.μ\n    H = J\n\n    # compute competitive equilibrium\n    c, p = M.competitive_equilibrium()\n    q, pm = M.equilibrium_with_monopoly()\n    c, p, q, pm = c.item(), p.item(), q.item(), pm.item()\n\n    # compute\n\n    # inverse supply/demand curve\n    marg_cost = lambda x: h + H * x\n    marg_rev = lambda x: -2 * 1 / μ * Π * Π * x + 1 / μ * Π * b\n    demand_inv = lambda x: 1 / μ * (Π * b - Π * Π * x)\n\n    xs = np.linspace(0, 2 * c, 100)\n    pms = np.ones(100) * pm\n    marg_cost_curve = marg_cost(xs)\n    marg_rev_curve = marg_rev(xs)\n    demand_curve = demand_inv(xs)\n\n    # plot\n    plt.figure()\n    plt.plot(xs, marg_cost_curve, label='Marginal cost', color='#020060')\n    plt.plot(xs, marg_rev_curve, label='Marginal revenue', color='#E55B13')\n    plt.plot(xs, demand_curve, label='Demand', color='#600001')\n\n    plt.fill_between(xs[xs <= q], demand_curve[xs <= q], pms[xs <= q], label='Consumer surplus', color='#EED1CF')\n    plt.fill_between(xs[xs <= q], marg_cost_curve[xs <= q], pms[xs <= q], label='Producer surplus', color='#E6E6F5')\n\n    plt.vlines(c, 0, p, linestyle=\"dashed\", color='black', alpha=0.7)\n    plt.hlines(p, 0, c, linestyle=\"dashed\", color='black', alpha=0.7)\n    plt.scatter(c, p, zorder=10, label='Competitive equilibrium', color='#600001')\n\n    plt.vlines(q, 0, pm, linestyle=\"dashed\", color='black', alpha=0.7)\n    plt.hlines(pm, 0, q, linestyle=\"dashed\", color='black', alpha=0.7)\n    plt.scatter(q, pm, zorder=10, label='Equilibrium with monopoly', color='#E55B13')\n\n    plt.legend(loc='upper right')\n    plt.margins(x=0, y=0)\n    plt.ylim(0)\n    plt.xlabel('Quantity')\n    plt.ylabel('Price')\n    plt.show()\n\n","type":"content","url":"/supply-demand-multiple-goods#a-monopolist","position":39},{"hierarchy":{"lvl1":"Supply and Demand with Many Goods","lvl4":"A multiple good example","lvl3":"A monopolist","lvl2":"Economies with endogenous supplies of goods"},"type":"lvl4","url":"/supply-demand-multiple-goods#a-multiple-good-example","position":40},{"hierarchy":{"lvl1":"Supply and Demand with Many Goods","lvl4":"A multiple good example","lvl3":"A monopolist","lvl2":"Economies with endogenous supplies of goods"},"content":"Let’s compare competitive equilibrium and monopoly outcomes in a multiple goods economy.\n\nΠ = np.array([[1, 0],\n              [0, 1.2]])\n\nb = np.array([10, 10])\n\nh = np.array([0.5, 0.5])\n\nJ = np.array([[1, 0.5],\n              [0.5, 1]])\nμ = 1\n\nM = Monopoly(Π, b, h, J, μ)\nc, p = M.competitive_equilibrium()\nq, pm = M.equilibrium_with_monopoly()\n\nprint('Competitive equilibrium price:', p)\nprint('Competitive equilibrium allocation:', c)\n\nprint('Equilibrium with monopolist supplier price:', pm)\nprint('Equilibrium with monopolist supplier allocation:', q)\n\n","type":"content","url":"/supply-demand-multiple-goods#a-multiple-good-example","position":41},{"hierarchy":{"lvl1":"Supply and Demand with Many Goods","lvl4":"A single-good example","lvl3":"A monopolist","lvl2":"Economies with endogenous supplies of goods"},"type":"lvl4","url":"/supply-demand-multiple-goods#a-single-good-example","position":42},{"hierarchy":{"lvl1":"Supply and Demand with Many Goods","lvl4":"A single-good example","lvl3":"A monopolist","lvl2":"Economies with endogenous supplies of goods"},"content":"\n\nΠ = np.array([[1]])  # the matrix now is a singleton\nb = np.array([10])\nh = np.array([0.5])\nJ = np.array([[1]])\nμ = 1\n\nM = Monopoly(Π, b, h, J, μ)\nc, p = M.competitive_equilibrium()\nq, pm = M.equilibrium_with_monopoly()\n\nprint('Competitive equilibrium price:', p.item())\nprint('Competitive equilibrium allocation:', c.item())\n\nprint('Equilibrium with monopolist supplier price:', pm.item())\nprint('Equilibrium with monopolist supplier allocation:', q.item())\n\n# plot\nplot_monopoly(M)\n\n","type":"content","url":"/supply-demand-multiple-goods#a-single-good-example","position":43},{"hierarchy":{"lvl1":"Supply and Demand with Many Goods","lvl2":"Multi-good welfare maximization problem"},"type":"lvl2","url":"/supply-demand-multiple-goods#multi-good-welfare-maximization-problem","position":44},{"hierarchy":{"lvl1":"Supply and Demand with Many Goods","lvl2":"Multi-good welfare maximization problem"},"content":"Our welfare maximization problem -- also sometimes called a social planning problem  -- is to choose c to maximize- \\frac{1}{2} \\mu^{-1}(\\Pi c -b) ^\\top (\\Pi c -b )\n\nminus the area under the inverse supply curve, namely,h c +  \\frac{1}{2} c^\\top J c\n\nSo the welfare criterion is- \\frac{1}{2} \\mu^{-1}(\\Pi c -b)^\\top (\\Pi c -b ) -h c \n        -  \\frac{1}{2} c^\\top J c\n\nIn this formulation, \\mu is a parameter that describes how the planner weighs interests of outside suppliers and our representative consumer.\n\nThe first-order condition with respect to c is- \\mu^{-1} \\Pi^\\top \\Pi c + \\mu^{-1}\\Pi^\\top b - h -  H c = 0\n\nwhich implies \n\n(34).\n\nThus, as for the single-good case, with multiple goods a competitive equilibrium quantity vector solves a planning problem.\n\n(This is another version of the first welfare theorem.)\n\nWe can deduce a competitive equilibrium price vector from either\n\nthe inverse demand curve, or\n\nthe inverse supply curve","type":"content","url":"/supply-demand-multiple-goods#multi-good-welfare-maximization-problem","position":45},{"hierarchy":{"lvl1":"Tax Smoothing"},"type":"lvl1","url":"/tax-smooth","position":0},{"hierarchy":{"lvl1":"Tax Smoothing"},"content":"","type":"content","url":"/tax-smooth","position":1},{"hierarchy":{"lvl1":"Tax Smoothing","lvl2":"Overview"},"type":"lvl2","url":"/tax-smooth#overview","position":2},{"hierarchy":{"lvl1":"Tax Smoothing","lvl2":"Overview"},"content":"This  is a sister lecture to our  lecture on \n\nconsumption​-smoothing.\n\nBy renaming variables, we  obtain  a  version of a model “tax-smoothing model” that  Robert Barro \n\nBarro (1979) used  to explain why governments sometimes choose not to balance their budgets every period but instead use issue debt to smooth tax rates over time.\n\nThe government chooses a tax collection path that minimizes the present value of its costs of raising revenue.\n\nThe government minimizes those costs by smoothing  tax collections  over time and by issuing government debt during temporary surges in government expenditures.\n\nThe present value of government expenditures is at the core of the tax-smoothing model,\nso we’ll again use formulas presented in \n\npresent value formulas.\n\nWe’ll again use the matrix multiplication and matrix inversion tools that we used in  \n\npresent value formulas.","type":"content","url":"/tax-smooth#overview","position":3},{"hierarchy":{"lvl1":"Tax Smoothing","lvl2":"Analysis"},"type":"lvl2","url":"/tax-smooth#analysis","position":4},{"hierarchy":{"lvl1":"Tax Smoothing","lvl2":"Analysis"},"content":"As usual, we’ll start by importing some Python modules.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom collections import namedtuple\n\nA government exists at times t=0, 1, \\ldots, S and  faces an exogenous stream of expenditures \\{G_t\\}_{t=0}^S.\n\nIt chooses  chooses a stream of tax collections \\{T_t\\}_{t=0}^S.\n\nThe model takes a government expenditure stream as an “exogenous” input that is somehow determined  outside the model.\n\nThe government faces a gross interest rate of R >1 that is constant over time.\n\nThe government can borrow or lend at interest rate R, subject to some limits on the amount of debt that it can issue  that we’ll describe below.\n\nLet\n\nS \\geq 2  be a positive integer that constitutes a time-horizon.\n\nG = \\{G_t\\}_{t=0}^S be a sequence of government expenditures.\n\nB = \\{B_t\\}_{t=0}^{S+1} be a sequence of government debt.\n\nT = \\{T_t\\}_{t=0}^S be a sequence of tax collections.\n\nR \\geq 1 be a fixed gross one period interest rate.\n\n\\beta \\in (0,1) be a fixed discount factor.\n\nB_0 be a given initial level of government debt\n\nB_{S+1} \\geq 0  be a terminal condition.\n\nThe sequence of government debt B is to be determined by the model.\n\nWe require it to satisfy two boundary conditions:\n\nit must equal an exogenous value B_0 at time 0\n\nit must equal or exceed an exogenous value B_{S+1} at time S+1.\n\nThe terminal condition B_{S+1} \\geq 0   requires that the government  not end up with negative assets.\n\n(This no-Ponzi condition ensures that the government  ultimately pays off its debts -- it can’t simply roll them over indefinitely.)\n\nThe government faces a sequence of budget constraints that constrain sequences (G, T, B)B_{t+1} = R (B_t + G_t - T_t), \\quad t =0, 1, \\ldots S\n\nEquations \n\n(1) constitute S+1 such budget constraints, one for each t=0, 1, \\ldots, S.\n\nGiven a sequence G of government expenditures, a large set of pairs (B, T) of (government debt, tax collections) sequences satisfy the sequence of budget constraints \n\n(1).\n\nThe  model follows the following logical flow:\n\nstart with an exogenous government expenditure sequence G, an initial government debt B_0, and\na candidate tax collection path T.\n\nuse the system of equations \n\n(1) for t=0, \\ldots, S to compute a path B of government debt\n\nverify that B_{S+1} satisfies the terminal debt constraint B_{S+1} \\geq 0.\n\nIf it does, declare that the candidate path is budget feasible.\n\nif the candidate tax path is not budget feasible, propose a different tax path and start over\n\nBelow, we’ll describe how to execute these steps using linear algebra -- matrix inversion and multiplication.\n\nThe above procedure seems like a sensible way to find “budget-feasible” tax paths T, i.e., paths that are consistent with the exogenous government expenditure stream G, the initial debt level B_0, and the terminal debt level B_{S+1}.\n\nIn general, there are many budget feasible tax paths T.\n\nAmong all budget-feasible tax paths, which one should a government choose?\n\nTo answer this question, we assess  alternative budget feasible tax paths T using the following cost functional:L = - \\sum_{t=0}^S \\beta^t (g_1 T_t - \\frac{g_2}{2} T_t^2 )\n\nwhere g_1 > 0, g_2 > 0.\n\nThis is called the “present value of revenue-raising costs” in \n\nBarro (1979).\n\nThe quadratic term -\\frac{g_2}{2} T_t^2 captures increasing marginal costs of taxation, implying that tax distortions rise more than proportionally with tax rates.\n\nThis creates an incentive for tax smoothing.\n\nIndeed, we shall see that when \\beta R = 1, criterion \n\n(2) leads to smoother tax paths.\n\nBy smoother we mean tax rates that are as close as possible to being constant over time.\n\nThe preference for smooth tax paths that is built into the model gives it the name “tax-smoothing model”.\n\nOr equivalently, we can transform this into the same problem as in the \n\nconsumption​-smoothing lecture by maximizing the welfare criterion:W = \\sum_{t=0}^S \\beta^t (g_1 T_t - \\frac{g_2}{2} T_t^2 )\n\nLet’s dive in and do some calculations that will help us understand how the model works.\n\nHere we use default parameters R = 1.05, g_1 = 1, g_2 = 1/2, and S = 65.\n\nWe create a Python namedtuple to store these parameters with default values.\n\nTaxSmoothing = namedtuple(\"TaxSmoothing\", \n                        [\"R\", \"g1\", \"g2\", \"β_seq\", \"S\"])\n\ndef create_tax_smoothing_model(R=1.01, g1=1, g2=1/2, S=65):\n    \"\"\"\n    Creates an instance of the tax smoothing model.\n    \"\"\"\n    β = 1/R\n    β_seq = np.array([β**i for i in range(S+1)])\n\n    return TaxSmoothing(R, g1, g2, β_seq, S)\n\n","type":"content","url":"/tax-smooth#analysis","position":5},{"hierarchy":{"lvl1":"Tax Smoothing","lvl2":"Barro tax-smoothing model"},"type":"lvl2","url":"/tax-smooth#barro-tax-smoothing-model","position":6},{"hierarchy":{"lvl1":"Tax Smoothing","lvl2":"Barro tax-smoothing model"},"content":"A key object is the present value of government expenditures at time 0:h_0 \\equiv \\sum_{t=0}^S R^{-t} G_t = \\begin{bmatrix} 1 & R^{-1} & \\cdots & R^{-S} \\end{bmatrix}\n\\begin{bmatrix} G_0 \\cr G_1  \\cr \\vdots \\cr G_S \\end{bmatrix}\n\nThis sum represents the present value of all future government expenditures that must be financed.\n\nFormally it resembles the present value calculations we saw in this QuantEcon lecture \n\npresent values.\n\nThis present value calculation is crucial for determining the government’s total financing needs.\n\nBy iterating on equation \n\n(1) and imposing the terminal conditionB_{S+1} = 0,\n\nit is possible to convert a sequence of budget constraints \n\n(1) into a single intertemporal constraint\\sum_{t=0}^S R^{-t} T_t = B_0 + h_0.\n\nEquation \n\n(6) says that the present value of tax collections must equal the sum of initial debt and the present value of government expenditures.\n\nWhen \\beta R = 1, it is optimal for a government to smooth taxes by settingT_t = T_0 \\quad t =0, 1, \\ldots, S\n\n(Later we’ll present a “variational argument” that shows that this constant path minimizes\ncriterion \n\n(2) and maximizes \n\n(3) when \\beta R =1.)\n\nIn this case, we can use the intertemporal budget constraint to writeT_t = T_0  = \\left(\\sum_{t=0}^S R^{-t}\\right)^{-1} (B_0 + h_0), \\quad t= 0, 1, \\ldots, S.\n\nEquation \n\n(8) is the tax-smoothing model in a nutshell.","type":"content","url":"/tax-smooth#barro-tax-smoothing-model","position":7},{"hierarchy":{"lvl1":"Tax Smoothing","lvl2":"Mechanics of tax-smoothing"},"type":"lvl2","url":"/tax-smooth#mechanics-of-tax-smoothing","position":8},{"hierarchy":{"lvl1":"Tax Smoothing","lvl2":"Mechanics of tax-smoothing"},"content":"As promised, we’ll provide step-by-step instructions on how to use linear algebra, readily implemented in Python, to compute all objects in play in the tax-smoothing model.\n\nIn the calculations below, we’ll set default values of R > 1, e.g., R = 1.05, and \\beta = R^{-1}.","type":"content","url":"/tax-smooth#mechanics-of-tax-smoothing","position":9},{"hierarchy":{"lvl1":"Tax Smoothing","lvl3":"Step 1","lvl2":"Mechanics of tax-smoothing"},"type":"lvl3","url":"/tax-smooth#step-1","position":10},{"hierarchy":{"lvl1":"Tax Smoothing","lvl3":"Step 1","lvl2":"Mechanics of tax-smoothing"},"content":"For a (S+1) \\times 1 vector G of government expenditures, use matrix algebra to compute the present valueh_0 = \\sum_{t=0}^S R^{-t} G_t = \\begin{bmatrix} 1 & R^{-1} & \\cdots & R^{-S} \\end{bmatrix}\n\\begin{bmatrix} G_0 \\cr G_1  \\cr \\vdots \\cr G_S \\end{bmatrix}","type":"content","url":"/tax-smooth#step-1","position":11},{"hierarchy":{"lvl1":"Tax Smoothing","lvl3":"Step 2","lvl2":"Mechanics of tax-smoothing"},"type":"lvl3","url":"/tax-smooth#step-2","position":12},{"hierarchy":{"lvl1":"Tax Smoothing","lvl3":"Step 2","lvl2":"Mechanics of tax-smoothing"},"content":"Compute a constant tax rate T_0:T_t = T_0 = \\left( \\frac{1 - R^{-1}}{1 - R^{-(S+1)}} \\right) (B_0 + \\sum_{t=0}^S R^{-t} G_t ) , \\quad t = 0, 1, \\ldots, S","type":"content","url":"/tax-smooth#step-2","position":13},{"hierarchy":{"lvl1":"Tax Smoothing","lvl3":"Step 3","lvl2":"Mechanics of tax-smoothing"},"type":"lvl3","url":"/tax-smooth#step-3","position":14},{"hierarchy":{"lvl1":"Tax Smoothing","lvl3":"Step 3","lvl2":"Mechanics of tax-smoothing"},"content":"Use the system of equations \n\n(1) for t=0, \\ldots, S to compute a path B of government debt.\n\nTo do this, we transform  that system of difference equations into a single matrix equation as follows:\\begin{bmatrix} \n1 & 0 & 0 & \\cdots & 0 & 0 & 0 \\cr\n-R & 1 & 0 & \\cdots & 0 & 0 & 0 \\cr\n0 & -R & 1 & \\cdots & 0 & 0 & 0 \\cr\n\\vdots  &\\vdots & \\vdots & \\cdots & \\vdots & \\vdots & \\vdots \\cr\n0 & 0 & 0 & \\cdots & -R & 1 & 0 \\cr\n0 & 0 & 0 & \\cdots & 0 & -R & 1\n\\end{bmatrix} \n\\begin{bmatrix} B_1 \\cr B_2 \\cr B_3 \\cr \\vdots \\cr B_S \\cr B_{S+1} \n\\end{bmatrix}\n= R \n\\begin{bmatrix} G_0 + B_0 - T_0 \\cr G_1 - T_0 \\cr G_2 - T_0 \\cr \\vdots\\cr G_{S-1} - T_0 \\cr G_S - T_0\n\\end{bmatrix}\n\nMultiply both sides by the inverse of the matrix on the left side to compute\\begin{bmatrix} B_1 \\cr B_2 \\cr B_3 \\cr \\vdots \\cr B_S \\cr B_{S+1} \\end{bmatrix}\n\nBecause we have built into our calculations that the government must satisfy its intertemporal budget constraint and end with zero debt, just barely satisfying the\nterminal condition that B_{S+1} \\geq 0, it should turn out thatB_{S+1} = 0.\n\nLet’s verify this with Python code.\n\nFirst we implement the model with compute_optimal\n\ndef compute_optimal(model, B0, G_seq):\n\n    R, S = model.R, model.S\n\n    # present value of government expenditures\n    h0 = model.β_seq @ G_seq     # since β = 1/R\n\n    # optimal constant tax rate\n    T0 = (1 - 1/R) / (1 - (1/R)**(S+1)) * (B0 + h0)\n    T_seq = T0*np.ones(S+1)\n\n    A = np.diag(-R*np.ones(S), k=-1) + np.eye(S+1)\n    b = G_seq - T_seq\n    b[0] = b[0] + B0\n    B_seq = np.linalg.inv(A) @ b\n    B_seq = np.concatenate([[B0], B_seq])\n\n    return T_seq, B_seq, h0\n\nWe use an example where the government starts with initial debt B_0>0.\n\nThis represents the government’s initial debt burden.\n\nThe government expenditure process \\{G_t\\}_{t=0}^{S} is constant and positive up to t=45 and then drops to zero afterward.\n\nThe drop in government expenditures could reflect a change in spending requirements or demographic shifts.\n\n# Initial debt\nB0 = 2     # initial government debt\n\n# Government expenditure process\nG_seq = np.concatenate([np.ones(46), 4*np.ones(5), np.ones(15)])\ntax_model = create_tax_smoothing_model()\nT_seq, B_seq, h0 = compute_optimal(tax_model, B0, G_seq)\n\nprint('check B_S+1=0:', \n      np.abs(B_seq[-1] - 0) <= 1e-8)\n\nThe graphs below show paths of government expenditures, tax collections, and government debt.\n\n# Sequence length\nS = tax_model.S\n\nfig, axes = plt.subplots(1, 2, figsize=(12,5))\n\naxes[0].plot(range(S+1), G_seq, label='expenditures', lw=2)\naxes[0].plot(range(S+1), T_seq, label='tax', lw=2)\naxes[1].plot(range(S+2), B_seq, label='debt', color='green', lw=2)\naxes[0].set_ylabel(r'$T_t,G_t$')\naxes[1].set_ylabel(r'$B_t$')\n\nfor ax in axes:\n    ax.plot(range(S+2), np.zeros(S+2), '--', lw=1, color='black')\n    ax.legend()\n    ax.set_xlabel(r'$t$')\n\nplt.show()\n\nNote that B_{S+1} = 0, as anticipated.\n\nWe can evaluate cost criterion \n\n(2) which measures the total cost / welfare of taxation\n\ndef cost(model, T_seq):\n    β_seq, g1, g2 = model.β_seq, model.g1, model.g2\n    cost_seq = g1 * T_seq - g2/2 * T_seq**2\n    return - β_seq @ cost_seq\n\nprint('Cost:', cost(tax_model, T_seq))\n\ndef welfare(model, T_seq):\n    return - cost(model, T_seq)\n\nprint('Welfare:', welfare(tax_model, T_seq))\n\n","type":"content","url":"/tax-smooth#step-3","position":15},{"hierarchy":{"lvl1":"Tax Smoothing","lvl3":"Experiments","lvl2":"Mechanics of tax-smoothing"},"type":"lvl3","url":"/tax-smooth#experiments","position":16},{"hierarchy":{"lvl1":"Tax Smoothing","lvl3":"Experiments","lvl2":"Mechanics of tax-smoothing"},"content":"In this section we describe how a tax sequence would optimally respond to different sequences of government expenditures.\n\nFirst we create a function plot_ts that generates graphs for different instances of the tax-smoothing model tax_model.\n\nThis will help us avoid rewriting code to plot outcomes for different government expenditure sequences.\n\ndef plot_ts(model,    # tax-smoothing model      \n            B0,       # initial government debt\n            G_seq     # government expenditure process\n           ):\n    \n    # Compute optimal tax path\n    T_seq, B_seq, h0 = compute_optimal(model, B0, G_seq)\n    \n    # Sequence length\n    S = tax_model.S\n    \n    fig, axes = plt.subplots(1, 2, figsize=(12,5))\n    \n    axes[0].plot(range(S+1), G_seq, label='expenditures', lw=2)\n    axes[0].plot(range(S+1), T_seq, label='taxes', lw=2)\n    axes[1].plot(range(S+2), B_seq, label='debt', color='green', lw=2)\n    axes[0].set_ylabel(r'$T_t,G_t$')\n    axes[1].set_ylabel(r'$B_t$')\n    \n    for ax in axes:\n        ax.plot(range(S+2), np.zeros(S+2), '--', lw=1, color='black')\n        ax.legend()\n        ax.set_xlabel(r'$t$')\n    \n    \n    plt.show()\n\nIn the experiments below, please study how tax and government debt sequences vary across different sequences for government expenditures.","type":"content","url":"/tax-smooth#experiments","position":17},{"hierarchy":{"lvl1":"Tax Smoothing","lvl4":"Experiment 1: one-time spending shock","lvl3":"Experiments","lvl2":"Mechanics of tax-smoothing"},"type":"lvl4","url":"/tax-smooth#experiment-1-one-time-spending-shock","position":18},{"hierarchy":{"lvl1":"Tax Smoothing","lvl4":"Experiment 1: one-time spending shock","lvl3":"Experiments","lvl2":"Mechanics of tax-smoothing"},"content":"We first assume a one-time spending shock of W_0 in year 21 of the expenditure sequence G.\n\nWe’ll make W_0 big - positive to indicate a spending surge (like a war or disaster), and negative to indicate a spending cut.\n\n# Spending surge W_0 = 2.5\nG_seq_pos = np.concatenate([np.ones(21), np.array([2.5]), \nnp.ones(24), np.ones(20)])\n\nplot_ts(tax_model, B0, G_seq_pos)\n\n","type":"content","url":"/tax-smooth#experiment-1-one-time-spending-shock","position":19},{"hierarchy":{"lvl1":"Tax Smoothing","lvl4":"Experiment 2: permanent expenditure shift","lvl3":"Experiments","lvl2":"Mechanics of tax-smoothing"},"type":"lvl4","url":"/tax-smooth#experiment-2-permanent-expenditure-shift","position":20},{"hierarchy":{"lvl1":"Tax Smoothing","lvl4":"Experiment 2: permanent expenditure shift","lvl3":"Experiments","lvl2":"Mechanics of tax-smoothing"},"content":"Now we assume a permanent increase in government expenditures of L in year 21 of the G-sequence.\n\nAgain we can study positive and negative cases\n\n# Positive temporary expenditure shift L = 0.5 when t >= 21\nG_seq_pos = np.concatenate(\n    [np.ones(21), 1.5*np.ones(25), np.ones(20)])\n\nplot_ts(tax_model, B0, G_seq_pos)\n\n# Negative temporary expenditure shift L = -0.5 when t >= 21\nG_seq_neg = np.concatenate(\n    [np.ones(21), .5*np.ones(25), np.ones(20)])\n\nplot_ts(tax_model, B0, G_seq_neg)\n\n","type":"content","url":"/tax-smooth#experiment-2-permanent-expenditure-shift","position":21},{"hierarchy":{"lvl1":"Tax Smoothing","lvl4":"Experiment 3: delayed spending surge","lvl3":"Experiments","lvl2":"Mechanics of tax-smoothing"},"type":"lvl4","url":"/tax-smooth#experiment-3-delayed-spending-surge","position":22},{"hierarchy":{"lvl1":"Tax Smoothing","lvl4":"Experiment 3: delayed spending surge","lvl3":"Experiments","lvl2":"Mechanics of tax-smoothing"},"content":"Now we simulate a G sequence in which government expenditures are zero for 46 years, and then rise to 1 for the last 20 years (perhaps due to demographic aging)\n\n# Delayed spending\nG_seq_late = np.concatenate(\n    [np.ones(46), 2*np.ones(20)])\n\nplot_ts(tax_model, B0, G_seq_late)\n\n","type":"content","url":"/tax-smooth#experiment-3-delayed-spending-surge","position":23},{"hierarchy":{"lvl1":"Tax Smoothing","lvl4":"Experiment 4: growing expenditures","lvl3":"Experiments","lvl2":"Mechanics of tax-smoothing"},"type":"lvl4","url":"/tax-smooth#experiment-4-growing-expenditures","position":24},{"hierarchy":{"lvl1":"Tax Smoothing","lvl4":"Experiment 4: growing expenditures","lvl3":"Experiments","lvl2":"Mechanics of tax-smoothing"},"content":"Now we simulate a geometric G sequence in which government expenditures grow at rate G_t = \\lambda^t G_0 in first 46 years.\n\nWe first experiment with \\lambda = 1.05 (growing expenditures)\n\n# Geometric growth parameters where λ = 1.05\nλ = 1.05\nG_0 = 1\nt_max = 46\n\n# Generate geometric G sequence\ngeo_seq = λ ** np.arange(t_max) * G_0 \nG_seq_geo = np.concatenate(\n            [geo_seq, np.max(geo_seq)*np.ones(20)])\n\nplot_ts(tax_model, B0, G_seq_geo)\n\nNow we show the behavior when \\lambda = 0.95 (declining expenditures)\n\nλ = 0.95\ngeo_seq = λ ** np.arange(t_max) * G_0 \nG_seq_geo = np.concatenate(\n            [geo_seq, λ ** t_max * np.ones(20)])\n\nplot_ts(tax_model, B0, G_seq_geo)\n\nWhat happens with oscillating expenditures\n\nλ = -0.95\ngeo_seq = λ ** np.arange(t_max) * G_0 + 1\nG_seq_geo = np.concatenate(\n            [geo_seq, np.ones(20)])\n\nplot_ts(tax_model, B0, G_seq_geo)\n\n","type":"content","url":"/tax-smooth#experiment-4-growing-expenditures","position":25},{"hierarchy":{"lvl1":"Tax Smoothing","lvl3":"Feasible Tax Variations","lvl2":"Mechanics of tax-smoothing"},"type":"lvl3","url":"/tax-smooth#feasible-tax-variations","position":26},{"hierarchy":{"lvl1":"Tax Smoothing","lvl3":"Feasible Tax Variations","lvl2":"Mechanics of tax-smoothing"},"content":"We promised to justify our claim that a constant tax rate T_t = T_0 for all t is optimal.\n\nLet’s do that now.\n\nThe approach we’ll take is an elementary example of the “calculus of variations”.\n\nLet’s dive in and see what the key idea is.\n\nTo explore what types of tax paths are cost-minimizing / welfare-improving, we shall create an admissible tax path variation sequence \\{v_t\\}_{t=0}^S\nthat satisfies\\sum_{t=0}^S R^{-t} v_t = 0.\n\nThis equation says that the present value of admissible tax path variations must be zero.\n\nSo once again, we encounter a formula for the present value:\n\nwe require that the present value of tax path variations be zero to maintain budget balance.\n\nHere we’ll restrict ourselves to a two-parameter class of admissible tax path variations of the formv_t = \\xi_1 \\phi^t - \\xi_0.\n\nWe say two and not three-parameter class because \\xi_0 will be a function of (\\phi, \\xi_1; R) that guarantees that the variation sequence is feasible.\n\nLet’s compute that function.\n\nWe require\\sum_{t=0}^S R^{-t}\\left[ \\xi_1 \\phi^t - \\xi_0 \\right] = 0\n\nwhich implies that\\xi_1 \\sum_{t=0}^S \\phi_t R^{-t} - \\xi_0 \\sum_{t=0}^S R^{-t} = 0\n\nwhich implies that\\xi_1 \\frac{1 - (\\phi R^{-1})^{S+1}}{1 - \\phi R^{-1}} - \\xi_0 \\frac{1 - R^{-(S+1)}}{1-R^{-1} } =0\n\nwhich implies that\\xi_0 = \\xi_0(\\phi, \\xi_1; R) = \\xi_1 \\left(\\frac{1 - R^{-1}}{1 - R^{-(S+1)}}\\right) \\left(\\frac{1 - (\\phi R^{-1})^{S+1}}{1 - \\phi R^{-1}}\\right)\n\nThis is our formula for \\xi_0.\n\nKey Idea: if T^o is a budget-feasible tax path, then so is T^o + v,\nwhere v is a budget-feasible variation.\n\nGiven R, we thus have a two parameter class of budget feasible variations v that we can use\nto compute alternative tax paths, then evaluate their welfare costs.\n\nNow let’s compute and plot tax path variations\n\ndef compute_variation(model, ξ1, ϕ, B0, G_seq, verbose=1):\n    R, S, β_seq = model.R, model.S, model.β_seq\n\n    ξ0 = ξ1*((1 - 1/R) / (1 - (1/R)**(S+1))) * ((1 - (ϕ/R)**(S+1)) / (1 - ϕ/R))\n    v_seq = np.array([(ξ1*ϕ**t - ξ0) for t in range(S+1)])\n    \n    if verbose == 1:\n        print('check feasible:', np.isclose(β_seq @ v_seq, 0))     \n\n    T_opt, _, _ = compute_optimal(model, B0, G_seq)\n    Tvar_seq = T_opt + v_seq\n\n    return Tvar_seq\n\nWe visualize variations for \\xi_1 \\in \\{.01, .05\\} and \\phi \\in \\{.95, 1.02\\}\n\nfig, ax = plt.subplots()\nξ1s = [.01, .05]\nϕs= [.95, 1.02]\ncolors = {.01: 'tab:blue', .05: 'tab:green'}\nparams = np.array(np.meshgrid(ξ1s, ϕs)).T.reshape(-1, 2)\nwel_opt = welfare(tax_model, T_seq)\n\nfor i, param in enumerate(params):\n    ξ1, ϕ = param\n    print(f'variation {i}: ξ1={ξ1}, ϕ={ϕ}')\n\n    Tvar_seq = compute_variation(model=tax_model, \n                                 ξ1=ξ1, ϕ=ϕ, B0=B0, \n                                 G_seq=G_seq)\n    print(f'welfare={welfare(tax_model, Tvar_seq)}')\n    print(f'welfare < optimal: {welfare(tax_model, Tvar_seq) < wel_opt}')\n    print('-'*64)\n\n    if i % 2 == 0:\n        ls = '-.'\n    else: \n        ls = '-'  \n    ax.plot(range(S+1), Tvar_seq, ls=ls, \n            color=colors[ξ1], \n            label=fr'$\\xi_1 = {ξ1}, \\phi = {ϕ}$')\n\nplt.plot(range(S+1), T_seq, \n         color='orange', label=r'Optimal $\\vec{T}$ ')\n\nplt.legend()\nplt.xlabel(r'$t$')\nplt.ylabel(r'$T_t$')\nplt.show()\n\nWe can even use the Python np.gradient command to compute derivatives of cost with respect to our two parameters.\n\nWe are teaching the key idea beneath the calculus of variations.\nFirst, we define the cost with respect to \\xi_1 and \\phi\n\ndef cost_rel(ξ1, ϕ):\n    \"\"\"\n    Compute cost of variation sequence \n    for given ϕ, ξ1 with a tax-smoothing model\n    \"\"\"\n    \n    Tvar_seq = compute_variation(tax_model, ξ1=ξ1, \n                                 ϕ=ϕ, B0=B0, \n                                 G_seq=G_seq, \n                                 verbose=0)\n    return cost(tax_model, Tvar_seq)\n\n# Vectorize the function to allow array input\ncost_vec = np.vectorize(cost_rel)\n\nThen we can visualize the relationship between cost and \\xi_1 and compute its derivatives\n\nξ1_arr = np.linspace(-0.5, 0.5, 20)\n\nplt.plot(ξ1_arr, cost_vec(ξ1_arr, 1.02))\nplt.ylabel('cost')\nplt.xlabel(r'$\\xi_1$')\nplt.show()\n\ncost_grad = cost_vec(ξ1_arr, 1.02)\ncost_grad = np.gradient(cost_grad)\nplt.plot(ξ1_arr, cost_grad)\nplt.ylabel('derivative of cost')\nplt.xlabel(r'$\\xi_1$')\nplt.show()\n\nThe same can be done on \\phi\n\nϕ_arr = np.linspace(-0.5, 0.5, 20)\n\nplt.plot(ξ1_arr, cost_vec(0.05, ϕ_arr))\nplt.ylabel('cost')\nplt.xlabel(r'$\\phi$')\nplt.show()\n\ncost_grad = cost_vec(0.05, ϕ_arr)\ncost_grad = np.gradient(cost_grad)\nplt.plot(ξ1_arr, cost_grad)\nplt.ylabel('derivative of cost')\nplt.xlabel(r'$\\phi$')\nplt.show()","type":"content","url":"/tax-smooth#feasible-tax-variations","position":27},{"hierarchy":{"lvl1":"Univariate Time Series with Matrix Algebra"},"type":"lvl1","url":"/time-series-with-matrices","position":0},{"hierarchy":{"lvl1":"Univariate Time Series with Matrix Algebra"},"content":"","type":"content","url":"/time-series-with-matrices","position":1},{"hierarchy":{"lvl1":"Univariate Time Series with Matrix Algebra","lvl2":"Overview"},"type":"lvl2","url":"/time-series-with-matrices#overview","position":2},{"hierarchy":{"lvl1":"Univariate Time Series with Matrix Algebra","lvl2":"Overview"},"content":"This lecture uses matrices to solve some linear difference equations.\n\nAs a running example, we’ll study a second-order linear difference\nequation that was the key technical tool in Paul Samuelson’s 1939\narticle \n\nSamuelson (1939) that introduced the multiplier-accelerator model.\n\nThis model became the workhorse that powered early econometric versions of\nKeynesian macroeconomic models in the United States.\n\nYou can read about the details of that model in .\n\n(That lecture also describes some technicalities about second-order linear difference equations.)\n\nIn this lecture, we’ll also learn about an autoregressive representation and a moving average representation of a  non-stationary\nunivariate time series \\{y_t\\}_{t=0}^T.\n\nWe’ll also study a “perfect foresight” model of stock prices that involves solving\na “forward-looking” linear difference equation.\n\nWe will use the following imports:\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib import cm\n\n# Custom figsize for this lecture\nplt.rcParams[\"figure.figsize\"] = (11, 5)\n\n# Set decimal printing to 3 decimal places\nnp.set_printoptions(precision=3, suppress=True)\n\n","type":"content","url":"/time-series-with-matrices#overview","position":3},{"hierarchy":{"lvl1":"Univariate Time Series with Matrix Algebra","lvl2":"Samuelson’s model"},"type":"lvl2","url":"/time-series-with-matrices#samuelsons-model","position":4},{"hierarchy":{"lvl1":"Univariate Time Series with Matrix Algebra","lvl2":"Samuelson’s model"},"content":"Let t = 0, \\pm 1, \\pm 2, \\ldots index time.\n\nFor t = 1, 2, 3, \\ldots, T suppose thaty_{t} = \\alpha_{0} + \\alpha_{1} y_{t-1} + \\alpha_{2} y_{t-2}\n\nwhere we assume that y_0 and y_{-1} are given numbers\nthat we take as initial conditions.\n\nIn Samuelson’s model, y_t stood for national income or perhaps a different\nmeasure of aggregate activity called gross domestic product (GDP) at time t.\n\nEquation \n\n(1) is called a second-order linear difference equation. It is called second order because it depends on two lags.\n\nBut actually, it is a collection of T simultaneous linear\nequations in the T variables y_1, y_2, \\ldots, y_T.\n\nNote\n\nTo be able to solve a second-order linear difference\nequation, we require two boundary conditions that can take the form\neither of two initial conditions, two terminal conditions or\npossibly one of each.\n\nLet’s write our equations as a stacked system\\underset{\\equiv A}{\\underbrace{\\left[\\begin{array}{cccccccc}\n1 & 0 & 0 & 0 & \\cdots & 0 & 0 & 0\\\\\n-\\alpha_{1} & 1 & 0 & 0 & \\cdots & 0 & 0 & 0\\\\\n-\\alpha_{2} & -\\alpha_{1} & 1 & 0 & \\cdots & 0 & 0 & 0\\\\\n0 & -\\alpha_{2} & -\\alpha_{1} & 1 & \\cdots & 0 & 0 & 0\\\\\n\\vdots & \\vdots & \\vdots & \\vdots & \\cdots & \\vdots & \\vdots & \\vdots\\\\\n0 & 0 & 0 & 0 & \\cdots & -\\alpha_{2} & -\\alpha_{1} & 1\n\\end{array}\\right]}}\\left[\\begin{array}{c}\ny_{1}\\\\\ny_{2}\\\\\ny_{3}\\\\\ny_{4}\\\\\n\\vdots\\\\\ny_{T}\n\\end{array}\\right]=\\underset{\\equiv b}{\\underbrace{\\left[\\begin{array}{c}\n\\alpha_{0}+\\alpha_{1}y_{0}+\\alpha_{2}y_{-1}\\\\\n\\alpha_{0}+\\alpha_{2}y_{0}\\\\\n\\alpha_{0}\\\\\n\\alpha_{0}\\\\\n\\vdots\\\\\n\\alpha_{0}\n\\end{array}\\right]}}\n\norA y = b\n\nwherey = \\begin{bmatrix} y_1 \\cr y_2 \\cr \\vdots \\cr y_T \\end{bmatrix}\n\nEvidently y can be computed fromy = A^{-1} b\n\nThe vector y is a complete time path \\{y_t\\}_{t=1}^T.\n\nLet’s put Python to work on an example that captures the flavor of\nSamuelson’s multiplier-accelerator model.\n\nWe’ll set parameters equal to the same values we used in .\n\nT = 80\n\n# parameters\nα_0 = 10.0\nα_1 = 1.53\nα_2 = -.9\n\ny_neg1 = 28.0 # y_{-1}\ny_0 = 24.0\n\nNow we construct A and b.\n\nA = np.identity(T)  # The T x T identity matrix\n\nfor i in range(T):\n\n    if i-1 >= 0:\n        A[i, i-1] = -α_1\n\n    if i-2 >= 0:\n        A[i, i-2] = -α_2\n\nb = np.full(T, α_0)\nb[0] = α_0 + α_1 * y_0 + α_2 * y_neg1\nb[1] = α_0 + α_2 * y_0\n\nLet’s look at the matrix A and the vector b for our\nexample.\n\nA, b\n\nNow let’s solve for the path of y.\n\nIf y_t is GNP at time t, then we have a version of\nSamuelson’s model of the dynamics for GNP.\n\nTo solve y = A^{-1} b we can either invert A directly, as in\n\nA_inv = np.linalg.inv(A)\n\ny = A_inv @ b\n\nor we can use np.linalg.solve:\n\ny_second_method = np.linalg.solve(A, b)\n\nHere make sure the two methods give the same result, at least up to floating\npoint precision:\n\nnp.allclose(y, y_second_method)\n\nA is invertible as it is lower triangular and \n\nits diagonal entries are non-zero\n\n# Check if A is lower triangular\nnp.allclose(A, np.tril(A))\n\nNote\n\nIn general, np.linalg.solve is more numerically stable than using\nnp.linalg.inv directly.\nHowever, stability is not an issue for this small example. Moreover, we will\nrepeatedly use A_inv in what follows, so there is added value in computing\nit directly.\n\nNow we can plot.\n\nplt.plot(np.arange(T)+1, y)\nplt.xlabel('t')\nplt.ylabel('y')\n\nplt.show()\n\nThe \n\n*steady state* value y^* of y_t is obtained by setting y_t = y_{t-1} =\ny_{t-2} = y^* in \n\n(1), which yieldsy^* = \\frac{\\alpha_{0}}{1 - \\alpha_{1} - \\alpha_{2}}\n\nIf we set the initial values to y_{0} = y_{-1} = y^*, then y_{t} will be\nconstant:\n\ny_star = α_0 / (1 - α_1 - α_2)\ny_neg1_steady = y_star # y_{-1}\ny_0_steady = y_star\n\nb_steady = np.full(T, α_0)\nb_steady[0] = α_0 + α_1 * y_0_steady + α_2 * y_neg1_steady\nb_steady[1] = α_0 + α_2 * y_0_steady\n\ny_steady = A_inv @ b_steady\n\nplt.plot(np.arange(T)+1, y_steady)\nplt.xlabel('t')\nplt.ylabel('y')\n\nplt.show()\n\n","type":"content","url":"/time-series-with-matrices#samuelsons-model","position":5},{"hierarchy":{"lvl1":"Univariate Time Series with Matrix Algebra","lvl2":"Adding a random term"},"type":"lvl2","url":"/time-series-with-matrices#adding-a-random-term","position":6},{"hierarchy":{"lvl1":"Univariate Time Series with Matrix Algebra","lvl2":"Adding a random term"},"content":"To generate some excitement, we’ll follow in the spirit of the great economists\n\n\nEugen Slutsky and \n\nRagnar Frisch and replace our original second-order difference\nequation with the following second-order stochastic linear difference\nequation:y_{t} = \\alpha_{0} + \\alpha_{1} y_{t-1} + \\alpha_{2} y_{t-2} + u_t\n\nwhere u_{t} \\sim N\\left(0, \\sigma_{u}^{2}\\right) and is \n\nIID,\nmeaning independent and identically distributed.\n\nWe’ll stack these T equations into a system cast in terms of\nmatrix algebra.\n\nLet’s define the random vectoru=\\left[\\begin{array}{c}\nu_{1}\\\\\nu_{2}\\\\\n\\vdots\\\\\nu_{T}\n\\end{array}\\right]\n\nWhere A, b, y are defined as above, now assume that y is\ngoverned by the systemA y = b + u\n\nThe solution for y becomesy = A^{-1} \\left(b + u\\right)\n\nLet’s try it out in Python.\n\nσ_u = 2.\nu = np.random.normal(0, σ_u, size=T)\ny = A_inv @ (b + u)\n\nplt.plot(np.arange(T)+1, y)\nplt.xlabel('t')\nplt.ylabel('y')\n\nplt.show()\n\nThe above time series looks a lot like (detrended) GDP series for a\nnumber of advanced countries in recent decades.\n\nWe can simulate N paths.\n\nN = 100\n\nfor i in range(N):\n    col = cm.viridis(np.random.rand())  # Choose a random color from viridis\n    u = np.random.normal(0, σ_u, size=T)\n    y = A_inv @ (b + u)\n    plt.plot(np.arange(T)+1, y, lw=0.5, color=col)\n\nplt.xlabel('t')\nplt.ylabel('y')\n\nplt.show()\n\nAlso consider the case when y_{0} and y_{-1} are at\nsteady state.\n\nN = 100\n\nfor i in range(N):\n    col = cm.viridis(np.random.rand())  # Choose a random color from viridis\n    u = np.random.normal(0, σ_u, size=T)\n    y_steady = A_inv @ (b_steady + u)\n    plt.plot(np.arange(T)+1, y_steady, lw=0.5, color=col)\n\nplt.xlabel('t')\nplt.ylabel('y')\n\nplt.show()\n\n","type":"content","url":"/time-series-with-matrices#adding-a-random-term","position":7},{"hierarchy":{"lvl1":"Univariate Time Series with Matrix Algebra","lvl2":"Computing population moments"},"type":"lvl2","url":"/time-series-with-matrices#computing-population-moments","position":8},{"hierarchy":{"lvl1":"Univariate Time Series with Matrix Algebra","lvl2":"Computing population moments"},"content":"We can apply standard formulas for multivariate normal distributions to compute the mean vector and covariance matrix\nfor our time series modely = A^{-1} (b + u) .\n\nYou can read about multivariate normal distributions in this lecture \n\nMultivariate Normal Distribution.\n\nLet’s write our  model asy = \\tilde A (b + u)\n\nwhere \\tilde A = A^{-1}.\n\nBecause  linear combinations of normal random variables are normal, we know thaty \\sim {\\mathcal N}(\\mu_y, \\Sigma_y)\n\nwhere\\mu_y = \\tilde A b\n\nand\\Sigma_y = \\tilde A (\\sigma_u^2 I_{T \\times T} ) \\tilde A^T\n\nLet’s write a Python  class that computes the mean vector \\mu_y and covariance matrix \\Sigma_y.\n\nclass population_moments:\n    \"\"\"\n    Compute population moments μ_y, Σ_y.\n    ---------\n    Parameters:\n    α_0, α_1, α_2, T, y_neg1, y_0\n    \"\"\"\n    def __init__(self, α_0=10.0, \n                       α_1=1.53, \n                       α_2=-.9, \n                       T=80, \n                       y_neg1=28.0, \n                       y_0=24.0, \n                       σ_u=1):\n\n        # compute A\n        A = np.identity(T)\n\n        for i in range(T):\n            if i-1 >= 0:\n                A[i, i-1] = -α_1\n\n            if i-2 >= 0:\n                A[i, i-2] = -α_2\n\n        # compute b\n        b = np.full(T, α_0)\n        b[0] = α_0 + α_1 * y_0 + α_2 * y_neg1\n        b[1] = α_0 + α_2 * y_0\n\n        # compute A inverse\n        A_inv = np.linalg.inv(A)\n\n        self.A, self.b, self.A_inv, self.σ_u, self.T = A, b, A_inv, σ_u, T\n    \n    def sample_y(self, n):\n        \"\"\"\n        Give a sample of size n of y.\n        \"\"\"\n        A_inv, σ_u, b, T = self.A_inv, self.σ_u, self.b, self.T\n        us = np.random.normal(0, σ_u, size=[n, T])\n        ys = np.vstack([A_inv @ (b + u) for u in us])\n\n        return ys\n\n    def get_moments(self):\n        \"\"\"\n        Compute the population moments of y.\n        \"\"\"\n        A_inv, σ_u, b = self.A_inv, self.σ_u, self.b\n\n        # compute μ_y\n        self.μ_y = A_inv @ b\n        self.Σ_y = σ_u**2 * (A_inv @ A_inv.T)\n        \n        return self.μ_y, self.Σ_y\n\n\nseries_process = population_moments()\n    \nμ_y, Σ_y = series_process.get_moments()\nA_inv = series_process.A_inv\n\nIt is enlightening  to study the \\mu_y, \\Sigma_y’s implied by  various parameter values.\n\nAmong other things, we can use the class to exhibit how  statistical stationarity of y prevails only for very special initial conditions.\n\nLet’s begin by generating N time realizations of y plotting them together with  population  mean \\mu_y .\n\n# Plot mean\nN = 100\n\nfor i in range(N):\n    col = cm.viridis(np.random.rand())  # Choose a random color from viridis\n    ys = series_process.sample_y(N)\n    plt.plot(ys[i,:], lw=0.5, color=col)\n    plt.plot(μ_y, color='red')\n\nplt.xlabel('t')\nplt.ylabel('y')\n\nplt.show()\n\nVisually, notice how the  variance across realizations of y_t decreases as t increases.\n\nLet’s plot the population variance of y_t against t.\n\n# Plot variance\nplt.plot(Σ_y.diagonal())\nplt.show()\n\nNotice how the population variance increases and asymptotes.\n\nLet’s print out the covariance matrix \\Sigma_y for a  time series y.\n\nseries_process = population_moments(α_0=0, \n                                    α_1=.8, \n                                    α_2=0, \n                                    T=6,\n                                    y_neg1=0., \n                                    y_0=0., \n                                    σ_u=1)\n\nμ_y, Σ_y = series_process.get_moments()\nprint(\"μ_y = \", μ_y)\nprint(\"Σ_y = \\n\", Σ_y)\n\nNotice that  the covariance between y_t and y_{t-1} -- the elements on the superdiagonal -- are not identical.\n\nThis is an indication that the time series represented by our y vector is not stationary.\n\nTo make it stationary, we’d have to alter our system so that our initial conditions (y_0, y_{-1}) are not fixed numbers but instead a jointly normally distributed random vector with a particular mean and  covariance matrix.\n\nWe describe how to do that in \n\nLinear State Space Models.\n\nBut just to set the stage for that analysis, let’s  print out the bottom right corner of \\Sigma_y.\n\nseries_process = population_moments()\nμ_y, Σ_y = series_process.get_moments()\n\nprint(\"bottom right corner of Σ_y = \\n\", Σ_y[72:,72:])\n\nPlease notice how the subdiagonal and superdiagonal elements seem to have converged.\n\nThis is an indication that our process is asymptotically stationary.\n\nYou can read  about stationarity of more general linear time series models in this lecture \n\nLinear State Space Models.\n\nThere is a lot to be learned about the process by staring at the off diagonal elements of \\Sigma_y corresponding to different time periods t, but we resist the temptation to do so here.\n\n","type":"content","url":"/time-series-with-matrices#computing-population-moments","position":9},{"hierarchy":{"lvl1":"Univariate Time Series with Matrix Algebra","lvl2":"Moving average representation"},"type":"lvl2","url":"/time-series-with-matrices#moving-average-representation","position":10},{"hierarchy":{"lvl1":"Univariate Time Series with Matrix Algebra","lvl2":"Moving average representation"},"content":"Let’s print out  A^{-1} and stare at  its structure\n\nis it triangular or almost triangular or \\ldots ?\n\nTo study the structure of A^{-1}, we shall print just  up to 3 decimals.\n\nLet’s begin by printing out just the upper left hand corner of A^{-1}.\n\nprint(A_inv[0:7,0:7])\n\nEvidently, A^{-1} is a lower triangular matrix.\n\nNotice how  every row ends with the previous row’s pre-diagonal entries.\n\nSince A^{-1} is lower triangular,  each  row represents   y_t for a particular t as the sum of\n\na time-dependent function A^{-1} b of the initial conditions incorporated in b, and\n\na weighted sum of  current and past values of the IID shocks \\{u_t\\}.\n\nThus,  let \\tilde{A}=A^{-1}.\n\nEvidently,  for t\\geq0,y_{t+1}=\\sum_{i=1}^{t+1}\\tilde{A}_{t+1,i}b_{i}+\\sum_{i=1}^{t}\\tilde{A}_{t+1,i}u_{i}+u_{t+1}\n\nThis is  a moving average representation with time-varying coefficients.\n\nJust as system \n\n(10) constitutes  a\nmoving average representation for y, system  \n\n(9) constitutes  an autoregressive representation for y.","type":"content","url":"/time-series-with-matrices#moving-average-representation","position":11},{"hierarchy":{"lvl1":"Univariate Time Series with Matrix Algebra","lvl2":"A forward looking model"},"type":"lvl2","url":"/time-series-with-matrices#a-forward-looking-model","position":12},{"hierarchy":{"lvl1":"Univariate Time Series with Matrix Algebra","lvl2":"A forward looking model"},"content":"Samuelson’s model is backward looking in the sense that we give it initial conditions and let it\nrun.\n\nLet’s now turn to model  that is forward looking.\n\nWe apply similar linear algebra machinery to study a perfect\nforesight model widely used as a benchmark in macroeconomics and\nfinance.\n\nAs an example, we suppose that p_t is the price of a stock and\nthat y_t is its dividend.\n\nWe assume that y_t is determined by second-order difference\nequation that we analyzed just above, so thaty = A^{-1} \\left(b + u\\right)\n\nOur perfect foresight model of stock prices isp_{t} = \\sum_{j=0}^{T-t} \\beta^{j} y_{t+j}, \\quad \\beta \\in (0,1)\n\nwhere \\beta is a discount factor.\n\nThe model asserts that the price of the stock at t equals the\ndiscounted present values of the (perfectly foreseen) future dividends.\n\nForm\\underset{\\equiv p}{\\underbrace{\\left[\\begin{array}{c}\np_{1}\\\\\np_{2}\\\\\np_{3}\\\\\n\\vdots\\\\\np_{T}\n\\end{array}\\right]}}=\\underset{\\equiv B}{\\underbrace{\\left[\\begin{array}{ccccc}\n1 & \\beta & \\beta^{2} & \\cdots & \\beta^{T-1}\\\\\n0 & 1 & \\beta & \\cdots & \\beta^{T-2}\\\\\n0 & 0 & 1 & \\cdots & \\beta^{T-3}\\\\\n\\vdots & \\vdots & \\vdots & \\vdots & \\vdots\\\\\n0 & 0 & 0 & \\cdots & 1\n\\end{array}\\right]}}\\left[\\begin{array}{c}\ny_{1}\\\\\ny_{2}\\\\\ny_{3}\\\\\n\\vdots\\\\\ny_{T}\n\\end{array}\\right]\n\nβ = .96\n\n\n\n# construct B\nB = np.zeros((T, T))\n\nfor i in range(T):\n    B[i, i:] = β ** np.arange(0, T-i)\n\n\n\nprint(B)\n\n\n\nσ_u = 0.\nu = np.random.normal(0, σ_u, size=T)\ny = A_inv @ (b + u)\ny_steady = A_inv @ (b_steady + u)\n\n\n\np = B @ y\n\n\n\nplt.plot(np.arange(0, T)+1, y, label='y')\nplt.plot(np.arange(0, T)+1, p, label='p')\nplt.xlabel('t')\nplt.ylabel('y/p')\nplt.legend()\n\nplt.show()\n\nCan you explain why the trend of the price is downward over time?\n\nAlso consider the case when y_{0} and y_{-1} are at the\nsteady state.\n\np_steady = B @ y_steady\n\nplt.plot(np.arange(0, T)+1, y_steady, label='y')\nplt.plot(np.arange(0, T)+1, p_steady, label='p')\nplt.xlabel('t')\nplt.ylabel('y/p')\nplt.legend()\n\nplt.show()","type":"content","url":"/time-series-with-matrices#a-forward-looking-model","position":13},{"hierarchy":{"lvl1":"Troubleshooting"},"type":"lvl1","url":"/troubleshooting","position":0},{"hierarchy":{"lvl1":"Troubleshooting"},"content":"This page is for readers experiencing errors when running the code from the lectures.","type":"content","url":"/troubleshooting","position":1},{"hierarchy":{"lvl1":"Troubleshooting","lvl2":"Fixing your local environment"},"type":"lvl2","url":"/troubleshooting#fixing-your-local-environment","position":2},{"hierarchy":{"lvl1":"Troubleshooting","lvl2":"Fixing your local environment"},"content":"The basic assumption of the lectures is that code in a lecture should execute whenever\n\nit is executed in a Jupyter notebook and\n\nthe notebook is running on a machine with the latest version of Anaconda Python.\n\nYou have installed Anaconda, haven’t you, following the instructions in \n\nthis lecture?\n\nAssuming that you have, the most common source of problems for our readers is that their Anaconda distribution is not up to date.\n\nHere’s a useful article\non how to update Anaconda.\n\nAnother option is to simply remove Anaconda and reinstall.\n\nYou also need to keep the external code libraries, such as \n\nQuantEcon.py up to date.\n\nFor this task you can either\n\nuse conda install -y quantecon on the command line, or\n\nexecute !conda install -y quantecon within a Jupyter notebook.\n\nIf your local environment is still not working you can do two things.\n\nFirst, you can use a remote machine instead, by clicking on the Launch Notebook icon available for each lecture\n\nSecond, you can report an issue, so we can try to fix your local set up.\n\nWe like getting feedback on the lectures so please don’t hesitate to get in\ntouch.","type":"content","url":"/troubleshooting#fixing-your-local-environment","position":3},{"hierarchy":{"lvl1":"Troubleshooting","lvl2":"Reporting an issue"},"type":"lvl2","url":"/troubleshooting#reporting-an-issue","position":4},{"hierarchy":{"lvl1":"Troubleshooting","lvl2":"Reporting an issue"},"content":"One way to give feedback is to raise an issue through our \n\nissue tracker.\n\nPlease be as specific as possible.  Tell us where the problem is and as much\ndetail about your local set up as you can provide.\n\nAnother feedback option is to use our \n\ndiscourse forum.\n\nFinally, you can provide direct feedback to \n\ncontact@quantecon​.org","type":"content","url":"/troubleshooting#reporting-an-issue","position":5},{"hierarchy":{"lvl1":"Some Unpleasant Monetarist Arithmetic"},"type":"lvl1","url":"/unpleasant","position":0},{"hierarchy":{"lvl1":"Some Unpleasant Monetarist Arithmetic"},"content":"","type":"content","url":"/unpleasant","position":1},{"hierarchy":{"lvl1":"Some Unpleasant Monetarist Arithmetic","lvl2":"Overview"},"type":"lvl2","url":"/unpleasant#overview","position":2},{"hierarchy":{"lvl1":"Some Unpleasant Monetarist Arithmetic","lvl2":"Overview"},"content":"This lecture builds on concepts and issues introduced in \n\nMoney Financed Government Deficits and Price Levels.\n\nThat lecture describes stationary equilibria that reveal a \n\nLaffer curve in the inflation tax rate and the associated  stationary rate of return\non currency.\n\nIn this lecture we study  a situation  in which a stationary equilibrium prevails after  date T > 0, but not before then.\n\nFor t=0, \\ldots, T-1, the money supply,  price level, and interest-bearing government debt vary along a transition path that ends at t=T.\n\nDuring this transition, the ratio of the real balances \\frac{m_{t+1}}{{p_t}} to indexed one-period  government bonds \\tilde R B_{t-1}  maturing at time t decreases each period.\n\nThis has consequences for the gross-of-interest government deficit that must be financed by printing money for times t \\geq T.\n\nThe critical money-to-bonds ratio stabilizes only at time T and afterwards.\n\nAnd the larger is T, the higher is the gross-of-interest government deficit that must be financed\nby printing money at times t \\geq T.\n\nThese outcomes are the essential finding of Sargent and Wallace’s “unpleasant monetarist arithmetic” \n\nSargent & Wallace (1981).\n\nThat lecture  described  supplies and demands for money that appear in lecture.\n\nIt also   characterized the steady state equilibrium from which we work backwards in this lecture.\n\nIn addition to learning about “unpleasant monetarist arithmetic”, in this lecture we’ll learn how to implement a \n\nfixed point algorithm for computing an initial price level.","type":"content","url":"/unpleasant#overview","position":3},{"hierarchy":{"lvl1":"Some Unpleasant Monetarist Arithmetic","lvl2":"Setup"},"type":"lvl2","url":"/unpleasant#setup","position":4},{"hierarchy":{"lvl1":"Some Unpleasant Monetarist Arithmetic","lvl2":"Setup"},"content":"Let’s start with quick reminders of the model’s components set out in \n\nMoney Financed Government Deficits and Price Levels.\n\nPlease consult that lecture for more details and Python code that we’ll also use in this lecture.\n\nFor t \\geq 1, real balances evolve according to\\frac{m_{t+1}}{p_t} - \\frac{m_{t}}{p_{t-1}} \\frac{p_{t-1}}{p_t} = g\n\norb_t - b_{t-1} R_{t-1} = g\n\nwhere\n\nb_t = \\frac{m_{t+1}}{p_t} is real balances at the end of period t\n\nR_{t-1} = \\frac{p_{t-1}}{p_t} is the gross rate of return on real balances held from t-1 to t\n\nThe demand for real balances isb_t = \\gamma_1 - \\gamma_2 R_t^{-1} .\n\nwhere \\gamma_1 > \\gamma_2 > 0.","type":"content","url":"/unpleasant#setup","position":5},{"hierarchy":{"lvl1":"Some Unpleasant Monetarist Arithmetic","lvl2":"Monetary-Fiscal Policy"},"type":"lvl2","url":"/unpleasant#monetary-fiscal-policy","position":6},{"hierarchy":{"lvl1":"Some Unpleasant Monetarist Arithmetic","lvl2":"Monetary-Fiscal Policy"},"content":"To the basic model of \n\nMoney Financed Government Deficits and Price Levels, we add inflation-indexed one-period government bonds as an additional way for the government to finance government expenditures.\n\nLet \\widetilde R > 1 be a time-invariant gross real rate of return on government one-period inflation-indexed bonds.\n\nWith this additional source of funds, the government’s budget constraint at time t \\geq 0 is nowB_t + \\frac{m_{t+1}}{p_t} = \\widetilde R B_{t-1} + \\frac{m_t}{p_t} + g\n\nJust before the beginning of time 0, the  public owns  \\check m_0 units of currency (measured in dollars)\nand \\widetilde R \\check B_{-1} units of one-period indexed bonds (measured in time 0 goods); these two quantities are initial conditions set outside the model.\n\nNotice that \\check m_0 is a nominal quantity, being measured in dollars, while\n\\widetilde R \\check B_{-1} is a real quantity, being measured in time 0 goods.","type":"content","url":"/unpleasant#monetary-fiscal-policy","position":7},{"hierarchy":{"lvl1":"Some Unpleasant Monetarist Arithmetic","lvl3":"Open market operations","lvl2":"Monetary-Fiscal Policy"},"type":"lvl3","url":"/unpleasant#open-market-operations","position":8},{"hierarchy":{"lvl1":"Some Unpleasant Monetarist Arithmetic","lvl3":"Open market operations","lvl2":"Monetary-Fiscal Policy"},"content":"At time 0, government can rearrange its portfolio of debts subject to the following constraint (on open-market operations):\\widetilde R B_{-1} + \\frac{m_0}{p_0} = \\widetilde R \\check B_{-1} + \\frac{\\check m_0}{p_0}\n\norB_{-1} - \\check B_{-1} = \\frac{1}{p_0 \\widetilde R} \\left( \\check m_0 - m_0 \\right)\n\nThis equation says that the government (e.g., the central bank) can decrease m_0 relative to\n\\check m_0 by increasing B_{-1} relative to \\check B_{-1}.\n\nThis is a version of a standard constraint on a central bank’s \n\nopen market operations in which it expands the stock of money by buying government bonds from  the public.","type":"content","url":"/unpleasant#open-market-operations","position":9},{"hierarchy":{"lvl1":"Some Unpleasant Monetarist Arithmetic","lvl2":"An open market operation at t=0"},"type":"lvl2","url":"/unpleasant#an-open-market-operation-at-t-0","position":10},{"hierarchy":{"lvl1":"Some Unpleasant Monetarist Arithmetic","lvl2":"An open market operation at t=0"},"content":"Following Sargent and Wallace \n\nSargent & Wallace (1981), we analyze consequences of a central bank policy that\nuses an open market operation to lower the price level in the face of a persistent fiscal\ndeficit that takes the form of a positive g.\n\nJust before time 0, the government chooses (m_0, B_{-1})  subject to constraint\n\n\n(6).\n\nFor t =0, 1, \\ldots, T-1,\\begin{aligned}\nB_t & = \\widetilde R B_{t-1} + g \\cr\nm_{t+1} &  = m_0 \n\\end{aligned}\n\nwhile for t \\geq T,\\begin{aligned}\nB_t & = B_{T-1} \\cr\nm_{t+1} & = m_t + p_t \\overline g\n\\end{aligned}\n\nwhere\\overline g = \\left[(\\tilde R -1) B_{T-1} +  g \\right]\n\nWe want to compute an equilibrium \\{p_t,m_t,b_t, R_t\\}_{t=0} sequence under this scheme for\nrunning monetary and fiscal policies.\n\nHere, by fiscal policy we mean the collection of actions that determine a sequence of net-of-interest government deficits \\{g_t\\}_{t=0}^\\infty that must be financed by issuing to the public  either money or interest bearing bonds.\n\nBy monetary policy or debt-management policy, we  mean the collection of actions that determine how the government divides its  portfolio of debts to the public  between interest-bearing parts (government bonds) and non-interest-bearing parts (money).\n\nBy an open market operation, we mean a government monetary policy action in which the government\n(or its delegate, say, a central bank) either buys  government bonds from the public for newly issued money, or sells  bonds to the public and withdraws the money it receives from public circulation.","type":"content","url":"/unpleasant#an-open-market-operation-at-t-0","position":11},{"hierarchy":{"lvl1":"Some Unpleasant Monetarist Arithmetic","lvl2":"Algorithm (basic idea)"},"type":"lvl2","url":"/unpleasant#algorithm-basic-idea","position":12},{"hierarchy":{"lvl1":"Some Unpleasant Monetarist Arithmetic","lvl2":"Algorithm (basic idea)"},"content":"We work backwards from t=T and first compute p_T, R_u associated with the low-inflation, low-inflation-tax-rate stationary equilibrium in \n\nInflation Rate Laffer Curves.\n\nTo start our description of our algorithm, it is useful to recall that a stationary rate of return\non currency \\bar R solves the quadratic equation-\\gamma_2 + (\\gamma_1 + \\gamma_2 - \\overline g) \\bar R - \\gamma_1 \\bar R^2 = 0\n\nQuadratic equation \n\n(10) has two roots, R_l < R_u < 1.\n\nFor reasons described at the end of \n\nMoney Financed Government Deficits and Price Levels, we select the larger root R_u.\n\nNext, we compute\\begin{aligned}\nR_T & = R_u \\cr\nb_T & = \\gamma_1 - \\gamma_2 R_u^{-1} \\cr\np_T & = \\frac{m_0}{\\gamma_1 - \\overline g - \\gamma_2 R_u^{-1}}\n\\end{aligned}\n\nWe can compute continuation sequences \\{R_t, b_t\\}_{t=T+1}^\\infty of rates of return and real balances that are associated with an equilibrium by solving equation \n\n(2) and \n\n(3) sequentially  for t \\geq 1:\\begin{aligned}\nb_t & = b_{t-1} R_{t-1} + \\overline g \\cr\nR_t^{-1} & = \\frac{\\gamma_1}{\\gamma_2} - \\gamma_2^{-1} b_t \\cr\np_t & = R_t p_{t-1} \\cr\n   m_t & = b_{t-1} p_t \n\\end{aligned}","type":"content","url":"/unpleasant#algorithm-basic-idea","position":13},{"hierarchy":{"lvl1":"Some Unpleasant Monetarist Arithmetic","lvl2":"Before time T"},"type":"lvl2","url":"/unpleasant#before-time-t","position":14},{"hierarchy":{"lvl1":"Some Unpleasant Monetarist Arithmetic","lvl2":"Before time T"},"content":"Define\\lambda \\equiv \\frac{\\gamma_2}{\\gamma_1}.\n\nOur restrictions that \\gamma_1 > \\gamma_2 > 0 imply that \\lambda \\in [0,1).\n\nWe want to compute\\begin{aligned}\np_0 &  = \\gamma_1^{-1} \\left[ \\sum_{j=0}^\\infty \\lambda^j m_{j} \\right] \\cr\n& = \\gamma_1^{-1} \\left[ \\sum_{j=0}^{T-1} \\lambda^j m_{0} + \\sum_{j=T}^\\infty \\lambda^j m_{1+j} \\right]\n\\end{aligned}\n\nThus,\\begin{aligned}\np_0 & = \\gamma_1^{-1} m_0  \\left\\{ \\frac{1 - \\lambda^T}{1-\\lambda} +  \\frac{\\lambda^T}{R_u-\\lambda}   \\right\\} \\cr\np_1 & = \\gamma_1^{-1} m_0  \\left\\{ \\frac{1 - \\lambda^{T-1}}{1-\\lambda} +  \\frac{\\lambda^{T-1}}{R_u-\\lambda}   \\right\\} \\cr\n\\quad \\vdots  & \\quad \\quad \\vdots \\cr\np_{T-1} & = \\gamma_1^{-1} m_0  \\left\\{ \\frac{1 - \\lambda}{1-\\lambda} +  \\frac{\\lambda}{R_u-\\lambda}   \\right\\}  \\cr\np_T & = \\gamma_1^{-1} m_0  \\left\\{\\frac{1}{R_u-\\lambda}   \\right\\}\n\\end{aligned}\n\nWe can implement  the preceding formulas by iterating onp_t = \\gamma_1^{-1} m_0 + \\lambda p_{t+1}, \\quad t = T-1, T-2, \\ldots, 0\n\nstarting fromp_T =   \\frac{m_0}{\\gamma_1 - \\overline g - \\gamma_2 R_u^{-1}}  = \\gamma_1^{-1} m_0  \\left\\{\\frac{1}{R_u-\\lambda} \\right\\}\n\nWe can verify the equivalence of the two formulas on the right sides of \n\n(17) by recalling that\nR_u is a root of the quadratic equation \n\n(10) that determines steady state rates of return on currency.","type":"content","url":"/unpleasant#before-time-t","position":15},{"hierarchy":{"lvl1":"Some Unpleasant Monetarist Arithmetic","lvl2":"Algorithm (pseudo code)"},"type":"lvl2","url":"/unpleasant#algorithm-pseudo-code","position":16},{"hierarchy":{"lvl1":"Some Unpleasant Monetarist Arithmetic","lvl2":"Algorithm (pseudo code)"},"content":"Now let’s describe a computational algorithm in more detail in the form of a description\nthat constitutes pseudo code because it approaches a set of instructions we could provide to a\nPython coder.\n\nTo compute an equilibrium, we deploy the following algorithm.\n\nGiven parameters include g, \\check m_0, \\check B_{-1}, \\widetilde R >1, T .\n\nWe define a mapping from p_0 to \\widehat p_0 as follows.\n\nSet m_0 and then compute B_{-1} to satisfy the constraint on time 0 open market operationsB_{-1}- \\check B_{-1}  = \\frac{\\widetilde R}{p_0} \\left( \\check m_0 - m_0 \\right)\n\nCompute B_{T-1} fromB_{T-1} = \\widetilde R^T B_{-1} + \\left( \\frac{1 - \\widetilde R^T}{1-\\widetilde R} \\right) g\n\nCompute\\overline g = g + \\left[ \\tilde R - 1\\right] B_{T-1}\n\nCompute R_u, p_T from formulas \n\n(10)  and \n\n(11) above\n\nCompute a new estimate of p_0, call it \\widehat p_0, from equation \n\n(15) above\n\nNote that the preceding steps define a mapping\\widehat p_0 = {\\mathcal S}(p_0)\n\nWe seek a fixed point of {\\mathcal S}, i.e., a solution of p_0 = {\\mathcal S}(p_0).\n\nCompute a fixed point by iterating to convergence on the relaxation algorithmp_{0,j+1} = (1-\\theta)  {\\mathcal S}(p_{0,j})  + \\theta  p_{0,j},\n\nwhere \\theta \\in [0,1) is a relaxation parameter.","type":"content","url":"/unpleasant#algorithm-pseudo-code","position":17},{"hierarchy":{"lvl1":"Some Unpleasant Monetarist Arithmetic","lvl2":"Example Calculations"},"type":"lvl2","url":"/unpleasant#example-calculations","position":18},{"hierarchy":{"lvl1":"Some Unpleasant Monetarist Arithmetic","lvl2":"Example Calculations"},"content":"We’ll set parameters of the model so that the steady state after time T is initially the same\nas in \n\nInflation Rate Laffer Curves\n\nIn particular, we set \\gamma_1=100, \\gamma_2 =50, g=3.0.  We set m_0 = 100 in that lecture,\nbut now the counterpart will be M_T, which is endogenous.\n\nAs for new parameters, we’ll set \\tilde R = 1.01, \\check B_{-1} = 0, \\check m_0 = 105, T = 5.\n\nWe’ll study a “small” open market operation by setting m_0 = 100.\n\nThese parameter settings mean that just before time 0, the “central bank” sells the public bonds in exchange for \\check m_0 - m_0 = 5 units of currency.\n\nThat leaves the public with less currency but more government interest-bearing bonds.\n\nSince the public has less currency (its supply has diminished) it is plausible to anticipate that the price level at time 0 will be driven downward.\n\nBut that is not the end of the story, because this open market operation at time 0 has consequences for future settings of m_{t+1} and the gross-of-interest government deficit \\bar g_t.\n\nLet’s start with some imports:\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom collections import namedtuple\n\nNow let’s dive in and implement our pseudo code in Python.\n\n# Create a namedtuple that contains parameters\nMoneySupplyModel = namedtuple(\"MoneySupplyModel\", \n                              [\"γ1\", \"γ2\", \"g\",\n                               \"R_tilde\", \"m0_check\", \"Bm1_check\",\n                               \"T\"])\n\ndef create_model(γ1=100, γ2=50, g=3.0,\n                 R_tilde=1.01,\n                 Bm1_check=0, m0_check=105,\n                 T=5):\n    \n    return MoneySupplyModel(γ1=γ1, γ2=γ2, g=g,\n                            R_tilde=R_tilde,\n                            m0_check=m0_check, Bm1_check=Bm1_check,\n                            T=T)\n\nmsm = create_model()\n\ndef S(p0, m0, model):\n\n    # unpack parameters\n    γ1, γ2, g = model.γ1, model.γ2, model.g\n    R_tilde = model.R_tilde\n    m0_check, Bm1_check = model.m0_check, model.Bm1_check\n    T = model.T\n\n    # open market operation\n    Bm1 = 1 / (p0 * R_tilde) * (m0_check - m0) + Bm1_check\n\n    # compute B_{T-1}\n    BTm1 = R_tilde ** T * Bm1 + ((1 - R_tilde ** T) / (1 - R_tilde)) * g\n\n    # compute g bar\n    g_bar = g + (R_tilde - 1) * BTm1\n\n    # solve the quadratic equation\n    Ru = np.roots((-γ1, γ1 + γ2 - g_bar, -γ2)).max()\n\n    # compute p0\n    λ = γ2 / γ1\n    p0_new = (1 / γ1) * m0 * ((1 - λ ** T) / (1 - λ) + λ ** T / (Ru - λ))\n\n    return p0_new\n\ndef compute_fixed_point(m0, p0_guess, model, θ=0.5, tol=1e-6):\n\n    p0 = p0_guess\n    error = tol + 1\n\n    while error > tol:\n        p0_next = (1 - θ) * S(p0, m0, model) + θ * p0\n\n        error = np.abs(p0_next - p0)\n        p0 = p0_next\n\n    return p0\n\nLet’s look at how  price level p_0  in the stationary  R_u equilibrium  depends on the initial\nmoney supply m_0.\n\nNotice that the slope of p_0 as a function of m_0 is constant.\n\nThis outcome indicates that our model verifies a quantity theory of money outcome,\nsomething that Sargent and Wallace \n\nSargent & Wallace (1981) purposefully built into their model to justify\nthe adjective monetarist in their title.\n\nm0_arr = np.arange(10, 110, 10)\n\nplt.plot(m0_arr, [compute_fixed_point(m0, 1, msm) for m0 in m0_arr])\n\nplt.ylabel('$p_0$')\nplt.xlabel('$m_0$')\n\nplt.show()\n\nNow let’s write and implement code that lets us experiment with the time 0 open market operation described earlier.\n\ndef simulate(m0, model, length=15, p0_guess=1):\n\n    # unpack parameters\n    γ1, γ2, g = model.γ1, model.γ2, model.g\n    R_tilde = model.R_tilde\n    m0_check, Bm1_check = model.m0_check, model.Bm1_check\n    T = model.T\n\n    # (pt, mt, bt, Rt)\n    paths = np.empty((4, length))\n\n    # open market operation\n    p0 = compute_fixed_point(m0, 1, model)\n    Bm1 = 1 / (p0 * R_tilde) * (m0_check - m0) + Bm1_check\n    BTm1 = R_tilde ** T * Bm1 + ((1 - R_tilde ** T) / (1 - R_tilde)) * g\n    g_bar = g + (R_tilde - 1) * BTm1\n    Ru = np.roots((-γ1, γ1 + γ2 - g_bar, -γ2)).max()\n\n    λ = γ2 / γ1\n\n    # t = 0\n    paths[0, 0] = p0\n    paths[1, 0] = m0\n\n    # 1 <= t <= T\n    for t in range(1, T+1, 1):\n        paths[0, t] = (1 / γ1) * m0 * \\\n                      ((1 - λ ** (T - t)) / (1 - λ)\n                       + (λ ** (T - t) / (Ru - λ)))\n        paths[1, t] = m0\n\n    # t > T\n    for t in range(T+1, length):\n        paths[0, t] = paths[0, t-1] / Ru\n        paths[1, t] = paths[1, t-1] + paths[0, t] * g_bar\n\n    # Rt = pt / pt+1\n    paths[3, :T] = paths[0, :T] / paths[0, 1:T+1]\n    paths[3, T:] = Ru\n\n    # bt = γ1 - γ2 / Rt\n    paths[2, :] = γ1 - γ2 / paths[3, :]\n\n    return paths\n\ndef plot_path(m0_arr, model, length=15):\n\n    fig, axs = plt.subplots(2, 2, figsize=(8, 5))\n    titles = ['$p_t$', '$m_t$', '$b_t$', '$R_t$']\n    \n    for m0 in m0_arr:\n        paths = simulate(m0, model, length=length)\n        for i, ax in enumerate(axs.flat):\n            ax.plot(paths[i])\n            ax.set_title(titles[i])\n    \n    axs[0, 1].hlines(model.m0_check, 0, length, color='r', linestyle='--')\n    axs[0, 1].text(length * 0.8, model.m0_check * 0.9, r'$\\check{m}_0$')\n    plt.show()\n\nplot_path([80, 100], msm)\n\n\n\nFigure 1:Unpleasant Arithmetic\n\nFig. 1 summarizes outcomes of two experiments that convey messages of Sargent and Wallace \n\nSargent & Wallace (1981).\n\nAn open market operation that reduces the supply of money at time t=0 reduces  the price level at time t=0\n\nThe lower is the post-open-market-operation money supply at time 0, lower is the price level at time 0.\n\nAn open  market operation that reduces the post open market operation money supply at time 0 also lowers the rate of return on money R_u at times t \\geq T because it brings  a higher gross of interest government deficit that must be financed by printing money (i.e., levying an inflation tax) at time t \\geq T.\n\nR is important in the context of maintaining monetary stability and addressing the consequences of increased inflation due to government deficits. Thus, a larger R might be chosen to mitigate the negative impacts on the real rate of return caused by inflation.","type":"content","url":"/unpleasant#example-calculations","position":19},{"hierarchy":{"lvl1":"References"},"type":"lvl1","url":"/zreferences","position":0},{"hierarchy":{"lvl1":"References"},"content":"","type":"content","url":"/zreferences","position":1}]}